
Sujan, M., Pool, R. and Salmon, P. (2022) ‘Eight human factors and ergonomics principles for healthcare artificial intelligence’, _BMJ health & care informatics_, 29(1), p. e100516. Available at: https://doi.org/10.1136/bmjhci-2021-100516.

*"Many approaches to explainable AI simply focus on providing detailed accounts of how an algorithm operates, but for explanations to be useful they ==need to be able to accommodate and be responsive to the needs of different users across a range of situations==,== for example, a patient might benefit from a different type of explanation compared with a healthcare professional. In this sense, rather than providing a description of a specific decision, ==explanation might be better regarded as a social process and a dialogue that allows the user to explore AI decision- making by interacting with the AI and by interrogating AI decisions==."*

---

McDermid, J.A. _et al._ (2021) ‘Artificial intelligence explainability: the technical and ethical dimensions’, _Philosophical transactions. Series A, Mathematical, physical, and engineering sciences_, 379(2207), p. 20200363. Available at: https://doi.org/10.1098/rsta.2020.0363.

Hussain, M. _et al._ (2024) ‘Development and translation of human-AI interaction models into working prototypes for clinical decision-making’, in _Designing Interactive Systems Conference_. _DIS ’24: Designing Interactive Systems Conference_, New York, NY, USA: ACM, pp. 1607–1619. Available at: https://doi.org/10.1145/3643834.3660697.

Ashmore, R., Calinescu, R. and Paterson, C. (2021) ‘Assuring the Machine Learning Lifecycle: Desiderata, Methods, and Challenges’, _ACM computing surveys_, 54(5), pp. 1–39. Available at: https://doi.org/10.1145/3453444.

Hendrycks, D. _et al._ (2021) ‘Unsolved Problems in ML Safety’, _arXiv [cs.LG]_. Available at: http://arxiv.org/abs/2109.13916.

---

Gunning, D. and Aha, D.W. (2019) ‘DARPA’s explainable artificial intelligence program’, _AI magazine_, 40(2), pp. 44–58. Available at: https://doi.org/10.1609/aimag.v40i2.2850.

Herm, L.-V. _et al._ (2023) ‘Stop ordering machine learning algorithms by their explainability! A user-centered investigation of performance and explainability’, _International journal of information management_, 69(102538), p. 102538. Available at: https://doi.org/10.1016/j.ijinfomgt.2022.102538.

Brennen, A. (2020) ‘What do people really want when they say they want “explainable AI?” we asked 60 stakeholders’, in _Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems_. _CHI ’20: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–7. Available at: https://doi.org/10.1145/3334480.3383047.

Matarese, M., Rea, F. and Sciutti, A. (2021) ‘A user-centred framework for Explainable Artificial Intelligence in human-robot interaction’, _arXiv [cs.AI]_. Available at: https://www.semanticscholar.org/paper/A-User-Centred-Framework-for-Explainable-Artificial-Matarese-Rea/06ed0fe2179d1a19fb4e8f2193bb63768349502e.

Gade, K. _et al._ (2019) ‘Explainable AI in Industry’, in _Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_. _KDD ’19: The 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, New York, NY, USA: ACM. Available at: https://doi.org/10.1145/3292500.3332281.



---
Endsley, M.R. _et al._ (2022) ‘Special issue on human-AI teaming and special issue on AI in healthcare’, _Journal of cognitive engineering and decision making_, 16(4), pp. 179–181. Available at: https://doi.org/10.1177/15553434221133288.

Zhang, R. _et al._ (2021) ‘“An Ideal Human”: Expectations of AI Teammates in Human-AI Teaming’, _Proceedings of the ACM on human-computer interaction_, 4(CSCW3), pp. 1–25. Available at: https://doi.org/10.1145/3432945.

Caldwell, S. _et al._ (2022) ‘An Agile new research framework for hybrid human-AI teaming: Trust, transparency, and transferability’, _ACM transactions on interactive intelligent systems_, 12(3), pp. 1–36. Available at: https://doi.org/10.1145/3514257.

Berretta, S. _et al._ (2023) ‘Defining human-AI teaming the human-centered way: a scoping review and network analysis’, _Frontiers in artificial intelligence_, 6, p. 1250725. Available at: https://doi.org/10.3389/frai.2023.1250725.

Ulfert, A.-S. _et al._ (2024) ‘Shaping a multidisciplinary understanding of team trust in human-AI teams: a theoretical framework’, _European journal of work and organizational psychology_, 33(2), pp. 158–171. Available at: https://doi.org/10.1080/1359432x.2023.2200172.

Gao, Q. _et al._ (2023) ‘Agent Teaming Situation Awareness (ATSA): A situation awareness framework for human-AI teaming’, _arXiv [cs.AI]_. Available at: http://arxiv.org/abs/2308.16785.

Hauptman, A.I. _et al._ (2023) ‘Adapt and overcome: Perceptions of adaptive autonomous agents for human-AI teaming’, _Computers in human behavior_, 138, p. 107451. Available at: https://doi.org/10.1016/j.chb.2022.107451.

O’Neill, T. _et al._ (2020) ‘Human-autonomy teaming: A review and analysis of the empirical literature’, _Human factors_, 64(5), pp. 904–938. Available at: https://doi.org/10.1177/0018720820960865.

---

Rochi, M. (2023) ‘Technology paternalism and smart products: Review, synthesis, and research agenda’, _Technological forecasting and social change_, 192(122557), p. 122557. Available at: https://doi.org/10.1016/j.techfore.2023.122557.

Rochi, M. _et al._ (2024) ‘Technology paternalism: Development and validation of a measurement scale’, _Psychology & marketing_, 41(5), pp. 1172–1188. Available at: https://doi.org/10.1002/mar.21971.

---

Ghajargar, M. _et al._ (2021) ‘From “Explainable AI” to “Graspable AI”’, in _TEI 2021 - Proceedings of the 15th International Conference on Tangible, Embedded, and Embodied Interaction_. Available at: https://doi.org/10.1145/3430524.3442704.

Clemmensen, T. (2021) ‘Socio-Technical HCI Design in a Wider Context’, in _Human Work Interaction Design_. Switzerland: Springer International Publishing AG (Human–Computer Interaction Series), pp. 267–280. Available at: https://doi.org/10.1007/978-3-030-71796-4_10.

Wang, D. _et al._ (2019) ‘Designing Theory-Driven User-Centric Explainable AI’, _International Conference on Human Factors in Computing Systems_ [Preprint]. Available at: https://doi.org/10.1145/3290605.3300831.

Arrieta, A.B. _et al._ (2019) ‘Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI’, _An international journal on information fusion_ [Preprint]. Available at: https://doi.org/10.1016/j.inffus.2019.12.012.

Ehsan, U. and Riedl, M.O. (2020) ‘Human-centered Explainable AI: Towards a Reflective Sociotechnical Approach’, _Lecture notes in computer science_ [Preprint]. Available at: https://doi.org/10.1007/978-3-030-60117-1_33.

Liao, Q.V., Gruen, D.M. and Miller, S. (2020) ‘Questioning the AI: Informing Design Practices for Explainable AI User Experiences’, _International Conference on Human Factors in Computing Systems_ [Preprint]. Available at: https://doi.org/10.1145/3313831.3376590.

Zhang, Y., Liao, Q.V. and Bellamy, R.K.E. (2020) ‘Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making’, _Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency_ [Preprint]. Available at: https://doi.org/10.1145/3351095.3372852.

Chromik, M. _et al._ (2021) ‘I Think I Get Your Point, AI! The Illusion of Explanatory Depth in Explainable AI’, _International Conference on Intelligent Systems Design and Applications_ [Preprint]. Available at: https://doi.org/10.1145/3397481.3450644.

Eiband, M., Buschek, D. and Hussmann, H. (2021) ‘How to Support Users in ==Understanding Intelligent Systems==? Structuring the Discussion’, _International Conference on Intelligent Systems Design and Applications_ [Preprint]. Available at: https://doi.org/10.1145/3397481.3450694.

Bertrand, A. _et al._ (2022) ‘How cognitive biases affect ==XAI-assisted decision-making==: A systematic review’, in _Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society_. _AIES ’22: AAAI/ACM Conference on AI, Ethics, and Society_, New York, NY, USA: ACM. Available at: https://doi.org/10.1145/3514094.3534164.

Kim, S.S.Y. _et al._ (2022) ‘“Help Me Help the AI”: Understanding How Explainability Can Support Human-AI Interaction’, _International Conference on Human Factors in Computing Systems_ [Preprint]. Available at: https://doi.org/10.48550/arxiv.2210.03735.

Rong, Y. _et al._ (2022) ‘Towards Human-centered Explainable AI: ==User Studies== for Model Explanations’, _ArXiv_ [Preprint]. Available at: https://doi.org/10.48550/arxiv.2210.11584.

Chen, V. _et al._ (2023) ‘Understanding the Role of Human Intuition on Reliance in Human-AI ==Decision-Making with Explanations==’, _Proceedings of the ACM on human-computer interaction_ [Preprint]. Available at: https://doi.org/10.48550/arxiv.2301.07255.

Schmude, T. _et al._ (2024) ‘Information That Matters: ==Exploring Information Needs== of ==People Affected== by Algorithmic Decisions’, _arXiv. org_ [Preprint]. Available at: https://doi.org/10.48550/arxiv.2401.13324.

Corti, L. _et al._ (2024) ‘“it is a moving process”: Understanding the evolution of ==explainability needs== of clinicians in pulmonary medicine’, in _Proceedings of the CHI Conference on Human Factors in Computing Systems_. _CHI ’24: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–21. Available at: https://doi.org/10.1145/3613904.3642551.

Bobek, S. _et al._ (2024) ‘User-centric ==evaluation of explainability== of AI with and for humans: a comprehensive empirical study’, _arXiv. org_ [Preprint]. Available at: https://doi.org/10.48550/arxiv.2410.15952.