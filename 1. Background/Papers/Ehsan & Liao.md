Ehsan, U. and Riedl, M.O. (2021) ‘Explainability pitfalls: Beyond dark patterns in explainable AI’, _Patterns of prejudice_ [Preprint]. Available at: https://doi.org/10.1016/j.patter.2024.100971.

Liao, Q. _et al._ (2021) ‘Human-Centered Explainable AI (XAI): From Algorithms to User Experiences’, _arXiv. org_ [Preprint].

Dhanorkar, S. _et al._ (2021) ‘Who needs to know what, when?: Broadening the Explainable AI (XAI) Design Space by Looking at Explanations Across the AI Lifecycle’, _Conference on Designing Interactive Systems_ [Preprint]. Available at: https://doi.org/10.1145/3461778.3462131.  
  
Liao, Q. _et al._ (2021) ‘Human-Centered Explainable AI (XAI): From Algorithms to User Experiences’, _arXiv. org_ [Preprint].

Ehsan, U., Liao, Q.V., _et al._ (2021) ‘Expanding Explainability: Towards Social Transparency in AI systems’, in _Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems_. _CHI ’21: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–19. Available at: https://doi.org/10.1145/3411764.3445188.  
  
Ehsan, U., Wintersberger, P., _et al._ (2021) ‘==Operationalizing human-centered perspectives in explainable AI==’, in _Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems_. _CHI ’21: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–6. Available at: https://doi.org/10.1145/3411763.3441342.  
  
Ehsan, U., Passi, S., _et al._ (2021) ‘==The who in XAI: How AI background shapes perceptions of AI explanations==’, _arXiv [cs.HC]_. Available at: http://arxiv.org/abs/2107.13509.  
  
Ehsan, U. _et al._ (2022) ‘Human-centered explainable AI (HCXAI): Beyond opening the black-box of AI’, in _CHI Conference on Human Factors in Computing Systems Extended Abstracts_. _CHI ’22: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–7. Available at: https://doi.org/10.1145/3491101.3503727.  

Ehsan, U. _et al._ (2023) ‘==Charting the Sociotechnical Gap in Explainable AI: A Framework to Address the Gap in XAI==’, _Proceedings of the ACM on human-computer interaction_ [Preprint]. Available at: https://doi.org/10.1145/3579467.

Ehsan, U., Liao, Q.V., _et al._ (2024) ‘==Seamful XAI: Operationalizing seamful design in Explainable AI’==, _Proceedings of the ACM on human-computer interaction_, 8(CSCW1), pp. 1–29. Available at: https://doi.org/10.1145/3637396.  
  
Ehsan, U., Passi, S., _et al._ (2024) ‘==The who in XAI: How AI background shapes perceptions of AI explanations==’, in _Proceedings of the CHI Conference on Human Factors in Computing Systems_. _CHI ’24: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–32. Available at: https://doi.org/10.1145/3613904.3642474.  


---

Wang, L., Liu, Y. and Goel, A.K. (2025) ‘==“good” XAI design: For what? In which ways?’==, in _Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems_. _CHI EA ’25: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–13. Available at: https://doi.org/10.1145/3706599.3720036.

Kim, S.S.Y. _et al._ (2025) ‘==Fostering appropriate reliance on large language models: The role of explanations, sources, and inconsistencies==’, _arXiv [cs.HC]_. Available at: http://arxiv.org/abs/2502.08554.  
  
Lai, V. _et al._ (2023) ‘==Selective explanations: Leveraging human input to align explainable AI’==, _Proceedings of the ACM on human-computer interaction_, 7(CSCW2), pp. 1–35. Available at: https://doi.org/10.1145/3610206.  
  
Liao, Q.V. and Wortman Vaughan, J. (2024) ‘==AI transparency in the age of LLMs: A human-centered research roadmap’==, _Special Issue 5: Grappling With the Generative AI Revolution_, (Special5). Available at: https://doi.org/10.1162/99608f92.8036d03b.  

Chen, V. _et al._ (2023) ‘==Understanding the role of human intuition on reliance in human-AI decision-making with explanations==’, _Proceedings of the ACM on human-computer interaction_, 7(CSCW2), pp. 1–32. Available at: https://doi.org/10.1145/3610219.  
   
Fan, M. _et al._ (2022) ‘==Human-AI collaboration for UX evaluation: Effects of explanation and synchronization==’, _Proceedings of the ACM on human-computer interaction_, 6(CSCW1), pp. 1–32. Available at: https://doi.org/10.1145/3512943.  

Boyd-Graber, J. _et al._ (2022) ‘==Human-centered evaluation of explanations==’, in M. Ballesteros, Y. Tsvetkov, and C.O. Alm (eds) 

Zhang, Y., Liao, Q.V. and Bellamy, R.K.E. (2020b) ‘==Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making==’, in _Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency_. _FAT* ’20: Conference on Fairness, Accountability, and Transparency_, New York, NY, USA: ACM, pp. 295–305. Available at: https://doi.org/10.1145/3351095.3372852.

Arya, V. _et al._ (2019) ‘One explanation does not fit all: ==a toolkit and taxonomy of AI explainability techniques ==(2019)’. Available at: http://arxiv.org/abs/1909.03012. 