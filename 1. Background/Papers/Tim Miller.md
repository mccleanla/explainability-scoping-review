
seminal paper on explanation:
Miller, T. (2019) ‘Explanation in artificial intelligence: Insights from the social sciences’, _Artificial intelligence_, 267, pp. 1–38. Available at: https://doi.org/10.1016/j.artint.2018.07.007.



then works such as:
- - Payrovnaziri, S.N. _et al._ (2020) ‘==Explainable artificial intelligence== models using real-world electronic health record data: a systematic scoping review’, _Journal of the American Medical Informatics Association: JAMIA_, 27(7), pp. 1173–1185. Available at: https://doi.org/10.1093/jamia/ocaa053.
-
- Miller, T. (2023) ‘Explainable AI is Dead, Long Live Explainable AI!: ==Hypothesis-driven Decision Support using Evaluative AI’==, in _2023 ACM Conference on Fairness Accountability and Transparency_. _FAccT ’23: the 2023 ACM Conference on Fairness, Accountability, and Transparency_, New York, NY, USA: ACM, pp. 333–342. Available at: https://doi.org/10.1145/3593013.3594001.

- Vered, M. _et al._ (2023) ‘The ==effects of explanations== on automation bias’, _Artificial intelligence_, 322(103952), p. 103952. Available at: https://doi.org/10.1016/j.artint.2023.103952.

- Singh, R. _et al._ (2023) ‘==Directive explanations for actionable explainability== in machine learning applications’, _ACM transactions on interactive intelligent systems_ [Preprint]. Available at: https://doi.org/10.1145/3579363.

- Hoffman, R.R. _et al._ (2023) ‘==Increasing the value of XAI for users: A psychological perspective==’, _KI - Künstliche Intelligenz_, 37(2–4), pp. 237–247. Available at: https://doi.org/10.1007/s13218-023-00806-9.

