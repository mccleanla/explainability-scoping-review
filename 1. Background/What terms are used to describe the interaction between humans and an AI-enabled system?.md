
A Bach, T. _et al._ (2023) ‘Unpacking human-AI interaction in safety-critical industries: A systematic literature review’, _arXiv [cs.HC]_. Available at: http://arxiv.org/abs/2310.03392.


A scoping study published in 2023:

seven of 24 articles used both “interaction” and “collaboration,” showing that similar terms are likely being used interchangeably.

In addition to the terms “interaction,” “collaboration,” “handovers,” and “hand-offs” that we found in this review, the broader literature contains other similar terms to describe HAII such as “human-AI teaming [51],” “human-AI cooperation” [107], “human-AI symbiosis” [108], “human-AI coordination” [109], and “human-AI complementarity” [110]. 

All these similar terms may or may not refer to the same thing or have overlapping meanings. Alternatively, the same term may refer to completely different topics. This divergence of terms makes it difficult to look to the research to improve HAII. The term HAII is often associated exclusively with user interface (UI) design [111], [112]. Whereas UI design is a significant field that enables users and AI-enabled systems


![[Pasted image 20250527193314.png]]

## explainability and interpretability

- In the literature, these terms have been used both interchangeably [121] and given explicitly different definitions [122]

explainability and interpretability are both part of ensuring that miscommunication is minimized between the AIenabled system’s explanation of its rationale and what the users understand about its rationale [122].
- Explainability means that the rationale behind an AI-enabled system’s decision is being explained to users in the most efficient and effective manner at the right time. 
- Interpretability here means that users can understand what is being explained correctly, accurately, and in a timely manner

**And is this different to presenting AI output?**

Presenting AI output to users can be done in a specific manner and time point as desired by users.  The difference between AI output and explainability and interpretability is that 
- the former focuses on how AI output is delivered and explained to users, 
- latter focuses on explaining the thinking process (the rationale) prior to producing an output. 
- They are both focused on closing the gap between what is being explained to users and what they understand. 
- In other words, minimizing miscommunication and misinterpretation.