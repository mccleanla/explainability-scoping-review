

Miller, T. (2019) ‘Explanation in artificial intelligence: Insights from the social sciences’, _Artificial intelligence_, 267, pp. 1–38. Available at: https://doi.org/10.1016/j.artint.2018.07.007.

A Bach, T. _et al._ (2023) ‘Unpacking human-AI interaction in safety-critical industries: A systematic literature review’, _arXiv [cs.HC]_. Available at: http://arxiv.org/abs/2310.03392.

Droste, J. _et al._ (2025) ‘Framing what can be explained - an operational taxonomy for explainability needs’, _Requirements Engineering_ [Preprint]. Available at: https://doi.org/10.1007/s00766-025-00440-x.

Hoffman, R.R. _et al._ (2023) ‘Explainable AI: roles and stakeholders, desirements and challenges’, _Frontiers Comput. Sci._ [Preprint]. Available at: https://doi.org/10.3389/fcomp.2023.1117848.

Ghassemi, M., Oakden-Rayner, L. and Beam, A.L. (2021) ‘The false hope of current approaches to explainable artificial intelligence in health care’, _The Lancet. Digital health_, 3(11), pp. e745–e750. Available at: https://doi.org/10.1016/S2589-7500(21)00208-9.

---

Yeo, W.J. _et al._ (2025) ‘A comprehensive review on ==financial explainable AI’==, _Artificial intelligence review_, 58(6). Available at: https://doi.org/10.1007/s10462-024-11077-7.

Černevičienė, J. and Kabašinskas, A. (2024) ‘==Explainable artificial intelligence (XAI) in finance==: a systematic literature review’, _Artificial intelligence review_, 57(8). Available at: https://doi.org/10.1007/s10462-024-10854-8.

Klein, T. and Walther, T. (2024) ‘Advances in explainable artificial intelligence (xAI) in finance’, _Finance research letters_, 70(106358), p. 106358. Available at: https://doi.org/10.1016/j.frl.2024.106358.

Li, X. _et al._ (2023) ‘Artificial intelligence applications in finance: a survey’, _Journal of management analytics_, 10(4), pp. 676–692. Available at: https://doi.org/10.1080/23270012.2023.2244503.

Gregory, G. and Vito, L. (2024) ‘ChatGPT: A canary in the coal mine or a parrot in the echo chamber? Detecting fraud with LLM: The case of FTX’, _Finance research letters_, 70(106349), p. 106349. Available at: https://doi.org/10.1016/j.frl.2024.106349.

---


Payrovnaziri, S.N. _et al._ (2020) ‘==Explainable artificial intelligence== models using real-world electronic health record data: a systematic scoping review’, _Journal of the American Medical Informatics Association: JAMIA_, 27(7), pp. 1173–1185. Available at: https://doi.org/10.1093/jamia/ocaa053.

Hoffman, R.R., Miller, T. and Clancey, W.J. (2022) ‘Psychology and AI at a crossroads: How might complex systems explain themselves?’, _The American journal of psychology_, 135(4), pp. 365–378. Available at: https://doi.org/10.5406/19398298.135.4.01.


 Miller, T. (2023) ‘Explainable AI is Dead, Long Live Explainable AI!: ==Hypothesis-driven Decision Support using Evaluative AI’==, in _2023 ACM Conference on Fairness Accountability and Transparency_. _FAccT ’23: the 2023 ACM Conference on Fairness, Accountability, and Transparency_, New York, NY, USA: ACM, pp. 333–342. Available at: https://doi.org/10.1145/3593013.3594001.

Vered, M. _et al._ (2023) ‘The ==effects of explanations== on automation bias’, _Artificial intelligence_, 322(103952), p. 103952. Available at: https://doi.org/10.1016/j.artint.2023.103952.

Singh, R. _et al._ (2023) ‘==Directive explanations for actionable explainability== in machine learning applications’, _ACM transactions on interactive intelligent systems_ [Preprint]. Available at: https://doi.org/10.1145/3579363.

Hoffman, R.R. _et al._ (2023) ‘==Increasing the value of XAI for users: A psychological perspective==’, _KI - Künstliche Intelligenz_, 37(2–4), pp. 237–247. Available at: https://doi.org/10.1007/s13218-023-00806-9.

Sujan, M., Pool, R. and Salmon, P. (2022) ‘Eight human factors and ergonomics principles for healthcare artificial intelligence’, _BMJ health & care informatics_, 29(1), p. e100516. Available at: https://doi.org/10.1136/bmjhci-2021-100516.

Venditti, R. _et al._ (2025) ‘Construal Level Theory (CLT) for designing explanation interfaces in operational contexts’, in _AHFE International_. _13th International Conference on Human Interaction & Emerging Technologies: Artificial Intelligence & Future Applications_, AHFE International. Available at: https://doi.org/10.54941/ahfe1005918.

Ehsan, U. and Riedl, M.O. (2021) ‘Explainability pitfalls: Beyond dark patterns in explainable AI’, _Patterns of prejudice_ [Preprint]. Available at: https://doi.org/10.1016/j.patter.2024.100971.

Liao, Q. _et al._ (2021) ‘Human-Centered Explainable AI (XAI): From Algorithms to User Experiences’, _arXiv. org_ [Preprint].

Dhanorkar, S. _et al._ (2021) ‘Who needs to know what, when?: Broadening the Explainable AI (XAI) Design Space by Looking at Explanations Across the AI Lifecycle’, _Conference on Designing Interactive Systems_ [Preprint]. Available at: https://doi.org/10.1145/3461778.3462131.  
  
Liao, Q. _et al._ (2021) ‘Human-Centered Explainable AI (XAI): From Algorithms to User Experiences’, _arXiv. org_ [Preprint].

Ehsan, U., Liao, Q.V., _et al._ (2021) ‘Expanding Explainability: Towards Social Transparency in AI systems’, in _Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems_. _CHI ’21: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–19. Available at: https://doi.org/10.1145/3411764.3445188.  
  
Ehsan, U., Wintersberger, P., _et al._ (2021) ‘==Operationalizing human-centered perspectives in explainable AI==’, in _Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems_. _CHI ’21: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–6. Available at: https://doi.org/10.1145/3411763.3441342.  
  
Ehsan, U., Passi, S., _et al._ (2021) ‘==The who in XAI: How AI background shapes perceptions of AI explanations==’, _arXiv [cs.HC]_. Available at: http://arxiv.org/abs/2107.13509.  
  
Ehsan, U. _et al._ (2022) ‘Human-centered explainable AI (HCXAI): Beyond opening the black-box of AI’, in _CHI Conference on Human Factors in Computing Systems Extended Abstracts_. _CHI ’22: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–7. Available at: https://doi.org/10.1145/3491101.3503727.  

Ehsan, U. _et al._ (2023) ‘==Charting the Sociotechnical Gap in Explainable AI: A Framework to Address the Gap in XAI==’, _Proceedings of the ACM on human-computer interaction_ [Preprint]. Available at: https://doi.org/10.1145/3579467.

Ehsan, U., Liao, Q.V., _et al._ (2024) ‘==Seamful XAI: Operationalizing seamful design in Explainable AI’==, _Proceedings of the ACM on human-computer interaction_, 8(CSCW1), pp. 1–29. Available at: https://doi.org/10.1145/3637396.  
  
Ehsan, U., Passi, S., _et al._ (2024) ‘==The who in XAI: How AI background shapes perceptions of AI explanations==’, in _Proceedings of the CHI Conference on Human Factors in Computing Systems_. _CHI ’24: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–32. Available at: https://doi.org/10.1145/3613904.3642474.  

Wang, L., Liu, Y. and Goel, A.K. (2025) ‘==“good” XAI design: For what? In which ways?’==, in _Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems_. _CHI EA ’25: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–13. Available at: https://doi.org/10.1145/3706599.3720036.

Kim, S.S.Y. _et al._ (2025) ‘==Fostering appropriate reliance on large language models: The role of explanations, sources, and inconsistencies==’, _arXiv [cs.HC]_. Available at: http://arxiv.org/abs/2502.08554.  
  
Lai, V. _et al._ (2023) ‘==Selective explanations: Leveraging human input to align explainable AI’==, _Proceedings of the ACM on human-computer interaction_, 7(CSCW2), pp. 1–35. Available at: https://doi.org/10.1145/3610206.  
  
Liao, Q.V. and Wortman Vaughan, J. (2024) ‘==AI transparency in the age of LLMs: A human-centered research roadmap’==, _Special Issue 5: Grappling With the Generative AI Revolution_, (Special5). Available at: https://doi.org/10.1162/99608f92.8036d03b.  

Chen, V. _et al._ (2023) ‘==Understanding the role of human intuition on reliance in human-AI decision-making with explanations==’, _Proceedings of the ACM on human-computer interaction_, 7(CSCW2), pp. 1–32. Available at: https://doi.org/10.1145/3610219.  
   
Fan, M. _et al._ (2022) ‘==Human-AI collaboration for UX evaluation: Effects of explanation and synchronization==’, _Proceedings of the ACM on human-computer interaction_, 6(CSCW1), pp. 1–32. Available at: https://doi.org/10.1145/3512943.  

Boyd-Graber, J. _et al._ (2022) ‘==Human-centered evaluation of explanations==’, in M. Ballesteros, Y. Tsvetkov, and C.O. Alm (eds) 

Zhang, Y., Liao, Q.V. and Bellamy, R.K.E. (2020b) ‘==Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making==’, in _Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency_. _FAT* ’20: Conference on Fairness, Accountability, and Transparency_, New York, NY, USA: ACM, pp. 295–305. Available at: https://doi.org/10.1145/3351095.3372852.

Arya, V. _et al._ (2019) ‘One explanation does not fit all: ==a toolkit and taxonomy of AI explainability techniques ==(2019)’. Available at: http://arxiv.org/abs/1909.03012. 

Macrae, C. (2022) ‘Learning from the Failure of Autonomous and Intelligent Systems: Accidents, Safety, and Sociotechnical Sources of Risk’, _Risk analysis: an official publication of the Society for Risk Analysis_, 42(9), pp. 1999–2025. Available at: https://doi.org/10.1111/risa.13850.

Lawton, T. _et al._ (2024) ‘Clinicians risk becoming “liability sinks” for artificial intelligence’, _Future healthcare journal_, 11. Available at: https://doi.org/10.1016/j.fhj.2024.100007.

Ryan Conmy, P.M. _et al._ (2023) ‘What’s my role? Modelling responsibility for AI-based safety-critical systems’, p. 22. Available at: https://eprints.whiterose.ac.uk/206868/ (Accessed: 12 June 2024).

Porter, Z. _et al._ (2022) ‘Distinguishing two features of accountability for AI technologies’, _Nature machine intelligence_, 4(9), pp. 734–736. Available at: https://doi.org/10.1038/s42256-022-00533-0.

Habli, I. _et al._ (2018) ‘What is the safety case for health IT? A study of assurance practices in England’, _Safety science_, 110, pp. 324–335. Available at: https://doi.org/10.1016/j.ssci.2018.09.001.

Kempt, H., Heilinger, J.-C. and Nagel, S.K. (2022) ‘Relative explainability and double standards in medical decision-making: Should medical AI be subjected to higher standards in medical decision-making than doctors?’, _Ethics and information technology_, 24(2). Available at: https://doi.org/10.1007/s10676-022-09646-x.

Dekker, S. (2016) _Drift into Failure_. 1st Edition. CRC Press. Available at: https://doi.org/10.1201/9781315257396.

Stoop, J. (2018) ‘Drift into failure, an obsolete construct’, _AUP advances_, 1(1), pp. 99–117. Available at: https://doi.org/10.5117/adv2018.1.007.stoo.

Woods, D.D. (2018) ‘The theory of graceful extensibility: basic rules that govern adaptive systems’, _Environment Systems and Decisions_, 38(4), pp. 433–457. Available at: https://doi.org/10.1007/s10669-018-9708-3.


Clemmensen, T. (2021) _Human Work Interaction Design: A Platform for Theory and Action_. Cham: Springer International Publishing (Human–Computer Interaction Series). Available at: https://play.google.com/store/books/details?id=QlQ0zgEACAAJ (Accessed: 26 September 2023).

McDermid, J.A. _et al._ (2021) ‘Artificial intelligence explainability: the technical and ethical dimensions’, _Philosophical transactions. Series A, Mathematical, physical, and engineering sciences_, 379(2207), p. 20200363. Available at: https://doi.org/10.1098/rsta.2020.0363.

Hussain, M. _et al._ (2024) ‘Development and translation of human-AI interaction models into working prototypes for clinical decision-making’, in _Designing Interactive Systems Conference_. _DIS ’24: Designing Interactive Systems Conference_, New York, NY, USA: ACM, pp. 1607–1619. Available at: https://doi.org/10.1145/3643834.3660697.

Ashmore, R., Calinescu, R. and Paterson, C. (2021) ‘Assuring the Machine Learning Lifecycle: Desiderata, Methods, and Challenges’, _ACM computing surveys_, 54(5), pp. 1–39. Available at: https://doi.org/10.1145/3453444.

Hendrycks, D. _et al._ (2021) ‘Unsolved Problems in ML Safety’, _arXiv [cs.LG]_. Available at: http://arxiv.org/abs/2109.13916.

---

Gunning, D. and Aha, D.W. (2019) ‘DARPA’s explainable artificial intelligence program’, _AI magazine_, 40(2), pp. 44–58. Available at: https://doi.org/10.1609/aimag.v40i2.2850.

Herm, L.-V. _et al._ (2023) ‘Stop ordering machine learning algorithms by their explainability! A user-centered investigation of performance and explainability’, _International journal of information management_, 69(102538), p. 102538. Available at: https://doi.org/10.1016/j.ijinfomgt.2022.102538.

Brennen, A. (2020) ‘What do people really want when they say they want “explainable AI?” we asked 60 stakeholders’, in _Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems_. _CHI ’20: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–7. Available at: https://doi.org/10.1145/3334480.3383047.

Matarese, M., Rea, F. and Sciutti, A. (2021) ‘A user-centred framework for Explainable Artificial Intelligence in human-robot interaction’, _arXiv [cs.AI]_. Available at: https://www.semanticscholar.org/paper/A-User-Centred-Framework-for-Explainable-Artificial-Matarese-Rea/06ed0fe2179d1a19fb4e8f2193bb63768349502e.

Gade, K. _et al._ (2019) ‘Explainable AI in Industry’, in _Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_. _KDD ’19: The 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, New York, NY, USA: ACM. Available at: https://doi.org/10.1145/3292500.3332281.



---
Endsley, M.R. _et al._ (2022) ‘Special issue on human-AI teaming and special issue on AI in healthcare’, _Journal of cognitive engineering and decision making_, 16(4), pp. 179–181. Available at: https://doi.org/10.1177/15553434221133288.

Zhang, R. _et al._ (2021) ‘“An Ideal Human”: Expectations of AI Teammates in Human-AI Teaming’, _Proceedings of the ACM on human-computer interaction_, 4(CSCW3), pp. 1–25. Available at: https://doi.org/10.1145/3432945.

Caldwell, S. _et al._ (2022) ‘An Agile new research framework for hybrid human-AI teaming: Trust, transparency, and transferability’, _ACM transactions on interactive intelligent systems_, 12(3), pp. 1–36. Available at: https://doi.org/10.1145/3514257.

Berretta, S. _et al._ (2023) ‘Defining human-AI teaming the human-centered way: a scoping review and network analysis’, _Frontiers in artificial intelligence_, 6, p. 1250725. Available at: https://doi.org/10.3389/frai.2023.1250725.

Ulfert, A.-S. _et al._ (2024) ‘Shaping a multidisciplinary understanding of team trust in human-AI teams: a theoretical framework’, _European journal of work and organizational psychology_, 33(2), pp. 158–171. Available at: https://doi.org/10.1080/1359432x.2023.2200172.

Gao, Q. _et al._ (2023) ‘Agent Teaming Situation Awareness (ATSA): A situation awareness framework for human-AI teaming’, _arXiv [cs.AI]_. Available at: http://arxiv.org/abs/2308.16785.

Hauptman, A.I. _et al._ (2023) ‘Adapt and overcome: Perceptions of adaptive autonomous agents for human-AI teaming’, _Computers in human behavior_, 138, p. 107451. Available at: https://doi.org/10.1016/j.chb.2022.107451.

O’Neill, T. _et al._ (2020) ‘Human-autonomy teaming: A review and analysis of the empirical literature’, _Human factors_, 64(5), pp. 904–938. Available at: https://doi.org/10.1177/0018720820960865.

---

Rochi, M. (2023) ‘Technology paternalism and smart products: Review, synthesis, and research agenda’, _Technological forecasting and social change_, 192(122557), p. 122557. Available at: https://doi.org/10.1016/j.techfore.2023.122557.

Rochi, M. _et al._ (2024) ‘Technology paternalism: Development and validation of a measurement scale’, _Psychology & marketing_, 41(5), pp. 1172–1188. Available at: https://doi.org/10.1002/mar.21971.

---

Ghajargar, M. _et al._ (2021) ‘From “Explainable AI” to “Graspable AI”’, in _TEI 2021 - Proceedings of the 15th International Conference on Tangible, Embedded, and Embodied Interaction_. Available at: https://doi.org/10.1145/3430524.3442704.

Clemmensen, T. (2021) ‘Socio-Technical HCI Design in a Wider Context’, in _Human Work Interaction Design_. Switzerland: Springer International Publishing AG (Human–Computer Interaction Series), pp. 267–280. Available at: https://doi.org/10.1007/978-3-030-71796-4_10.

Wang, D. _et al._ (2019) ‘Designing Theory-Driven User-Centric Explainable AI’, _International Conference on Human Factors in Computing Systems_ [Preprint]. Available at: https://doi.org/10.1145/3290605.3300831.

Arrieta, A.B. _et al._ (2019) ‘Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI’, _An international journal on information fusion_ [Preprint]. Available at: https://doi.org/10.1016/j.inffus.2019.12.012.

Ehsan, U. and Riedl, M.O. (2020) ‘Human-centered Explainable AI: Towards a Reflective Sociotechnical Approach’, _Lecture notes in computer science_ [Preprint]. Available at: https://doi.org/10.1007/978-3-030-60117-1_33.

Liao, Q.V., Gruen, D.M. and Miller, S. (2020) ‘Questioning the AI: Informing Design Practices for Explainable AI User Experiences’, _International Conference on Human Factors in Computing Systems_ [Preprint]. Available at: https://doi.org/10.1145/3313831.3376590.

Zhang, Y., Liao, Q.V. and Bellamy, R.K.E. (2020) ‘Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making’, _Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency_ [Preprint]. Available at: https://doi.org/10.1145/3351095.3372852.

Chromik, M. _et al._ (2021) ‘I Think I Get Your Point, AI! The Illusion of Explanatory Depth in Explainable AI’, _International Conference on Intelligent Systems Design and Applications_ [Preprint]. Available at: https://doi.org/10.1145/3397481.3450644.

Eiband, M., Buschek, D. and Hussmann, H. (2021) ‘How to Support Users in ==Understanding Intelligent Systems==? Structuring the Discussion’, _International Conference on Intelligent Systems Design and Applications_ [Preprint]. Available at: https://doi.org/10.1145/3397481.3450694.

Bertrand, A. _et al._ (2022) ‘How cognitive biases affect ==XAI-assisted decision-making==: A systematic review’, in _Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society_. _AIES ’22: AAAI/ACM Conference on AI, Ethics, and Society_, New York, NY, USA: ACM. Available at: https://doi.org/10.1145/3514094.3534164.

Kim, S.S.Y. _et al._ (2022) ‘“Help Me Help the AI”: Understanding How Explainability Can Support Human-AI Interaction’, _International Conference on Human Factors in Computing Systems_ [Preprint]. Available at: https://doi.org/10.48550/arxiv.2210.03735.

Rong, Y. _et al._ (2022) ‘Towards Human-centered Explainable AI: ==User Studies== for Model Explanations’, _ArXiv_ [Preprint]. Available at: https://doi.org/10.48550/arxiv.2210.11584.

Chen, V. _et al._ (2023) ‘Understanding the Role of Human Intuition on Reliance in Human-AI ==Decision-Making with Explanations==’, _Proceedings of the ACM on human-computer interaction_ [Preprint]. Available at: https://doi.org/10.48550/arxiv.2301.07255.

Schmude, T. _et al._ (2024) ‘Information That Matters: ==Exploring Information Needs== of ==People Affected== by Algorithmic Decisions’, _arXiv. org_ [Preprint]. Available at: https://doi.org/10.48550/arxiv.2401.13324.

Corti, L. _et al._ (2024) ‘“it is a moving process”: Understanding the evolution of ==explainability needs== of clinicians in pulmonary medicine’, in _Proceedings of the CHI Conference on Human Factors in Computing Systems_. _CHI ’24: CHI Conference on Human Factors in Computing Systems_, New York, NY, USA: ACM, pp. 1–21. Available at: https://doi.org/10.1145/3613904.3642551.

Bobek, S. _et al._ (2024) ‘User-centric ==evaluation of explainability== of AI with and for humans: a comprehensive empirical study’, _arXiv. org_ [Preprint]. Available at: https://doi.org/10.48550/arxiv.2410.15952.