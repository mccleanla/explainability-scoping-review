Publication Type,Article Number,Document Type,Article Title,Foreign Title,Authors,Corporate Authors,Source Title,Volume,Issue,Pages,Publication Year,Publication Date,Language,180 Day Usage Count,Since 2013 Usage Count,Abstract,Other Abstract,Addresses,ResearcherID,ORCID Identifier,MeSH Heading,Citation Subsets,Keyword List,Molecular Sequence Data,Gene Symbol,Chemical,Personal Name Subject,Space Flight Mission,Research Areas,ISSN,NLM Unique ID,Country,Grant Information,Record Owner,Status,Investigations,Number of References,Dates,Notes,Published Electronically,General Notes,DOI,Open Access Designations,Highly Cited Status,Hot Paper Status,Date of Export,Accession Number
J,33981990,Journal Article; Review,Human- versus Artificial Intelligence.,,"Korteling, J E Hans; van de Boer-Visschedijk, G C; Blankendaal, R A M; Boonekamp, R C; Eikelboom, A R",,Frontiers in artificial intelligence,4,,622364,2021,2021,English,272,1950,"Copyright © 2021 Korteling, van de Boer-Visschedijk, Blankendaal, Boonekamp and Eikelboom.AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and collaborate with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI partners with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying 'psychological' mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed.",,"TNO Human Factors, Soesterberg, Netherlands.",,"Duque, Jorge/0000-0003-4939-6176",,,artificial general intelligence; artificial intelligence; cognitive bias; cognitive complexity; human intelligence; human-AI collaboration; human-level artificial intelligence; narrow artificial intelligence,,,,,,,2624-8212,101770551,Switzerland,,,PubMed-not-MEDLINE,,,/ 02 Apr 2024,,25 Mar 2021,,10.3389/frai.2021.622364,"gold, Green Published",,,2025-05-29,MEDLINE:33981990
J,37375838,Journal Article; Review,"The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies.",,"Blanco-Gonzalez, Alexandre; Cabezon, Alfonso; Seco-Gonzalez, Alejandro; Conde-Torres, Daniel; Antelo-Riveiro, Paula; Pineiro, Angel; Garcia-Fandino, Rebeca",,"Pharmaceuticals (Basel, Switzerland)",16,6,,2023,2023 Jun 18,English,69,286,"Artificial intelligence (AI) has the potential to revolutionize the drug discovery process, offering improved efficiency, accuracy, and speed. However, the successful application of AI is dependent on the availability of high-quality data, the addressing of ethical concerns, and the recognition of the limitations of AI-based approaches. In this article, the benefits, challenges, and drawbacks of AI in this field are reviewed, and possible strategies and approaches for overcoming the present obstacles are proposed. The use of data augmentation, explainable AI, and the integration of AI with traditional experimental methods, as well as the potential advantages of AI in pharmaceutical research, are also discussed. Overall, this review highlights the potential of AI in drug discovery and provides insights into the challenges and opportunities for realizing its potential in this field. Note from the human authors: This article was created to test the ability of ChatGPT, a chatbot based on the GPT-3.5 language model, in terms of assisting human authors in writing review articles. The text generated by the AI following our instructions (see Supporting Information) was used as a starting point, and its ability to automatically generate content was evaluated. After conducting a thorough review, the human authors practically rewrote the manuscript, striving to maintain a balance between the original proposal and the scientific criteria. The advantages and limitations of using AI for this purpose are discussed in the last section.",,"Department of Organic Chemistry, Center for Research in Biological Chemistry and Molecular Materials, University of Santiago de Compostela, CIQUS, 15705 Santiago de Compostela, Spain.; Soft Matter & Molecular Biophysics Group, Department of Applied Physics, Faculty of Physics, University of Santiago de Compostela, 15705 Santiago de Compostela, Spain.; MD.USE Innovations S.L., Edificio Emprendia, 15782 Santiago de Compostela, Spain.","Blanco-Gonzalez, Alexandre/JHU-4041-2023; Fandino, Rebeca/M-1880-2014; Pineiro, Angel/C-1098-2009","Pineiro, Angel/0000-0001-9350-8468; SECO GONZALEZ, ALEJANDRO/0009-0002-8344-7010; Conde Torres, Daniel/0000-0002-5806-9655; Blanco-Gonzalez, Alexandre/0000-0001-8593-5881; Antelo-Riveiro, Paula/0009-0005-4675-032X; Cabezon Vizoso, Alfonso/0000-0003-2777-3217",,,AI-assisted content generation; AI-limitations; artificial intelligence; drug discovery,,,,,,,1424-8247,101238453,Switzerland,"RTI2018-098795-A-I00, PID2019-111327GB-I00 and PDC2022-133402-I00 / Agencia Estatal de Investigacion (Spain). ED431F 2020/05, ED431B 2022/36, and Centro singular de investigacion de Galicia accreditation 2016-2019, ED431G/09 / Xunta de GaliciaXunta de Galicia",,PubMed-not-MEDLINE,,,/ 01 Jul 2023,,18 Jun 2023,,10.3390/ph16060891,"Green Published, Green Submitted, gold",,,2025-05-29,MEDLINE:37375838
J,33915362,Journal Article,Interpretable heartbeat classification using local model-agnostic explanations on ECGs.,,"Neves, Ines; Folgado, Duarte; Santos, Sara; Barandas, Marilia; Campagner, Andrea; Ronzio, Luca; Cabitza, Federico; Gamboa, Hugo",,Computers in biology and medicine,133,,104393,2021,2021 06 (Epub 2021 Apr 16),English,4,68,"Copyright © 2021 Elsevier Ltd. All rights reserved.Treatment and prevention of cardiovascular diseases often rely on Electrocardiogram (ECG) interpretation. Dependent on the physician's variability, ECG interpretation is subjective and prone to errors. Machine learning models are often developed and used to support doctors; however, their lack of interpretability stands as one of the main drawbacks of their widespread operation. This paper focuses on an Explainable Artificial Intelligence (XAI) solution to make heartbeat classification more explainable using several state-of-the-art model-agnostic methods. We introduce a high-level conceptual framework for explainable time series and propose an original method that adds temporal dependency between time samples using the time series' derivative. The results were validated in the MIT-BIH arrhythmia dataset: we performed a performance's analysis to evaluate whether the explanations fit the model's behaviour; and employed the 1-D Jaccard's index to compare the subsequences extracted from an interpretable model and the XAI methods used. Our results show that the use of the raw signal and its derivative includes temporal dependency between samples to promote classification explanation. A small but informative user study concludes this study to evaluate the potential of the visual explanations produced by our original method for being adopted in real-world clinical settings, either as diagnostic aids or training resource.",,"Associacao Fraunhofer Portugal Research, Rua Alfredo Allen 455/461, 4200-135, Porto, Portugal.; Associacao Fraunhofer Portugal Research, Rua Alfredo Allen 455/461, 4200-135, Porto, Portugal; Laboratorio de Instrumentacao, Engenharia Biomedica e Fisica da Radiacao (LIBPhys-UNL), Departamento de Fisica, Faculdade de Ciencias e Tecnologia, FCT, Universidade Nova de Lisboa, 2829-516, Caparica, Portugal. Electronic address: duarte.folgado@fraunhofer.pt.; Associacao Fraunhofer Portugal Research, Rua Alfredo Allen 455/461, 4200-135, Porto, Portugal; Laboratorio de Instrumentacao, Engenharia Biomedica e Fisica da Radiacao (LIBPhys-UNL), Departamento de Fisica, Faculdade de Ciencias e Tecnologia, FCT, Universidade Nova de Lisboa, 2829-516, Caparica, Portugal.; Dipartimento di Informatica, Sistemistica e Comunicazione, Universita degli Studi di Milano-Bicocca, Viale Sarca 336 - 20126, Milano, Italy.","Folgado, Duarte/AAO-6304-2021; Barandas, Marilia/J-3482-2019; Campagner, Andrea/AAB-4238-2020; Cabitza, Federico/JCO-4001-2023; Gamboa, Hugo/M-8799-2013; Cabitza, Federico/L-2263-2013","Barandas, Marilia/0000-0002-9445-4809; Santos, Sara/0000-0002-2554-3648; Gamboa, Hugo/0000-0002-4022-7424; Folgado, Duarte/0000-0002-8481-6079; Cabitza, Federico/0000-0002-4065-3415; CAMPAGNER, ANDREA/0000-0002-0027-5157","Arrhythmias, Cardiac / diagnosis. *Artificial Intelligence. *Electrocardiography. Heart Rate. Humans. Machine Learning",Index Medicus,Electrocardiogram; Explainable artificial intelligence; Heartbeat classification; Human-AI interfaces; Machine learning; Model-agnostic method; Time series; Usability; Visual explanations,,,,,,Cardiovascular System & Cardiology; Computer Science (provided by Clarivate Analytics),1879-0534,1250250,United States,,,MEDLINE,,,/ 25 Jun 2021 / 25 Jun 2021,,16 Apr 2021,,10.1016/j.compbiomed.2021.104393,Green Submitted,,,2025-05-29,MEDLINE:33915362
J,33733193,Journal Article; Review,The Next Generation of Medical Decision Support: A Roadmap Toward Transparent Expert Companions.,,"Bruckert, Sebastian; Finzel, Bettina; Schmid, Ute",,Frontiers in artificial intelligence,3,,507973,2020,2020,English,1,13,"Copyright © 2020 Bruckert, Finzel and Schmid.Increasing quality and performance of artificial intelligence (AI) in general and machine learning (ML) in particular is followed by a wider use of these approaches in everyday life. As part of this development, ML classifiers have also gained more importance for diagnosing diseases within biomedical engineering and medical sciences. However, many of those ubiquitous high-performing ML algorithms reveal a black-box-nature, leading to opaque and incomprehensible systems that complicate human interpretations of single predictions or the whole prediction process. This puts up a serious challenge on human decision makers to develop trust, which is much needed in life-changing decision tasks. This paper is designed to answer the question how expert companion systems for decision support can be designed to be interpretable and therefore transparent and comprehensible for humans. On the other hand, an approach for interactive ML as well as human-in-the-loop-learning is demonstrated in order to integrate human expert knowledge into ML models so that humans and machines act as companions within a critical decision task. We especially address the problem of Semantic Alignment between ML classifiers and its human users as a prerequisite for semantically relevant and useful explanations as well as interactions. Our roadmap paper presents and discusses an interdisciplinary yet integrated Comprehensible Artificial Intelligence (cAI)-transition-framework with regard to the task of medical diagnosis. We explain and integrate relevant concepts and research areas to provide the reader with a hands-on-cookbook for achieving the transition from opaque black-box models to interactive, transparent, comprehensible and trustworthy systems. To make our approach tangible, we present suitable state of the art methods with regard to the medical domain and include a realization concept of our framework. The emphasis is on the concept of Mutual Explanations (ME) that we introduce as a dialog-based, incremental process in order to provide human ML users with trust, but also with stronger participation within the learning process.",,"Cognitive Systems, University of Bamberg, Bamberg, Germany.",,"Finzel, Bettina/0000-0002-9415-6254; Schmid, Ute/0000-0002-1301-0326; Kiefer, Sebastian/0000-0002-1194-917X",,,companion; explainable artificial intelligence; interactive ML; interpretability; medical decision support; medical diagnosis; trust,,,,,,,2624-8212,101770551,Switzerland,,,PubMed-not-MEDLINE,,,/ 20 Mar 2021,,24 Sep 2020,,10.3389/frai.2020.507973,"Green Published, gold",,,2025-05-29,MEDLINE:33733193
J,35857532,"Journal Article; Research Support, U.S. Gov't, Non-P.H.S.",In situ bidirectional human-robot value alignment.,,"Yuan, Luyao; Gao, Xiaofeng; Zheng, Zilong; Edmonds, Mark; Wu, Ying Nian; Rossano, Federico; Lu, Hongjing; Zhu, Yixin; Zhu, Song-Chun",,Science robotics,7,68,eabm4183,2022,2022 07 13 (Epub 2022 Jul 13),English,14,135,"A prerequisite for social coordination is bidirectional communication between teammates, each playing two roles simultaneously: as receptive listeners and expressive speakers. For robots working with humans in complex situations with multiple goals that differ in importance, failure to fulfill the expectation of either role could undermine group performance due to misalignment of values between humans and robots. Specifically, a robot needs to serve as an effective listener to infer human users' intents from instructions and feedback and as an expressive speaker to explain its decision processes to users. Here, we investigate how to foster effective bidirectional human-robot communications in the context of value alignment-collaborative robots and users form an aligned understanding of the importance of possible task goals. We propose an explainable artificial intelligence (XAI) system in which a group of robots predicts users' values by taking in situ feedback into consideration while communicating their decision processes to users through explanations. To learn from human feedback, our XAI system integrates a cooperative communication model for inferring human values associated with multiple desirable goals. To be interpretable to humans, the system simulates human mental dynamics and predicts optimal explanations using graphical models. We conducted psychological experiments to examine the core components of the proposed computational framework. Our results show that real-time human-robot mutual understanding in complex cooperative tasks is achievable with a learning model based on bidirectional communication. We believe that this interaction framework can shed light on bidirectional value alignment in communicative XAI systems and, more broadly, in future human-machine teaming systems.",,"Department of Computer Science, University of California, Los Angeles, Los Angeles, CA 90095, USA.; Department of Statistics, University of California, Los Angeles, Los Angeles, CA 90095, USA.; Beijing Institute for General Artificial Intelligence (BIGAI), Beijing 100080, China.; Department of Cognitive Science, University of California, San Diego, San Diego, CA 92093, USA.; Department of Psychology, University of California, Los Angeles, Los Angeles, CA 90095, USA.; Institute for Artificial Intelligence, Peking University, Beijing 100871, China.","; Gao, Xiaofeng/HME-2741-2023","Zhu, Yixin/0000-0001-7024-1545; Wu, Yingnian/0000-0001-8029-3664; Gao, Xiaofeng/0000-0003-3331-9846; Zheng, Zilong/0000-0003-1219-5151; Rossano, Federico/0000-0002-6544-7685; Yuan, Luyao/0000-0001-6624-1227; Lu, Hongjing/0000-0003-0660-1176",Artificial Intelligence. Communication. Feedback. Humans. Man-Machine Systems. *Robotics,Index Medicus,,,,,,,Computer Science; Communication; Information Science & Library Science; Engineering; Robotics (provided by Clarivate Analytics),2470-9476,101733136,United States,,,MEDLINE,,,/ 22 Jul 2022 / 16 Aug 2022,,13 Jul 2022,,10.1126/scirobotics.abm4183,,,,2025-05-29,MEDLINE:35857532
J,34834566,Journal Article,Explainable Artificial Intelligence for Human-Machine Interaction in Brain Tumor Localization.,,"Esmaeili, Morteza; Vettukattil, Riyas; Banitalebi, Hasan; Krogh, Nina R; Geitung, Jonn Terje",,Journal of personalized medicine,11,11,,2021,2021 Nov 16,English,6,37,"Primary malignancies in adult brains are globally fatal. Computer vision, especially recent developments in artificial intelligence (AI), have created opportunities to automatically characterize and diagnose tumor lesions in the brain. AI approaches have provided scores of unprecedented accuracy in different image analysis tasks, including differentiating tumor-containing brains from healthy brains. AI models, however, perform as a black box, concealing the rational interpretations that are an essential step towards translating AI imaging tools into clinical routine. An explainable AI approach aims to visualize the high-level features of trained models or integrate into the training process. This study aims to evaluate the performance of selected deep-learning algorithms on localizing tumor lesions and distinguishing the lesion from healthy regions in magnetic resonance imaging contrasts. Despite a significant correlation between classification and lesion localization accuracy (R = 0.46, p = 0.005), the known AI algorithms, examined in this study, classify some tumor brains based on other non-relevant features. The results suggest that explainable AI approaches can develop an intuition for model interpretability and may play an important role in the performance evaluation of deep learning models. Developing explainable AI approaches will be an essential tool to improve human-machine interactions and assist in the selection of optimal training methods.",,"Department of Diagnostic Imaging, Akershus University Hospital, 1478 Lorenskog, Norway.; Department of Electrical Engineering and Computer Science, Faculty of Science and Technology, University of Stavanger, 4021 Stavanger, Norway.; Faculty of Medicine, Institute of Clinical Medicine, University of Oslo, 0315 Oslo, Norway.; Division of Paediatric and Adolescent Medicine, Oslo University Hospital, 0372 Oslo, Norway.","esmaeili, morteza/B-1106-2018; Banitalebi, Hasan/AAA-7044-2022; Geitung, Jonn-Terje/Y-8749-2019","Geitung, Jonn Terje/0000-0001-9259-1060; Vettukattil, Riyas/0000-0002-2152-4933",,,black box CNN; explainable AI; gliomas; machine learning; tumor localization,,,,,,,2075-4426,101602269,Switzerland,201804 / Wellcome TrustWellcome Trust,,PubMed-not-MEDLINE,,,/ 30 Nov 2021,,16 Nov 2021,,10.3390/jpm11111213,"Green Published, gold",,,2025-05-29,MEDLINE:34834566
J,33867901,Journal Article,Explaining Deep Classification of Time-Series Data with Learned Prototypes.,,"Gee, Alan H; Garcia-Olano, Diego; Ghosh, Joydeep; Paydarfar, David",,CEUR workshop proceedings,2429,,15-22,2019,2019 Aug,English,2,2,"The emergence of deep learning networks raises a need for explainable AI so that users and domain experts can be confident applying them to high-risk decisions. In this paper, we leverage data from the latent space induced by deep learning models to learn stereotypical representations or prototypes during training to elucidate the algorithmic decision-making process. We study how leveraging prototypes effect classification decisions of two dimensional time-series data in a few different settings: (1) electrocardiogram (ECG) waveforms to detect clinical bradycardia, a slowing of heart rate, in preterm infants, (2) respiration waveforms to detect apnea of prematurity, and (3) audio waveforms to classify spoken digits. We improve upon existing models by optimizing for increased prototype diversity and robustness, visualize how these prototypes in the latent space are used by the model to distinguish classes, and show that prototypes are capable of learning features on two dimensional time-series data to produce explainable insights during classification tasks. We show that the prototypes are capable of learning real-world features - bradycardia in ECG, apnea in respiration, and articulation in speech - as well as features within sub-classes. Our novel work leverages learned prototypical framework on two dimensional time-series data to produce explainable insights during classification tasks.",,"Electrical and Computer Engineering, The University of Texas at Austin.; Neurology, Dell Medical School, The University of Texas at Austin.",,,,,,,,,,,,1613-0073,101560115,Germany,R01 GM104987 / NIGMS NIH HHSUnited States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS). U01 HL133536 / NHLBI NIH HHSUnited States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI),,PubMed-not-MEDLINE,,,/ 13 Aug 2022,,,,,,,,2025-05-29,MEDLINE:33867901
J,37716910,Journal Article; Review,Artificial Intelligence for Quantitative Modeling in Drug Discovery and Development: An Innovation and Quality Consortium Perspective on Use Cases and Best Practices.,,"Terranova, Nadia; Renard, Didier; Shahin, Mohamed H; Menon, Sujatha; Cao, Youfang; Hop, Cornelis E C A; Hayes, Sean; Madrasi, Kumpal; Stodtmann, Sven; Tensfeldt, Thomas; Vaddady, Pavan; Ellinwood, Nicholas; Lu, James",,Clinical pharmacology and therapeutics,115,4,658-672,2024,2024 04 (Epub 2023 Oct 06),English,4,12,"© 2023 The Authors. Clinical Pharmacology & Therapeutics published by Wiley Periodicals LLC on behalf of American Society for Clinical Pharmacology and Therapeutics.Recent breakthroughs in artificial intelligence (AI) and machine learning (ML) have ushered in a new era of possibilities across various scientific domains. One area where these advancements hold significant promise is model-informed drug discovery and development (MID3). To foster a wider adoption and acceptance of these advanced algorithms, the Innovation and Quality (IQ) Consortium initiated the AI/ML working group in 2021 with the aim of promoting their acceptance among the broader scientific community as well as by regulatory agencies. By drawing insights from workshops organized by the working group and attended by key stakeholders across the biopharma industry, academia, and regulatory agencies, this white paper provides a perspective from the IQ Consortium. The range of applications covered in this white paper encompass the following thematic topics: (i) AI/ML-enabled Analytics for Pharmacometrics and Quantitative Systems Pharmacology (QSP) Workflows; (ii) Explainable Artificial Intelligence and its Applications in Disease Progression Modeling; (iii) Natural Language Processing (NLP) in Quantitative Pharmacology Modeling; and (iv) AI/ML Utilization in Drug Discovery. Additionally, the paper offers a set of best practices to ensure an effective and responsible use of AI, including considering the context of use, explainability and generalizability of models, and having human-in-the-loop. We believe that embracing the transformative power of AI in quantitative modeling while adopting a set of good practices can unlock new opportunities for innovation, increase efficiency, and ultimately bring benefits to patients.",,"Quantitative Pharmacology, Merck KGaA, Lausanne, Switzerland.; Full Development Pharmacometrics, Novartis Pharma AG, Basel, Switzerland.; Clinical Pharmacology, Pfizer Inc., Groton, Connecticut, USA.; Clinical Pharmacology and Translational Medicine, Eisai Inc., Nutley, New Jersey, USA.; DMPK, Genentech Inc., South San Francisco, California, USA.; Quantitative Pharmacology & Pharmacometrics, Merck & Co. Inc., Rahway, New Jersey, USA.; Modeling & Simulation, Sanofi, Bridgewater, New Jersey, USA.; Pharmacometrics, AbbVie Deutschland GmbH & Co. KG, Ludwigshafen, Germany.; Quantitative Clinical Pharmacology, Daiichi Sankyo, Inc., Basking Ridge, New Jersey, USA.; Global PK/PD & Pharmacometrics, Eli Lilly, Indianapolis, Indiana, USA.; Clinical Pharmacology, Genentech Inc., South San Francisco, California, USA.","Shahin, Mohamed/Q-2874-2019; Cao, Youfang/A-1771-2010","Vaddady, Pavan/0000-0002-7369-6649; Renard, Didier/0009-0004-9663-0230; Madrasi, Kumpal/0000-0002-1442-8919; Stodtmann, Sven/0000-0002-7986-4447; Lu, James/0000-0002-9687-5607; Terranova, Nadia/0000-0002-0033-3695",Algorithms. *Artificial Intelligence. *Drug Discovery. Humans. Machine Learning. Natural Language Processing,Index Medicus,,,,,,,Computer Science; Pharmacology & Pharmacy; Mathematics (provided by Clarivate Analytics),1532-6535,372741,United States,,,MEDLINE,,,/ 21 Mar 2024 / 11 Apr 2024,,06 Oct 2023,,10.1002/cpt.3053,hybrid,,,2025-05-29,MEDLINE:37716910
J,35197560,"Journal Article; Research Support, Non-U.S. Gov't",MIXTURE of human expertise and deep learning-developing an explainable model for predicting pathological diagnosis and survival in patients with interstitial lung disease.,,"Uegami, Wataru; Bychkov, Andrey; Ozasa, Mutsumi; Uehara, Kazuki; Kataoka, Kensuke; Johkoh, Takeshi; Kondoh, Yasuhiro; Sakanashi, Hidenori; Fukuoka, Junya",,"Modern pathology : an official journal of the United States and Canadian Academy of Pathology, Inc",35,8,1083-1091,2022,2022 08 (Epub 2022 Feb 23),English,1,26,"© 2022. The Author(s).Interstitial pneumonia is a heterogeneous disease with a progressive course and poor prognosis, at times even worse than those in the main cancer types. Histopathological examination is crucial for its diagnosis and estimation of prognosis. However, the evaluation strongly depends on the experience of pathologists, and the reproducibility of diagnosis is low. Herein, we propose MIXTURE (huMan-In-the-loop eXplainable artificial intelligence Through the Use of REcurrent training), an original method to develop deep learning models for extracting pathologically significant findings based on an expert pathologist's perspective with a small annotation effort. The procedure of MIXTURE consists of three steps as follows. First, we created feature extractors for tiles from whole slide images using self-supervised learning. The similar looking tiles were clustered based on the output features and then pathologists integrated the pathologically synonymous clusters. Using the integrated clusters as labeled data, deep learning models to classify the tiles into pathological findings were created by transfer-learning the feature extractors. We developed three models for different magnifications. Using these extracted findings, our model was able to predict the diagnosis of usual interstitial pneumonia, a finding suggestive of progressive disease, with high accuracy (AUC 0.90 in validation set and AUC 0.86 in test set). This high accuracy could not be achieved without the integration of findings by pathologists. The patients predicted as UIP had poorer prognosis (5-year overall survival [OS]: 55.4%) than those predicted as non-UIP (OS: 95.2%). The Cox proportional hazards model for each microscopic finding and prognosis pointed out dense fibrosis, fibroblastic foci, elastosis, and lymphocyte aggregation as independent risk factors. We suggest that MIXTURE may serve as a model approach to different diseases evaluated by medical imaging, including pathology and radiology, and be the prototype for explainable artificial intelligence that can collaborate with humans.",,"Department of Pathology, Nagasaki University Graduate School of Biomedical Sciences, Nagasaki, Japan.; Department of Pathology, Kameda Medical Center, Kamogawa, Japan.; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan.; Department of Respiratory Medicine and Allergy, Tosei General Hospital, Seto, Japan.; Department of Radiology, Kansai Rosai Hospital, Amagasaki, Hyogo, Japan.; Department of Pathology, Nagasaki University Graduate School of Biomedical Sciences, Nagasaki, Japan. fukuokaj@nagasaki-u.ac.jp.; Department of Pathology, Kameda Medical Center, Kamogawa, Japan. fukuokaj@nagasaki-u.ac.jp.","Kondo, Yasuhiro/AAP-3658-2020; Uegami, Wataru/CAG-1189-2022; Uehara, Kazuki/M-1742-2018; Bychkov, Andrey/N-1884-2019; Fukuoka, Junya/AAT-2924-2021; Sakanashi, Hidenori/B-1613-2017","Bychkov, Andrey/0000-0002-4203-5696; Fukuoka, Junya/0000-0002-2496-3050","Artificial Intelligence. *Deep Learning. Humans. *Idiopathic Pulmonary Fibrosis / diagnosis; pathology. *Lung Diseases, Interstitial / diagnosis; pathology. Reproducibility of Results",Index Medicus,,,,,,,Computer Science; Respiratory System (provided by Clarivate Analytics),1530-0285,8806605,United States,,,MEDLINE,,,/ 27 Jul 2022 / 10 Feb 2023,,23 Feb 2022,,10.1038/s41379-022-01025-7,"hybrid, Green Submitted, Green Published",,,2025-05-29,MEDLINE:35197560
J,37841234,Journal Article; Scoping Review,Defining human-AI teaming the human-centered way: a scoping review and network analysis.,,"Berretta, Sophie; Tausch, Alina; Ontrup, Greta; Gilles, Bjorn; Peifer, Corinna; Kluge, Annette",,Frontiers in artificial intelligence,6,,1250725,2023,2023,English,21,71,"Copyright © 2023 Berretta, Tausch, Ontrup, Gilles, Peifer and Kluge.Introduction: With the advancement of technology and the increasing utilization of AI, the nature of human work is evolving, requiring individuals to collaborate not only with other humans but also with AI technologies to accomplish complex goals. This requires a shift in perspective from technology-driven questions to a human-centered research and design agenda putting people and evolving teams in the center of attention. A socio-technical approach is needed to view AI as more than just a technological tool, but as a team member, leading to the emergence of human-AI teaming (HAIT). In this new form of work, humans and AI synergistically combine their respective capabilities to accomplish shared goals.Methods: The aim of our work is to uncover current research streams on HAIT and derive a unified understanding of the construct through a bibliometric network analysis, a scoping review and synthetization of a definition from a socio-technical point of view. In addition, antecedents and outcomes examined in the literature are extracted to guide future research in this field.Results: Through network analysis, five clusters with different research focuses on HAIT were identified. These clusters revolve around (1) human and (2) task-dependent variables, (3) AI explainability, (4) AI-driven robotic systems, and (5) the effects of AI performance on human perception. Despite these diverse research focuses, the current body of literature is predominantly driven by a technology-centric and engineering perspective, with no consistent definition or terminology of HAIT emerging to date.Discussion: We propose a unifying definition combining a human-centered and team-oriented perspective as well as summarize what is still needed in future research regarding HAIT. Thus, this work contributes to support the idea of the Frontiers Research Topic of a theoretical and conceptual basis for human work with AI systems.",,"Department of Psychology, Organizational, and Business Psychology, Ruhr University Bochum, Bochum, Germany.; Department of Psychology I, University of Lubeck, Lubeck, Germany.","Ontrup, Greta/AAF-9422-2021; Peifer, Corinna/V-2944-2019; Kluge, Annette/AAX-3178-2020","Tausch, Alina/0000-0002-3190-6185; Ontrup, Greta/0000-0003-4720-1494; Kluge, Annette/0000-0002-8123-0427; Berretta, Sophie/0000-0002-2879-2164",,,artificial intelligence; bibliometric analysis; bibliometric coupling; human-AI teaming; human-centered AI; humane work; network analysis; work psychology,,,,,,,2624-8212,101770551,Switzerland,,,PubMed-not-MEDLINE,,,/ 30 Jan 2025,,29 Sep 2023,,10.3389/frai.2023.1250725,"Green Published, gold",,,2025-05-29,MEDLINE:37841234
J,34366701,Journal Article,Explainable recommendation: when design meets trust calibration.,,"Naiseh, Mohammad; Al-Thani, Dena; Jiang, Nan; Ali, Raian",,World wide web,24,5,1857-1884,2021,2021 (Epub 2021 Aug 02),English,7,51,"© The Author(s) 2021.Human-AI collaborative decision-making tools are being increasingly applied in critical domains such as healthcare. However, these tools are often seen as closed and intransparent for human decision-makers. An essential requirement for their success is the ability to provide explanations about themselves that are understandable and meaningful to the users. While explanations generally have positive connotations, studies showed that the assumption behind users interacting and engaging with these explanations could introduce trust calibration errors such as facilitating irrational or less thoughtful agreement or disagreement with the AI recommendation. In this paper, we explore how to help trust calibration through explanation interaction design. Our research method included two main phases. We first conducted a think-aloud study with 16 participants aiming to reveal main trust calibration errors concerning explainability in AI-Human collaborative decision-making tools. Then, we conducted two co-design sessions with eight participants to identify design principles and techniques for explanations that help trust calibration. As a conclusion of our research, we provide five design principles: Design for engagement, challenging habitual actions, attention guidance, friction and support training and learning. Our findings are meant to pave the way towards a more integrated framework for designing explanations with trust calibration as a primary goal.",,"Faculty of Science and Technology, Bournemouth University, Fern Barrow, Poole, BH12 5BB UK.; College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar.","Ali, Raian/HZI-8249-2023; Naiseh, Mohammad/JCE-1911-2023; Naiseh, Mohammad/MCK-3985-2025","Naiseh, Mohammad/0000-0002-4927-5086",,,Explainable AI; Trust; Trust Calibration; User Centric AI,,,,,,,1573-1413,101729120,United States,,,PubMed-not-MEDLINE,,,/ 18 Feb 2022,,02 Aug 2021,,10.1007/s11280-021-00916-0,"Green Accepted, Green Published, hybrid",,,2025-05-29,MEDLINE:34366701
J,38928675,Journal Article; Review,Empowering Modern Dentistry: The Impact of Artificial Intelligence on Patient Care and Clinical Decision Making.,,"Semerci, Zeliha Merve; Yardimci, Selmi",,"Diagnostics (Basel, Switzerland)",14,12,,2024,2024 Jun 14,English,14,29,"Advancements in artificial intelligence (AI) are poised to catalyze a transformative shift across diverse dental disciplines including endodontics, oral radiology, orthodontics, pediatric dentistry, periodontology, prosthodontics, and restorative dentistry. This narrative review delineates the burgeoning role of AI in enhancing diagnostic precision, streamlining treatment planning, and potentially unveiling innovative therapeutic modalities, thereby elevating patient care standards. Recent analyses corroborate the superiority of AI-assisted methodologies over conventional techniques, affirming their capacity for personalization, accuracy, and efficiency in dental care. Central to these AI applications are convolutional neural networks and deep learning models, which have demonstrated efficacy in diagnosis, prognosis, and therapeutic decision making, in some instances surpassing traditional methods in complex cases. Despite these advancements, the integration of AI into clinical practice is accompanied by challenges, such as data security concerns, the demand for transparency in AI-generated outcomes, and the imperative for ongoing validation to establish the reliability and applicability of AI tools. This review underscores the prospective benefits of AI in dental practice, envisioning AI not as a replacement for dental professionals but as an adjunctive tool that fortifies the dental profession. While AI heralds improvements in diagnostics, treatment planning, and personalized care, ethical and practical considerations must be meticulously navigated to ensure responsible development of AI in dentistry.",,"Department of Oral and Maxillofacial Radiology, Faculty of Dentistry, Akdeniz University, Antalya 07070, Turkey.","TUNC, Selmi/B-2959-2018","TUNC, Selmi/0000-0001-9546-6548; SEMERCI, Zeliha Merve/0000-0002-0323-4940",,,artificial intelligence; convolutional neural networks; dentistry; diagnostic accuracy; patient care,,,,,,,2075-4418,101658402,Switzerland,,,PubMed-not-MEDLINE,,,/ 29 Jun 2024,,14 Jun 2024,,10.3390/diagnostics14121260,gold,,,2025-05-29,MEDLINE:38928675
J,34124173,Journal Article,Moral Decision Making in Human-Agent Teams: Human Control and the Role of Explanations.,,"van der Waa, Jasper; Verdult, Sabine; van den Bosch, Karel; van Diggelen, Jurriaan; Haije, Tjalling; van der Stigchel, Birgit; Cocu, Ioana",,Frontiers in robotics and AI,8,,640647,2021,2021,English,3,34,"Copyright © 2021 van der Waa, Verdult, van den Bosch, van Diggelen, Haije, van der Stigchel and Cocu.With the progress of Artificial Intelligence, intelligent agents are increasingly being deployed in tasks for which ethical guidelines and moral values apply. As artificial agents do not have a legal position, humans should be held accountable if actions do not comply, implying humans need to exercise control. This is often labeled as Meaningful Human Control (MHC). In this paper, achieving MHC is addressed as a design problem, defining the collaboration between humans and agents. We propose three possible team designs (Team Design Patterns), varying in the level of autonomy on the agent's part. The team designs include explanations given by the agent to clarify its reasoning and decision-making. The designs were implemented in a simulation of a medical triage task, to be executed by a domain expert and an artificial agent. The triage task simulates making decisions under time pressure, with too few resources available to comply with all medical guidelines all the time, hence involving moral choices. Domain experts (i.e., health care professionals) participated in the present study. One goal was to assess the ecological relevance of the simulation. Secondly, to explore the control that the human has over the agent to warrant moral compliant behavior in each proposed team design. Thirdly, to evaluate the role of agent explanations on the human's understanding in the agent's reasoning. Results showed that the experts overall found the task a believable simulation of what might occur in reality. Domain experts experienced control over the team's moral compliance when consequences were quickly noticeable. When instead the consequences emerged much later, the experts experienced less control and felt less responsible. Possibly due to the experienced time pressure implemented in the task or over trust in the agent, the experts did not use explanations much during the task; when asked afterwards they however considered these to be useful. It is concluded that a team design should emphasize and support the human to develop a sense of responsibility for the agent's behavior and for the team's decisions. The design should include explanations that fit with the assigned team roles as well as the human cognitive state.",,"Perceptual and Cognitive Systems, TNO, Soesterberg, Netherlands.; Interactive Intelligence, Technical University Delft, Delft, Netherlands.; Training and Performance Innovations, TNO, Soesterberg, Netherlands.; Artificial Intelligence, Radboud University, Nijmegen, Nijmegen, Netherlands.","van+Diggelen, Jurriaan/AAJ-1126-2021; van der Waa, Jasper/ITT-0397-2023",,,,artificial intelligence; ethical AI; explainable AI; human study; human-agent teaming; meaningful human control; moral AI; team design patterns,,,,,,,2296-9144,101749350,Switzerland,,,PubMed-not-MEDLINE,,,/ 15 Jun 2021,,27 May 2021,,10.3389/frobt.2021.640647,"Green Published, gold",,,2025-05-29,MEDLINE:34124173
J,36158603,Journal Article,The influence of interdependence and a transparent or explainable communication style on human-robot teamwork.,,"Verhagen, Ruben S; Neerincx, Mark A; Tielman, Myrthe L",,Frontiers in robotics and AI,9,,993997,2022,2022,English,9,41,"Copyright © 2022 Verhagen, Neerincx and Tielman.Humans and robots are increasingly working together in human-robot teams. Teamwork requires communication, especially when interdependence between team members is high. In previous work, we identified a conceptual difference between sharing what you are doing (i.e., being transparent) and why you are doing it (i.e., being explainable). Although the second might sound better, it is important to avoid information overload. Therefore, an online experiment (n = 72) was conducted to study the effect of communication style of a robot (silent, transparent, explainable, or adaptive based on time pressure and relevancy) on human-robot teamwork. We examined the effects of these communication styles on trust in the robot, workload during the task, situation awareness, reliance on the robot, human contribution during the task, human communication frequency, and team performance. Moreover, we included two levels of interdependence between human and robot (high vs. low), since mutual dependency might influence which communication style is best. Participants collaborated with a virtual robot during two simulated search and rescue tasks varying in their level of interdependence. Results confirm that in general robot communication results in more trust in and understanding of the robot, while showing no evidence of a higher workload when the robot communicates or adds explanations to being transparent. Providing explanations, however, did result in more reliance on RescueBot. Furthermore, compared to being silent, only being explainable results a higher situation awareness when interdependence is high. Results further show that being highly interdependent decreases trust, reliance, and team performance while increasing workload and situation awareness. High interdependence also increases human communication if the robot is not silent, human rescue contribution if the robot does not provide explanations, and the strength of the positive association between situation awareness and team performance. From these results, we can conclude that robot communication is crucial for human-robot teamwork, and that important differences exist between being transparent, explainable, or adaptive. Our findings also highlight the fundamental importance of interdependence in studies on explainability in robots.",,"Interactive Intelligence, Intelligent Systems Department, Delft University of Technology, Delft, Netherlands.; Human-Machine Teaming, Netherlands Organization for Applied Scientific Research (TNO), Amsterdam, Netherlands.",,"Tielman, Myrthe/0000-0002-7826-5821; Verhagen, Ruben/0000-0003-2234-0754",,,communication; explainability; explainable AI; human-agent teaming; human-robot teamwork; interdependence; transparency; user study,,,,,,,2296-9144,101749350,Switzerland,,,PubMed-not-MEDLINE,,,/ 28 Sep 2022,,08 Sep 2022,,10.3389/frobt.2022.993997,"gold, Green Published",,,2025-05-29,MEDLINE:36158603
J,39675423,Editorial,Is human oversight to AI systems still possible?,,"Holzinger, Andreas; Zatloukal, Kurt; Muller, Heimo",,New biotechnology,85,,59-62,2025,2025 Mar 25 (Epub 2024 Dec 13),English,10,10,"Copyright © 2024 The Authors. Published by Elsevier B.V. All rights reserved.The rapid proliferation of artificial intelligence (AI) systems across diverse domains raises critical questions about the feasibility of meaningful human oversight, particularly in high-stakes domains such as new biotechnology. As AI systems grow increasingly complex, opaque, and autonomous, ensuring responsible use becomes a formidable challenge. During our editorial work for the special issue Artificial Intelligence for Life Sciences, we placed increasing emphasis on the topic of human oversight. Consequently, in this editorial we briefly discuss the evolving role of human oversight in AI governance, focusing on the practical, technical, and ethical dimensions of maintaining control. It examines how the complexity of contemporary AI architectures, such as large-scale neural networks and generative AI applications, undermine human understanding and decision-making capabilities. Furthermore, it evaluates emerging approaches-such as explainable AI (XAI), human-in-the-loop systems, and regulatory frameworks-that aim to enable oversight while acknowledging their limitations. Through a comprehensive analysis, the picture emerged while complete oversight may no longer be viable in certain contexts, strategic interventions leveraging human-AI collaboration and trustworthy AI design principles can preserve accountability and safety. The discussion highlights the urgent need for interdisciplinary efforts to rethink oversight mechanisms in an era where AI may outpace human comprehension.",,"Human-Centered AI Lab, Institute of Forest Engineering, Department for Ecosystem Management, Climate and Biodiversity, University of Natural Resources and Life Sciences Vienna,Austria; Information Science and Machine Learning Group, Diagnostic and Research Institute of Pathology, Medical University Graz, Austria. Electronic address: andreas.holzinger@boku.ac.at.; Information Science and Machine Learning Group, Diagnostic and Research Institute of Pathology, Medical University Graz,Austria.","Holzinger, Andreas/E-9530-2010",,*Artificial Intelligence / ethics. Humans,Index Medicus,Artificial intelligence; Biotechnology; Deep learning; Digital transformation; Machine learning,,,,,,Computer Science (provided by Clarivate Analytics),1876-4347,101465345,Netherlands,,,MEDLINE,,,/ 07 Feb 2025 / 19 May 2025,,13 Dec 2024,,10.1016/j.nbt.2024.12.003,gold,,,2025-05-29,MEDLINE:39675423
J,38755410,Journal Article,A retrieval-augmented chatbot based on GPT-4 provides appropriate differential diagnosis in gastrointestinal radiology: a proof of concept study.,,"Rau, Stephan; Rau, Alexander; Nattenmuller, Johanna; Fink, Anna; Bamberg, Fabian; Reisert, Marco; Russe, Maximilian F",,European radiology experimental,8,1,60,2024,2024 May 17,English,5,9,"© 2024. The Author(s).BACKGROUND: We investigated the potential of an imaging-aware GPT-4-based chatbot in providing diagnoses based on imaging descriptions of abdominal pathologies.METHODS: Utilizing zero-shot learning via the LlamaIndex framework, GPT-4 was enhanced using the 96 documents from the Radiographics Top 10 Reading List on gastrointestinal imaging, creating a gastrointestinal imaging-aware chatbot (GIA-CB). To assess its diagnostic capability, 50 cases on a variety of abdominal pathologies were created, comprising radiological findings in fluoroscopy, MRI, and CT. We compared the GIA-CB to the generic GPT-4 chatbot (g-CB) in providing the primary and 2 additional differential diagnoses, using interpretations from senior-level radiologists as ground truth. The trustworthiness of the GIA-CB was evaluated by investigating the source documents as provided by the knowledge-retrieval mechanism. Mann-Whitney U test was employed.RESULTS: The GIA-CB demonstrated a high capability to identify the most appropriate differential diagnosis in 39/50 cases (78%), significantly surpassing the g-CB in 27/50 cases (54%) (p=0.006). Notably, the GIA-CB offered the primary differential in the top 3 differential diagnoses in 45/50 cases (90%) versus g-CB with 37/50 cases (74%) (p=0.022) and always with appropriate explanations. The median response time was 29.8s for GIA-CB and 15.7s for g-CB, and the mean cost per case was $0.15 and $0.02, respectively.CONCLUSIONS: The GIA-CB not only provided an accurate diagnosis for gastrointestinal pathologies, but also direct access to source documents, providing insight into the decision-making process, a step towards trustworthy and explainable AI. Integrating context-specific data into AI models can support evidence-based clinical decision-making.RELEVANCE STATEMENT: A context-aware GPT-4 chatbot demonstrates high accuracy in providing differential diagnoses based on imaging descriptions, surpassing the generic GPT-4. It provided formulated rationale and source excerpts supporting the diagnoses, thus enhancing trustworthy decision-support.KEY POINTS: Knowledge retrieval enhances differential diagnoses in a gastrointestinal imaging-aware chatbot (GIA-CB). GIA-CB outperformed the generic counterpart, providing formulated rationale and source excerpts. GIA-CB has the potential to pave the way for AI-assisted decision support systems.",,"Department of Diagnostic and Interventional Radiology, Faculty of Medicine, Medical Center - University of Freiburg, University of Freiburg, 79106, Freiburg Im Breisgau, Germany. stephan.rau@uniklinik-freiburg.de.; Department of Diagnostic and Interventional Radiology, Faculty of Medicine, Medical Center - University of Freiburg, University of Freiburg, 79106, Freiburg Im Breisgau, Germany.; Department of Neuroradiology, Faculty of Medicine, Medical Center - University of Freiburg, University of Freiburg, Hugstetter Str. 55, 79106, Freiburg Im Breisgau, Germany.","Nattenmuller, Johanna/GNH-5653-2022; Fink, Anna/KLY-9411-2024; Rau, Alexander/AAK-3948-2021","Fink, Anna/0009-0002-9903-283X; Rau, Stephan/0000-0002-8992-2401","*Artificial Intelligence. Diagnosis, Differential. *Gastrointestinal Diseases / diagnostic imaging. Humans. *Proof of Concept Study",Index Medicus,Artificial intelligence; Diagnosis (differential); Gastrointestinal diseases; Knowledge acquisition (computer); Zero-shot learning,,,,,,Gastroenterology & Hepatology; Computer Science (provided by Clarivate Analytics),2509-9280,101721752,England,,,MEDLINE,,,/ 16 May 2024 / 14 Aug 2024,,17 May 2024,,10.1186/s41747-024-00457-x,gold,,,2025-05-29,MEDLINE:38755410
J,38579495,Journal Article,AI and the transformation of industrial work: Hybrid intelligence vs double-black box effect.,,"Wahlstrom, Mikael; Tammentie, Bastian; Salonen, Tuisku-Tuuli; Karvonen, Antero",,Applied ergonomics,118,,104271,2024,2024 Jul (Epub 2024 Apr 04),English,19,30,"Copyright © 2024. Published by Elsevier Ltd.It is uncertain how the application of artificial intelligence (AI) technology transforms industrial work. We address this question from the perspective of cognitive systems, which, in this case, includes considerations of AI and process transparency, resilience, division of labor, and worker skills. We draw from a case study on glass tempering that includes a machine-vision-based quality control system and an advanced automation process control system. Based on task analysis and background literature, we develop the concept of hybrid intelligence that implies balanced AI transparency that supports upskilling and resilience. So-called fragmented intelligence, in turn, may result from the combination of the complexity of advanced automation along with the complexity of the process physics that places critical emphasis on expert knowledge. This combination can result in the so-called double black box effect, given that designing for understandability for the line workers might not be feasible: expert networks are needed for resilience.",,"VTT Technical Research Centre of Finland Ltd., Espoo, Finland. Electronic address: mikael.wahlstrom@vtt.fi.; VTT Technical Research Centre of Finland Ltd., Espoo, Finland.",,"Salonen, Tuisku/0000-0002-9528-1735; Karvonen, Antero/0000-0001-8032-2947",*Artificial Intelligence. Automation. Glass. Humans. Industry. Task Performance and Analysis,Index Medicus,Artificial intelligence; Glass tempering; Hybrid intelligence; Industrial processes; Resilience; Task analysis,,,,,,Computer Science; Psychology; Behavioral Sciences; Business & Economics; Automation & Control Systems (provided by Clarivate Analytics),1872-9126,261412,England,,,MEDLINE,,,/ 01 May 2024 / 01 May 2024,,04 Apr 2024,,10.1016/j.apergo.2024.104271,,,,2025-05-29,MEDLINE:38579495
J,36568208,Journal Article,A human-in-the-loop based Bayesian network approach to improve imbalanced radiation outcomes prediction for hepatocellular cancer patients with stereotactic body radiotherapy.,,"Luo, Yi; Cuneo, Kyle C; Lawrence, Theodore S; Matuszak, Martha M; Dawson, Laura A; Niraula, Dipesh; Ten Haken, Randall K; El Naqa, Issam",,Frontiers in oncology,12,,1061024,2022,2022,English,1,6,"Copyright © 2022 Luo, Cuneo, Lawrence, Matuszak, Dawson, Niraula, Ten Haken and El Naqa.Background: Imbalanced outcome is one of common characteristics of oncology datasets. Current machine learning approaches have limitation in learning from such datasets. Here, we propose to resolve this problem by utilizing a human-in-the-loop (HITL) approach, which we hypothesize will also lead to more accurate and explainable outcome prediction models.Methods: A total of 119 HCC patients with 163 tumors were used in the study. 81 patients with 104 tumors from the University of Michigan Hospital treated with SBRT were considered as a discovery dataset for radiation outcomes model building. The external testing dataset included 59 tumors from 38 patients with SBRT from Princess Margaret Hospital. In the discovery dataset, 100 tumors from 77 patients had local control (LC) (96% of 104 tumors) and 23 patients had at least one grade increment of ALBI (I-ALBI) during six-month follow up (28% of 81 patients). Each patient had a total of 110 features, where 15 or 20 features were identified by physicians as expert knowledge features (EKFs) for LC or I-ALBI prediction. We proposed a HITL based Bayesian network (HITL-BN) approach to enhance the capability of selecting important features from imbalanced data in terms of accuracy and explainability through humans' participation by integrating feature importance ranking and Markov blanket algorithms. A pure data-driven Bayesian network (PD-BN) method was applied to the same discovery dataset of HCC patients as a benchmark.Results: In the training and testing phases, the areas under receiver operating characteristic curves of the HITL-BN models for LC or I-ALBI prediction during SBRT are 0.85 (95% confidence interval: 0.75-0.95) or 0.89 (0.81-0.95) and 0.77 or 0.78, respectively. They significantly outperformed the during-treatment PD-BN model in predicting LC or I-ALBI based on the discovery cross-validation and testing datasets from the Delong tests.Conclusion: By allowing the human expert to be part of the model building process, the HITL-BN approach yielded significantly improved accuracy as well as better explainability when dealing with imbalanced outcomes in the prediction of post-SBRT treatment response of HCC patients when compared to the PD-BN method.",,"Department of Machine Learning, Moffitt Cancer Center, Tampa, FL, United States.; Department of Radiation Oncology, University of Michigan, Ann Arbor, MI, United States.; Department of Radiation Oncology, University of Toronto, Toronto, ON, Canada.","Naqa, Issam/T-3066-2019; Cuneo, Kyle/DZG-3141-2022; Niraula, Dipesh/AAE-6536-2020","LAWRENCE, THEODORE S./0000-0002-4186-8821; Niraula, Dipesh/0000-0002-2245-8536; Cuneo, Kyle/0000-0002-8264-6483; Matuszak, Martha/0000-0002-4129-1030",,,Bayesian networks; accuracy and explainability; hepatocellular cancer; human-in-the-loop; outcome prediction; stereotactic body radiotherapy,,,,,,,2234-943X,101568867,Switzerland,R01 CA233487 / NCI NIH HHSUnited States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI),,PubMed-not-MEDLINE,,,/ 11 Apr 2023,,09 Dec 2022,,10.3389/fonc.2022.1061024,"Green Published, gold",,,2025-05-29,MEDLINE:36568208
J,36605113,Journal Article,The key to an effective AI-powered digital pathology: Establishing a symbiotic workflow between pathologists and machine.,,"Jarrahi, Mohammad Hossein; Davoudi, Vahid; Haeri, Mohammad",,Journal of pathology informatics,13,,100156,2022,2022,English,1,1,"© 2022 The Authors.Pathology is a fundamental element of modern medicine that determines the final diagnosis of medical conditions, leads medical decisions, and portrays the prognosis. Due to continuous improvements in AI capabilities (e.g., object recognition and image processing), intelligent systems are bound to play a key role in augmenting pathology research and clinical practices. Despite the pervasive deployment of computational approaches in similar fields such as radiology, there has been less success in integrating AI in clinical practices and histopathological diagnosis. This is partly due to the opacity of end-to-end AI systems, which raises issues of interoperability and accountability of medical practices. In this article, we draw on interactive machine learning to take advantage of AI in digital pathology to open the black box of AI and generate a more effective partnership between pathologists and AI systems based on the metaphors of parameterization and implicitization.",,"University of North Carolina, 100 Manning Hall, Chapel Hill, NC 27599, USA.; Alzheimer Disease Research Center, University of Kansas, Kansas University Medical Center, Kansas City, Kansas, USA.; Department of Pathology & Laboratory Medicine, University of Kansas Medical Center, Kansas City, Kansas, USA.",,"Haeri, Mohammad/0000-0001-6055-9779",,,Artificial intelligence; Computational pathology; Digital pathology; Explainable AI; Human-in-the-loop; Image analysis,,,,,,,2229-5089,101528849,United States,,,PubMed-not-MEDLINE,,,/ 07 Jan 2023,,10 Nov 2022,,10.1016/j.jpi.2022.100156,"Green Published, gold",,,2025-05-29,MEDLINE:36605113
J,39074956,Journal Article,AI and XAI second opinion: the danger of false confirmation in human-AI collaboration.,,"Rosenbacke, Rikard; Melhus, Asa; McKee, Martin; Stuckler, David",,Journal of medical ethics,51,6,396-399,2025,2025 May 21,English,12,22,"© Author(s) (or their employer(s)) 2025. No commercial re-use. See rights and permissions. Published by BMJ Group.Can AI substitute a human physician's second opinion? Recently the Journal of Medical Ethics published two contrasting views: Kempt and Nagel advocate for using artificial intelligence (AI) for a second opinion except when its conclusions significantly diverge from the initial physician's while Jongsma and Sand argue for a second human opinion irrespective of AI's concurrence or dissent. The crux of this debate hinges on the prevalence and impact of 'false confirmation'-a scenario where AI erroneously validates an incorrect human decision. These errors seem exceedingly difficult to detect, reminiscent of heuristics akin to confirmation bias. However, this debate has yet to engage with the emergence of explainable AI (XAI), which elaborates on why the AI tool reaches its diagnosis. To progress this debate, we outline a framework for conceptualising decision-making errors in physician-AI collaborations. We then review emerging evidence on the magnitude of false confirmation errors. Our simulations show that they are likely to be pervasive in clinical practice, decreasing diagnostic accuracy to between 5% and 30%. We conclude with a pragmatic approach to employing AI as a second opinion, emphasising the need for physicians to make clinical decisions before consulting AI; employing nudges to increase awareness of false confirmations and critically engaging with XAI explanations. This approach underscores the necessity for a cautious, evidence-based methodology when integrating AI into clinical decision-making.",,"Centre for Corporate Governance, Department of Accounting, Copenhagen Business School, Frederiksberg, Denmark rikard@rosenbacke.com.; Department of Medical Sciences, Uppsala University, Uppsala, Sweden.; Department of Health Services Research and Policy, London School of Hygiene and Tropical Medicine, London, UK.; Department of Social and Political Science, Bocconi University, Milano, Italy.","Stuckler, David/H-2261-2012; McKee, Martin/E-6673-2018","Stuckler, David/0000-0002-1288-8401; Rosenbacke, Rikard/0009-0007-4504-9106",*Artificial Intelligence / ethics. *Clinical Decision-Making / ethics. Cooperative Behavior. *Decision Making / ethics. Diagnostic Errors. Humans. *Physicians / ethics,Index Medicus,Decision Making; Ethics- Medical; Information Technology; Medical Errors,,,,,,Computer Science; Behavioral Sciences; Psychology (provided by Clarivate Analytics),1473-4257,7513619,England,,,MEDLINE,,,/ 21 May 2025 / 21 May 2025,,21 May 2025,,10.1136/jme-2024-110074,,,,2025-05-29,MEDLINE:39074956
J,39292314,Journal Article,Identifying Facilitators and Barriers to Implementation of AI-Assisted Clinical Decision Support in an Electronic Health Record System.,,"Finkelstein, Joseph; Gabriel, Aileen; Schmer, Susanna; Truong, Tuyet-Trinh; Dunn, Andrew",,Journal of medical systems,48,1,89,2024,2024 Sep 18,English,7,8,"© 2024. The Author(s).Recent advancements in computing have led to the development of artificial intelligence (AI) enabled healthcare technologies. AI-assisted clinical decision support (CDS) integrated into electronic health records (EHR) was demonstrated to have a significant potential to improve clinical care. With the rapid proliferation of AI-assisted CDS, came the realization that a lack of careful consideration of socio-technical issues surrounding the implementation and maintenance of these tools can result in unanticipated consequences, missed opportunities, and suboptimal uptake of these potentially useful technologies. The 48-h Discharge Prediction Tool (48DPT) is a new AI-assisted EHR CDS to facilitate discharge planning. This study aimed to methodologically assess the implementation of 48DPT and identify the barriers and facilitators of adoption and maintenance using the validated implementation science frameworks. The major dimensions of RE-AIM (Reach, Effectiveness, Adoption, Implementation, Maintenance) and the constructs of the Consolidated Framework for Implementation Research (CFIR) frameworks have been used to analyze interviews of 24 key stakeholders using 48DPT. The systematic assessment of the 48DPT implementation allowed us to describe facilitators and barriers to implementation such as lack of awareness, lack of accuracy and trust, limited accessibility, and transparency. Based on our evaluation, the factors that are crucial for the successful implementation of AI-assisted EHR CDS were identified. Future implementation efforts of AI-assisted EHR CDS should engage the key clinical stakeholders in the AI tool development from the very inception of the project, support transparency and explainability of the AI models, provide ongoing education and onboarding of the clinical users, and obtain continuous input from clinical staff on the CDS performance.",,"Department of Biomedical Informatics, University of Utah, 421 Wakara Way, Rm. 2028, Salt Lake City, UT, 84108, USA. Joseph.Finkelstein@utah.edu.; Department of Biomedical Informatics, University of Utah, 421 Wakara Way, Rm. 2028, Salt Lake City, UT, 84108, USA.; Department of Case Management, Mount Sinai Health System, New York, NY, USA.; Division of Hospital Medicine, Icahn School of Medicine at Mount Sinai, New York, NY, USA.",,,"*Artificial Intelligence. *Decision Support Systems, Clinical / organization & administration. *Electronic Health Records / organization & administration. Humans. Patient Discharge",Index Medicus,Artificial Intelligence; Clinical Decision Support; Electronic Health Record; Implementation Science; Socio-Technical Factors,,,,,,Health Care Sciences & Services; Medical Informatics; Computer Science (provided by Clarivate Analytics),1573-689X,7806056,United States,R33 HL143317 / NHLBI NIH HHSUnited States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI). R33HL143317 / NHLBI NIH HHSUnited States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI),,MEDLINE,,,/ 18 Sep 2024 / 05 Feb 2025,,18 Sep 2024,,10.1007/s10916-024-02104-9,hybrid,,,2025-05-29,MEDLINE:39292314
J,39766395,Journal Article,Decoding Schizophrenia: How AI-Enhanced fMRI Unlocks New Pathways for Precision Psychiatry.,,"Di Stefano, Valeria; D'Angelo, Martina; Monaco, Francesco; Vignapiano, Annarita; Martiadis, Vassilis; Barone, Eugenia; Fornaro, Michele; Steardo, Luca; Solmi, Marco; Manchia, Mirko; Steardo, Luca Jr",,Brain sciences,14,12,,2024,2024 Nov 27,English,4,4,"Schizophrenia, a highly complex psychiatric disorder, presents significant challenges in diagnosis and treatment due to its multifaceted neurobiological underpinnings. Recent advancements in functional magnetic resonance imaging (fMRI) and artificial intelligence (AI) have revolutionized the understanding and management of this condition. This manuscript explores how the integration of these technologies has unveiled key insights into schizophrenia's structural and functional neural anomalies. fMRI research highlights disruptions in crucial brain regions like the prefrontal cortex and hippocampus, alongside impaired connectivity within networks such as the default mode network (DMN). These alterations correlate with the cognitive deficits and emotional dysregulation characteristic of schizophrenia. AI techniques, including machine learning (ML) and deep learning (DL), have enhanced the detection and analysis of these complex patterns, surpassing traditional methods in precision. Algorithms such as support vector machines (SVMs) and Vision Transformers (ViTs) have proven particularly effective in identifying biomarkers and aiding early diagnosis. Despite these advancements, challenges such as variability in methodologies and the disorder's heterogeneity persist, necessitating large-scale, collaborative studies for clinical translation. Moreover, ethical considerations surrounding data integrity, algorithmic transparency, and patient individuality must guide AI's integration into psychiatry. Looking ahead, AI-augmented fMRI holds promise for tailoring personalized interventions, addressing unique neural dysfunctions, and improving therapeutic outcomes for individuals with schizophrenia. This convergence of neuroimaging and computational innovation heralds a transformative era in precision psychiatry.",,"Psychiatry Unit, Department of Health Sciences, University of Catanzaro Magna Graecia, 88100 Catanzaro, Italy.; Department of Mental Health, Azienda Sanitaria Locale Salerno, 84125 Salerno, Italy.; European Biomedical Research Institute of Salerno (EBRIS), 84125 Salerno, Italy.; Department of Mental Health, Azienda Sanitaria Locale (ASL) Napoli 1 Centro, 80145 Naples, Italy.; Department of Psychiatry, University of Campania Luigi Vanvitelli, 80138 Naples, Italy.; Department of Neuroscience, Reproductive Science and Odontostomatology, University of Naples Federico II, 80138 Naples, Italy.; Department of Clinical Psychology, University Giustino Fortunato, 82100 Benevento, Italy.; Department of Physiology and Pharmacology Vittorio Erspamer, SAPIENZA University of Rome, 00185 Rome, Italy.; Department of Psychiatry, University of Ottawa, Ottawa, ON K1N 6N5, Canada.; On Track: The Champlain First Episode Psychosis Program, Department of Mental Health, The Ottawa Hospital, Ottawa, ON K1H 8L6, Canada.; Clinical Epidemiology Program, Ottawa Hospital Research Institute, University of Ottawa, Ottawa, ON K1N 6N5, Canada.; School of Epidemiology and Public Health, Faculty of Medicine, University of Ottawa, Ottawa, ON K1N 6N5, Canada.; Department of Child and Adolescent Psychiatry, Charite-Universitatsmedizin, 10117 Berlin, Germany.; Section of Psychiatry, Department of Medical Sciences and Public Health, University of Cagliari, 09124 Cagliari, Italy.; Unit of Clinical Psychiatry, University Hospital Agency of Cagliari, 09123 Cagliari, Italy.; Department of Pharmacology, Dalhousie University, Halifax, NS B3H 4R2, Canada.","Steardo, Luca/AAL-6966-2020; solmi, marco/K-3906-2018; Vignapiano, Annarita/IVH-5764-2023; Manchia, Mirko/A-2907-2010; Monaco, Francesco/ADD-7161-2022; Martiadis, Vassilis/AGI-1081-2022","Manchia, Mirko/0000-0003-4175-6413; Vignapiano, Annarita/0009-0004-8301-3401; Di Stefano, Valeria/0009-0006-2333-0637; Fornaro, Michele/0000-0002-9647-0853; Monaco, Francesco/0000-0002-1854-292X; Martiadis, Vassilis/0000-0002-3344-1000",,,artificial intelligence; deep learning; fMRI; machine learning; schizophrenia,,,,,,,2076-3425,101598646,Switzerland,,,PubMed-not-MEDLINE,,,/ 08 Jan 2025,,27 Nov 2024,,10.3390/brainsci14121196,gold,,,2025-05-29,MEDLINE:39766395
J,39359529,Journal Article; Review,Application of Artificial Intelligence in Ophthalmology: An Updated Comprehensive Review.,,"Hashemian, Hesam; Peto, Tunde; Ambrosio, Renato Jr; Lengyel, Imre; Kafieh, Rahele; Muhammed Noori, Ahmed; Khorrami-Nejad, Masoud",,Journal of ophthalmic & vision research,19,3,354-367,2024,2024,English,12,13,"Copyright © 2024 Hashemian et al.Artificial intelligence (AI) holds immense promise for transforming ophthalmic care through automated screening, precision diagnostics, and optimized treatment planning. This paper reviews recent advances and challenges in applying AI techniques such as machine learning and deep learning to major eye diseases. In diabetic retinopathy, AI algorithms analyze retinal images to accurately identify lesions, which helps clinicians in ophthalmology practice. Systems like IDx-DR (IDx Technologies Inc, USA) are FDA-approved for autonomous detection of referable diabetic retinopathy. For glaucoma, deep learning models assess optic nerve head morphology in fundus photographs to detect damage. In age-related macular degeneration, AI can quantify drusen and diagnose disease severity from both color fundus and optical coherence tomography images. AI has also been used in screening for retinopathy of prematurity, keratoconus, and dry eye disease. Beyond screening, AI can aid treatment decisions by forecasting disease progression and anti-VEGF response. However, potential limitations such as the quality and diversity of training data, lack of rigorous clinical validation, and challenges in regulatory approval and clinician trust must be addressed for the widespread adoption of AI. Two other significant hurdles include the integration of AI into existing clinical workflows and ensuring transparency in AI decision-making processes. With continued research to address these limitations, AI promises to enable earlier diagnosis, optimized resource allocation, personalized treatment, and improved patient outcomes. Besides, synergistic human-AI systems could set a new standard for evidence-based, precise ophthalmic care.",,"Translational Ophthalmology Research Center, Farabi Eye Hospital, Tehran University of Medical Sciences, Tehran, Iran.; School of Medicine, Dentistry and Biomedical Sciences, Centre for Public Health, Queen's University Belfast, Northern Ireland, UK.; Department of Ophthalmology, Federal University the State of Rio de Janeiro (UNIRIO), Brazil.; Department of Ophthalmology, Federal University of Sao Paulo, Sao Paulo, Brazil.; Brazilian Study Group of Artificial Intelligence and Corneal Analysis - BrAIN, Rio de Janeiro & Maceio, Brazil.; Rio Vision Hospital, Rio de Janeiro, Brazil.; Instituto de Olhos Renato Ambrosio, Rio de Janeiro, Brazil.; School of Medicine, Dentistry and Biomedical Sciences, Queen's University Belfast, Northern Ireland.; Department of Engineering, Durham University, United Kingdom.; School of Rehabilitation, Tehran University of Medical Sciences, Tehran, Iran.; Department of Optical Techniques, Al-Mustaqbal University College, Hillah, Babylon 51001, Iraq.","Peto, Tunde/G-8812-2018; Khorrami-Nejad, Masoud/AAG-1993-2021; Ambrosio, Renato/AAI-6715-2020; Ambrosio Jr, Renato/H-6504-2017; Peto, Tunde/M-2081-2013; kafieh, rahele/E-6456-2012; Lengyel, Imre/B-5217-2009; Hashemian, Hesam/M-3740-2013","Ambrosio Jr, Renato/0000-0001-6919-4606; Peto, Tunde/0000-0001-6265-0381; kafieh, rahele/0000-0003-0087-9476; Lengyel, Imre/0000-0001-7467-2174; Khorrami-Nejad, Masoud/0000-0002-8270-9704; Ghanim, Ahmed/0009-0004-3894-6309; Hashemian, Hesam/0000-0003-0836-8937",,,Ophthalmology; Prognosis; Screening; Treatment; Artificial Intelligence,,,,,,,2008-2010,101497643,United Arab Emirates,,,PubMed-not-MEDLINE,,,/ 09 Nov 2024,,16 Sep 2024,,10.18502/jovr.v19i3.15893,gold,,,2025-05-29,MEDLINE:39359529
J,38781432,Journal Article,Understanding Human Cognition Through Computational Modeling.,,"Hsiao, Janet Hui-Wen",,Topics in cognitive science,16,3,349-376,2024,2024 Jul (Epub 2024 May 23),English,11,27,"© 2024 The Author(s). Topics in Cognitive Science published by Wiley Periodicals LLC on behalf of Cognitive Science Society.One important goal of cognitive science is to understand the mind in terms of its representational and computational capacities, where computational modeling plays an essential role in providing theoretical explanations and predictions of human behavior and mental phenomena. In my research, I have been using computational modeling, together with behavioral experiments and cognitive neuroscience methods, to investigate the information processing mechanisms underlying learning and visual cognition in terms of perceptual representation and attention strategy. In perceptual representation, I have used neural network models to understand how the split architecture in the human visual system influences visual cognition, and to examine perceptual representation development as the results of expertise. In attention strategy, I have developed the Eye Movement analysis with Hidden Markov Models method for quantifying eye movement pattern and consistency using both spatial and temporal information, which has led to novel findings across disciplines not discoverable using traditional methods. By integrating it with deep neural networks (DNN), I have developed DNN+HMM to account for eye movement strategy learning in human visual cognition. The understanding of the human mind through computational modeling also facilitates research on artificial intelligence's (AI) comparability with human cognition, which can in turn help explainable AI systems infer humans' belief on AI's operations and provide human-centered explanations to enhance human-AI interaction and mutual understanding. Together, these demonstrate the essential role of computational modeling methods in providing theoretical accounts of the human mind as well as its interaction with its environment and AI systems.",,"Division of Social Science, Hong Kong University of Science and Technology.","Hsiao, Janet/KMY-8634-2024; Hsiao, Janet Hui-wen/D-4916-2009","Hsiao, Janet Hui-wen/0000-0003-2271-8710","Artificial Intelligence. Attention / physiology. *Cognition / physiology. Computer Simulation. Eye Movements / physiology. Humans. Learning / physiology. *Neural Networks, Computer. Visual Perception / physiology",Index Medicus,Computational modeling; Deep neural network; Explainable artificial intelligence; Eye movement; Hidden Markov model; Human learning; Machine learning; Psycholinguistics; Visual cognition,,,,,,Psychology; Behavioral Sciences; Ophthalmology; Computer Science (provided by Clarivate Analytics),1756-8765,101506764,United States,/ Huawei TechnologiesHuawei Technologies. / Research Grant Council (Hong Kong)Hong Kong Research Grants Council,,MEDLINE,,,/ 16 Jul 2024 / 16 Jul 2024,,23 May 2024,,10.1111/tops.12737,hybrid,,,2025-05-29,MEDLINE:38781432
J,38984198,Journal Article; Review,Joining forces for pathology diagnostics with AI assistance: The EMPAIA initiative.,,"Zerbe, Norman; Schwen, Lars Ole; GeiSSler, Christian; Wiesemann, Katja; Bisson, Tom; Boor, Peter; Carvalho, Rita; Franz, Michael; Jansen, Christoph; Kiehl, Tim-Rasmus; Lindequist, Bjorn; Pohlan, Nora Charlotte; Schmell, Sarah; Strohmenger, Klaus; Zakrzewski, Falk; Plass, Markus; Takla, Michael; Kuster, Tobias; Homeyer, Andre; Hufnagl, Peter",,Journal of pathology informatics,15,,100387,2024,2024 Dec,English,0,0,"© 2024 The Author(s).Over the past decade, artificial intelligence (AI) methods in pathology have advanced substantially. However, integration into routine clinical practice has been slow due to numerous challenges, including technical and regulatory hurdles in translating research results into clinical diagnostic products and the lack of standardized interfaces. The open and vendor-neutral EMPAIA initiative addresses these challenges. Here, we provide an overview of EMPAIA's achievements and lessons learned. EMPAIA integrates various stakeholders of the pathology AI ecosystem, i.e., pathologists, computer scientists, and industry. In close collaboration, we developed technical interoperability standards, recommendations for AI testing and product development, and explainability methods. We implemented the modular and open-source EMPAIA Platform and successfully integrated 14 AI-based image analysis apps from eight different vendors, demonstrating how different apps can use a single standardized interface. We prioritized requirements and evaluated the use of AI in real clinical settings with 14 different pathology laboratories in Europe and Asia. In addition to technical developments, we created a forum for all stakeholders to share information and experiences on digital pathology and AI. Commercial, clinical, and academic stakeholders can now adopt EMPAIA's common open-source interfaces, providing a unique opportunity for large-scale standardization and streamlining of processes. Further efforts are needed to effectively and broadly establish AI assistance in routine laboratory use. To this end, a sustainable infrastructure, the non-profit association EMPAIA International, has been established to continue standardization and support broad implementation and advocacy for an AI-assisted digital pathology future.",,"Charite-Universitatsmedizin Berlin, Corporate Member of Freie Universitat Berlin and Humboldt-Universitat zu Berlin, Institute of Pathology, Chariteplatz 1, 10117 Berlin, Germany.; Fraunhofer Institute for Digital Medicine MEVIS, Max-von-Laue-StraSSe 2, 28359 Bremen, Germany.; Technische Universitat Berlin, DAI-Labor, Ernst-Reuter-Platz 7, 10587 Berlin, Germany.; QuIP GmbH, ReinhardtstraSSe 1, 10117 Berlin, Germany.; Institute of Pathology, University Hospital RWTH Aachen, PauwelsstraSSe 30, 52074 Aachen, Germany.; Institute of Pathology, Carl Gustav Carus University Hospital Dresden (UKD), TU Dresden (TUD), FetscherstraSSe 74, 01307 Dresden, Germany.; Medical University of Graz, Diagnostic and Research Center for Molecular BioMedicine, Diagnostic & Research Institute of Pathology, Neue Stiftingtalstrasse 6, 8010 Graz, Austria.; Vitasystems GmbH, Gottlieb-Daimler-StraSSe 8, 68165 Mannheim, Germany.",,"Bisson, Tom/0000-0002-7743-0792; Homeyer, Andre/0000-0002-9910-7136; Zerbe, Norman/0000-0002-0314-3037; Lindequist, Bjorn/0000-0001-9521-0964",,,Artificial intelligence; Digital pathology; Explainability; Interoperability; Standardization; Validation of algorithms,,,,,,,2229-5089,101528849,United States,,,PubMed-not-MEDLINE,,,/ 11 Jul 2024,,31 May 2024,,10.1016/j.jpi.2024.100387,"Green Published, Green Submitted, gold",,,2025-05-29,MEDLINE:38984198
J,39286480,Journal Article,Trusted artificial intelligence for environmental assessments: An explainable high-precision model with multi-source big data.,,"Xu, Haoli; Yang, Xing; Hu, Yihua; Wang, Daqing; Liang, Zhenyu; Mu, Hua; Wang, Yangyang; Shi, Liang; Gao, Haoqi; Song, Daoqing; Cheng, Zijian; Lu, Zhao; Zhao, Xiaoning; Lu, Jun; Wang, Bingwen; Hu, Zhiyang",,Environmental science and ecotechnology,22,,100479,2024,2024 Nov,English,27,39,"© 2024 The Authors.Environmental assessments are critical for ensuring the sustainable development of human civilization. The integration of artificial intelligence (AI) in these assessments has shown great promise, yet the black box nature of AI models often undermines trust due to the lack of transparency in their decision-making processes, even when these models demonstrate high accuracy. To address this challenge, we evaluated the performance of a transformer model against other AI approaches, utilizing extensive multivariate and spatiotemporal environmental datasets encompassing both natural and anthropogenic indicators. We further explored the application of saliency maps as a novel explainability tool in multi-source AI-driven environmental assessments, enabling the identification of individual indicators' contributions to the model's predictions. We find that the transformer model outperforms others, achieving an accuracy of about 98% and an area under the receiver operating characteristic curve (AUC) of 0.891. Regionally, the environmental assessment values are predominantly classified as level II or III in the central and southwestern study areas, level IV in the northern region, and level V in the western region. Through explainability analysis, we identify that water hardness, total dissolved solids, and arsenic concentrations are the most influential indicators in the model. Our AI-driven environmental assessment model is accurate and explainable, offering actionable insights for targeted environmental management. Furthermore, this study advances the application of AI in environmental science by presenting a robust, explainable model that bridges the gap between machine learning and environmental governance, enhancing both understanding and trust in AI-assisted environmental assessments.",,"State Key Laboratory of Pulsed Power Laser, College of Electronic Engineering, National University of Defense Technology, Hefei, 230037, China.; Jianghuai Advance Technology Center, Hefei, 230000, China.; Key Laboratory of Electronic Restriction of Anhui Province, Hefei, 230037, China.; Defense Engineering College, Army Engineering University of PLA, Nanjing, 210007, China.; International Studies College, National University of Defense Technology, Nanjing, 210000, China.; School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, 230009, China.","Liang, Eric/KFB-4301-2024; wang, bingwen/LWI-7141-2024; Lu, Jun/ADG-9339-2022; Hu, Yihua/ABD-5053-2021; Yang, Xing/HHS-6130-2022; 高, 皓琪/HCH-9081-2022; Hu, Zhiyang/LJL-5964-2024","Wang, Bingwen/0000-0003-2612-9120",,,Explainable AI; Intelligent environmental assessment; Multi-source data; Transformer,,,,,,,2666-4984,9.91845E+15,Netherlands,,,PubMed-not-MEDLINE,,,/ 18 Sep 2024,,23 Aug 2024,,10.1016/j.ese.2024.100479,"Green Published, gold",,,2025-05-29,MEDLINE:39286480
J,39626596,Journal Article,An AI-assisted explainable mTMCNN architecture for detection of mandibular third molar presence from panoramic radiography.,,"Kayadibi, Ismail; Kose, Utku; Guraksin, Gur Emre; Cetin, Bilgun",,International journal of medical informatics,195,,105724,2025,2025 Mar (Epub 2024 Nov 23),English,7,7,"Copyright © 2024 Elsevier B.V. All rights reserved.OBJECTIVE: This study aimed to design and systematically evaluate an architecture, proposed as the Explainable Mandibular Third Molar Convolutional Neural Network (E-mTMCNN), for detecting the presence of mandibular third molars (m-M3) in panoramic radiography (PR). The proposed architecture seeks to enhance the accuracy of early detection and improve clinical decision-making and treatment planning in dentistry.METHODS: A new dataset, named the Mandibular Third Molar (m-TM) dataset, was developed through expert labeling of raw PR images from the UESB dataset. This dataset was subsequently made publicly accessible to support further research. Several advanced image preprocessing techniques, including Gaussian filtering, gamma correction, and data augmentation, were applied to improve image quality. Various Deep learning (DL) based Convolutional Neural Network (CNN) architectures were trained and validated using Transfer Learning (TL) methodologies. Among these, the E-mTMCNN, leveraging the GoogLeNet architecture, achieved the highest performance metrics. To ensure transparency in the model's decision-making process, Local Interpretable Model-Agnostic Explanations (LIME) were integrated as an eXplainable Artificial Intelligence (XAI) approach. Clinical reliability and applicability were assessed through an expert survey conducted among specialized dentists using a decision support system based on the E-mTMCNN.RESULTS: The E-mTMCNN architecture demonstrated a classification accuracy of 87.02%, with a sensitivity of 75%, specificity of 94.73%, precision of 77.68%, an F1 score of 75.51%, and an area under the curve (AUC) of 87.01%. The integration of LIME provided visual explanations of the model's decision-making rationale, reinforcing the robustness of the proposed architecture. Results from the expert survey indicated high clinical acceptance and confidence in the reliability of the system.CONCLUSION: The findings demonstrate that the E-mTMCNN architecture effectively detects the presence of m-M3 in PRs, outperforming current state-of-the-art methodologies. The proposed architecture shows considerable potential for integration into computer-aided diagnostic systems, advancing early detection capabilities and enhancing the precision of treatment planning in dental practice.",,"Department of Computer Engineering, Faculty of Engineering and Natural Sciences, Suleyman Demirel University, Isparta, Turkey; Department of Management Information Systems, Faculty of Economic and Administrative Sciences, Afyon Kocatepe University, Afyonkarahisar, Turkey. Electronic address: ikayadibi@aku.edu.tr.; Department of Computer Engineering, Faculty of Engineering and Natural Sciences, Suleyman Demirel University, Isparta, Turkey. Electronic address: utkukose@sdu.edu.tr.; Department of Computer Engineering, Faculty of Engineering, Afyon Kocatepe University, Afyonkarahisar, Turkey. Electronic address: emreguraksin@aku.edu.tr.; Department of Oral and Maxillofacial Radiology, Faculty of Dentistry, Selcuk University, Konya, Turkey. Electronic address: bcetin@selcuk.edu.tr.","Kose, Utku/C-8683-2009; CETIN, Bilgun/IZQ-2110-2023; Kayadibi, Ismail/JQW-3761-2023; Guraksin, Gur/ABI-3335-2020","Kayadibi, Ismail/0000-0002-1949-8211","Deep Learning. Humans. *Mandible / diagnostic imaging. *Molar, Third / diagnostic imaging. *Neural Networks, Computer. *Radiography, Panoramic / methods",Index Medicus,Convolutional Neural Network; Decision Support Systems; Mandibular Third Molar; Panoramic Radiography; eXplainable Artificial Intelligence,,,,,,"Radiology, Nuclear Medicine & Medical Imaging; Dentistry, Oral Surgery & Medicine (provided by Clarivate Analytics)",1872-8243,9711057,Ireland,,,MEDLINE,,,/ 26 Apr 2025 / 26 Apr 2025,,23 Nov 2024,,10.1016/j.ijmedinf.2024.105724,,,,2025-05-29,MEDLINE:39626596
J,39048726,Journal Article,Explainable AI decision support improves accuracy during telehealth strep throat screening.,,"Gomez, Catalina; Smith, Brittany-Lee; Zayas, Alisa; Unberath, Mathias; Canares, Therese",,Communications medicine,4,1,149,2024,2024 Jul 24,English,3,4,"© 2024. The Author(s).BACKGROUND: Artificial intelligence-based (AI) clinical decision support systems (CDSS) using unconventional data, like smartphone-acquired images, promise transformational opportunities for telehealth; including remote diagnosis. Although such solutions' potential remains largely untapped, providers' trust and understanding are vital for effective adoption. This study examines how different human-AI interaction paradigms affect clinicians' responses to an emerging AI CDSS for streptococcal pharyngitis (strep throat) detection from smartphone throat images.METHODS: In a randomized experiment, we tested explainable AI strategies using three AI-based CDSS prototypes for strep throat prediction. Participants received clinical vignettes via an online survey to predict the disease state and offer clinical recommendations. The first set included a validated CDSS prediction (Modified Centor Score) and the second introduced an explainable AI prototype randomly. We used linear models to assess explainable AI's effect on clinicians' accuracy, confirmatory testing rates, and perceived trust and understanding of the CDSS.RESULTS: The study, involving 121 telehealth providers, shows that compared to using the Centor Score, AI-based CDSS can improve clinicians' predictions. Despite higher agreement with AI, participants report lower trust in its advice than in the Centor Score, leading to more requests for in-person confirmatory testing.CONCLUSIONS: Effectively integrating AI is crucial in the telehealth-based diagnosis of infectious diseases, given the implications of antibiotic over-prescriptions. We demonstrate that AI-based CDSS can improve the accuracy of remote strep throat screening yet underscores the necessity to enhance human-machine collaboration, particularly in trust and intelligibility. This ensures providers and patients can capitalize on AI interventions and smartphones for virtual healthcare.","Strep pharyngitis, or strep throat, is a bacterial infection that can cause a sore throat. Artificial intelligence (AI) can use photos taken on a persons phone to help diagnose strep throat, offering an additional way for doctors to screen patients during virtual appointments. However, it is currently unclear whether doctors will trust AI recommendations or how they might use them in decision-making. We surveyed clinicians about their use of an AI system for strep throat screening with smartphone images. We compared different ways of providing AI recommendations to standard medical guidelines. We found that all testedAImethods helped clinicians to identify strep throat cases. However, clinicians trusted AI less than their usual clinical guidelines, leading to more requests for follow-up in-person testing. Our results show how AI may improve the accuracy of pharyngitis assessment. Still, further research is needed to ensure doctors trust and collaborate with AI to improve remote healthcare.","Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA.; Johns Hopkins University School of Medicine, Baltimore, MD, USA.; Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA. unberath@jhu.edu.; Johns Hopkins University School of Medicine, Baltimore, MD, USA. unberath@jhu.edu.; Division of Pediatric Emergency Medicine, Johns Hopkins University School of Medicine, Baltimore, MD, USA.","Canares, Therese/AAP-7384-2020","Canares, Therese/0000-0001-9877-4028; Smith, Brittany-Lee/0000-0002-7880-993X",,,,,,,,,,2730-664X,9.91825E+15,England,,,PubMed-not-MEDLINE,,,/ 29 Jul 2024,,24 Jul 2024,,10.1038/s43856-024-00568-x,"Green Published, gold",,,2025-05-29,MEDLINE:39048726
J,37905780,Journal Article,Responsible use of AI in military systems: prospects and challenges.,,"Schraagen, Jan Maarten",,Ergonomics,66,11,1719-1729,2023,2023 Nov (Epub 2024 Jan 02),English,8,32,"Artificial Intelligence (AI) holds great potential for the military domain but is also seen as prone to data bias and lacking transparency and explainability. In order to advance the trustworthiness of AI-enabled systems, a dynamic approach to the development, deployment and use of AI systems is required. This approach, when incorporating ethical principles such as lawfulness, traceability, reliability and bias mitigation, is called 'Responsible AI'. This article describes the challenges of using AI responsibly in the military domain from a human factors and ergonomics perspective. Many of the ironies of automation originally described by Bainbridge still apply in the field of AI, but there are also some unique challenges and requirements that need to be considered, such as a larger emphasis on ethical risk analyses and validation and verification up-front, as well as moral situation awareness during deployment and use of AI in military systems.","Responsible AI is a relatively novel transdisciplinary field incorporating ethical principles in the development and use of AI in military systems. I describe the prospects and challenges with Responsible AI from a human factors and ergonomics perspective. There is in particular a need for new methods for testing and evaluation, validation and verification, explainability and transparency of AI, as well as for new ways of Human-AI Teaming.","Human-Machine Teaming, TNO Locatie Soesterberg, Soesterberg, The Netherlands.","Schraagen, Jan/K-4391-2019","Schraagen, Jan Maarten/0009-0005-5503-8000",*Artificial Intelligence. Automation. Awareness. Humans. *Military Personnel. Reproducibility of Results,Index Medicus,Artificial Intelligence; ethics; explainability; human-machine teaming; military systems; testing and evaluation; transparency; validation and verification,,,,,,Computer Science; Automation & Control Systems; Psychology; Behavioral Sciences (provided by Clarivate Analytics),1366-5847,373220,England,,,MEDLINE,,,/ 03 Jan 2024 / 03 Jan 2024,,02 Jan 2024,,10.1080/00140139.2023.2278394,,,,2025-05-29,MEDLINE:37905780
J,37891803,Journal Article,"The Projective Consciousness Model: Projective Geometry at the Core of Consciousness and the Integration of Perception, Imagination, Motivation, Emotion, Social Cognition and Action.",,"Rudrauf, David; Sergeant-Perthuis, Gregoire; Tisserand, Yvain; Poloudenny, Germain; Williford, Kenneth; Amorim, Michel-Ange",,Brain sciences,13,10,,2023,2023 Oct 09,English,4,12,"Consciousness has been described as acting as a global workspace that integrates perception, imagination, emotion and action programming for adaptive decision making. The mechanisms of this workspace and their relationships to the phenomenology of consciousness need to be further specified. Much research in this area has focused on the neural correlates of consciousness, but, arguably, computational modeling can better be used toward this aim. According to the Projective Consciousness Model (PCM), consciousness is structured as a viewpoint-organized, internal space, relying on 3D projective geometry and governed by the action of the Projective Group as part of a process of active inference. The geometry induces a group-structured subjective perspective on an encoded world model, enabling adaptive perspective taking in agents. Here, we review and discuss the PCM. We emphasize the role of projective mechanisms in perception and the appraisal of affective and epistemic values as tied to the motivation of action, under an optimization process of Free Energy minimization, or more generally stochastic optimal control. We discuss how these mechanisms enable us to model and simulate group-structured drives in the context of social cognition and to understand the mechanisms underpinning empathy, emotion expression and regulation, and approach-avoidance behaviors. We review previous results, drawing on applications in robotics and virtual humans. We briefly discuss future axes of research relating to applications of the model to simulation- and model-based behavioral science, geometrically structured artificial neural networks, the relevance of the approach for explainable AI and human-machine interactions, and the study of the neural correlates of consciousness.",,"CIAMS, Universite Paris-Saclay, 91405 Orsay, France.; CIAMS, Universite d'Orleans, 45067 Orleans, France.; Laboratoire de Biologie Computationnelle et Quantitative (LCQB), CNRS, IBPS, UMR 7238, Sorbonne Universite, 75005 Paris, France.; IMJ-PRG, Inria Paris-Ouragan Project-Team, Sorbonne University, 75005 Paris, France.; CISA, Universite de Geneve, 1202 Geneve, Switzerland.; Laboratoire de Mathematiques de Lens (LML), UR 2462, Universite d'Artois, 62300 Lens, France.; Philosophy and Humanities, University of Texas at Arlington, Arlington, TX 76019, USA.","; Amorim, Michel-Ange/E-7209-2017","Tisserand, Yvain/0000-0001-9027-6497; Amorim, Michel-Ange/0000-0002-8455-1437; Rudrauf, David/0000-0002-9621-1800; Poloudenny, Germain/0009-0003-9723-5657",,,active inference; affective value; behavioral science; computational modeling; consciousness; emotion; epistemic value; projective geometry; social cognition and communication,,,,,,,2076-3425,101598646,Switzerland,ANR-22-CPJ2-0135-01 / Agence Nationale de la RechercheAgence Nationale de la Recherche (ANR),,PubMed-not-MEDLINE,,,/ 30 Oct 2023,,09 Oct 2023,,10.3390/brainsci13101435,"Green Published, gold",,,2025-05-29,MEDLINE:37891803
J,39805194,Journal Article,Clinicians' perspectives on the use of artificial intelligence to triage MRI brain scans.,,"Din, Munaib; Daga, Karan; Saoud, Jihad; Wood, David; Kierkegaard, Patrick; Brex, Peter; Booth, Thomas C",,European journal of radiology,183,,111921,2025,2025 Feb (Epub 2025 Jan 06),English,1,1,"Copyright © 2025 The Authors. Published by Elsevier B.V. All rights reserved.Artificial intelligence (AI) tools can triage radiology scans to streamline the patient pathway and also relieve clinician workload. Validated AI tools can mitigate the delays in reporting scans by flagging time-sensitive and actionable findings. In this study, we aim to investigate current stakeholder perspectives and identify obstacles to integrating AI in clinical pathways. We created a survey to ascertain the perspectives of 133 clinicians across the United Kingdom regarding the acceptability of an AI tool that triages MRI brain scans into 'normal' and 'abnormal'. As part of this survey, we supplied clinicians with information on training and validation case numbers, model performance, validation using unseen data, and explainability saliency maps. With regards to the specific use case of AI in MRI brain scans, 71% of respondents preferred the use of an AI-assisted triage compared to the current system without triage, typically chronologically. Notably, information that explained and helped visualise the AI model's decision making was found to improve clinician confidence. When shown a heatmap, 60% of participants felt more confident in the AI's decision. The results of this short communication demonstrate a positive support for the implementation of AI-assistive tools in triage.",,"School of Biomedical Engineering & Imaging Sciences, King's College London, London, the United Kingdom of Great Britain and Northern Ireland; Department of Radiology. Guy's and St. Thomas' NHS Foundation Trust, London, United Kingdom.; School of Biomedical Engineering & Imaging Sciences, King's College London, London, the United Kingdom of Great Britain and Northern Ireland.; CRUK Convergence Science Centre, Institute for Cancer Research & Imperial College London, London, the United Kingdom of Great Britain and Northern Ireland.; Department of Neurology, King's College Hospital NHS Foundation Trust, London, the United Kingdom of Great Britain and Northern Ireland.; School of Biomedical Engineering & Imaging Sciences, King's College London, London, the United Kingdom of Great Britain and Northern Ireland; Department of Neuroradiology, King's College Hospital National Health Service Foundation Trust, London, the United Kingdom of Great Britain and Northern Ireland. Electronic address: thomas.booth@kcl.ac.uk.",,"Kierkegaard, Patrick/0000-0001-8600-7956",Adult. *Artificial Intelligence / statistics & numerical data. *Attitude of Health Personnel. *Brain / diagnostic imaging. Female. Humans. *Magnetic Resonance Imaging / methods; statistics & numerical data. Male. Surveys and Questionnaires. *Triage / methods; statistics & numerical data. United Kingdom,Index Medicus,Artificial Intelligence; Brain; MRI; Triage,,,,,,"Emergency Medicine; Radiology, Nuclear Medicine & Medical Imaging; Computer Science; Psychology; Behavioral Sciences; Neurosciences & Neurology (provided by Clarivate Analytics)",1872-7727,8106411,Ireland,,,MEDLINE,,,/ 30 Apr 2025 / 30 Apr 2025,,06 Jan 2025,,10.1016/j.ejrad.2025.111921,hybrid,,,2025-05-29,MEDLINE:39805194
J,39746202,Journal Article,"Enhancing Interpretable, Transparent, and Unobtrusive Detection of Acute Marijuana Intoxication in Natural Environments: Harnessing Smart Devices and Explainable AI to Empower Just-In-Time Adaptive Interventions: Longitudinal Observational Study.",,"Bae, Sang Won; Chung, Tammy; Zhang, Tongze; Dey, Anind K; Islam, Rahul",,JMIR AI,4,,e52270,2025,2025 Jan 02,English,2,2,"©Sang Won Bae, Tammy Chung, Tongze Zhang, Anind K Dey, Rahul Islam. Originally published in JMIR AI (https://ai.jmir.org), 02.01.2025.BACKGROUND: Acute marijuana intoxication can impair motor skills and cognitive functions such as attention and information processing. However, traditional tests, like blood, urine, and saliva, fail to accurately detect acute marijuana intoxication in real time.OBJECTIVE: This study aims to explore whether integrating smartphone-based sensors with readily accessible wearable activity trackers, like Fitbit, can enhance the detection of acute marijuana intoxication in naturalistic settings. No previous research has investigated the effectiveness of passive sensing technologies for enhancing algorithm accuracy or enhancing the interpretability of digital phenotyping through explainable artificial intelligence in real-life scenarios. This approach aims to provide insights into how individuals interact with digital devices during algorithmic decision-making, particularly for detecting moderate to intensive marijuana intoxication in real-world contexts.METHODS: Sensor data from smartphones and Fitbits, along with self-reported marijuana use, were collected from 33 young adults over a 30-day period using the experience sampling method. Participants rated their level of intoxication on a scale from 1 to 10 within 15 minutes of consuming marijuana and during 3 daily semirandom prompts. The ratings were categorized as not intoxicated (0), low (1-3), and moderate to intense intoxication (4-10). The study analyzed the performance of models using mobile phone data only, Fitbit data only, and a combination of both (MobiFit) in detecting acute marijuana intoxication.RESULTS: The eXtreme Gradient Boosting Machine classifier showed that the MobiFit model, which combines mobile phone and wearable device data, achieved 99% accuracy (area under the curve=0.99; F1-score=0.85) in detecting acute marijuana intoxication in natural environments. The F1-score indicated significant improvements in sensitivity and specificity for the combined MobiFit model compared to using mobile or Fitbit data alone. Explainable artificial intelligence revealed that moderate to intense self-reported marijuana intoxication was associated with specific smartphone and Fitbit metrics, including elevated minimum heart rate, reduced macromovement, and increased noise energy around participants.CONCLUSIONS: This study demonstrates the potential of using smartphone sensors and wearable devices for interpretable, transparent, and unobtrusive monitoring of acute marijuana intoxication in daily life. Advanced algorithmic decision-making provides valuable insight into behavioral, physiological, and environmental factors that could support timely interventions to reduce marijuana-related harm. Future real-world applications of these algorithms should be evaluated in collaboration with clinical experts to enhance their practicality and effectiveness.",,"Human-Computer Interaction and Human-Centered AI Systems Lab, AI for Healthcare Lab, Charles V. Schaefer, Jr. School of Engineering and Science, Stevens Institute of Technology, Hoboken, NJ, United States.; Institute for Health, Healthcare Policy and Aging Research, Rutgers University, Newark, NJ, United States.; Information School, University of Washington, Seattle, WA, United States.","dey, anind/B-1312-2008; Bae, Sang Won/ABF-7315-2020","Islam, Mohammad Rahul/0000-0003-3601-0078; Dey, Anind K./0000-0002-3004-0770; Bae, Sang Won/0000-0002-2047-1358; Zhang, Tongze/0000-0002-3375-7136",,,Fitbit; JITAI; XAI; XGBoost; algorithmic decision-making process; artificial intelligence; cannabis; data collection; decision support; digital phenotyping; eXtreme Gradient Boosting Machine classifier; experience sampling; explainable artificial intelligence; intoxication; just-in-time adaptive interventions; mHealth; machine learning; marijuana; passive sensing; smart devices; smartphone-based sensors; wearables,,,,,,,2817-1705,9.91865E+15,Canada,U01 DA056472 / NIDA NIH HHSUnited States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Drug Abuse (NIDA),,PubMed-not-MEDLINE,,,/ 29 Jan 2025,,02 Jan 2025,,10.2196/52270,"gold, Green Published",,,2025-05-29,MEDLINE:39746202
J,39730794,Journal Article,Explainable AI improves task performance in human-AI collaboration.,,"Senoner, Julian; Schallmoser, Simon; Kratzwald, Bernhard; Feuerriegel, Stefan; Netland, Torbjorn",,Scientific reports,14,1,31150,2024,2024 12 28,English,66,66,"© 2024. The Author(s).Artificial intelligence (AI) provides considerable opportunities to assist human work. However, one crucial challenge of human-AI collaboration is that many AI algorithms operate in a black-box manner where the way how the AI makes predictions remains opaque. This makes it difficult for humans to validate a prediction made by AI against their own domain knowledge. For this reason, we hypothesize that augmenting humans with explainable AI improves task performance in human-AI collaboration. To test this hypothesis, we implement explainable AI in the form of visual heatmaps in inspection tasks conducted by domain experts. Visual heatmaps have the advantage that they are easy to understand and help to localize relevant parts of an image. We then compare participants that were either supported by (a)black-box AI or (b)explainable AI, where the latter supports them to follow AI predictions when the AI is accurate or overrule the AI when the AI predictions are wrong. We conducted two preregistered experiments with representative, real-world visual inspection tasks from manufacturing and medicine. The first experiment was conducted with factory workers from an electronics factory, who performed [Formula: see text] assessments of whether electronic products have defects. The second experiment was conducted with radiologists, who performed [Formula: see text] assessments of chest X-ray images to identify lung lesions. The results of our experiments with domain experts performing real-world tasks show that task performance improves when participants are supported by explainable AI with heatmaps instead of black-box AI. We find that explainable AI as a decision aid improved the task performance by 7.7 percentage points (95% confidence interval [CI]: 3.3% to 12.0%, [Formula: see text]) in the manufacturing experiment and by 4.7 percentage points (95% CI: 1.1% to 8.3%, [Formula: see text]) in the medical experiment compared to black-box AI. These gains represent a significant improvement in task performance.",,"ETH Zurich, Zurich, Switzerland.; EthonAI, Zurich, Switzerland.; LMU Munich, Munich, Germany.; Munich Center for Machine Learning (MCML), Munich, Germany.; ETH Zurich, Zurich, Switzerland. tnetland@ethz.ch.","Feuerriegel, Stefan/ABD-6599-2021; Netland, Torbjorn/C-4944-2013",,Adult. Algorithms. *Artificial Intelligence. Female. Humans. Male. *Task Performance and Analysis,Index Medicus,Decision-making; Explainable AI; Human-centered AI; Human-AI collaboration; Task performance,,,,,,Computer Science; Behavioral Sciences; Psychology; Mathematics (provided by Clarivate Analytics),2045-2322,101563288,England,186932 / Schweizerischer Nationalfonds zur Forderung der Wissenschaftlichen Forschung,,MEDLINE,,,/ 28 Dec 2024 / 04 Jan 2025,,28 Dec 2024,,10.1038/s41598-024-82501-9,gold,,,2025-05-29,MEDLINE:39730794
J,38437598,Journal Article,More Is Not Always Better: Impacts of AI-Generated Confidence and Explanations in Human-Automation Interaction.,,"Ling, Shihong; Zhang, Yutong; Du, Na",,Human factors,66,12,2606-2620,2024,2024 12 (Epub 2024 Mar 04),English,33,80,"OBJECTIVE: The study aimed to enhance transparency in autonomous systems by automatically generating and visualizing confidence and explanations and assessing their impacts on performance, trust, preference, and eye-tracking behaviors in human-automation interaction.BACKGROUND: System transparency is vital to maintaining appropriate levels of trust and mission success. Previous studies presented mixed results regarding the impact of displaying likelihood information and explanations, and often relied on hand-created information, limiting scalability and failing to address real-world dynamics.METHOD: We conducted a dual-task experiment involving 42 university students who operated a simulated surveillance testbed with assistance from intelligent detectors. The study used a 2 (confidence visualization: yes vs. no) * 3 (visual explanations: none, bounding boxes, bounding boxes and keypoints) mixed design. Task performance, human trust, preference for intelligent detectors, and eye-tracking behaviors were evaluated.RESULTS: Visual explanations using bounding boxes and keypoints improved detection task performance when confidence was not displayed. Meanwhile, visual explanations enhanced trust and preference for the intelligent detector, regardless of the explanation type. Confidence visualization did not influence human trust in and preference for the intelligent detector. Moreover, both visual information slowed saccade velocities.CONCLUSION: The study demonstrated that visual explanations could improve performance, trust, and preference in human-automation interaction without confidence visualization partially by changing the search strategies. However, excessive information might cause adverse effects.APPLICATION: These findings provide guidance for the design of transparent automation, emphasizing the importance of context-appropriate and user-centered explanations to foster effective human-machine collaboration.",,"University of Pittsburgh, USA.","Du, Na/AAS-1588-2021","Ling, Shihong/0009-0008-1414-2436; DU, NA/0000-0002-4383-2451; Zhang, Yutong/0009-0006-6923-7403",Adult. *Artificial Intelligence. Eye-Tracking Technology. Female. Humans. Male. *Man-Machine Systems. Task Performance and Analysis. *Trust. Young Adult,Index Medicus,explainable artificial intelligence; eye-tracking analysis; human-automation interaction; task performance; transparency; trust,,,,,,Psychology; Behavioral Sciences; Engineering; Computer Science (provided by Clarivate Analytics),1547-8181,374660,United States,,,MEDLINE,,,/ 15 Oct 2024 / 05 Nov 2024,,04 Mar 2024,,10.1177/00187208241234810,,,,2025-05-29,MEDLINE:38437598
J,39968162,Journal Article,Factors influencing trust in algorithmic decision-making: an indirect scenario-based experiment.,,"Marmolejo-Ramos, Fernando; Marrone, Rebecca; Korolkiewicz, Malgorzata; Gabriel, Florence; Siemens, George; Joksimovic, Srecko; Yamada, Yuki; Mori, Yuki; Rahwan, Talal; Sahakyan, Maria; Sonna, Belona; Meirmanov, Assylbek; Bolatov, Aidos; Som, Bidisha; Ndukaihe, Izuchukwu; Arinze, Nwadiogo C; Kundrat, Josef; Skanderova, Lenka; Ngo, Van-Giang; Nguyen, Giang; Lacia, Michelle; Kung, Chun-Chia; Irmayanti, Meiselina; Muktadir, Abdul; Samosir, Fransiska Timoria; Liuzza, Marco Tullio; Giorgini, Roberto; Khatin-Zadeh, Omid; Banaruee, Hassan; Ozdogru, Asil Ali; Ariyabuddhiphongs, Kris; Rakchai, Wachirawit; Trujillo, Natalia; Valencia, Stella Maris; Janyan, Armina; Kostov, Kiril; Montoro, Pedro R; Hinojosa, Jose; Medeiros, Kelsey; Hunt, Thomas E; Posada, Julian; Freitag, Raquel Meister Ko; Tejada, Julian",,Frontiers in artificial intelligence,7,,1465605,2024,2024,English,6,6,"Copyright © 2025 Marmolejo-Ramos, Marrone, Korolkiewicz, Gabriel, Siemens, Joksimovic, Yamada, Mori, Rahwan, Sahakyan, Sonna, Meirmanov, Bolatov, Som, Ndukaihe, Arinze, Kundrat, Skanderova, Ngo, Nguyen, Lacia, Kung, Irmayanti, Muktadir, Samosir, Liuzza, Giorgini, Khatin-Zadeh, Banaruee, Ozdogru, Ariyabuddhiphongs, Rakchai, Trujillo, Valencia, Janyan, Kostov, Montoro, Hinojosa, Medeiros, Hunt, Posada, Freitag and Tejada.Algorithms are involved in decisions ranging from trivial to significant, but people often express distrust toward them. Research suggests that educational efforts to explain how algorithms work may help mitigate this distrust. In a study of 1,921 participants from 20 countries, we examined differences in algorithmic trust for low-stakes and high-stakes decisions. Our results suggest that statistical literacy is negatively associated with trust in algorithms for high-stakes situations, while it is positively associated with trust in low-stakes scenarios with high algorithm familiarity. However, explainability did not appear to influence trust in algorithms. We conclude that having statistical literacy enables individuals to critically evaluate the decisions made by algorithms, data and AI, and consider them alongside other factors before making significant life decisions. This ensures that individuals are not solely relying on algorithms that may not fully capture the complexity and nuances of human behavior and decision-making. Therefore, policymakers should consider promoting statistical/AI literacy to address some of the complexities associated with trust in algorithms. This work paves the way for further research, including the triangulation of data with direct observations of user interactions with algorithms or physiological measures to assess trust more accurately.",,"College of Education, Psychology, and Social Work, Flinders University, Adelaide, SA, Australia.; Centre for Change and Complexity in Learning, University of South Australia, Adelaide, SA, Australia.; Faculty of Arts and Science, Kyushu University, Fukuoka, Japan.; Graduate School of Human-Environment Studies, Kyushu University, Fukuoka, Japan.; Computer Science, Science Division, New York University Abu Dhabi, Abu Dhabi, United Arab Emirates.; African Masters of Machine Intelligence (AMMI), African Institute for Mathematical Sciences (AIMS), Limbe, Cameroon.; Higher Schools, Pedagogical Institute, Astana International University, Astana, Kazakhstan.; Department of General and Biological Chemistry, Astana Medical University, Astana, Kazakhstan.; Department of Humanities and Social Science, Indian Institute of Technology Guwahati, Guwahati, Assam, India.; Department of Psychology, Alex Ekwueme Federal University Ndufu-Alike, Ebonyi, Nigeria.; Department of Psychology, Faculty of Arts, University of Ostrava, Ostrava, Czechia.; Department of Computer Science, Faculty of Electrical Engineering and Computer Science, Technical University of Ostrava, Ostrava, Czechia.; Department of English, Hanoi University, Hanoi, Vietnam.; College of Arts and Sciences, Notre Dame University, Cotabato, Philippines.; Department of Psychology, National Cheng Kung University, Tainan, Taiwan.; Department of Communication, University of Bengkulu, Bengkulu, Indonesia.; Principles and Implication of Mind Sciences, Psychology Program, National Cheng Kung University, Tainan, Taiwan.; Postgraduate Program of Basic Education, University of Bengkulu, Bengkulu, Indonesia.; Library and Information Science, University of Bengkulu, Bengkulu, Indonesia.; Department of Developmental Psychology and Socialization, Universita di Padova, Padua, Italy.; Department of Medical and Surgical Sciences, Magna Graecia University of Catanzaro, Catanzaro, Italy.; School of Foreign Languages, University of Electronic Science and Technology of China, Chengdu, China.; Department of Educational Psychology, University of Education of Weingarten, Weingarten, Germany.; Department of Psychology, Marmara University, Istanbul, Turkiye.; Faculty of Psychology, Chulalongkorn University, Bangkok, Thailand.; Faculty of Public Health, University of Antioquia, Medellin, Colombia.; Department of Cognitive Science and Psychology, New Bulgarian University, Sofia, Bulgaria.; Research Centre for Cognitive Science, New Bulgarian University, Sofia, Bulgaria.; Departamento de Psicologia Basica 1, Universidad Nacional de Educacion a Distancia (UNED), Madrid, Spain.; Instituto Pluridisciplinar, Universidad Complutense de Madrid, Madrid, Spain.; Centro de Investigacion Nebrija en Cognicion (CINC), Universidad Nebrija, Madrid, Spain.; Department of Management, University of Nebraska Omaha, Omaha, NE, United States.; School of Psychology, University of Derby, Derby, United Kingdom.; Department of American Studies, Yale University, New Haven, CT, United States.; Departamento de Psicologia, Universidade Federal de Sergipe, Sao Cristovao, Brazil.","Marrone, Rebecca/AAV-1100-2020; Ndukaihe, Izuchukwu/AAI-3716-2020; Nguyen, Giang/S-3291-2016; Banaruee, Hassan/T-5558-2017; Siemens, George/E-9682-2019; Marmolejo-Ramos, Fernando/D-9826-2012; Liuzza, Marco Tullio/A-9967-2012; Freitag, Raquel/E-4156-2017; Kundrat, Josef/V-6262-2018; Tejada, Julian/B-4000-2011; Gabriel, Florence/AAE-7977-2020; Ozdogru, Asil/LSK-6521-2024; Bolatov, Aidos/AAD-7418-2021; Rahwan, Talal/A-2884-2017; Yamada, Yuki/B-2671-2008; Joksimovic, Srecko/R-3093-2019; Arinze, Nwadiogo/AET-0515-2022; Korolkiewicz, Malgorzata/F-4664-2013","Marmolejo-Ramos, Fernando/0000-0003-4680-1287; Tejada, Julian/0000-0003-0275-3578; Marrone, Rebecca/0000-0002-9218-4120; Korolkiewicz, Malgorzata/0000-0001-6756-4415",,,AI; algorithms; data; explainability; statistical literacy; trust,,,,,,,2624-8212,101770551,Switzerland,,,PubMed-not-MEDLINE,,,/ 20 Feb 2025,,04 Feb 2025,,10.3389/frai.2024.1465605,gold,,,2025-05-29,MEDLINE:39968162
J,38725622,Journal Article,Development and external validation of a transfer learning-based system for the pathological diagnosis of colorectal cancer: a large emulated prospective study.,,"Yuan, Liuhong; Zhou, Henghua; Xiao, Xiao; Zhang, Xiuqin; Chen, Feier; Liu, Lin; Liu, Jingjia; Bao, Shisan; Tao, Kun",,Frontiers in oncology,14,,1365364,2024,2024,English,4,4,"Copyright © 2024 Yuan, Zhou, Xiao, Zhang, Chen, Liu, Liu, Bao and Tao.Background: The progress in Colorectal cancer (CRC) screening and management has resulted in an unprecedented caseload for histopathological diagnosis. While artificial intelligence (AI) presents a potential solution, the predominant emphasis on slide-level aggregation performance without thorough verification of cancer in each location, impedes both explainability and transparency. Effectively addressing these challenges is crucial to ensuring the reliability and efficacy of AI in histology applications.Method: In this study, we created an innovative AI algorithm using transfer learning from a polyp segmentation model in endoscopy. The algorithm precisely localized CRC targets within 0.25 mm grids from whole slide imaging (WSI). We assessed the CRC detection capabilities at this fine granularity and examined the influence of AI on the diagnostic behavior of pathologists. The evaluation utilized an extensive dataset comprising 858 consecutive patient cases with 1418 WSIs obtained from an external center.Results: Our results underscore a notable sensitivity of 90.25% and specificity of 96.60% at the grid level, accompanied by a commendable area under the curve (AUC) of 0.962. This translates to an impressive 99.39% sensitivity at the slide level, coupled with a negative likelihood ratio of <0.01, signifying the dependability of the AI system to preclude diagnostic considerations. The positive likelihood ratio of 26.54, surpassing 10 at the grid level, underscores the imperative for meticulous scrutiny of any AI-generated highlights. Consequently, all four participating pathologists demonstrated statistically significant diagnostic improvements with AI assistance.Conclusion: Our transfer learning approach has successfully yielded an algorithm that can be validated for CRC histological localizations in whole slide imaging. The outcome advocates for the integration of the AI system into histopathological diagnosis, serving either as a diagnostic exclusion application or a computer-aided detection (CADe) tool. This integration has the potential to alleviate the workload of pathologists and ultimately benefit patients.",,"Department of Pathology, Tongji Hospital, School of Medicine, Tongji University, Shanghai, China.; Department of Pathology, Tongren Hospital, School of Medicine Shanghai Jiaotong University, Shanghai, China.; Wision Ltd., Chengdu, China.; Institute of Natural Sciences, MOE-LSC, School of Mathematical Sciences, CMA-Shanghai, SJTU-Yale Joint Center for Biostatistics and Data Science, Shanghai Jiao Tong University, Shanghai, China.",,,,,AI-assisted pathological diagnosis; CRC (colorectal cancer); artificial intelligence (AI); pathological diagnosis; transfer learning,,,,,,,2234-943X,101568867,Switzerland,,,PubMed-not-MEDLINE,,,/ 11 May 2024,,25 Apr 2024,,10.3389/fonc.2024.1365364,"Green Published, gold",,,2025-05-29,MEDLINE:38725622
J,37372268,Journal Article,Shaped-Charge Learning Architecture for the Human-Machine Teams.,,"Galitsky, Boris; Ilvovsky, Dmitry; Goldberg, Saveli",,"Entropy (Basel, Switzerland)",25,6,,2023,2023 Jun 12,English,1,7,"In spite of great progress in recent years, deep learning (DNN) and transformers have strong limitations for supporting human-machine teams due to a lack of explainability, information on what exactly was generalized, and machinery to be integrated with various reasoning techniques, and weak defense against possible adversarial attacks of opponent team members. Due to these shortcomings, stand-alone DNNs have limited support for human-machine teams. We propose a Meta-learning/DNN kNN architecture that overcomes these limitations by integrating deep learning with explainable nearest neighbor learning (kNN) to form the object level, having a deductive reasoning-based meta-level control learning process, and performing validation and correction of predictions in a way that is more interpretable by peer team members. We address our proposal from structural and maximum entropy production perspectives.",,"Knowledge-Trail, San Jose, CA 93635, USA.; Computer Science Faculty, HSE University, Moscow 101000, Russia.; Department of Radiology at Massachusetts General Hospital, Boston, MA 02114, USA.","Galitsky, Boris/AAF-5611-2021","Galitsky, Boris/0000-0003-0670-8520",,,deep and nearest-neighbor learning; machine-learning support for human-machine teams; maximum entropy production; structural entropy production,,,,,,,1099-4300,101243874,Switzerland,,,PubMed-not-MEDLINE,,,/ 01 Jul 2023,,12 Jun 2023,,10.3390/e25060924,gold,,,2025-05-29,MEDLINE:37372268
J,36072654,Journal Article,Transparent human - (non-) transparent technology? The Janus-faced call for transparency in AI-based health care technologies.,,"Ott, Tabea; Dabrock, Peter",,Frontiers in genetics,13,,902960,2022,2022,English,7,20,"Copyright © 2022 Ott and Dabrock.The use of Artificial Intelligence and Big Data in health care opens up new opportunities for the measurement of the human. Their application aims not only at gathering more and better data points but also at doing it less invasive. With this change in health care towards its extension to almost all areas of life and its increasing invisibility and opacity, new questions of transparency arise. While the complex human-machine interactions involved in deploying and using AI tend to become non-transparent, the use of these technologies makes the patient seemingly transparent. Papers on the ethical implementation of AI plead for transparency but neglect the factor of the transparent patient as intertwined with AI. Transparency in this regard appears to be Janus-faced: The precondition for receiving help - e.g., treatment advice regarding the own health - is to become transparent for the digitized health care system. That is, for instance, to donate data and become visible to the AI and its operators. The paper reflects on this entanglement of transparent patients and (non-) transparent technology. It argues that transparency regarding both AI and humans is not an ethical principle per se but an infraethical concept. Further, it is no sufficient basis for avoiding harm and human dignity violations. Rather, transparency must be enriched by intelligibility following Judith Butler's use of the term. Intelligibility is understood as an epistemological presupposition for recognition and the ensuing humane treatment. Finally, the paper highlights ways to testify intelligibility in dealing with AI in health care ex ante, ex post, and continuously.",,"Chair of Systematic Theology II (Ethics), Faculty of Humanities, Social Sciences, and Theology, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.",,"Ott, Tabea/0000-0002-4247-5085",,,AI; Data; Ethics; Health Care; Infraethics; Intelligibility; Learning Systems; Transparency,,,,,,,1664-8021,101560621,Switzerland,,,PubMed-not-MEDLINE,,,/ 10 Sep 2022,,22 Aug 2022,,10.3389/fgene.2022.902960,"Green Published, gold",,,2025-05-29,MEDLINE:36072654
J,40224528,Journal Article; Review,Artificial intelligence for early detection of diabetes mellitus complications via retinal imaging.,,"Sobhi, Navid; Sadeghi-Bazargani, Yasin; Mirzaei, Majid; Abdollahi, Mirsaeed; Jafarizadeh, Ali; Pedrammehr, Siamak; Alizadehsani, Roohallah; Tan, Ru-San; Islam, Sheikh Mohammed Shariful; Acharya, U Rajendra",,Journal of diabetes and metabolic disorders,24,1,104,2025,2025 Jun,English,1,1,"© The Author(s) 2025.Background: Diabetes mellitus (DM) increases the risk of vascular complications, and retinal vasculature imaging serves as a valuable indicator of both microvascular and macrovascular health. Moreover, artificial intelligence (AI)-enabled systems developed for high-throughput detection of diabetic retinopathy (DR) using digitized retinal images have become clinically adopted. This study reviews AI applications using retinal images for DM-related complications, highlighting advancements beyond DR screening, diagnosis, and prognosis, and addresses implementation challenges, such as ethics, data privacy, equitable access, and explainability.Methods: We conducted a thorough literature search across several databases, including PubMed, Scopus, and Web of Science, focusing on studies involving diabetes, the retina, and artificial intelligence. We reviewed the original research based on their methodology, AI algorithms, data processing techniques, and validation procedures to ensure a detailed analysis of AI applications in diabetic retinal imaging.Results: Retinal images can be used to diagnose DM complications including DR, neuropathy, nephropathy, and atherosclerotic cardiovascular disease, as well as to predict the risk of cardiovascular events. Beyond DR screening, AI integration also offers significant potential to address the challenges in the comprehensive care of patients with DM.Conclusion: With the ability to evaluate the patient's health status in relation to DM complications as well as risk prognostication of future cardiovascular complications, AI-assisted retinal image analysis has the potential to become a central tool for modern personalized medicine in patients with DM.",,"Nikookari Eye Center, Tabriz University of Medical Sciences, Tabriz, Iran.; Student Research Committee, Tabriz University of Medical Sciences, Tabriz, Iran.; Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, 75 Pigdons Rd, Waurn Ponds, VIC 3216 Australia.; Faculty of Design, Tabriz Islamic Art University, Tabriz, Iran.; National Heart Centre Singapore, Singapore, Singapore.; Duke-NUS Medical School, Singapore, Singapore.; Institute for Physical Activity and Nutrition, School of Exercise and Nutrition Sciences, Deakin University, Melbourne, VIC Australia.; Cardiovascular Division, The George Institute for Global Health, Newtown, Australia.; Sydney Medical School, University of Sydney, Camperdown, Australia.; School of Mathematics, Physics, and Computing, University of Southern Queensland, Springfield, QLD 4300 Australia.; Centre for Health Research, University of Southern Queensland, Springfield, Australia.","Alizadehsani, Roohallah/HLP-8160-2023; Tan, Ru San/HJI-5085-2023; Shariful Islam, Sheikh Mohammed/B-1219-2011; Acharya, Rajendra/E-3791-2010; Pedrammehr, Siamak/V-3301-2017; Jafarizadeh, Ali/ISB-5229-2023","Sobhi, Navid/0000-0003-0663-850X; Pedrammehr, Siamak/0000-0002-2974-1801; Abdollahi, Mirsaeed/0000-0002-2444-1172; Jafarizadeh, Ali/0000-0003-4922-1923; Tan, Ru San/0000-0003-2086-6517",,,Artificial intelligence; Diabetes complications; Diabetes mellitus; Diabetic retinopathy; Retina,,,,,,,2251-6581,101590741,Switzerland,,,PubMed-not-MEDLINE,,,/ 15 Apr 2025,,12 Apr 2025,,10.1007/s40200-025-01596-7,hybrid,,,2025-05-29,MEDLINE:40224528
J,40321117,Journal Article; Review,Explicating the transformative role of artificial intelligence in designing targeted nanomedicine.,,"Akhtar, Masheera; Nehal, Nida; Gull, Azka; Parveen, Rabea; Khan, Sana; Khan, Saba; Ali, Javed",,Expert opinion on drug delivery,,,1-21,2025,2025 May 21 (Epub 2025 May 21),English,2,2,"INTRODUCTION: Artificial intelligence (AI) has emerged as a transformative force in nanomedicine, revolutionizing drug delivery, diagnostics, and personalized treatment. While nanomedicine offers precise targeted drug delivery and reduced toxic effects, its clinical translation is hindered by biological complexity, unpredictable in vivo behavior, and inefficient trial-and-error approaches.AREAS COVERED: This review covers the application of AI and Machine Learning (ML) across the nanomedicine development pipeline, starting from drug and target identification to nanoparticle design, toxicity prediction, and personalized dosing. Different AI/ML models like QSAR, MTK-QSBER, and Alchemite, along with data sources and high-throughput screening methods, have been explored. Real-world applications are critically discussed, including AI-assisted drug repurposing, controlled-release formulations, and cancer-specific delivery systems.EXPERT OPINION: AI has emerged as an essential component in designing next-generation nanomedicine. Efficiently handling multidimensional datasets, optimizing formulations, and personalizing treatment regimens, it has sped up the innovation process. However, challenges like data heterogeneity, model transparency, and regulatory gaps remain. Addressing these hurdles through interdisciplinary efforts and emerging innovations like explainable AI and federated learning will pave the way for the clinical translation of AI-driven nanomedicine.",,"Department of Pharmaceutics, School of Pharmaceutical Education & Research, New Delhi, India.; Department of Pharmacology, School of Pharmaceutical Education & Research, New Delhi, India.",,,,Index Medicus,Artificial intelligence; deep learning; machine learning; nanomedicine; personalized treatments,,,,,,,1744-7593,101228421,England,,,Publisher,,,/ 21 May 2025,,21 May 2025,,10.1080/17425247.2025.2502022,,,,2025-05-29,MEDLINE:40321117
J,40405638,Journal Article,An overview of artificial intelligence and machine learning in shoulder surgery.,,"Cho, Sung-Hyun; Kim, Yang-Soo",,Clinics in shoulder and elbow,,,,2025,2025 May 19 (Epub 2025 May 19),English,0,0,"Machine learning (ML), a subset of artificial intelligence (AI), utilizes advanced algorithms to learn patterns from data, enabling accurate predictions and decision-making without explicit programming. In orthopedic surgery, ML is transforming clinical practice, particularly in shoulder arthroplasty and rotator cuff tears (RCTs) management. This review explores the fundamental paradigms of ML, including supervised, unsupervised, and reinforcement learning, alongside key algorithms such as XGBoost, neural networks, and generative adversarial networks. In shoulder arthroplasty, ML accurately predicts postoperative outcomes, complications, and implant selection, facilitating personalized surgical planning and cost optimization. Predictive models, including ensemble learning methods, achieve over 90% accuracy in forecasting complications, while neural networks enhance surgical precision through AI-assisted navigation. In RCTs treatment, ML enhances diagnostic accuracy using deep learning models on magnetic resonance imaging and ultrasound, achieving area under the curve values exceeding 0.90. ML models also predict tear reparability with 85% accuracy and postoperative functional outcomes, including range of motion and patient-reported outcomes. Despite remarkable advancements, challenges such as data variability, model interpretability, and integration into clinical workflows persist. Future directions involve federated learning for robust model generalization and explainable AI to enhance transparency. ML continues to revolutionize orthopedic care by providing data-driven, personalized treatment strategies and optimizing surgical outcomes.",,"Department of Orthopedic Surgery, Seoul St. Mary's Hospital, College of Medicine, The Catholic University of Korea, Seoul, Korea.",,,,,Arthroplasty; Artificial intelligence; Machine learning; Rotator cuff tears,,,,,,,2288-8721,101658558,Korea (South),,,Publisher,,,/ 23 May 2025,,19 May 2025,,10.5397/cise.2025.00185,,,,2025-05-29,MEDLINE:40405638
J,40282155,Journal Article,"Consumer Autonomy in Generative AI Services: The Role of Task Difficulty and AI Design Elements in Enhancing Trust, Satisfaction, and Usage Intention.",,"Han, Jihyung; Ko, Daekyun",,"Behavioral sciences (Basel, Switzerland)",15,4,,2025,2025 Apr 15,English,9,9,"As generative AI services become increasingly integrated into consumer decision making, concerns have grown regarding their influence on consumer autonomy-the extent to which individuals retain independent control over AI-assisted decisions. Although these services offer efficiency and convenience, they can simultaneously constrain consumer decision making, potentially impacting trust, satisfaction, and usage intention. This study investigates the role of perceived consumer autonomy in shaping consumer responses, specifically examining how task difficulty (Study 1) and AI service design elements-explainability, feedback, and shared responsibility (Study 2)-influence autonomy perceptions and subsequent consumer outcomes. Using two scenario-based experiments involving a total of 708 participants, the results reveal that perceived autonomy significantly enhances consumer trust, particularly in contexts involving high task difficulty. Among the tested AI design interventions, shared responsibility emerged as most effective in enhancing perceived autonomy, trust, satisfaction, and long-term engagement, whereas explainability and feedback alone showed limited impact. These findings underscore the importance of designing AI services that actively support consumer agency through user-involved decision-making frameworks rather than relying solely on passive informational transparency. Theoretical implications for consumer autonomy in AI interactions are discussed, along with practical recommendations for designing consumer-centered AI services.",,"Research Institute of Human Ecology, Seoul National University, Seoul 08826, Republic of Korea.; Department of Consumer Science, Chungnam National University, Daejeon 34134, Republic of Korea.",,,,,consumer autonomy; generative AI services; satisfaction; trust; usage intention,,,,,,,2076-328X,101576826,Switzerland,,,PubMed-not-MEDLINE,,,/ 29 Apr 2025,,15 Apr 2025,,10.3390/bs15040534,,,,2025-05-29,MEDLINE:40282155
J,40087157,Journal Article; Systematic Review; Review,Comprehensive overview of artificial intelligence in surgery: a systematic review and perspectives.,,"Chevalier, Olivia; Dubey, Gerard; Benkabbou, Amine; Majbar, Mohammed Anass; Souadka, Amine",,Pflugers Archiv : European journal of physiology,477,4,617-626,2025,2025 Apr (Epub 2025 Mar 15),English,4,4,"© 2025. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.The rapid integration of artificial intelligence (AI) into surgical practice necessitates a comprehensive evaluation of its applications, challenges, and physiological impact. This systematic review synthesizes current AI applications in surgery, with a particular focus on machine learning (ML) and its role in optimizing preoperative planning, intraoperative decision-making, and postoperative patient management. Using PRISMA guidelines and PICO criteria, we analyzed key studies addressing AI's contributions to surgical precision, outcome prediction, and real-time physiological monitoring. While AI has demonstrated significant promise-from enhancing diagnostics to improving intraoperative safety-many surgeons remain skeptical due to concerns over algorithmic unpredictability, surgeon autonomy, and ethical transparency. This review explores AI's physiological integration into surgery, discussing its role in real-time hemodynamic assessments, AI-guided tissue characterization, and intraoperative physiological modeling. Ethical concerns, including algorithmic opacity and liability in high-stakes scenarios, are critically examined alongside AI's potential to augment surgical expertise. We conclude that longitudinal validation, improved AI explainability, and adaptive regulatory frameworks are essential to ensure safe, effective, and ethically sound integration of AI into surgical decision-making. Future research should focus on bridging AI-driven analytics with real-time physiological feedback to refine precision surgery and patient safety strategies.",,"Institut-Mines Telecom Business School, Universite Paris 1 Pantheon-Sorbonne, Paris, France.; Surgical Oncology Department, National Institute of Oncology, Mohammed V University, Rabat, Morocco.; Surgical Oncology Department, National Institute of Oncology, Mohammed V University, Rabat, Morocco. a.souadka@um5r.ac.ma.","Majbar, Anass/AAB-7168-2020",,"*Artificial Intelligence. Humans. Machine Learning. *Surgical Procedures, Operative / methods",Index Medicus,Decision support systems in surgery; Ethical implications of AI.; Human-AI collaboration; Machine learning in surgery; Surgical artificial intelligence,,,,,,Computer Science; Surgery (provided by Clarivate Analytics),1432-2013,154720,Germany,,,MEDLINE,,,/ 31 Mar 2025 / 15 May 2025,,15 Mar 2025,,10.1007/s00424-025-03076-6,,,,2025-05-29,MEDLINE:40087157
J,40079459,Journal Article; Review,Enhancing education for children with ASD: a review of evaluation and measurement in AI tool implementation.,,"Adako, Oyeyemi Patricia; Adeusi, Oluwafemi Clement; Alaba, Peter Adeniyi",,Disability and rehabilitation. Assistive technology,,,1-18,2025,2025 Mar 13 (Epub 2025 Mar 13),English,18,18,"This article addresses the gaps in current research regarding the use of artificial intelligence (AI) tools to educate children with autism spectrum disorder (ASD). The proposed metrics are specifically designed to evaluate the progress of learning in AI-assisted education, considering the unique needs of this demographic. The review highlights the potential of long-term impact studies to determine the lasting effects of AI on social skills, emotional development, and overall academic achievement. The ethical considerations surrounding AI intervention in autistic education are thoroughly examined. By combining diverse methodologies utilized in existing studies, a comprehensive analysis of the challenges is presented, along with interdisciplinary approaches for improvement that can serve as a roadmap for future research. The manuscript provides innovative perspectives, bridges existing gaps, and advocates for the ethical and effective integration of AI tools in educating children with ASD.","Metrics: In the context of AI-assisted education, metrics refer to the quantitative and qualitative measures used to evaluate the effectiveness of AI tools in supporting learning. These may include student engagement levels, progress in skill development, accuracy in task completion, and behavioral improvements.Traditional Assessment Methods: Traditional assessment methods refer to conventional ways of evaluating learning outcomes, such as standardized tests, teacher observations, and structured evaluations. These methods typically focus on academic performance but may not always capture the unique learning patterns of children with autism spectrum disorder (ASD).AI Interventions: AI interventions in autism education involve the application of artificial intelligence technologiessuch as machine learning algorithms, speech recognition, and adaptive learning platformsto personalize learning experiences, provide real-time feedback, and enhance the educational process for children with ASD.AI-Supported Progress Assessment: AI-supported progress assessment refers to the use of AI-driven analytics to track and measure learning advancements over time. These assessments often include dynamic data analysis, pattern recognition, and adaptive modifications to teaching strategies based on individual learning needs.Standardized Assessment Frameworks: Standardized assessment frameworks are structured models used to evaluate educational progress consistently across different learners. In AI-assisted autism education, these frameworks help ensure that AI tools align with established educational benchmarks while allowing for personalized learning adaptations.Explainability and Accountability in AI: Explainability refers to the ability of an AI system to provide clear, understandable reasons for its decisions or recommendations. Accountability ensures that AI developers, educators, and stakeholders take responsibility for the outcomes of AI-driven educational interventions, ensuring fairness, reliability, and ethical use.Privacy and Data Security: Privacy and data security involve the ethical handling, storage, and protection of sensitive personal and behavioral data collected by AI systems. Given the vulnerable nature of children with ASD, AI interventions must comply with strict data protection regulations to safeguard student information.Ethical AI Implementation: Ethical AI implementation refers to the responsible design, deployment, and use of AI technologies in autism education. This includes considerations such as bias prevention, equitable access, human oversight, and ensuring that AI complements rather than replaces human educators.Interdisciplinary Collaboration: Interdisciplinary collaboration in AI-assisted education involves experts from various fieldssuch as education, psychology, computer science, and behavioral therapyworking together to develop, assess, and refine AI tools that best support the needs of children with ASD.Inclusive Research Practices: Inclusive research practices ensure that AI-driven educational tools and methodologies account for the diverse needs of children with autism, incorporating perspectives from students, educators, parents, and autism advocates to minimize bias and promote equitable learning opportunities.","Department of Education, Anglia Ruskin University Chelmsford Essex, Chelmsford, United Kingdom.; Department of Computer Science, Staffordshire University, Stoke-on-Trent, United Kingdom.; Department of Chemical Engineering, Faculty of Engineering, University of Malaya, Kuala Lumpur, Malaysia.; Premium Edible Oil Product Limited, Oyo State, Ibadan.","Alaba, Peter/M-5166-2016",,,Index Medicus,AI-assisted education; AI-powered tools; Autism education; artificial intelligence; autism spectrum disorder; children with ASD; interdisciplinary approach; longitudinal studies,,,,,,,1748-3115,101255937,England,,,Publisher,,,/ 13 Mar 2025,,13 Mar 2025,,10.1080/17483107.2025.2477678,,,,2025-05-29,MEDLINE:40079459
J,40071729,Journal Article,The Effect of Workload and Task Priority on Multitasking Performance and Reliance on Level 1 Explainable AI (XAI) Use.,,"Alami, Jawad; El Iskandarani, Mohamad; Riggs, Sara Lu",,Human factors,,,1.87208E+14,2025,2025 Mar 12 (Epub 2025 Mar 12),English,15,15,"ObjectiveThis study investigates the effects of workload and task priority on multitasking performance and reliance on Level 1 Explainable Artificial Intelligence (XAI) systems in high-stakes decision environments.BackgroundOperators in critical settings manage multiple tasks under varying levels of workload and priority, potentially leading to performance degradation. XAI offers opportunities to support decision making by providing insights into AI's reasoning, yet its adoption and effectiveness in multitasking scenarios remain underexplored.MethodThirty participants engaged in a simulated multitasking environment, involving UAV command and control tasks, with the assistance of a Level 1 (i.e., basic perceptual information) XAI system on one of the tasks. The study utilized a within-subjects experimental design, manipulating workload (low, medium, and high) and AI-supported-task priority (low and high) across six conditions. Participants' accuracy, use of automatic rerouting, AI miss detection, false alert identification, and use of AI explanations were measured and analyzed across the different experimental conditions.ResultsWorkload significantly hindered performance on the AI-assisted task and increased reliance on the AI system especially when the AI-assisted task was given low priority. The use of AI explanations was significantly affected by task priority only.ConclusionAn increase in workload led to proper offloading by relying on the AI's alerts, but it also led to a lower rate of alert verification despite the alert feature's high false alert rate.ApplicationThe findings from the present work help inform AI system designers on how to design their systems for high-stakes environments such that reliance on AI is properly calibrated.",,"University of Virginia, USA.",,"Riggs, Sara/0000-0002-0112-9469",,Index Medicus,automation; explanation; multitasking; performance; reliance; workload,,,,,,,1547-8181,374660,United States,,,Publisher,,,/ 12 Mar 2025,,12 Mar 2025,,10.1177/00187208251323478,,,,2025-05-29,MEDLINE:40071729
J,39759954,Journal Article,"Three versions of an atopic dermatitis case report written by humans, artificial intelligence, or both: Identification of authorship and preferences.",,"Giavina Bianchi, Mara; D'adario, Andrew; Giavina Bianchi, Pedro; Machado, Birajara Soares",IChat Group,The journal of allergy and clinical immunology. Global,4,1,100373,2025,2025 Feb,English,1,1,"© 2024 The Author(s).Background: The use of artificial intelligence (AI) in scientific writing is rapidly increasing, raising concerns about authorship identification, content quality, and writing efficiency.Objectives: This study investigates the real-world impact of ChatGPT, a large language model, on those aspects in a simulated publication scenario.Methods: Forty-eight individuals representing 3 medical expertise levels (medical students, residents, and experts in allergy or dermatology) evaluated 3 blinded versions of an atopic dermatitis case report: one each human written (HUM), AI generated (AI), and combined written (COM). The survey assessed authorship, ranked their preference, and graded 13 quality criteria for each text. Time taken to generate each manuscript was also recorded.Results: Authorship identification accuracy mirrored the odds at 33%. Expert participants (50.9%) demonstrated significantly higher accuracy compared to residents (27.7%) and students (19.6%, P< .001). Participants favored AI-assisted versions (AI and COM) over HUM (P< .001), with COM receiving the highest quality scores. COM and AI achieved 83.8% and 84.3% reduction in writing time, respectively, compared to HUM, while showing 13.9% (P< .001) and 11.1% improvement in quality (P< .001), respectively. However, experts assigned the lowest score for the references of the AI manuscript, potentially hindering its publication.Conclusion: AI can deceptively mimic human writing, particularly for less experienced readers. Although AI-assisted writing is appealing and offers significant time savings, human oversight remains crucial to ensure accuracy, ethical considerations, and optimal quality. These findings underscore the need for transparency in AI use and highlight the potential of human-AI collaboration in the future of scientific writing.",,"Big Data Department, Faculdade Israelita de Ciencias da Saude Albert Einstein, Sao Paulo, Brazil.; Department of Clinical Immunology and Allergy, Universidade de Sao Paulo, Sao Paulo, Brazil.",,"Baptista Brunheroto, Felipe/0000-0002-1986-4453; Mansour, Eli/0000-0001-6450-6930; GIAVINA-BIANCHI, MARA/0000-0001-7059-4068; Costa de Oliveira, Emerson/0000-0002-0714-8791",,,ChatGPT; Generative Pre-training Transformer (GPT); artificial intelligence; large language model (LLM); medical survey; scientific writing,,,,,,,2772-8293,9.91845E+15,United States,,,PubMed-not-MEDLINE,"Agondi, Rosana; Almeida, Stephanie Ka; Alves Junior, Wandilson Xavier; Armelin, Larissa M; Vivolo Aun, Marcelo; Bordignon, Natalia; Boufleur, Karla; Brunheroto, Felipe B; Callegaro, Elisabeth A; Castro, Paula Lazaretti M; Chong-Neto, Herberto Jose; Dall'Osto, Mariana D; Abou Dias, Julia; Ferreira, Viviane Heintze; Oliveira Feodrippe, Andre Luiz; Fonseca, Livia G; Garcia, Clydia M; Giavina-Bianchi, Bruna H; Goudouris, Ekaterini; Goncalves, Danilo Gois; Hernandes, Debora D; Imad, Malek; Izabel, Larissa S; Caue Jacintho, Lucas; Khouri-Panzarin, Carolina; Kuschnir, Fabio; Padua Lima, Maria Beatriz; Lopes, Amanda I; Macedo Nobrega Lopes, Larissa Nathalia; Rocha de Magalhaes, Alice; Mansour, Eli; Marinho, Ana Karolina Bb; Martimiano, Vivian S; Milori, Pedro H; Marcondes Mutarelli, Antonio; Goncalves Nogueira, Guilherme Paes; Oguido, Beatriz Kt; Alarcon de Oliveira, Bruna S; Costa de Oliveira, Emerson; Padulla, Georgia A; D'Ordaz Lhano Santos, Leticia; Meneses Santos, Micaelly Samara; Sarinho, Emanuel; Schoen, Marcela; Sousa, Brian Lucas A; Magalhaes de Souza-Lima, Eduardo; Todt, Beatriz C; Braz da Silva Vaz, Najla",,/ 06 Jan 2025,,26 Nov 2024,,10.1016/j.jacig.2024.100373,"gold, Green Published",,,2025-05-29,MEDLINE:39759954
J,39911582,Journal Article,Towards human-AI collaboration in radiology: a multidimensional evaluation of the acceptability of AI for chest radiograph analysis in supporting pulmonary tuberculosis diagnosis.,,"Hua, David; Petrina, Neysa; Sacks, Alan J; Young, Noel; Cho, Jin-Gun; Smith, Ross; Poon, Simon K",,JAMIA open,8,1,ooae151,2025,2025 Feb,English,3,3,"© The Author(s) 2025. Published by Oxford University Press on behalf of the American Medical Informatics Association.Objective: Artificial intelligence (AI) technology promises to be a powerful tool in addressing the global health challenges posed by tuberculosis (TB). However, evidence for its real-world impact is lacking, which may hinder safe, responsible adoption. This case study addresses this gap by assessing the technical performance, usability and workflow aspects, and health impact of implementing a commercial AI system (qXR by Qure.ai) to support Australian radiologists in diagnosing pulmonary TB.Materials and Methods: A retrospective diagnostic accuracy evaluation was conducted to establish the technical performance of qXR in detecting TB compared to a human radiologist and microbiological reference standard. A qualitative human factors assessment was performed to investigate the user experience and clinical decision-making process of radiologists using qXR. A task productivity analysis was completed to quantify how the radiological screening turnaround time is impacted.Results: qXR displays near-human performance satisfying the World Health Organization's suggested accuracy profile. Radiologists reported high satisfaction with using qXR based on minimal workflow disruptions, respect for their professional autonomy, and limited increases in workload burden despite poor algorithm explainability. qXR delivers considerable productivity gains for normal cases and optimizes resource allocation through redistributing time from normal to abnormal cases.Discussion and Conclusion: This study provides preliminary evidence of how an AI system with reasonable diagnostic accuracy and a human-centered user experience can meaningfully augment the TB diagnostic workflow. Future research needs to investigate the impact of AI on clinician accuracy, its relationship with efficiency, and best practices for optimizing the impact of clinician-AI collaboration.",,"School of Computer Science, The University of Sydney, Sydney, NSW 2006, Australia.; Sydney Law School, The University of Sydney, Sydney, NSW 2050, Australia.; Our Medical Radiology, Sydney, NSW 2065, Australia.; Lumus Imaging, Sydney, NSW 2000, Australia.; Western Sydney Local Health District, Sydney, NSW 2145, Australia.; Sydney Medical School, The University of Sydney, Sydney, NSW 2050, Australia.","Hua, David/JUU-4737-2023; Cho, Jin-Gun/ABC-5673-2020",,,,artificial intelligence; evaluation; human factors; pulmonary tuberculosis; technical performance; translational impact,,,,,,,2574-2531,101730643,United States,,,PubMed-not-MEDLINE,,,/ 07 Feb 2025,,05 Feb 2025,,10.1093/jamiaopen/ooae151,"gold, Green Accepted",,,2025-05-29,MEDLINE:39911582
J,40376574,Journal Article,YOLOv8 framework for COVID-19 and pneumonia detection using synthetic image augmentation.,,"A Hasib, Uddin; Md Abu, Raihan; Yang, Jing; Bhatti, Uzair Aslam; Ku, Chin Soon; Por, Lip Yee",,Digital health,11,,2.05521E+16,2025,2025,English,0,0,"© The Author(s) 2025.Objective: Early and accurate detection of COVID-19 and pneumonia through medical imaging is critical for effective patient management. This study aims to develop a robust framework that integrates synthetic image augmentation with advanced deep learning (DL) models to address dataset imbalance, improve diagnostic accuracy, and enhance trust in artificial intelligence (AI)-driven diagnoses through Explainable AI (XAI) techniques.Methods: The proposed framework benchmarks state-of-the-art models (InceptionV3, DenseNet, ResNet) for initial performance evaluation. Synthetic images are generated using Feature Interpolation through Linear Mapping and principal component analysis to enrich dataset diversity and balance class distribution. YOLOv8 and InceptionV3 models, fine-tuned via transfer learning, are trained on the augmented dataset. Grad-CAM is used for model explainability, while large language models (LLMs) support visualization analysis to enhance interpretability.Results: YOLOv8 achieved superior performance with 97% accuracy, precision, recall, and F1-score, outperforming benchmark models. Synthetic data generation effectively reduced class imbalance and improved recall for underrepresented classes. Comparative analysis demonstrated significant advancements over existing methodologies. XAI visualizations (Grad-CAM heatmaps) highlighted anatomically plausible focus areas aligned with clinical markers of COVID-19 and pneumonia, thereby validating the model's decision-making process.Conclusion: The integration of synthetic data generation, advanced DL, and XAI significantly enhances the detection of COVID-19 and pneumonia while fostering trust in AI systems. YOLOv8's high accuracy, coupled with interpretable Grad-CAM visualizations and LLM-driven analysis, promotes transparency crucial for clinical adoption. Future research will focus on developing a clinically viable, human-in-the-loop diagnostic workflow, further optimizing performance through the integration of transformer-based language models to improve interpretability and decision-making.",,"Department of Computer Science and Engineering, Khwaja Yunus Ali University, Sirajganj, Bangladesh.; Center of Research for Cyber Security and Network (CSNET), Faculty of Computer Science and Information Technology, Universiti Malaya, Kuala Lumpur, Malaysia.; School of information and Communication Engineering, Hainan University, Haikou, China.; Department of Computer Science, Universiti Tunku Abdul Rahman, Kampar, Malaysia.","ku, chin soon/N-6119-2015; Por, Lip Yee/B-5309-2010","Por, Lip Yee/0000-0001-5865-1533",,,COVID-19 detection; YOLOv8; medical image analysis; pneumonia classification; synthetic image augmentation,,,,,,,2055-2076,101690863,United States,,,PubMed-not-MEDLINE,,,/ 17 May 2025,,14 May 2025,,10.1177/20552076251341092,,,,2025-05-29,MEDLINE:40376574
J,40241963,Journal Article; Review,Artificial intelligence in hospital infection prevention: an integrative review.,,"El Arab, Rabie Adel; Almoosa, Zainab; Alkhunaizi, May; Abuadas, Fuad H; Somerville, Joel",,Frontiers in public health,13,,1547450,2025,2025,English,2,2,"Copyright © 2025 El Arab, Almoosa, Alkhunaizi, Abuadas and Somerville.Background: Hospital-acquired infections (HAIs) represent a persistent challenge in healthcare, contributing to substantial morbidity, mortality, and economic burden. Artificial intelligence (AI) offers promising potential for improving HAIs prevention through advanced predictive capabilities.Objective: To evaluate the effectiveness, usability, and challenges of AI models in preventing, detecting, and managing HAIs.Methods: This integrative review synthesized findings from 42 studies, guided by the SPIDER framework for inclusion criteria. We assessed the quality of included studies by applying the TRIPOD checklist to individual predictive studies and the AMSTAR 2 tool for reviews.Results: AI models demonstrated high predictive accuracy for the detection, surveillance, and prevention of multiple HAIs, with models for surgical site infections and urinary tract infections frequently achieving area-under-the-curve (AUC) scores exceeding 0.80, indicating strong reliability. Comparative data suggest that while both machine learning and deep learning approaches perform well, some deep learning models may offer slight advantages in complex data environments. Advanced algorithms, including neural networks, decision trees, and random forests, significantly improved detection rates when integrated with EHRs, enabling real-time surveillance and timely interventions. In resource-constrained settings, non-real-time AI models utilizing historical EHR data showed considerable scalability, facilitating broader implementation in infection surveillance and control. AI-supported surveillance systems outperformed traditional methods in accurately identifying infection rates and enhancing compliance with hand hygiene protocols. Furthermore, Explainable AI (XAI) frameworks and interpretability tools such as Shapley additive explanations (SHAP) values increased clinician trust and facilitated actionable insights. AI also played a pivotal role in antimicrobial stewardship by predicting the emergence of multidrug-resistant organisms and guiding optimal antibiotic usage, thereby reducing reliance on second-line treatments. However, challenges including the need for comprehensive clinician training, high integration costs, and ensuring compatibility with existing workflows were identified as barriers to widespread adoption.Discussion: The integration of AI in HAI prevention and management represents a potentially transformative shift in enhancing predictive capabilities and supporting effective infection control measures. Successful implementation necessitates standardized validation protocols, transparent data reporting, and the development of user-friendly interfaces to ensure seamless adoption by healthcare professionals. Variability in data sources and model validations across studies underscores the necessity for multicenter collaborations and external validations to ensure consistent performance across diverse healthcare environments. Innovations in non-real-time AI frameworks offer viable solutions for scaling AI applications in low- and middle-income countries (LMICs), addressing the higher prevalence of HAIs in these regions.Conclusions: Artificial Intelligence stands as a transformative tool in the fight against hospital-acquired infections, offering advanced solutions for prevention, surveillance, and management. To fully realize its potential, the healthcare sector must prioritize rigorous validation standards, comprehensive data quality reporting, and the incorporation of interpretability tools to build clinician confidence. By adopting scalable AI models and fostering interdisciplinary collaborations, healthcare systems can overcome existing barriers, integrating AI seamlessly into infection control policies and ultimately enhancing patient safety and care quality. Further research is needed to evaluate cost-effectiveness, real-world applications, and strategies (e.g., clinician training and the integration of explainable AI) to improve trust and broaden clinical adoption.",,"Almoosa College of Health Sciences, Al Mubarraz, Saudi Arabia.; Department of Infectious Disease, Almoosa Specialist Hospital, Al Mubarraz, Saudi Arabia.; Department of Pediatric, Almoosa Specialist Hospital, Al Mubarraz, Saudi Arabia.; Department of Community Health Nursing, College of Nursing, Jouf University, Sakaka, Saudi Arabia.; Inverness College, University of the Highlands and Island, Inverness, United Kingdom.; Glasgow Caledonian University, Glasgow, United Kingdom.","Shaban, Mostafa/GLR-7092-2022; El Arab, Rabie/AEC-8068-2022","El Arab, Rabie Adel/0000-0002-3822-9236",*Artificial Intelligence. *Cross Infection / prevention & control. Humans. *Infection Control / methods,Index Medicus,artificial intelligence; explainable AI; hospital-acquired infections; infection control; infection prevention; infection surveillance; predictive analytics,,,,,,"Computer Science; Infectious Diseases; Public, Environmental & Occupational Health (provided by Clarivate Analytics)",2296-2565,101616579,Switzerland,,,MEDLINE,,,/ 17 Apr 2025 / 18 Apr 2025,,02 Apr 2025,,10.3389/fpubh.2025.1547450,,,,2025-05-29,MEDLINE:40241963
J,40104157,Journal Article,Pathology in the artificial intelligenceera: Guiding innovation and implementation to preserve human insight.,,"Gaffney, Harry; Mirza, Kamran M",,Academic pathology,12,1,100166,2025,2025,English,3,3,"© 2025 The Author(s).The integration of artificial intelligence in pathology has ignited discussions about the role of technology in diagnostics-whether artificial intelligence serves as a tool for augmentation or risks replacing human expertise. This manuscript explores artificial intelligence's evolving contributions to pathology, emphasizing its potential capacity to enhance, rather than eclipse, the pathologist's role. Through historical comparisons, such as the transition from analog to digital in radiology, this paper highlights how technological advancements have historically expanded professional capabilities without diminishing the essential human element. Current applications of artificial intelligence in pathology-from diagnostic standardization to workflow efficiency-demonstrate its potential to augment diagnostic accuracy, expedite processes, and improve consistency across institutions. However, challenges remain in algorithmic bias, regulatory oversight, and maintaining interpretive skills among pathologists. The discussion underscores the importance of comprehensive governance frameworks, evolving educational curricula, and public engagement initiatives to ensure artificial intelligence in pathology remains a collaborative endeavor that empowers professionals, upholds ethical standards, and enhances patient outcomes. This manuscript ultimately advocates for a balanced approach where artificial intelligence and human expertise work in concert to advance the future of diagnostic medicine.",,"Concord Clinical School, Faculty of Medicine and Health, The University of Sydney, Sydney, New South Wales, Australia.; The Godfrey D. Stobbe Professor of Pathology Education, Assistant Chair for Education and Director of the Division of Training, Programs and Communication, University of Michigan (Michigan Medicine) Department of Pathology, Ann Arbor, MI, USA.",,,,,AI-Assisted diagnostics; Algorithmic transparency; Artificial intelligence; Diagnostic accuracy; Diagnostic augmentation; Educational frameworks; Governance; Pathology; Public engagement; Workflow optimization,,,,,,,2374-2895,101698648,United States,,,PubMed-not-MEDLINE,,,/ 20 Mar 2025,,28 Feb 2025,,10.1016/j.acpath.2025.100166,gold,,,2025-05-29,MEDLINE:40104157
J,40166361,Journal Article,Applied machine learning in intelligent systems: knowledge graph-enhanced ophthalmic contrastive learning with clinical profile prompts.,,"Han Wang, Mini; Cui, Jiazheng; Lee, Simon Ming-Yuen; Lin, Zhiyuan; Zeng, Peijin; Li, Xinyue; Liu, Haoyang; Liu, Yunxiao; Xu, Yang; Wang, Yapeng; Alves, Jose Lopes Camilo Da Costa; Hou, Guanghui; Fang, Junbin; Yu, Xiangrong; Chong, Kelvin Kam-Lung; Pan, Yi",,Frontiers in artificial intelligence,8,,1527010,2025,2025,English,3,3,"Copyright © 2025 Han Wang, Cui, Lee, Lin, Zeng, Li, Liu, Liu, Xu, Wang, Alves, Hou, Fang, Yu, Chong and Pan.Introduction: The integration of artificial intelligence (AI) into ophthalmic diagnostics has the potential to significantly enhance diagnostic accuracy and interpretability, thereby supporting clinical decision-making. However, a major challenge in AI-driven medical applications is the lack of transparency, which limits clinicians' trust in automated recommendations. This study investigates the application of machine learning techniques by integrating knowledge graphs with contrastive learning and utilizing clinical profile prompts to refine the performance of the ophthalmology-specific large language model, MeEYE, which is built on the CHATGLM3-6B architecture. This approach aims to improve the model's ability to capture clinically relevant features while enhancing both the accuracy and explainability of diagnostic predictions.Methods: This study employs a novel methodological framework that incorporates domain-specific knowledge through knowledge graphs and enhances feature representation using contrastive learning. The MeEYE model is fine-tuned with structured clinical knowledge, enabling it to better distinguish subtle yet significant ophthalmic features. Additionally, clinical profile prompts are incorporated to further improve contextual understanding and diagnostic precision. The proposed method is evaluated through comprehensive performance benchmarking, including quantitative assessments and clinical case studies, to ensure its efficacy in real-world ophthalmic diagnosis.Results: The experimental findings demonstrate that integrating knowledge graphs and contrastive learning into the MeEYE model significantly improves both diagnostic accuracy and model interpretability. Comparative analyses against baseline models reveal that the proposed approach enhances the identification of ophthalmic conditions with higher precision and clarity. Furthermore, the model's ability to generate transparent and clinically relevant AI recommendations is substantiated through rigorous evaluation, highlighting its potential for real-world clinical implementation.Discussion: The results underscore the importance of explainable AI in medical diagnostics, particularly in ophthalmology, where model transparency is critical for clinical acceptance and utility. By incorporating domain-specific knowledge with advanced machine learning techniques, the proposed approach not only enhances model performance but also ensures that AI-generated insights are interpretable and reliable for clinical decision-making. These findings suggest that integrating structured medical knowledge with machine learning frameworks can address key challenges in AI-driven diagnostics, ultimately contributing to improved patient outcomes. Future research should explore the adaptability of this approach across various medical domains to further advance AI-assisted diagnostic systems.",,"Zhuhai Precision Medical Center, Zhuhai People's Hospital, The Affiliated Hospital of Beijing Institute of Technology, Zhuhai Clinical Medical College of Jinan University, Zhuhai, China.; Department of Ophthalmology and Visual Sciences, Faculty of Medicine, The Chinese University of Hong Kong, Shatin, Hong Kong SAR, China.; Zhuhai Institute of Advanced Technology, Chinese Academy of Sciences (CAS), Zhuhai, China.; Beijing Normal University - Hong Kong Baptist University United International College, Zhuhai, China.; Department of Food Science and Nutrition, Hong Kong Polytechnic University, Kowloon, Hong Kong SAR, China.; Perspective Technology Group, Zhuhai, China.; Beijing Institute of Technology, Zhuhai, China.; Department of Ophthalmology, Tianjin Medical University, Tianjin, China.; Faculty of Applied Sciences, Macao Polytechnic University, Macao, Macao SAR, China.; Digital Healthcare and Artificial Intelligence Association, Macao, Macao SAR, China.; Faculty of Business, City University of Macau, Macao, Macao SAR, China.; Zhuhai Aier Eye Hospital, Zhuhai, China.; College of Science & Engineering, Jinan University, Shenzhen, China.; Zhuhai People's Hospital (Zhuhai Clinical Medical College of Jinan University), Zhuhai, China.; Shenzhen Key Laboratory of Intelligent Bioinformatics, Shenzhen Institute of Advanced Technology, Shenzhen, China.","Wang, Mini Han/ABM-1417-2022; 于, 向荣/KWU-2936-2024",,,,clinical profile prompts; contrastive learning; interpretable artificial intelligence; knowledge graph; machine learning; medical intelligent systems; ophthalmic disease detection,,,,,,,2624-8212,101770551,Switzerland,,,PubMed-not-MEDLINE,,,/ 02 Apr 2025,,12 Mar 2025,,10.3389/frai.2025.1527010,gold,,,2025-05-29,MEDLINE:40166361
J,39176805,Journal Article,Demystifying XAI: Requirements for Understandable XAI Explanations.,,"Stodt, Jan; Reich, Christoph; Knahl, Martin",,Studies in health technology and informatics,316,,565-569,2024,2024 Aug 22,English,4,7,"This paper establishes requirements for assessing the usability of Explainable Artificial Intelligence (XAI) methods, focusing on non-AI experts like healthcare professionals. Through a synthesis of literature and empirical findings, it emphasizes achieving optimal cognitive load, task performance, and task time in XAI explanations. Key components include tailoring explanations to user expertise, integrating domain knowledge, and using non-propositional representations for comprehension. The paper highlights the critical role of relevance, accuracy, and truthfulness in fostering user trust. Practical guidelines are provided for designing transparent and user-friendly XAI explanations, especially in high-stakes contexts like healthcare. Overall, the paper's primary contribution lies in delineating clear requirements for effective XAI explanations, facilitating human-AI collaboration across diverse domains.",,"Institute for Data Science, Cloud Computing, and IT Security, Furtwangen University, Furtwangen, Germany.",,"Stodt, Jan/0000-0001-9115-7668",*Artificial Intelligence. Comprehension. Humans,Index Medicus,Explanations; Non-AI Experts; Understandability Requirements; XAI,,,,,,Computer Science; Psychology; Behavioral Sciences (provided by Clarivate Analytics),1879-8365,9214582,Netherlands,,,MEDLINE,,,/ 23 Aug 2024 / 23 Aug 2024,,,,10.3233/SHTI240477,"hybrid, Green Submitted",,,2025-05-29,MEDLINE:39176805
J,38803523,Journal Article,An optimized framework for processing multicentric polysomnographic data incorporating expert human oversight.,,"Holm, Benedikt; Jouan, Gabriel; Hardarson, Emil; Sigurdardottir, Sigridur; Hoelke, Kenan; Murphy, Conor; Arnardottir, Erna Sif; Oskarsdottir, Maria; Islind, Anna Sigridur",,Frontiers in neuroinformatics,18,,1379932,2024,2024,English,0,0,"Copyright © 2024 Holm, Jouan, Hardarson, Sigurdardottir, Hoelke, Murphy, Arnardottir, Oskarsdottir and Islind.Introduction: Polysomnographic recordings are essential for diagnosing many sleep disorders, yet their detailed analysis presents considerable challenges. With the rise of machine learning methodologies, researchers have created various algorithms to automatically score and extract clinically relevant features from polysomnography, but less research has been devoted to how exactly the algorithms should be incorporated into the workflow of sleep technologists. This paper presents a sophisticated data collection platform developed under the Sleep Revolution project, to harness polysomnographic data from multiple European centers.Methods: A tripartite platform is presented: a user-friendly web platform for uploading three-night polysomnographic recordings, a dedicated splitter that segments these into individual one-night recordings, and an advanced processor that enhances the one-night polysomnography with contemporary automatic scoring algorithms. The platform is evaluated using real-life data and human scorers, whereby scoring time, accuracy, and trust are quantified. Additionally, the scorers were interviewed about their trust in the platform, along with the impact of its integration into their workflow.Results: We found that incorporating AI into the workflow of sleep technologists both decreased the time to score by up to 65 min and increased the agreement between technologists by as much as 0.17 kappa.Discussion: We conclude that while the inclusion of AI into the workflow of sleep technologists can have a positive impact in terms of speed and agreement, there is a need for trust in the algorithms.",,"Department of Computer Science, Reykjavik University, Reykjavik, Iceland.; School of Technology, Reykjavik University Sleep Institute, Reykjavik, Iceland.; Board of Registered Polysomnographic Technologists, Arlington, VA, United States.; Physical Activity, Physical Education, Sport and Health Research Centre (PAPESH), Sports Science Department, School of Social Sciences, Reykjavik University, Reykjavik, Iceland.","Islind, Anna Sigridur/HGE-0618-2022","Oskarsdottir, Maria/0000-0001-5095-5356",,,agreement; explainable AI; human-in-the-loop; machine learning; platform; scoring time; sleep research; trust,,,,,,,1662-5196,101477957,Switzerland,,,PubMed-not-MEDLINE,,,/ 29 May 2024,,13 May 2024,,10.3389/fninf.2024.1379932,"gold, Green Published",,,2025-05-29,MEDLINE:38803523
J,37998188,Journal Article,Applications of Shaped-Charge Learning.,,"Galitsky, Boris",,"Entropy (Basel, Switzerland)",25,11,,2023,2023 Oct 30,English,2,6,"It is well known that deep learning (DNN) has strong limitations due to a lack of explainability and weak defense against possible adversarial attacks. These attacks would be a concern for autonomous teams producing a state of high entropy for the team's structure. In our first article for this Special Issue, we propose a meta-learning/DNN kNN architecture that overcomes these limitations by integrating deep learning with explainable nearest neighbor learning (kNN). This architecture is named shaped charge. The focus of the current article is the empirical validation of shaped charge. We evaluate the proposed architecture for summarization, question answering, and content creation tasks and observe a significant improvement in performance along with enhanced usability by team members. We observe a substantial improvement in question answering accuracy and also the truthfulness of the generated content due to the application of the shaped-charge learning approach.",,"Knowledge-Trail, Los Banos, CA 93635, USA.","Galitsky, Boris/AAF-5611-2021","Galitsky, Boris/0000-0003-0670-8520",,,deep and nearest neighbor learning; machine learning support for human-machine teams; structural entropy production,,,,,,,1099-4300,101243874,Switzerland,,,PubMed-not-MEDLINE,,,/ 26 Nov 2023,,30 Oct 2023,,10.3390/e25111496,"Green Published, gold",,,2025-05-29,MEDLINE:37998188
J,33628085,Journal Article,Toward Robust policy Summarization: Extended Abstract.,,"Lage, Isaac; Lifschitz, Daphna; Doshi-Velez, Finale; Amir, Ofra",,Autonomous agents and multi-agent systems,2019,,2081-2083,2019,2019 May,English,0,0,"AI agents are being developed to help people with high stakes decision-making processes from driving cars to prescribing drugs. It is therefore becoming increasingly important to develop explainable AI methods that help people understand the behavior of such agents. Summaries of agent policies can help human users anticipate agent behavior and facilitate more effective collaboration. Prior work has framed agent summarization as a machine teaching problem where examples of agent behavior are chosen to maximize reconstruction quality under the assumption that people do inverse reinforcement learning to infer an agent's policy from demonstrations. We compare summaries generated under this assumption to summaries generated under the assumption that people use imitation learning. We show through simulations that in some domains, there exist summaries that produce high-quality reconstructions under different models, but in other domains, only matching the summary extraction model to the reconstruction model produces high-quality reconstructions. These results highlight the importance of assuming correct computational models for how humans extrapolate from a summary, suggesting human-in-the-loop approaches to summary extraction.",,Harvard University.; Technion - Israel Institute of Technology.,,,,,Explainable AI; Policy Summarization,,,,,,,1387-2532,101137288,United States,T32 LM012411 / NLM NIH HHSUnited States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM),,PubMed-not-MEDLINE,,,/ 27 Feb 2021,,,,,,,,2025-05-29,MEDLINE:33628085