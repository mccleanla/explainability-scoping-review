Publication Type,Authors,Book Authors,Book Editors,Book Group Authors,Author Full Names,Book Author Full Names,Group Authors,Article Title,Source Title,Book Series Title,Book Series Subtitle,Language,Document Type,Conference Title,Conference Date,Conference Location,Conference Sponsor,Conference Host,Author Keywords,Keywords Plus,Abstract,Addresses,Affiliations,Reprint Addresses,Email Addresses,Researcher Ids,ORCIDs,Funding Orgs,Funding Name Preferred,Funding Text,Cited References,Cited Reference Count,"Times Cited, WoS Core","Times Cited, All Databases",180 Day Usage Count,Since 2013 Usage Count,Publisher,Publisher City,Publisher Address,ISSN,eISSN,ISBN,Journal Abbreviation,Journal ISO Abbreviation,Publication Date,Publication Year,Volume,Issue,Part Number,Supplement,Special Issue,Meeting Abstract,Start Page,End Page,Article Number,DOI,DOI Link,Book DOI,Early Access Date,Number of Pages,WoS Categories,Web of Science Index,Research Areas,IDS Number,Pubmed Id,Open Access Designations,Highly Cited Status,Hot Paper Status,Date of Export,UT (Unique WOS ID),Web of Science Record
J,"Bienefeld, N; Keller, E; Grote, G",,,,"Bienefeld, Nadine; Keller, Emanuela; Grote, Gudela",,,Human-AI Teaming in Critical Care: A Comparative Analysis of Data Scientists' and Clinicians' Perspectives on AI Augmentation and Automation,JOURNAL OF MEDICAL INTERNET RESEARCH,,,,Article,,,,,,,,"Background: Artificial intelligence (AI) holds immense potential for enhancing clinical and administrative health care tasks. However, slow adoption and implementation challenges highlight the need to consider how humans can effectively collaborate with AI within broader socio-technical systems in health care. Objective: In the example of intensive care units (ICUs), we compare data scientists' and clinicians' assessments of the optimal utilization of human and AI capabilities by determining suitable levels of human-AI teaming for safely and meaningfully augmenting or automating 6 core tasks. The goal is to provide actionable recommendations for policy makers and health care practitioners regarding AI design and implementation. Methods: In this multimethod study, we combine a systematic task analysis across 6 ICUs with an international Delphi survey involving 19 health data scientists from the industry and academia and 61 ICU clinicians (25 physicians and 36 nurses) to define and assess optimal levels of human-AI teaming (level 1=no performance benefits; level 2=AI augments human performance; level 3=humans augment AI performance; level 4=AI performs without human input). Stakeholder groups also considered ethical and social implications. Results: Both stakeholder groups chose level 2 and 3 human-AI teaming for 4 out of 6 core tasks in the ICU. For one task (monitoring), level 4 was the preferred design choice. For the task of patient interactions, both data scientists and clinicians agreed that AI should not be used regardless of technological feasibility due to the importance of the physician-patient and nurse-patient relationship and ethical concerns. Human-AI design choices rely on interpretability, predictability, and control over AI systems. If these conditions are not met and AI performs below human-level reliability, a reduction to level 1 or shifting accountability away from human end users is advised. If AI performs at or beyond human-level reliability and these conditions are not met, shifting to level 4 automation should be considered to ensure safe and efficient human-AI teaming. Conclusions: By considering the sociotechnical system and determining appropriate levels of human-AI teaming, our study showcases the potential for improving the safety and effectiveness of AI usage in ICUs and broader health care settings. Regulatory measures should prioritize interpretability, predictability, and control if clinicians hold full accountability. Ethical and social implications must be carefully evaluated to ensure effective collaboration between humans and AI, particularly considering the most recent advancements in generative AI.","[Bienefeld, Nadine; Grote, Gudela] Swiss Fed Inst Technol, Dept Management Technol & Econ, Zurich, Switzerland; [Keller, Emanuela] Univ Hosp, Inst Intens Care Med, Dept Neurosurg, Zurich, Switzerland; [Keller, Emanuela] Univ Zurich, Zurich, Switzerland",,"Bienefeld, N (corresponding author), Swiss Fed Inst Technol, Dept Management Technol & Econ, Zurich, Switzerland.",nbienefeld@ethz.ch,,,,,,,,1,1,,,,,,,,,,,JUL 24,2024,26,,,,,,,,e50130,10.2196/50130,http://dx.doi.org/10.2196/50130,,,,,,,,,,,,2025-05-29,WOS:001297028800001,View Full Record in Web of Science
J,"Lindgren, H",,,,"Lindgren, Helena",,,Emerging Roles and Relationships Among Humans and Interactive AI Systems,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,,,,Article; Early Access,,,,,,,,"Metaphors have for long time been used for describing and explaining the roles of technology in human activity. Such descriptions are embedding an increasing level of ambience, where technology is expected to sense, interpret, and adapt to an individual's needs and wishes, while at the same time, the demands for transparency and accountability is making way for new regulations and guidelines for systems based on artificial intelligence (AI). The purpose of this research is to explore social roles of humans and AI systems, and to identify open research questions and challenges when designing for transparency and sense of control. A socio-technical relationship framework was developed for assessing the social roles of AI systems, and for designing for change in roles and relationships. The framework was developed based on activity theory, metaphors for human-technology interaction, and emergent research on human-AI collaboration. By focusing on meaningful shared activity, the situations when technology is socially and personally relevant can be distinguished from the situations where technology is functionally relevant. The identified roles are partly overlapping and fluent depending on the situation, which increases the need for transparency and accountability, and consequently, AI techniques that allows explainability, negotiation and adaptation of the enacted roles. The framework is exemplified in two case studies to elicit role transformations in a work and a home environment respectively, where an individual's changing need for supporting development of capabilities and autonomy through AI-based technology are addressed. We identify a number of open research questions and propose to apply the framework to capture and design for developing capability in humans and AI systems, collaborative capabilities in human-AI teaming, and for eliciting the ethical and moral consequences of AI systems operating within a person's zone of development.","[Lindgren, Helena] Umea Univ, Dept Comp Sci, Umea, Sweden",,"Lindgren, H (corresponding author), Umea Univ, Dept Comp Sci, Umea, Sweden.",helena.lindgren@umu.se,,,,,,,,3,3,,,,,,,,,,,2024 DEC 13,2024,,,,,,,,,,10.1080/10447318.2024.2435693,http://dx.doi.org/10.1080/10447318.2024.2435693,,DEC 2024,,,,,,,,,,2025-05-29,WOS:001378463100001,View Full Record in Web of Science
J,"Jiang, HR; Shi, SH; Zhang, SH; Zheng, J; Li, Q",,,,"Jiang, Haoran; Shi, Shaohan; Zhang, Shuhao; Zheng, Jie; Li, Quan",,,SLInterpreter: An Exploratory and Iterative Human-AI Collaborative System for GNN-based Synthetic Lethal Prediction,IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS,,,,Article,,,,,,,,"Synthetic Lethal (SL) relationships, though rare among the vast array of gene combinations, hold substantial promise for targeted cancer therapy. Despite advancements in AI model accuracy, there is still a significant need among domain experts for interpretive paths and mechanism explorations that align better with domain-specific knowledge, particularly due to the high costs of experimentation. To address this gap, we propose an iterative Human-AI collaborative framework with two key components: 1) Human-Engaged Knowledge Graph Refinement based on Metapath Strategies, which leverages insights from interpretive paths and domain expertise to refine the knowledge graph through metapath strategies with appropriate granularity. 2) Cross-Granularity SL Interpretation Enhancement and Mechanism Analysis, which aids experts in organizing and comparing predictions and interpretive paths across different granularities, uncovering new SL relationships, enhancing result interpretation, and elucidating potential mechanisms inferred by Graph Neural Network (GNN) models. These components cyclically optimize model predictions and mechanism explorations, enhancing expert involvement and intervention to build trust. Facilitated by SLInterpreter, this framework ensures that newly generated interpretive paths increasingly align with domain knowledge and adhere more closely to real-world biological principles through iterative Human-AI collaboration. We evaluate the framework's efficacy through a case study and expert interviews.","[Jiang, Haoran; Shi, Shaohan; Zhang, Shuhao; Zheng, Jie; Li, Quan] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China; [Jiang, Haoran; Shi, Shaohan; Zhang, Shuhao; Zheng, Jie; Li, Quan] Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China",,"Jiang, HR (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.;Jiang, HR (corresponding author), Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.",jianghr2023@shanghaitech.edu.cn; shishh2023@shanghaitech.edu.cn; zhangshh@shanghaitech.edu.cn; zhengjie@shanghaitech.edu.cn; liquan@shanghaitech.edu.cn,,,,,,,,0,0,,,,,,,,,,,JAN,2025,31,1,,,,,919,929,,10.1109/TVCG.2024.3456325,http://dx.doi.org/10.1109/TVCG.2024.3456325,,,,,,,,,,,,2025-05-29,WOS:001449829900075,View Full Record in Web of Science
J,"Zhang, R; Flathmann, C; Musick, G; Schelble, B; McNeese, NJ; Knijnenburg, B; Duan, W",,,,"Zhang, Rui; Flathmann, Christopher; Musick, Geoff; Schelble, Beau; McNeese, Nathan J.; Knijnenburg, Bart; Duan, Wen",,,"I Know This Looks Bad, But I Can Explain: Understanding When AI Should Explain Actions In Human-AI Teams",ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS,,,,Article,,,,,,,,"Explanation of artificial intelligence (AI) decision-making has become an important research area in humancomputer interaction (HCI) and computer-supported teamwork research. While plenty of research has investigated AI explanations with an intent to improve AI transparency and human trust in AI, how AI explanations function in teaming environments remains unclear. Given that a major benefit of AI giving explanations is to increase human trust understanding howAI explanations impact human trust is crucial to effective human-AI teamwork. An online experiment was conducted with 156 participants to explore this question by examining how a teammate's explanations impact the perceived trust of the teammate and the effectiveness of the team and how these impacts vary based on whether the teammate is a human or an AI. This study shows that explanations facilitate trust in AI teammates when explaining why AI disobeyed humans' orders but hindered trust when explaining why an AI lied to humans. In addition, participants' personal characteristics (e.g., their gender and the individual's ethical framework) impacted their perceptions of AI teammates both directly and indirectly in different scenarios. Our study contributes to interactive intelligent systems and HCI by shedding light on how an AI teammate's actions and corresponding explanations are perceived by humans while identifying factors that impact trust and perceived effectiveness. This work provides an initial understanding of AI explanations in human-AI teams, which can be used for future research to build upon in exploring AI explanation implementation in collaborative environments.","[Zhang, Rui; Flathmann, Christopher; Musick, Geoff; Schelble, Beau; McNeese, Nathan J.; Knijnenburg, Bart; Duan, Wen] Clemson Univ, Clemson, SC 29634 USA",,"Zhang, R (corresponding author), Clemson Univ, Clemson, SC 29634 USA.",rzhang2@clemson.edu; clathm@clemson.edu; gmusick@clemson.edu; bschelb@clemson.edu; mcneese@clemson.edu; bartk@clemson.edu; wend@clemson.edu,,,,,,,,5,5,,,,,,,,,,,JAN,2024,14,1,,,,,,,6,10.1145/3635474,http://dx.doi.org/10.1145/3635474,,,,,,,,,,,,2025-05-29,WOS:001193993900006,View Full Record in Web of Science
J,"Herrera, F",,,,"Herrera, Francisco",,,Reflections and attentiveness on eXplainable Artificial Intelligence (XAI). The journey ahead from criticisms to human-AI collaboration,INFORMATION FUSION,,,,Article,,,,,,,,"The emergence of deep learning over the past decade has driven the development of increasingly complex AI models, amplifying the need for Explainable Artificial Intelligence (XAI). As AI systems grow in size and complexity, ensuring interpretability and transparency becomes essential, especially in high-stakes applications. With the rapid expansion of XAI research, addressing emerging debates and criticisms requires a comprehensive examination. This paper explores the complexities of XAI from multiple perspectives, proposing six key axes that shed light on its role in human-AI interaction and collaboration. First, it examines the imperative of XAI under the dominance of black-box AI models. Given the lack of definitional cohesion, the paper argues that XAI must be framed through the lens of audience and understanding, highlighting its different uses in AI-human interaction. The recent BLUE vs. RED XAI distinction is analyzed through this perspective. The study then addresses the criticisms of XAI, evaluating its maturity, current trajectory, and limitations in handling complex problems. The discussion then shifts to explanations as a bridge between AI models and human understanding, emphasizing the importance of usability of explanations in human-AI decision making. Key aspects such as AI reliance, human intuition, and emerging collaboration theories - including the human-algorithm centaur and co-intelligence paradigms - are explored in connection with XAI. The medical field is considered as a case study, given its extensive research on collaboration between doctors and AI through explainability. The paper proposes a framework to evaluate the maturity of XAI using three dimensions: practicality, auditability, and AI governance. Provide the final lessons learned focused on trends and questions to tackle in the near future. This is an in-depth exploration of the impact and urgency of XAI in the era of pervasive expansion of AI. Three Key reflections from this study include: (a) XAI must enhance cognitive engagement with explanations, (b) it must evolve to fully address why, what, and for what purpose explanations are needed, and (c) it plays a crucial role in building societal trust in AI. By advancing XAI in these directions, we can ensure that AI remains transparent, auditable, and accountable, and aligned with human needs.","[Herrera, Francisco] Univ Granada, Andalusian Inst Data Sci & Computat Intelligence D, Dept Comp Sci & Artificial Intelligence, Granada, Spain; [Herrera, Francisco] ADIA Lab, Abu Dhabi, U Arab Emirates",,"Herrera, F (corresponding author), Univ Granada, Andalusian Inst Data Sci & Computat Intelligence D, Dept Comp Sci & Artificial Intelligence, Granada, Spain.;Herrera, F (corresponding author), ADIA Lab, Abu Dhabi, U Arab Emirates.",herrera@decsai.ugr.es,,,,,,,,1,1,,,,,,,,,,,SEP,2025,121,,,,,,,,103133,10.1016/j.inffus.2025.103133,http://dx.doi.org/10.1016/j.inffus.2025.103133,,MAR 2025,,,,,,,,,,2025-05-29,WOS:001460341800001,View Full Record in Web of Science
J,"Wang, ZH; Wang, JC; Tian, CY; Ali, A; Yin, XC",,,,"Wang, Ziheng; Wang, Jiachen; Tian, Chengyu; Ali, Ahsan; Yin, Xicheng",,,Adopting AI teammates in knowledge-intensive crowdsourcing contests: the roles of transparency and explainability,KYBERNETES,,,,Article; Early Access,,,,,,,,"PurposeAs the role of AI on human teams shifts from a tool to a teammate, the implementation of AI teammates into knowledge-intensive crowdsourcing (KI-C) contest teams represents a forward-thinking and feasible solution to improve team performance. Since contest teams are characterized by virtuality, temporality, competitiveness, and skill diversity, the human-AI interaction mechanism underlying conventional teams is no longer applicable. This study empirically analyzes the effects of AI teammate attributes on human team members' willingness to adopt AI in crowdsourcing contests.Design/methodology/approachA questionnaire-based online experiment was designed to perform behavioral data collection. We obtained 206 valid anonymized samples from 28 provinces in China. The Ordinary Least Squares (OLS) model was used to test the proposed hypotheses.FindingsWe find that the transparency and explainability of AI teammates have mediating effects on human team members' willingness to adopt AI through trust. Due to the different tendencies exhibited by members with regard to three types of cognitive load, nonlinear U-shaped relationships are observed among explainability, cognitive load, and willingness to adopt AI.Originality/valueWe provide design ideas for human-AI team mechanisms in KI-C scenarios, and rationally explain how the U-shaped relationship between AI explainability and cognitive load emerges.","[Wang, Ziheng; Wang, Jiachen; Tian, Chengyu; Yin, Xicheng] Nanjing Univ Sci & Technol, Sch Cyber Sci & Engn, Wuxi, Peoples R China; [Ali, Ahsan] Zhejiang Sci Tech Univ, Sch Econ & Management, Hangzhou, Peoples R China",,"Yin, XC (corresponding author), Nanjing Univ Sci & Technol, Sch Cyber Sci & Engn, Wuxi, Peoples R China.",xichengyin@njust.edu.cn,,,,,,,,1,1,,,,,,,,,,,2024 JUN 3,2024,,,,,,,,,,10.1108/K-02-2024-0478,http://dx.doi.org/10.1108/K-02-2024-0478,,JUN 2024,,,,,,,,,,2025-05-29,WOS:001234502900001,View Full Record in Web of Science
J,"Tsiakas, K; Murray-Rust, D",,,,"Tsiakas, Konstantinos; Murray-Rust, Dave",,,Unpacking Human-AI interactions: From Interaction Primitives to a Design Space,ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS,,,,Article,,,,,,,,"This article aims to develop a semi-formal representation for Human-AI (HAI) interactions, by building a set of interaction primitives which can specify the information exchanges between users and AI systems during their interaction. We show how these primitives can be combined into a set of interaction patterns which can capture common interactions between humans and AI/ML models. The motivation behind this is twofold: firstly, to provide a compact generalization of existing practices for the design and implementation of HAI interactions; and secondly, to support the creation of new interactions by extending the design space of HAI interactions. Taking into consideration frameworks, guidelines, and taxonomies related to human-centered design and implementation of AI systems, we define a vocabulary for describing information exchanges based on the model's characteristics and interactional capabilities. Based on this vocabulary, a message passing model for interactions between humans and models is presented, which we demonstrate can account for existing HAI interaction systems and approaches. Finally, we build this into design patterns which can describe common interactions between users and models, and we discuss how this approach can be used toward a design space for HAI interactions that creates new possibilities for designs as well as keeping track of implementation issues and concerns.","[Tsiakas, Konstantinos; Murray-Rust, Dave] Delft Univ Technol, Delft, Netherlands",,"Murray-Rust, D (corresponding author), Delft Univ Technol, Delft, Netherlands.",tsiakas.konstantinos@gmail.com; D.S.Murray-Rust@tudelft.nl,,,,,,,,1,1,,,,,,,,,,,SEP,2024,14,3,,,,,,,3664522,10.1145/3664522,http://dx.doi.org/10.1145/3664522,,,,,,,,,,,,2025-05-29,WOS:001325864200003,View Full Record in Web of Science
J,"Prasad, KDV; Singh, S; Hiran, D; Agarwal, P; Kothari, H",,,,"Prasad, K. D., V; Singh, Shivoham; Hiran, Divya; Agarwal, Preeti; Kothari, Hemant",,,Analyzing Factors Influencing Technology Adoption in Healthcare: A Structural Equation Modeling Perspective,PACIFIC BUSINESS REVIEW INTERNATIONAL,,,,Article,,,,,,,,"Trust is a cornerstone of effective human-AI collaboration, particularly in an era of rapid digitalization where AI systems are increasingly integrated into decision-making processes across various sectors. This study investigates the critical factors influencing trust namely Transparency, Interpretability, and Satisfaction, and their sector-specific dynamics in healthcare, finance, and customer service. Utilizing a crosssectional survey of 500 participants and stratified sampling, the research highlights pivotal role of transparency and interpretability in fostering trust, particularly in high-stakes sectors such as healthcare and finance. Transparency (fl = 0.512, p < 0.001) and interpretability ((3 = 0.602, p < 0.001) significantly enhance trust, with stronger effects observed in healthcare ( El 2 = 0.494) and finance (02 = 0.511) compared to customer service ( E 2= 0.374). Satisfaction had been emerged as a crucial mediating variable that amplifies the relationship between transparency and trust. The indirect effect of transparency on trust through satisfaction ((3 = 0.223, p < 0.001) underscores the importance of user-centric design in building trust. Furthermore, satisfaction demonstrates a stronger influence on trust in customer service ( E =0.653), emphasizing its importance in customer-facing applications. This study provides theoretical contributions by extending trust frameworks to sector- specific contexts and offers actionable insights for AI system developers and policymakers. The findings advocate for tailored trust-building strategies, prioritizing transparency and interpretability in healthcare and finance, while emphasizing user satisfaction in customer service. The research will advances the understanding of trust dynamics in human-AI collaboration, addressing the ethical, operational, and design challenges ofAl systems in a digitalized world.","[Prasad, K. D., V; Singh, Shivoham] Symbiosis Inst Business Management, Hyderabad, India; [Prasad, K. D., V; Singh, Shivoham] Symbiosis Int Univ, Pune, India; [Hiran, Divya] Govt Meera Girls Coll, Udaipur, India; [Agarwal, Preeti; Kothari, Hemant] Pacific Acad Higher Educ & Res Univ, Udaipur, India",,"Prasad, KDV (corresponding author), Symbiosis Inst Business Management, Hyderabad, India.;Prasad, KDV (corresponding author), Symbiosis Int Univ, Pune, India.",kdv.prasad@sibmhyd.edu.in; shivohamsingh@gmail.com; divyahiran123@gmail.com; preetiagarwal76@hotmail.com; kots.hemant@gmail.com,,,,,,,,0,0,,,,,,,,,,,JAN,2025,17,7,,,,,83,98,,,,,,,,,,,,,,,2025-05-29,WOS:001439248200008,View Full Record in Web of Science
J,"Pagliari, M; Chambon, V; Berberian, B",,,,"Pagliari, Marine; Chambon, Valerian; Berberian, Bruno",,,What is new with Artificial Intelligence? Human-agent interactions through the lens of social agency,FRONTIERS IN PSYCHOLOGY,,,,Review,,,,,,,,"In this article, we suggest that the study of social interactions and the development of a sense of agency in joint action can help determine the content of relevant explanations to be implemented in artificial systems to make them explainable. The introduction of automated systems, and more broadly of Artificial Intelligence (AI), into many domains has profoundly changed the nature of human activity, as well as the subjective experience that agents have of their own actions and their consequences - an experience that is commonly referred to as sense of agency. We propose to examine the empirical evidence supporting this impact of automation on individuals' sense of agency, and hence on measures as diverse as operator performance, system explicability and acceptability. Because of some of its key characteristics, AI occupies a special status in the artificial systems landscape. We suggest that this status prompts us to reconsider human-AI interactions in the light of human-human relations. We approach the study of joint actions in human social interactions to deduce what key features are necessary for the development of a reliable sense of agency in a social context and suggest that such framework can help define what constitutes a good explanation. Finally, we propose possible directions to improve human-AI interactions and, in particular, to restore the sense of agency of human operators, improve their confidence in the decisions made by artificial agents, and increase the acceptability of such agents.","[Pagliari, Marine; Chambon, Valerian] Paris Sci & Lettres Univ, Ecole Normale Super, CNRS, Inst Jean Nicod,Dept Etud Cognit, Paris, France; [Pagliari, Marine; Berberian, Bruno] Off Natl Etud & Rech Aerosp, Informat Proc & Syst, Salon De Provence, France",,"Pagliari, M; Chambon, V (corresponding author), Paris Sci & Lettres Univ, Ecole Normale Super, CNRS, Inst Jean Nicod,Dept Etud Cognit, Paris, France.;Pagliari, M; Berberian, B (corresponding author), Off Natl Etud & Rech Aerosp, Informat Proc & Syst, Salon De Provence, France.",marine.pagliari@gmail.com; valerian.chambon@gmail.com; bruno.berberian@onera.fr,,,,,,,,12,12,,,,,,,,,,,SEP 29,2022,13,,,,,,,,954444,10.3389/fpsyg.2022.954444,http://dx.doi.org/10.3389/fpsyg.2022.954444,,,,,,,,,,,,2025-05-29,WOS:000868508100001,View Full Record in Web of Science
J,"Senoner, J; Schallmoser, S; Kratzwald, B; Feuerriegel, S; Netland, T",,,,"Senoner, Julian; Schallmoser, Simon; Kratzwald, Bernhard; Feuerriegel, Stefan; Netland, Torbjorn",,,Explainable AI improves task performance in human-AI collaboration,SCIENTIFIC REPORTS,,,,Article,,,,,,,,"Artificial intelligence (AI) provides considerable opportunities to assist human work. However, one crucial challenge of human-AI collaboration is that many AI algorithms operate in a black-box manner where the way how the AI makes predictions remains opaque. This makes it difficult for humans to validate a prediction made by AI against their own domain knowledge. For this reason, we hypothesize that augmenting humans with explainable AI improves task performance in human-AI collaboration. To test this hypothesis, we implement explainable AI in the form of visual heatmaps in inspection tasks conducted by domain experts. Visual heatmaps have the advantage that they are easy to understand and help to localize relevant parts of an image. We then compare participants that were either supported by (a) black-box AI or (b) explainable AI, where the latter supports them to follow AI predictions when the AI is accurate or overrule the AI when the AI predictions are wrong. We conducted two preregistered experiments with representative, real-world visual inspection tasks from manufacturing and medicine. The first experiment was conducted with factory workers from an electronics factory, who performed \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$N=9,600$$\end{document} assessments of whether electronic products have defects. The second experiment was conducted with radiologists, who performed \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$N=5,650$$\end{document} assessments of chest X-ray images to identify lung lesions. The results of our experiments with domain experts performing real-world tasks show that task performance improves when participants are supported by explainable AI with heatmaps instead of black-box AI. We find that explainable AI as a decision aid improved the task performance by 7.7 percentage points (95% confidence interval [CI]: 3.3% to 12.0%, \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$P=0.001$$\end{document}) in the manufacturing experiment and by 4.7 percentage points (95% CI: 1.1% to 8.3%, \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$P=0.010$$\end{document}) in the medical experiment compared to black-box AI. These gains represent a significant improvement in task performance.","[Senoner, Julian; Kratzwald, Bernhard; Netland, Torbjorn] Swiss Fed Inst Technol, Zurich, Switzerland; [Schallmoser, Simon; Feuerriegel, Stefan] Ludwig Maximilians Univ Munchen, Munich, Germany; [Schallmoser, Simon; Feuerriegel, Stefan] Munich Ctr Machine Learning MCML, Munich, Germany; [Senoner, Julian; Kratzwald, Bernhard] EthonAI, Zurich, Switzerland",,"Netland, T (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.",tnetland@ethz.ch,,,,,,,,1,1,,,,,,,,,,,DEC 28,2024,14,1,,,,,,,31150,10.1038/s41598-024-82501-9,http://dx.doi.org/10.1038/s41598-024-82501-9,,,,,,,,,,,,2025-05-29,WOS:001386530100002,View Full Record in Web of Science
J,"Mortenson, T; Kovesdi, C; Mohon, J",,,,"Mortenson, Torrey; Kovesdi, Casey; Mohon, Jeremy",,,Human Factors Considerations in Artificial Intelligence Applications for Nuclear Power Plants,NUCLEAR TECHNOLOGY,,,,Article; Early Access,,,,,,,,"In recent years, there has been a wave of artificial intelligence (AI) technologies that offer to solve problems from shopping habits to mortgage approvals to critical systems operations. The rapidity of the development of these systems has led to both excitement and apprehension about the roles these systems should play in our modern societies. This paper focuses on the critical infrastructure industry, in general, and nuclear power generation, in particular, and seeks to scrutinize how we can leverage these novel technologies in human-centered ways to maintain or enhance the established high levels of reliability and resilience in these industries. First, we discuss the broader aspects of cognitive systems and activities that are critical to understanding the human-AI space. Then we explore different approaches to explainability in AI and the notions of trust. We then move on to discuss several human factors concepts and methods and how they can support the design of human-AI teams. We then explore recent research related to nuclear power that has been undertaken and evaluate the current industry and regulatory landscapes. Finally, we discuss identified research gaps and recommendations for solving these for the critical infrastructure space.","[Mortenson, Torrey; Kovesdi, Casey; Mohon, Jeremy] Idaho Natl Lab, Human Factors & Reliabil, Idaho Falls, ID 83415 USA",,"Mortenson, T (corresponding author), Idaho Natl Lab, Human Factors & Reliabil, Idaho Falls, ID 83415 USA.",torrey.mortenson@inl.gov,,,,,,,,0,0,,,,,,,,,,,2024 OCT 25,2024,,,,,,,,,,10.1080/00295450.2024.2411153,http://dx.doi.org/10.1080/00295450.2024.2411153,,OCT 2024,,,,,,,,,,2025-05-29,WOS:001339583200001,View Full Record in Web of Science
J,"Berretta, S; Tausch, A; Ontrup, G; Gilles, B; Peifer, C; Kluge, A",,,,"Berretta, Sophie; Tausch, Alina; Ontrup, Greta; Gilles, Bjoern; Peifer, Corinna; Kluge, Annette",,,Defining human-AI teaming the human-centered way: a scoping review and network analysis,FRONTIERS IN ARTIFICIAL INTELLIGENCE,,,,Review,,,,,,,,"Introduction: With the advancement of technology and the increasing utilization of AI, the nature of human work is evolving, requiring individuals to collaborate not only with other humans but also with AI technologies to accomplish complex goals. This requires a shift in perspective from technology-driven questions to a human-centered research and design agenda putting people and evolving teams in the center of attention. A socio-technical approach is needed to view AI as more than just a technological tool, but as a team member, leading to the emergence of human-AI teaming (HAIT). In this new form of work, humans and AI synergistically combine their respective capabilities to accomplish shared goals.Methods: The aim of our work is to uncover current research streams on HAIT and derive a unified understanding of the construct through a bibliometric network analysis, a scoping review and synthetization of a definition from a socio-technical point of view. In addition, antecedents and outcomes examined in the literature are extracted to guide future research in this field.Results: Through network analysis, five clusters with different research focuses on HAIT were identified. These clusters revolve around (1) human and (2) task-dependent variables, (3) AI explainability, (4) AI-driven robotic systems, and (5) the effects of AI performance on human perception. Despite these diverse research focuses, the current body of literature is predominantly driven by a technology-centric and engineering perspective, with no consistent definition or terminology of HAIT emerging to date.Discussion: We propose a unifying definition combining a human-centered and team-oriented perspective as well as summarize what is still needed in future research regarding HAIT. Thus, this work contributes to support the idea of the Frontiers Research Topic of a theoretical and conceptual basis for human work with AI systems.","[Berretta, Sophie; Tausch, Alina; Ontrup, Greta; Gilles, Bjoern; Kluge, Annette] Ruhr Univ Bochum, Dept Psychol Org & Business Psychol, Bochum, Germany; [Peifer, Corinna] Univ Lubeck, Dept Psychol 1, Lubeck, Germany",,"Berretta, S; Tausch, A (corresponding author), Ruhr Univ Bochum, Dept Psychol Org & Business Psychol, Bochum, Germany.",sophie.berretta@rub.de; alina.tausch@rub.de,,,,,,,,17,17,,,,,,,,,,,SEP 29,2023,6,,,,,,,,1250725,10.3389/frai.2023.1250725,http://dx.doi.org/10.3389/frai.2023.1250725,,,,,,,,,,,,2025-05-29,WOS:001094695600001,View Full Record in Web of Science
J,"Kirkby, A; Baumgarth, C; Henseler, J",,,,"Kirkby, Alexandra; Baumgarth, Carsten; Henseler, Jorg",,,"Welcome, new brand colleague! A conceptual framework for efficient and effective human-AI co-creation for creative brand voice",JOURNAL OF BRAND MANAGEMENT,,,,Article; Early Access,,,,,,,,"The rapid advancement of artificial intelligence (AI) capabilities has extended into creative realms, presenting opportunities for creative collaboration between human brand professionals and AI in support of brand voice efforts. However, there remains little clarity regarding the implementation of this creative interaction. With a conceptual approach, the current research proposes a three-level framework of human-AI co-creation for creative brand voice that highlights key factors that can facilitate brand efficiency and effectiveness at the individual (AI task roles, co-creation teaming, knowledge and skills), organisational (infrastructure and brand voice database, socialisation), and societal (responsibility and accountability, AI transparency, brand voice copyright) levels. Each level presents different challenges and insights. At the individual level, it is critical to consider operational processes; at the organisational level, managing the interactions is key; and at the societal level, external influences must be accounted for, to manage the brand. This research contribution in turn offers theoretical guidance, aligned with a high-level brand management perspective, on how to pursue efficiency and effectiveness at three defined levels, as well as relevant avenues for further research.","[Kirkby, Alexandra; Henseler, Jorg] Univ Twente, Dept Design Prod & Management, Enschede, Netherlands; [Kirkby, Alexandra; Baumgarth, Carsten] Hsch Wirtschaft & Recht Berlin, FB Wirtschaftswissensch 1, Berlin, Germany; [Henseler, Jorg] Univ Nova Lisboa, Lisbon, Portugal",,"Kirkby, A (corresponding author), Univ Twente, Dept Design Prod & Management, Enschede, Netherlands.;Kirkby, A (corresponding author), Hsch Wirtschaft & Recht Berlin, FB Wirtschaftswissensch 1, Berlin, Germany.",a.l.kirkby@utwente.nl,,,,,,,,0,0,,,,,,,,,,,2025 MAY 14,2025,,,,,,,,,,10.1057/s41262-025-00387-y,http://dx.doi.org/10.1057/s41262-025-00387-y,,MAY 2025,,,,,,,,,,2025-05-29,WOS:001488406400001,View Full Record in Web of Science
J,"Lee, C; Cha, K",,,,"Lee, ChangHyun; Cha, KyungJin",,,FAT-CAT-Explainability and augmentation for an AI system: A case study on AI recruitment-system adoption,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES,,,,Article,,,,,,,,"Because artificial intelligence (AI) recruitment systems exhibited discriminatory decisions in recent applications, the adoption of such systems in industry has raised doubts. As equity has been emphasized in AI decision-making frameworks, the non-explainability issue regarding the high performance of AI methods has become prominent. Therefore, scholars have focused on human-AI augmentation in which humans consider equity and AI supports the consideration. As a result, explainability is highlighted as a new capability of AI methods for an ideal decision. In this regard, this study proposes the so-called fairness, accountability, and transparency (FAT)-complexity, anxiety, and trust (CAT) model that describes the path from explainability to AI system adoption considering augmentation, assuming that the capability of the AI decision maker to explain the basis of its decision and interact with the human decision maker is crucial for AI recruitment system adoption. We found that explainability and augmentation are two key factors in AI recruitment system adoption and assessed that their importance will gradually increase as recruiters will be asked to use such AI systems more commonly. Moreover, this study conceptualized the role of an augmented relationship between humans and AI in decision-making, in which they complement each other's limitations.","[Lee, ChangHyun; Cha, KyungJin] Hanyang Univ, 222, Wangsimni ro, Seoul, South Korea",,"Cha, K (corresponding author), Hanyang Univ, 222, Wangsimni ro, Seoul, South Korea.",newdlckdgus@hanyang.ac.kr; kjcha7@hanyang.ac.kr,,,,,,,,14,14,,,,,,,,,,,MAR,2023,171,,,,,,,,102976,10.1016/j.ijhcs.2022.102976,http://dx.doi.org/10.1016/j.ijhcs.2022.102976,,DEC 2022,,,,,,,,,,2025-05-29,WOS:000993060700001,View Full Record in Web of Science
J,"Tutul, AA; Nirjhar, EH; Chaspari, T",,,,"Tutul, Abdullah Aman; Nirjhar, Ehsanul Haque; Chaspari, Theodora",,,Investigating Trust in Human-AI Collaboration for a Speech-Based Data Analytics Task,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,,,,Article,,,,,,,,"Complex real-world problems can benefit from the collaboration between humans and artificial intelligence (AI) to achieve reliable decision-making. We investigate trust in a human-in-the-loop decision-making task, in which participants with background on psychological sciences collaborate with an explainable AI system for estimating one's anxiety level from speech. The AI system relies on the explainable boosting machine (EBM) model which takes prosodic features as the input and estimates the anxiety level. Trust in AI is quantified via self-reported (i.e., administered via a questionnaire) and behavioral (i.e., computed as user-AI agreement) measures, which are positively correlated with each other. Results indicate that humans and AI depict differences in performance depending on the characteristics of the specific case under review. Overall, human annotators' trust in the AI increases over time, with momentary decreases after the AI partner makes an error. Annotators further differ in terms of appropriate trust calibration in the AI system, with some annotators over-trusting and some under-trusting the system. Personality characteristics (i.e., agreeableness, conscientiousness) and overall propensity to trust machines further affect the level of trust in the AI system, with these findings approaching statistical significance. Results from this work will lead to a better understanding of human-AI collaboration and will guide the design of AI algorithms toward supporting better calibration of user trust.","[Tutul, Abdullah Aman; Nirjhar, Ehsanul Haque] Texas A&M Univ, College Stn, TX 77843 USA; [Chaspari, Theodora] Univ Colorado Boulder, Boulder, CO USA",,"Tutul, AA (corresponding author), Texas A&M Univ, College Stn, TX 77843 USA.",abdullahaman633@tamu.edu,,,,,,,,3,3,,,,,,,,,,,MAR 4,2025,41,5,,,,,2936,2954,,10.1080/10447318.2024.2328910,http://dx.doi.org/10.1080/10447318.2024.2328910,,MAR 2024,,,,,,,,,,2025-05-29,WOS:001189455600001,View Full Record in Web of Science
J,"Jia, SC; Li, ZY; Chen, N; Zhang, JW",,,,"Jia, Shichao; Li, Zeyu; Chen, Nuo; Zhang, Jiawan",,,Towards Visual Explainable Active Learning for Zero-Shot Classification,IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS,,,,Article,,,,,,,,"Zero-shot classification is a promising paradigm to solve an applicable problem when the training classes and test classes are disjoint. Achieving this usually needs experts to externalize their domain knowledge by manually specifying a class-attribute matrix to define which classes have which attributes. Designing a suitable class-attribute matrix is the key to the subsequent procedure, but this design process is tedious and trial-and-error with no guidance. This paper proposes a visual explainable active learning approach with its design and implementation called semantic navigator to solve the above problems. This approach promotes human-AI teaming with four actions (ask, explain, recommend, respond) in each interaction loop. The machine asks contrastive questions to guide humans in the thinking process of attributes. A novel visualization called semantic map explains the current status of the machine. Therefore analysts can better understand why the machine misclassifies objects. Moreover, the machine recommends the labels of classes for each attribute to ease the labeling burden. Finally, humans can steer the model by modifying the labels interactively, and the machine adjusts its recommendations. The visual explainable active learning approach improves humans' efficiency of building zero-shot classification models interactively, compared with the method without guidance. We justify our results with user studies using the standard benchmarks for zero-shot classification.","[Jia, Shichao; Li, Zeyu; Chen, Nuo; Zhang, Jiawan] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China; [Zhang, Jiawan] State Adm Cultural Heritage, Tianjin Cultural Heritage Conservat & Inheritance, Tianjin, Peoples R China; [Zhang, Jiawan] State Adm Cultural Heritage, Key Res Ctr Surface Monitoring & Anal Rel, Tianjin, Peoples R China",,"Jia, SC (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.",jsc_se@tju.edu.cn; lzytianda@tju.edu.cn; nicole_0420@tju.edu.cn; jwzhang@tju.edu.cn,,,,,,,,21,23,,,,,,,,,,,JAN,2022,28,1,,,,,791,801,,10.1109/TVCG.2021.3114793,http://dx.doi.org/10.1109/TVCG.2021.3114793,,,,,,,,,,,,2025-05-29,WOS:000733959000082,View Full Record in Web of Science
J,"Knop, M; Weber, S; Mueller, M; Niehaves, B",,,,"Knop, Michael; Weber, Sebastian; Mueller, Marius; Niehaves, Bjoern",,,Human Factors and Technological Characteristics Influencing the Interaction of Medical Professionals With Artificial Intelligence-Enabled Clinical Decision Support Systems: Literature Review,JMIR HUMAN FACTORS,,,,Review,,,,,,,,"Background: The digitization and automation of diagnostics and treatments promise to alter the quality of health care and improve patient outcomes, whereas the undersupply of medical personnel, high workload on medical professionals, and medical case complexity increase. Clinical decision support systems (CDSSs) have been proven to help medical professionals in their everyday work through their ability to process vast amounts of patient information. However, comprehensive adoption is partially disrupted by specific technological and personal characteristics. With the rise of artificial intelligence (AI), CDSSs have become an adaptive technology with human-like capabilities and are able to learn and change their characteristics over time. However, research has not reflected on the characteristics and factors essential for effective collaboration between human actors and AI-enabled CDSSs. Objective: Our study aims to summarize the factors influencing effective collaboration between medical professionals and AI-enabled CDSSs. These factors are essential for medical professionals, management, and technology designers to reflect on the adoption, implementation, and development of an AI-enabled CDSS. Methods: We conducted a literature review including 3 different meta-databases, screening over 1000 articles and including 101 articles for full-text assessment. Of the 101 articles, 7 (6.9%) met our inclusion criteria and were analyzed for our synthesis. Results: We identified the technological characteristics and human factors that appear to have an essential effect on the collaboration of medical professionals and AI-enabled CDSSs in accordance with our research objective, namely, training data quality, performance, explainability, adaptability, medical expertise, technological expertise, personality, cognitive biases, and trust. Comparing our results with those from research on non-AI CDSSs, some characteristics and factors retain their importance, whereas others gain or lose relevance owing to the uniqueness of human-AI interactions. However, only a few (1/7, 14%) studies have mentioned the theoretical foundations and patient outcomes related to AI-enabled CDSSs. Conclusions: Our study provides a comprehensive overview of the relevant characteristics and factors that influence the interaction and collaboration between medical professionals and AI-enabled CDSSs. Rather limited theoretical foundations currently hinder the possibility of creating adequate concepts and models to explain and predict the interrelations between these characteristics and factors. For an appropriate evaluation of the human-AI collaboration, patient outcomes and the role of patients in the decision-making process should be considered.","[Knop, Michael; Weber, Sebastian; Mueller, Marius; Niehaves, Bjoern] Univ Siegen, Dept Informat Syst, Kohlbettstr 15, D-57072 Siegen, Germany",,"Knop, M (corresponding author), Univ Siegen, Dept Informat Syst, Kohlbettstr 15, D-57072 Siegen, Germany.",michael.knop@uni-siegen.de,,,,,,,,37,38,,,,,,,,,,,JAN-MAR,2022,9,1,,,,,,,e28639,10.2196/28639,http://dx.doi.org/10.2196/28639,,,,,,,,,,,,2025-05-29,WOS:000787631400047,View Full Record in Web of Science
J,"Binbeshr, F; Imam, M; Ghaleb, M; Hamdan, M; Rahim, MA; Hammoudeh, M",,,,"Binbeshr, Farid; Imam, Muhammad; Ghaleb, Mustafa; Hamdan, Mosab; Rahim, Mussadiq Abdul; Hammoudeh, Mohammad",,,The Rise of Cognitive SOCs: A Systematic Literature Review on AI Approaches,IEEE OPEN JOURNAL OF THE COMPUTER SOCIETY,,,,Article,,,,,,,,"The increasing sophistication of cyber threats has led to the evolution of Security Operations Centers (SOCs) towards more intelligent and adaptive systems. This review explores the integration of Artificial Intelligence (AI) in SOCs, focusing on their current state, challenges, opportunities, and advantages over traditional methods. We address three key questions: (1) What are the current AI approaches in SOCs? (2) What challenges and opportunities exist with these approaches? (3) What benefits do AI models offer in SOC environments compared to traditional methods? We analyzed 38 studies using a structured methodology involving database searches, quality checks, and data extraction. Our findings show that Machine Learning (ML) techniques dominate SOC research, with a trend towards multi-approach AI methods. We classified these into ML, Natural Language Processing, multi-approach, and others, forming a detailed taxonomy of AI applications in SOCs. Challenges include data quality, model interpretability, legacy system integration, and the need for constant adaptation. Opportunities involve task automation, enhanced threat detection, real-time analysis, and adaptive learning. AI-driven SOCs show better accuracy, reduced false positives, greater scalability, and predictive capabilities than traditional approaches. This review defines Cognitive SOCs, emphasizing their ability to mimic human-like processes. We offer practical insights for SOC designers and managers on implementing AI to improve security operations. Finally, we suggest future research directions in explainable AI, human-AI collaboration, and privacy-preserving AI for SOCs.","[Binbeshr, Farid; Imam, Muhammad; Ghaleb, Mustafa; Rahim, Mussadiq Abdul] King Fahd Univ Petr & Minerals, Interdisciplinary Res Ctr Intelligent Secure Syst, Dhahran 31261, Saudi Arabia; [Imam, Muhammad] King Fahd Univ Petr & Minerals, Dept Comp Engn, Dhahran 31261, Saudi Arabia; [Hammoudeh, Mohammad] King Fahd Univ Petr & Minerals, Dept Informat & Comp Sci, Dhahran 31261, Saudi Arabia; [Hamdan, Mosab] Natl Coll Ireland, Sch Comp, Dublin D02 VY45, Ireland",,"Imam, M (corresponding author), King Fahd Univ Petr & Minerals, Interdisciplinary Res Ctr Intelligent Secure Syst, Dhahran 31261, Saudi Arabia.;Imam, M (corresponding author), King Fahd Univ Petr & Minerals, Dept Comp Engn, Dhahran 31261, Saudi Arabia.",mimam@kfupm.edu.sa,,,,,,,,0,0,,,,,,,,,,,,2025,6,,,,,,360,379,,10.1109/OJCS.2025.3536800,http://dx.doi.org/10.1109/OJCS.2025.3536800,,,,,,,,,,,,2025-05-29,WOS:001432841300004,View Full Record in Web of Science
J,"Bach, TA; Kristiansen, JK; Babic, A; Jacovi, A",,,,"Bach, Tita A.; Kristiansen, Jenny K.; Babic, Aleksandar; Jacovi, Alon",,,Unpacking Human-AI Interaction in Safety-Critical Industries: A Systematic Literature Review,IEEE ACCESS,,,,Article,,,,,,,,"Ensuring quality human-AI interaction (HAII) in safety-critical industries is essential. Failure to do so can lead to catastrophic and deadly consequences. Despite this urgency, existing research on HAII is limited, fragmented, and inconsistent. We present here a survey of that literature and recommendations for research best practices that should improve the field. We divided our investigation into the following areas: 1) terms used to describe HAII, 2) primary roles of AI-enabled systems, 3) factors that influence HAII, and 4) how HAII is measured. Additionally, we described the capabilities and maturity of the AI-enabled systems used in safety-critical industries discussed in these articles. We found that no single term is used across the literature to describe HAII and some terms have multiple meanings. According to our literature, seven factors influence HAII: user characteristics (e.g., user personality), user perceptions and attitudes (e.g., user biases), user expectations and experience (e.g., mismatched user expectations and experience), AI interface and features (e.g., interactive design), AI output (e.g., perceived accuracy), explainability and interpretability (e.g., level of detail, user understanding), and usage of AI (e.g., heterogeneity of environments). HAII is most measured with user-related subjective metrics (e.g., user perceptions, trust, and attitudes), and AI-assisted decision-making is the most common primary role of AI-enabled systems. Based on this review, we conclude that there are substantial research gaps in HAII. Researchers and developers need to codify HAII terminology, involve users throughout the AI lifecycle (especially during development), and tailor HAII in safety-critical industries to the users and environments.","[Bach, Tita A.; Kristiansen, Jenny K.; Babic, Aleksandar] DNV, Grp Res & Dev, N-1322 Hovik, Norway; [Jacovi, Alon] Bar Ilan Univ, Dept Comp Sci, IL-5290002 Ramat Gan, Israel",,"Bach, TA (corresponding author), DNV, Grp Res & Dev, N-1322 Hovik, Norway.",tita.alissa.bach@dnv.com,,,,,,,,2,2,,,,,,,,,,,,2024,12,,,,,,106385,106414,,10.1109/ACCESS.2024.3437190,http://dx.doi.org/10.1109/ACCESS.2024.3437190,,,,,,,,,,,,2025-05-29,WOS:001288439400001,View Full Record in Web of Science
J,"Finzel, B",,,,"Finzel, Bettina",,,Toward trustworthy AI with integrative explainable AI frameworks,IT-INFORMATION TECHNOLOGY,,,,Article; Early Access,,,,,,,,"As artificial intelligence (AI) increasingly permeates high-stakes domains such as healthcare, transportation, and law enforcement, ensuring its trustworthiness has become a critical challenge. This article proposes an integrative Explainable AI (XAI) framework to address the challenges of interpretability, explainability, interactivity, and robustness. By combining XAI methods, incorporating human-AI interaction and using suitable evaluation techniques, the implementation of this framework serves as a holistic XAI approach. The article discusses the framework's contribution to trustworthy AI and gives an outlook on open challenges related to interdisciplinary collaboration, AI generalization and AI evaluation.","[Finzel, Bettina] Univ Bamberg, Cognit Syst, Bamberg, Germany",,"Finzel, B (corresponding author), Univ Bamberg, Cognit Syst, Bamberg, Germany.",bettina.finzel@uni-bamberg.de,,,,,,,,0,0,,,,,,,,,,,2025 MAY 1,2025,,,,,,,,,,10.1515/itit-2025-0007,http://dx.doi.org/10.1515/itit-2025-0007,,MAY 2025,,,,,,,,,,2025-05-29,WOS:001478924200001,View Full Record in Web of Science
J,"Korteling, JE; Van de Boer-Visschedijk, GC; Blankendaal, RAM; Boonekamp, RC; Eikelboom, AR",,,,"Korteling, J. E. (Hans); Van de Boer-Visschedijk, G. C.; Blankendaal, R. A. M.; Boonekamp, R. C.; Eikelboom, A. R.",,,Human- versus Artificial Intelligence,FRONTIERS IN ARTIFICIAL INTELLIGENCE,,,,Article,,,,,,,,"AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and collaborate with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI partners with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying `psychological' mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed.","[Korteling, J. E. (Hans); Van de Boer-Visschedijk, G. C.; Blankendaal, R. A. M.; Boonekamp, R. C.; Eikelboom, A. R.] TNO Human Factors, Soesterberg, Netherlands",,"Korteling, JE (corresponding author), TNO Human Factors, Soesterberg, Netherlands.",hans.korteling@tno.nl,,,,,,,,181,191,,,,,,,,,,,,2021,4,,,,,,,,622364,10.3389/frai.2021.622364,http://dx.doi.org/10.3389/frai.2021.622364,,,,,,,,,,,,2025-05-29,WOS:000751704800034,View Full Record in Web of Science
J,"Tinguely, PN; Lee, J; He, VF",,,,"Tinguely, Patrick Nicolas; Lee, Junghyun; He, Vivianna Fang",,,Designing human resource management systems in the age of AI,JOURNAL OF ORGANIZATION DESIGN,,,,Article,,,,,,,,"The increasing adoption of artificial intelligence (AI) is reshaping the practices of human resource management (HRM). We propose a typology of HR-AI collaboration systems across the dimensions of task characteristics (routine vs. non-routine; low vs. high cognitive complexity) and social acceptability of such systems among organizational members. We discuss how organizations should design HR-AI collaboration systems in light of issues of AI explainability, high stakes contexts, and threat to employees' professional identities. We point out important design considerations that may affect employees' perceptions of organizational fairness and emphasize HR professionals' role in the design process. We conclude by discussing how our Point of View article contributes to literatures on organization design and human-AI collaboration and suggesting potential avenues for future research.","[Tinguely, Patrick Nicolas] Swiss Fed Inst Technol, Dept Management Technol & Econ, Weinbergstr 56-58, CH-8092 Zurich, Switzerland; [Lee, Junghyun] Univ Michigan Dearborn, Dept Management Studies, 107 Fairlane Ctr South, Dearborn, MI 48126 USA; [He, Vivianna Fang] Univ St Gallen, Sch Management, Dufourstr 40A,3-237, CH-9000 St Gallen, Switzerland",,"Tinguely, PN (corresponding author), Swiss Fed Inst Technol, Dept Management Technol & Econ, Weinbergstr 56-58, CH-8092 Zurich, Switzerland.",ptinguely@ethz.ch; jhjess@umich.edu; viviannafang.he@unisg.ch,,,,,,,,4,4,,,,,,,,,,,DEC,2023,12,4,,,SI,,263,269,,10.1007/s41469-023-00153-x,http://dx.doi.org/10.1007/s41469-023-00153-x,,SEP 2023,,,,,,,,,,2025-05-29,WOS:001072271600001,View Full Record in Web of Science
J,"Chen, CD; Zheng, YC",,,,"Chen, Changdong; Zheng, Yuchen",,,When consumers need more interpretability of artificial intelligence (AI) recommendations? The effect of decision-making domains,BEHAVIOUR & INFORMATION TECHNOLOGY,,,,Article,,,,,,,,"Due to the black-box' nature of artificial intelligence (AI) recommendations, interpretability is critical to the consumer experience of human-AI interaction. Unfortunately, improving the interpretability of AI recommendations is technically challenging and costly. Therefore, there is an urgent need for the industry to identify when the interpretability of AI recommendations is more likely to be needed. This study defines the construct of Need for Interpretability (NFI) of AI recommendations and empirically tests consumers' need for interpretability of AI recommendations in different decision-making domains. Across two experimental studies, we demonstrate that consumers do indeed have a need for interpretability toward AI recommendations, and that the need for interpretability is higher in utilitarian domains than in hedonic domains. This study would help companies to identify the varying need for interpretability of AI recommendations in different application scenarios.","[Chen, Changdong] Chongqing Normal Univ, Sch Econ & Management, Chongqing, Peoples R China; [Zheng, Yuchen] Shanghai Univ Finance & Econ, Coll Business, Shanghai, Peoples R China; [Zheng, Yuchen] Shanghai Univ Finance & Econ, Coll Business, 777 Guoding Rd, Shanghai 200433, Peoples R China",,"Zheng, YC (corresponding author), Shanghai Univ Finance & Econ, Coll Business, 777 Guoding Rd, Shanghai 200433, Peoples R China.",915313908@qq.com,,,,,,,,1,1,,,,,,,,,,,OCT 25,2024,43,14,,,SI,,3481,3489,,10.1080/0144929X.2023.2279658,http://dx.doi.org/10.1080/0144929X.2023.2279658,,NOV 2023,,,,,,,,,,2025-05-29,WOS:001097751800001,View Full Record in Web of Science
J,"Zhou, LN; Rudin, C; Gombolay, M; Spohrer, J; Zhou, M; Paul, S",,,,"Zhou, Lina; Rudin, Cynthia; Gombolay, Matthew; Spohrer, Jim; Zhou, Michelle; Paul, Souren",,,"From Artificial Intelligence (AI) to Intelligence Augmentation (IA): Design Principles, Potential Risks, and Emerging Issues",AIS TRANSACTIONS ON HUMAN-COMPUTER INTERACTION,,,,Article,,,,,,,,"We typically think of artificial intelligence (AI) as focusing on empowering machines with human capabilities so that they can function on their own, but, in truth, much of AI focuses on intelligence augmentation (IA), which is to augment human capabilities. We propose a framework for designing intelligent augmentation (IA) systems and it addresses six central questions about IA: why, what, who/whom, how, when, and where. To address the how aspect, we introduce four guiding principles: simplification, interpretability, human-centeredness, and ethics. The what aspect includes an IA architecture that goes beyond the direct interactions between humans and machines by introducing their indirect relationships through data and domain. The architecture also points to the directions for operationalizing the IA design simplification principle. We further identify some potential risks and emerging issues in IA design and development to suggest new questions for future IA research and to foster its positive impact on humanity.","[Zhou, Lina] Univ North Carolina Charlotte, Dept Business Informat Syst & Operat Management, Charlotte, NC 28223 USA; [Rudin, Cynthia] Duke Univ, Dept Comp Sci, Durham, NC USA; [Rudin, Cynthia] Duke Univ, Dept Elect & Cmp Engn, Durham, NC USA; [Gombolay, Matthew] Georgia Inst Technol, Interact Comp, Atlanta, GA USA; [Spohrer, Jim] Int Soc Serv Innovat Profess, San Jose, CA USA; [Zhou, Michelle] Juji, San Jose, CA USA; [Paul, Souren] Northern Kentucky Univ, Sch Comp & Analyt, Highland Hts, KY USA",,"Zhou, LN (corresponding author), Univ North Carolina Charlotte, Dept Business Informat Syst & Operat Management, Charlotte, NC 28223 USA.",lzhou8@uncc.edu; cynthia@cs.duke.edu; matthew.gombolay@cc.gatech.edu; spohrer@gmail.com; mzhou@juji-inc.com; souren.paul@gmail.com,,,,,,,,6,6,,,,,,,,,,,,2023,15,1,,,,,,,,10.17705/1thci.00185,http://dx.doi.org/10.17705/1thci.00185,,,,,,,,,,,,2025-05-29,WOS:001466875800005,View Full Record in Web of Science
J,"Sharma, AK; Sharma, R",,,,"Sharma, Animesh Kumar; Sharma, Rahul",,,Navigating the Ethical Landscape: Implementing Machine Learning in Smart Healthcare Informatics,INDIAN JOURNAL OF COMMUNITY HEALTH,,,,Article,,,,,,,,"The integration of Machine Learning (ML) into healthcare informatics holds immense promise, revolutionizing patient care and treatment strategies. However, as this technology advances, it brings forth ethical challenges crucial for careful navigation. ML offers unprecedented abilities to analyze vast healthcare data, leading to personalized medicine and improved outcomes. Yet, ethical concerns emerge, notably in privacy protection, algorithm bias, transparency, informed consent, and data quality. Transparency, explainability, and patient autonomy in decision-making processes are crucial to foster trust and accountability. Striking a balance between innovation and compliance, ensuring data quality, and promoting human-AI collaboration are essential. Addressing these challenges demands adherence to ethical frameworks, continuous monitoring, multidisciplinary governance, education, and regulatory compliance. To fully harness ML's potential in healthcare while upholding ethical standards, collaboration among stakeholders is imperative, ensuring patient welfare remains central amid technological advancements. Ethical considerations must be embedded at every stage of ML implementation to maintain an ethical, equitable, and patient-centered healthcare system.","[Sharma, Animesh Kumar; Sharma, Rahul] Lovely Profess Univ, Mittal Sch Business, Jalandhar Delhi GT Rd, Phagwara 144411, Punjab, India",,"Sharma, AK (corresponding author), Lovely Profess Univ, Mittal Sch Business, Jalandhar Delhi GT Rd, Phagwara 144411, Punjab, India.",mr.animesh@gmail.com,,,,,,,,1,1,,,,,,,,,,,JAN-MAR,2024,36,1,,,,,149,152,,10.47203/IJCH.2024.v36i01.024,http://dx.doi.org/10.47203/IJCH.2024.v36i01.024,,,,,,,,,,,,2025-05-29,WOS:001198390300006,View Full Record in Web of Science
J,"Buschmeyer, K; Zenner, J; Hatfield, S",,,,"Buschmeyer, Katharina; Zenner, Julie; Hatfield, Sarah",,,Effectiveness of AI-based decision support systems in work environment: a systematic literature review,INTERNATIONAL JOURNAL OF HUMAN FACTORS AND ERGONOMICS,,,,Review,,,,,,,,"Artificial intelligence (AI) is being increasingly used in high-stakes working areas to augment experts in challenging decision-making situations. The AI support is intended to reduce the cognitive load on experts, which should ideally be reflected both in a greater sense of well-being when working on demanding tasks and in joint performance exceeding that of both the humans and AI alone. However, the extent and conditions of achievement (such as the AI accuracy and explainability) of these intended effects have not been systematically investigated. Therefore, we identified and reviewed 44 articles published since 2018 that have investigated the effects of AI-based decision support systems on experts in controlled experimental settings. The results suggest that, for optimal human-AI performance, which surpasses the performance of either alone, both must operate at similar and high levels. However, the effect on the psychological load remains unclear owing to limited research.","[Buschmeyer, Katharina; Hatfield, Sarah] Augsburg Tech Univ Appl Sci, Fac Business, D-86163 Augsburg, Germany; [Zenner, Julie] Augsburg Tech Univ Appl Sci, Fac Liberal Arts & Sci, D-86163 Augsburg, Germany",,"Buschmeyer, K (corresponding author), Augsburg Tech Univ Appl Sci, Fac Business, D-86163 Augsburg, Germany.",katharina.buschmeyer@tha.de; julie.zenner@tha.de; sarah.hatfield@tha.de,,,,,,,,0,0,,,,,,,,,,,,2024,11,5,,,,,,,,10.1504/IJHFE.2024.142761,http://dx.doi.org/10.1504/IJHFE.2024.142761,,,,,,,,,,,,2025-05-29,WOS:001360997400001,View Full Record in Web of Science
J,"Malandri, L; Mercorio, F; Mezzanzanica, M; Nobani, N",,,,"Malandri, Lorenzo; Mercorio, Fabio; Mezzanzanica, Mario; Nobani, Navid",,,ConvXAI: a System for Multimodal Interaction with Any Black-box Explainer,COGNITIVE COMPUTATION,,,,Article,,,,,,,,"Several studies have addressed the importance of context and users' knowledge and experience in quantifying the usability and effectiveness of the explanations generated by explainable artificial intelligence (XAI) systems. However, to the best of our knowledge, no component-agnostic system that accounts for this need has yet been built. This paper describes an approach called ConvXAI, which can create a dialogical multimodal interface for any black-box explainer by considering the knowledge and experience of the user. First, we formally extend the state-of-the-art conversational explanation framework by introducing clarification dialogue as an additional dialogue type. We then implement our approach as an off-the-shelf Python tool. To evaluate our framework, we performed a user study including 45 participants divided into three groups based on their level of technology use and job function. Experimental results show that (i) different groups perceive explanations differently; (ii) all groups prefer textual explanations over graphical ones; and (iii) ConvXAI provides clarifications that enhance the usefulness of the original explanations.","[Malandri, Lorenzo; Mercorio, Fabio; Mezzanzanica, Mario] Univ Milano Bicocca, Dept Stat & Quantitat Methods, Milan, Italy; [Malandri, Lorenzo; Mercorio, Fabio; Mezzanzanica, Mario] Univ Milano Bicocca, Crisp Res Ctr, Milan, Italy; [Nobani, Navid] Univ Milano Bicocca, Dept Informat Syst & Commun, Milan, Italy; [Nobani, Navid] Digital Attitude Srl, Milan, Italy",,"Nobani, N (corresponding author), Univ Milano Bicocca, Dept Informat Syst & Commun, Milan, Italy.;Nobani, N (corresponding author), Digital Attitude Srl, Milan, Italy.",navid.nobani@unimib.it,,,,,,,,12,12,,,,,,,,,,,MAR,2023,15,2,,,,,613,644,,10.1007/s12559-022-10067-7,http://dx.doi.org/10.1007/s12559-022-10067-7,,NOV 2022,,,,,,,,,,2025-05-29,WOS:000879689200001,View Full Record in Web of Science
J,"Xu, K; Shi, JY",,,,"Xu, Kun; Shi, Jingyuan",,,Visioning a two-level human-machine communication framework: initiating conversations between explainable AI and communication,COMMUNICATION THEORY,,,,Article,,,,,,,,"Amid mounting interest in artificial intelligence (AI) technology, communication scholars have sought to understand humans' perceptions of and attitudes toward AI's predictions, recommendations, and decisions. Meanwhile, scholars in the nascent but growing field of explainable AI (XAI) have aimed to clarify AI's operational mechanisms and make them interpretable, visible, and transparent. In this conceptual article, we suggest that a conversation between human-machine communication (HMC) and XAI is advantageous and necessary. Following the introduction of these two areas, we demonstrate how research on XAI can inform the HMC scholarship regarding the human-in-the-loop approach and the message production explainability. Next, we expound upon how communication scholars' focuses on message sources, receivers, features, and effects can reciprocally benefit XAI research. At its core, this article proposes a two-level HMC framework and posits that bridging the two fields can guide future AI research and development.","[Xu, Kun] Univ Florida, Coll Journalism & Commun, Gainesville, FL USA; [Shi, Jingyuan] Hong Kong Baptist Univ, Dept Interact Media, Hong Kong, Peoples R China",,"Shi, JY (corresponding author), Hong Kong Baptist Univ, Dept Interact Media, Hong Kong, Peoples R China.",jolieshi@hkbu.edu.hk,,,,,,,,2,2,,,,,,,,,,,JUL 30,2024,34,4,,,,,216,229,,10.1093/ct/qtae016,http://dx.doi.org/10.1093/ct/qtae016,,JUL 2024,,,,,,,,,,2025-05-29,WOS:001279763800001,View Full Record in Web of Science
J,"Gajcin, J; Dusparic, I",,,,"Gajcin, Jasmina; Dusparic, Ivana",,,"Redefining Counterfactual Explanations for Reinforcement Learning: Overview, Challenges and Opportunities",ACM COMPUTING SURVEYS,,,,Article,,,,,,,,"While AI algorithms have shown remarkable success in various fields, their lack of transparency hinders their application to real-life tasks. Although explanations targeted at non-experts are necessary for user trust and human-AI collaboration, the majority of explanation methods for AI are focused on developers and expert users. Counterfactual explanations are local explanations that offer users advice on what can be changed in the input for the output of the black-box model to change. Counterfactuals are user-friendly and provide actionable advice for achieving the desired output from the AI system. While extensively researched in supervised learning, there are few methods applying them to reinforcement learning (RL). In this work, we explore the reasons for the underrepresentation of a powerful explanation method in RL. We start by reviewing the current work in counterfactual explanations in supervised learning. Additionally, we explore the differences between counterfactual explanations in supervised learning and RL and identify the main challenges that prevent the adoption of methods from supervised in reinforcement learning. Finally, we redefine counterfactuals for RL and propose research directions for implementing counterfactuals in RL.","[Gajcin, Jasmina; Dusparic, Ivana] Trinity Coll Dublin, Coll Green, Dublin D02PN40, Ireland",,"Gajcin, J (corresponding author), Trinity Coll Dublin, Coll Green, Dublin D02PN40, Ireland.",gajcinj@tcd.ie; ivana.dusparic@tcd.ie,,,,,,,,2,2,,,,,,,,,,,SEP,2024,56,9,,,,,,,219,10.1145/3648472,http://dx.doi.org/10.1145/3648472,,,,,,,,,,,,2025-05-29,WOS:001230135700004,View Full Record in Web of Science
J,"Lee, BCG; Downey, D; Lo, K; Weld, DS",,,,"Lee, Benjamin Charles Germain; Downey, Doug; Lo, Kyle; Weld, Daniel S.",,,LIMEADE: From AI Explanations to Advice Taking,ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS,,,,Article,,,,,,,,"Research in human-centered AI has shown the benefits of systems that can explain their predictions. Methods that allow AI to take advice from humans in response to explanations are similarly useful. While both capabilities are well developed for transparent learning models (e.g., linear models and GA2Ms) and recent techniques (e.g., LIME and SHAP) can generate explanations for opaque models, little attention has been given to advice methods for opaque models. This article introduces LIMEADE, the first general framework that translates both positive and negative advice (expressed using high-level vocabulary such as that employed by post hoc explanations) into an update to an arbitrary, underlying opaque model. We demonstrate the generality of our approach with case studies on 70 real-world models across two broad domains: image classification and text recommendation. We show that our method improves accuracy compared to a rigorous baseline on the image classification domains. For the text modality, we apply our framework to a neural recommender system for scientific papers on a public website; our user study shows that our framework leads to significantly higher perceived user control, trust, and satisfaction.","[Lee, Benjamin Charles Germain; Weld, Daniel S.] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Box 352355, Seattle, WA 98195 USA; [Lee, Benjamin Charles Germain; Downey, Doug; Lo, Kyle; Weld, Daniel S.] Allen Inst Artificial Intelligence, 2157 N Northlake Way 110, Seattle, WA 98103 USA",,"Lee, BCG (corresponding author), Univ Washington, Paul G Allen Sch Comp Sci & Engn, Box 352355, Seattle, WA 98195 USA.",bcgl@uw.edu; dougd@allenai.org; kylel@allenai.org; weld@cs.washington.edu,,,,,,,,2,3,,,,,,,,,,,DEC,2023,13,4,,,SI,,,,24,10.1145/3589345,http://dx.doi.org/10.1145/3589345,,,,,,,,,,,,2025-05-29,WOS:001153515100005,View Full Record in Web of Science
J,"Truss, M; Schmitt, M",,,,"Truss, Mario; Schmitt, Marc",,,"Human-Centered AI Product Prototyping with No-Code AutoML: Conceptual Framework, Potentials and Limitations",INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,,,,Article; Early Access,,,,,,,,"This paper addresses AI product prototyping, focusing on the challenges posed by the probabilistic nature of AI behavior and the limited accessibility of prototyping tools to AI non-experts. A design science research (DSR) approach is presented, which culminates in a conceptual framework for structuring the AI prototyping process with no-code AutoML technologies for textual and tabular ML use cases. Through a comprehensive literature review, key challenges were identified, and no-code AutoML was positioned as a solution. The framework describes the incorporation of non-expert input and evaluation during prototyping, leveraging the potential of no-code AutoML to enhance accessibility and interpretability. A hybrid approach combining naturalistic (case study) and artificial evaluation methods (criteria-based analysis) validated the utility of our approach, highlighting its efficacy in supporting AI non-experts and streamlining decision-making and its limitations. The implications for academia and industry focus on the strategic integration of no-code AutoML to enhance AI product development processes, mitigate risks, and foster innovation.","[Truss, Mario] Adobe, Munich, Germany; [Schmitt, Marc] Siemens, Munich, Germany",,"Truss, M (corresponding author), Adobe, Munich, Germany.",mtruss@adobe.com,,,,,,,,0,0,,,,,,,,,,,2024 NOV 26,2024,,,,,,,,,,10.1080/10447318.2024.2425454,http://dx.doi.org/10.1080/10447318.2024.2425454,,NOV 2024,,,,,,,,,,2025-05-29,WOS:001364550900001,View Full Record in Web of Science
J,"Rieger, T; Schindler, H; Onnasch, L; Roesler, E",,,,"Rieger, Tobias; Schindler, Hanna; Onnasch, Linda; Roesler, Eileen",,,Explaining AI weaknesses improves human-AI performance in a dynamic control task,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES,,,,Article,,,,,,,,"AI-based decision support is increasingly implemented to support operators in dynamic control tasks. While these systems continuously improve, to truly achieve human-system synergy, one must also study humans' system understanding and behavior. Accordingly, we investigated the impact of explainability instructions regarding a specific system weakness on performance and trust in two experiments (with higher task demands in Experiment 2). Participants performed a dynamic control task with support from either an explainable AI (XAI, information on a system weakness), a non-explainable AI (nonXAI, no information on system weakness), or without support (manual, only in Experiment 2). Results show that participants with XAI support outperformed those in the nonXAI group, particularly in situations where the AI actually erred. Notably, informing users of system weaknesses did not affect trust once they had interacted with the system. In addition, Experiment 2 showed the general benefit of decision support over working manually under higher task demands. These findings suggest that AI support can enhance performance in complex tasks and that providing information on potential system weaknesses aids in managing system errors and resource allocation without compromising trust.","[Rieger, Tobias; Schindler, Hanna; Onnasch, Linda] Tech Univ Berlin, Dept Psychol & Ergon, Berlin, Germany; [Roesler, Eileen] George Mason Univ, Dept Psychol, Fairfax, VA USA",,"Rieger, T (corresponding author), Tech Univ Berlin, Dept Psychol & Ergon, Berlin, Germany.",t.rieger@tu-berlin.de,,,,,,,,0,0,,,,,,,,,,,MAY,2025,199,,,,,,,,103505,10.1016/j.ijhcs.2025.103505,http://dx.doi.org/10.1016/j.ijhcs.2025.103505,,APR 2025,,,,,,,,,,2025-05-29,WOS:001461821700001,View Full Record in Web of Science
J,"Schraagen, JM",,,,"Schraagen, Jan Maarten",,,Responsible use of AI in military systems: prospects and challenges,ERGONOMICS,,,,Article,,,,,,,,"Artificial Intelligence (AI) holds great potential for the military domain but is also seen as prone to data bias and lacking transparency and explainability. In order to advance the trustworthiness of AI-enabled systems, a dynamic approach to the development, deployment and use of AI systems is required. This approach, when incorporating ethical principles such as lawfulness, traceability, reliability and bias mitigation, is called 'Responsible AI'. This article describes the challenges of using AI responsibly in the military domain from a human factors and ergonomics perspective. Many of the ironies of automation originally described by Bainbridge still apply in the field of AI, but there are also some unique challenges and requirements that need to be considered, such as a larger emphasis on ethical risk analyses and validation and verification up-front, as well as moral situation awareness during deployment and use of AI in military systems. 'Responsible AI' is a relatively novel transdisciplinary field incorporating ethical principles in the development and use of AI in military systems. I describe the prospects and challenges with Responsible AI from a human factors and ergonomics perspective. There is in particular a need for new methods for testing and evaluation, validation and verification, explainability and transparency of AI, as well as for new ways of Human-AI Teaming.","[Schraagen, Jan Maarten] TNO Locatie Soesterberg, Human Machine Teaming, Soesterberg, Netherlands",,"Schraagen, JM (corresponding author), TNO Locatie Soesterberg, Human Machine Teaming, Soesterberg, Netherlands.",jan_maarten.schraagen@tno.nl,,,,,,,,2,2,,,,,,,,,,,NOV 2,2023,66,11,,,SI,,1719,1729,,10.1080/00140139.2023.2278394,http://dx.doi.org/10.1080/00140139.2023.2278394,,NOV 2023,,,,,,,,,,2025-05-29,WOS:001096703600001,View Full Record in Web of Science
J,"Holzinger, A; Zatloukal, K; Müller, H",,,,"Holzinger, Andreas; Zatloukal, Kurt; Mueller, Heimo",,,Is human oversight to AI systems still possible?,NEW BIOTECHNOLOGY,,,,Editorial Material,,,,,,,,"The rapid proliferation of artificial intelligence (AI) systems across diverse domains raises critical questions about the feasibility of meaningful human oversight, particularly in high-stakes domains such as new biotechnology. As AI systems grow increasingly complex, opaque, and autonomous, ensuring responsible use becomes a formidable challenge. During our editorial work for the special issue Artificial Intelligence for Life Sciences, we placed increasing emphasis on the topic of human oversight. Consequently, in this editorial we briefly discuss the evolving role of human oversight in AI governance, focusing on the practical, technical, and ethical dimensions of maintaining control. It examines how the complexity of contemporary AI architectures, such as large-scale neural networks and generative AI applications, undermine human understanding and decision-making capabilities. Furthermore, it evaluates emerging approaches-such as explainable AI (XAI), human-in-the-loop systems, and regulatory frameworks-that aim to enable oversight while acknowledging their limitations. Through a comprehensive analysis, the picture emerged while complete oversight may no longer be viable in certain contexts, strategic interventions leveraging human-AI collaboration and trustworthy AI design principles can preserve accountability and safety. The discussion highlights the urgent need for interdisciplinary efforts to rethink oversight mechanisms in an era where AI may outpace human comprehension.","[Holzinger, Andreas] Univ Nat Resources & Life Sci Vienna, Inst Forest Engn, Dept Ecosyst Management Climate & Biodivers, Human Ctr AI Lab, Vienna, Austria; [Holzinger, Andreas; Zatloukal, Kurt; Mueller, Heimo] Med Univ Graz, Diagnost & Res Inst Pathol, Informat Sci & Machine Learning Grp, Graz, Austria",,"Holzinger, A (corresponding author), Univ Nat Resources & Life Sci Vienna, Inst Forest Engn, Dept Ecosyst Management Climate & Biodivers, Human Ctr AI Lab, Vienna, Austria.",andreas.holzinger@boku.ac.at,,,,,,,,8,8,,,,,,,,,,,MAR 25,2025,85,,,,,,59,62,,10.1016/j.nbt.2024.12.003,http://dx.doi.org/10.1016/j.nbt.2024.12.003,,DEC 2024,,,,,,,,,,2025-05-29,WOS:001391606400001,View Full Record in Web of Science
J,"Zhang, ZT; Argin, SK; Bilen, MB; Urgun, D; Deniz, SM; Liu, YT; Hassib, M",,,,"Zhang, Zelun Tony; Argin, Seniha Ketenci; Bilen, Mustafa Baha; Urgun, Dogan; Deniz, Sencer Melih; Liu, Yuanting; Hassib, Mariam",,,Measuring the effect of mental workload and explanations on appropriate AI reliance using EEG,BEHAVIOUR & INFORMATION TECHNOLOGY,,,,Article; Early Access,,,,,,,,"AI is anticipated to improve human decision-making across various domains, often in high-stakes, difficult tasks. However, human reliance on AI recommendations is often inappropriate. A common approach to address this is to provide explanations about the AI output to decision makers, but results have been mixed so far. It often remains unclear when people can rely appropriately on AI and when explanations can help. In this work, we conducted a lab experiment (N = 34) to investigate how the appropriateness of human reliance on (explainable) AI depends on the mental workload induced by different decision difficulties. Instead of self-assessments, we used EEG (Emotiv Epoc Flex head cap, 32 wet electrodes) to more directly measure participants' mental workload. We found that the difficulty of a decision, indicated by the induced mental workload, strongly influences participants' ability to rely appropriately on AI, as assessed through relative self-reliance, relative AI reliance, and decision accuracy with and without AI. While reliance was appropriate for low mental workload decisions, participants were prone to overreliance in high mental workload decisions. Explanations had no significant effect in either case. Our results imply that alternatives to the common 'recommend-and-explain' approach should be explored to assist human decision-making in challenging tasks.","[Zhang, Zelun Tony; Liu, Yuanting; Hassib, Mariam] Fortiss GmbH, Res Inst Free State Bavaria, Munich, Germany; [Zhang, Zelun Tony] Ludwig Maximilians Univ Munchen, Munich, Germany; [Argin, Seniha Ketenci; Bilen, Mustafa Baha; Urgun, Dogan; Deniz, Sencer Melih] Sci & Technol Res Council Turkey TUBITAK, Informat & Informat Secur Res Ctr BILGEM, Gebze, Turkiye; [Urgun, Dogan] Karabuk Univ, Karabuk, Turkiye; [Deniz, Sencer Melih] Bogazici Univ, Istanbul, Turkiye",,"Zhang, ZT (corresponding author), Guerickestr 25, D-80805 Munich, Germany.",zhang@fortiss.org,,,,,,,,0,0,,,,,,,,,,,2024 NOV 23,2024,,,,,,,,,,10.1080/0144929X.2024.2431055,http://dx.doi.org/10.1080/0144929X.2024.2431055,,NOV 2024,,,,,,,,,,2025-05-29,WOS:001364729200001,View Full Record in Web of Science
J,"Neves, I; Folgado, D; Santos, S; Barandas, M; Campagner, A; Ronzio, L; Cabitza, F; Gamboa, H",,,,"Neves, Ines; Folgado, Duarte; Santos, Sara; Barandas, Marilia; Campagner, Andrea; Ronzio, Luca; Cabitza, Federico; Gamboa, Hugo",,,Interpretable heartbeat classification using local model-agnostic explanations on ECGs,COMPUTERS IN BIOLOGY AND MEDICINE,,,,Article,,,,,,,,"Treatment and prevention of cardiovascular diseases often rely on Electrocardiogram (ECG) interpretation. Dependent on the physician's variability, ECG interpretation is subjective and prone to errors. Machine learning models are often developed and used to support doctors; however, their lack of interpretability stands as one of the main drawbacks of their widespread operation. This paper focuses on an Explainable Artificial Intelligence (XAI) solution to make heartbeat classification more explainable using several state-of-the-art model-agnostic methods. We introduce a high-level conceptual framework for explainable time series and propose an original method that adds temporal dependency between time samples using the time series' derivative. The results were validated in the MIT-BIH arrhythmia dataset: we performed a performance's analysis to evaluate whether the explanations fit the model's behaviour; and employed the 1-D Jaccard's index to compare the subsequences extracted from an interpretable model and the XAI methods used. Our results show that the use of the raw signal and its derivative includes temporal dependency between samples to promote classification explanation. A small but informative user study concludes this study to evaluate the potential of the visual explanations produced by our original method for being adopted in real-world clinical settings, either as diagnostic aids or training resource.","[Neves, Ines; Folgado, Duarte; Santos, Sara; Barandas, Marilia; Gamboa, Hugo] Associacao Fraunhofer Portugal Res, Rua Alfredo Allen 455-461, P-4200135 Porto, Portugal; [Folgado, Duarte; Barandas, Marilia; Gamboa, Hugo] Univ Nova Lisboa, Lab Instrumentacao Engn Biomed & Fis Radiacao LIB, Dept Fis, Fac Ciencias & Tecnol,FCT, P-2829516 Caparica, Portugal; [Campagner, Andrea; Ronzio, Luca; Cabitza, Federico] Univ Milano Bicocca, Dipartimento Informat Sistemist & Comunicaz, Viale Sarca 336, I-20126 Milan, Italy",,"Folgado, D (corresponding author), Associacao Fraunhofer Portugal Res, Rua Alfredo Allen 455-461, P-4200135 Porto, Portugal.",duarte.folgado@fraunhofer.pt,,,,,,,,51,54,,,,,,,,,,,JUN,2021,133,,,,,,,,104393,10.1016/j.compbiomed.2021.104393,http://dx.doi.org/10.1016/j.compbiomed.2021.104393,,APR 2021,,,,,,,,,,2025-05-29,WOS:000663491300007,View Full Record in Web of Science
J,"Malandri, L; Mercorio, F; Mezzanzanica, M; Nobani, N; Seveso, A",,,,"Malandri, Lorenzo; Mercorio, Fabio; Mezzanzanica, Mario; Nobani, Navid; Seveso, Andrea",,,ContrXT: Generating contrastive explanations from any text classifier,INFORMATION FUSION,,,,Article,,,,,,,,"The need for explanations of ML systems is growing as new models outperform their predecessors while becoming more complex and less comprehensible for their end-users. Though several XAI methods have been proposed in recent years, not enough attention was paid to explaining how models change their behaviour in contrast with previous ones (e.g., due to retraining). In such cases, an XAI system should explain why the model changes its predictions concerning past outcomes. Capturing and understanding such differences is crucial, as the need for trust is key in any application to support human-AI decision-making processes. This is the idea of ContrXT, a novel approach that (i) traces the decision criteria of a black box text classifier by encoding the changes in the decision logic through Binary Decision Diagrams. Then (ii) it provides global, model-agnostic, Time-Contrastive (T-contrast) explanations in natural language, estimating why - and to what extent - the model has modified its behaviour over time. We implemented and evaluated ContrXT over several supervised ML models trained on a benchmark dataset and a real-life application, showing it is effective in catching majorly changed classes and in explaining their variation through a user study. The approach has been implemented, and it is available to the community both as a python package and through REST API, providing contrastive explanations as a service.","[Malandri, Lorenzo; Mercorio, Fabio; Mezzanzanica, Mario] Univ Milano Bicocca, Dept Stat & Quantitat Methods, Milan, Italy; [Nobani, Navid; Seveso, Andrea] Univ Milano Bicocca, Dept Informat Syst & Commun, Milan, Italy; [Malandri, Lorenzo; Mercorio, Fabio; Mezzanzanica, Mario; Seveso, Andrea] Univ Milano Bicocca, CRISP Res Ctr, Milan, Italy",,"Mercorio, F (corresponding author), Via Bicocca Arcimboldi,Bldg U7, I-20100 Milan, Italy.",fabio.mercorio@unimib.it,,,,,,,,13,13,,,,,,,,,,,MAY,2022,81,,,,,,103,115,,10.1016/j.inffus.2021.11.016,http://dx.doi.org/10.1016/j.inffus.2021.11.016,,DEC 2021,,,,,,,,,,2025-05-29,WOS:000735294100007,View Full Record in Web of Science
J,"Le Guillou, M; Prevot, L; Berberian, B",,,,"Le Guillou, Marin; Prevot, Laurent; Berberian, Bruno",,,Bringing Together Ergonomic Concepts and Cognitive Mechanisms for Human-AI Agents Cooperation,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,,,,Article,,,,,,,,"The deployment of artificial intelligence from experimental settings to concrete applications implies to consider the social aspects of the environment and consequently to conceive the interaction between humans and computers endowed with the aim of being partners in action. This article proposes a review of the research initiatives regarding human-artificial agents interaction, including eXplainable Artificial Intelligence (XAI) and HRI/HCI. We argue that even if vocabulary and approaches are different, the concepts converge on the necessity for the artificial agents to provide an accurate mental model of their behavior to the humans they are interacting with. This has different implications depending on whether we consider a tool/user interaction or a cooperation interaction-which is far less documented despite being at the heart of the future concepts of autonomous vehicles. From this observation, the article uses the cognitive science corpus on joint-action to raise finer cognitive mechanisms proved to be essential for human joint-action which could be considered as cognitive requirements for future artificial agents, including shared task representation and mentalization. Finally, interactions content hypotheses are arisen to satisfy the identified mechanisms, including the ability for the artificial agent to elicit its intentions and to trigger mentalization toward them from the human cooperators.","[Le Guillou, Marin; Berberian, Bruno] Off Natl Etud & Rech Aerosp, French Aerosp Lab, Informat Proc & Syst Dept, Salon De Provence, France; [Le Guillou, Marin; Prevot, Laurent] Aix Marseille Univ, CNRS, Lab Parole Language, Aix En Provence, France",,"Le Guillou, M (corresponding author), Off Natl Etud & Rech Aerosp, French Aerosp Lab, Informat Proc & Syst Dept, Salon De Provence, France.;Le Guillou, M (corresponding author), Aix Marseille Univ, CNRS, Lab Parole Language, Aix En Provence, France.",marin.le_guillou@onera.fr,,,,,,,,8,8,,,,,,,,,,,MAY 28,2023,39,9,,,SI,,1827,1840,,10.1080/10447318.2022.2129741,http://dx.doi.org/10.1080/10447318.2022.2129741,,OCT 2022,,,,,,,,,,2025-05-29,WOS:000866327600001,View Full Record in Web of Science
J,"Ayorinde, JOO; Citterio, F; Landrò, M; Peruzzo, E; Islam, T; Tilley, S; Taylor, G; Bardsley, V; Liò, P; Samoshkin, A; Pettigrew, GJ",,,,"Ayorinde, John O. O.; Citterio, Federica; Landro, Matteo; Peruzzo, Elia; Islam, Tuba; Tilley, Simon; Taylor, Geoffrey; Bardsley, Victoria; Lio, Pietro; Samoshkin, Alex; Pettigrew, Gavin J.",,,Artificial Intelligence You Can Trust: What Matters Beyond Performance When Applying Artificial Intelligence to Renal Histopathology?,JOURNAL OF THE AMERICAN SOCIETY OF NEPHROLOGY,,,,Review,,,,,,,,"Although still in its infancy, artificial intelligence (AI) analysis of kidney biopsy images is anticipated to become an integral aspect of renal histopathology. As these systems are developed, the focus will understandably be on developing ever more accurate models, but successful translation to the clinic will also depend upon other characteristics of the system.In the extreme, deployment of highly performant but ?black box? AI is fraught with risk, and high-profile errors could damage future trust in the technology. Furthermore, a major factor determining whether new systems are adopted in clinical settings is whether they are ?trusted? by clinicians. Key to unlocking trust will be designing platforms optimized for intuitive human-AI interactions and ensuring that, where judgment is required to resolve ambiguous areas of assessment, the workings of the AI image classifier are understandable to the human observer. Therefore, determining the optimal design for AI systems depends on factors beyond performance, with considerations of goals, interpretability, and safety constraining many design and engineering choices.In this article, we explore challenges that arise in the application of AI to renal histopathology, and consider areas where choices around model architecture, training strategy, and workflow design may be influenced by factors beyond the final performance metrics of the system.","[Ayorinde, John O. O.; Pettigrew, Gavin J.] Univ Cambridge, Addenbrookes Hosp, Dept Surg, Cambridge, England; [Citterio, Federica; Landro, Matteo; Peruzzo, Elia; Islam, Tuba; Tilley, Simon; Taylor, Geoffrey] SAS Inst Inc, Cary, NC USA; [Bardsley, Victoria] Addenbrookes Hosp, Dept Histopathol, Cambridge, England; [Lio, Pietro] Univ Cambridge, Dept Comp Sci & Technol, Cambridge, England; [Samoshkin, Alex] Univ Cambridge, Sch Clin Med, Off Translat Res, Cambridge, England",,"Pettigrew, GJ (corresponding author), Addenbrookes Hosp, Dept Surg, Level 9,Hills Rd, Cambridge CB2 0QQ, England.",gjp25@cam.ac.uk,,,,,,,,6,6,,,,,,,,,,,DEC,2022,33,12,,,,,2133,2140,,10.1681/ASN.2022010069,http://dx.doi.org/10.1681/ASN.2022010069,,,,,,,,,,,,2025-05-29,WOS:000905310400004,View Full Record in Web of Science
J,"Chevalier, O; Dubey, G; Benkabbou, A; Majbar, MA; Souadka, A",,,,"Chevalier, Olivia; Dubey, Gerard; Benkabbou, Amine; Majbar, Mohammed Anass; Souadka, Amine",,,Comprehensive overview of artificial intelligence in surgery: a systematic review and perspectives,PFLUGERS ARCHIV-EUROPEAN JOURNAL OF PHYSIOLOGY,,,,Review,,,,,,,,"The rapid integration of artificial intelligence (AI) into surgical practice necessitates a comprehensive evaluation of its applications, challenges, and physiological impact. This systematic review synthesizes current AI applications in surgery, with a particular focus on machine learning (ML) and its role in optimizing preoperative planning, intraoperative decision-making, and postoperative patient management. Using PRISMA guidelines and PICO criteria, we analyzed key studies addressing AI's contributions to surgical precision, outcome prediction, and real-time physiological monitoring. While AI has demonstrated significant promise-from enhancing diagnostics to improving intraoperative safety-many surgeons remain skeptical due to concerns over algorithmic unpredictability, surgeon autonomy, and ethical transparency. This review explores AI's physiological integration into surgery, discussing its role in real-time hemodynamic assessments, AI-guided tissue characterization, and intraoperative physiological modeling. Ethical concerns, including algorithmic opacity and liability in high-stakes scenarios, are critically examined alongside AI's potential to augment surgical expertise. We conclude that longitudinal validation, improved AI explainability, and adaptive regulatory frameworks are essential to ensure safe, effective, and ethically sound integration of AI into surgical decision-making. Future research should focus on bridging AI-driven analytics with real-time physiological feedback to refine precision surgery and patient safety strategies.","[Chevalier, Olivia; Dubey, Gerard] Univ Paris 1 Pantheon Sorbonne, Inst Mines Telecom Business Sch, Paris, France; [Benkabbou, Amine; Majbar, Mohammed Anass; Souadka, Amine] Mohammed V Univ, Natl Inst Oncol, Surg Oncol Dept, Rabat, Morocco",,"Souadka, A (corresponding author), Mohammed V Univ, Natl Inst Oncol, Surg Oncol Dept, Rabat, Morocco.",a.souadka@um5r.ac.ma,,,,,,,,0,0,,,,,,,,,,,APR,2025,477,4,,,,,617,626,,10.1007/s00424-025-03076-6,http://dx.doi.org/10.1007/s00424-025-03076-6,,MAR 2025,,,,,,,,,,2025-05-29,WOS:001444637900001,View Full Record in Web of Science
J,"Cabour, G; Morales-Forero, A; Ledoux, É; Bassetto, S",,,,"Cabour, Garrick; Morales-Forero, Andres; Ledoux, Elise; Bassetto, Samuel",,,An explanation space to align user studies with the technical development of Explainable AI,AI & SOCIETY,,,,Article,,,,,,,,"Providing meaningful and actionable explanations for end-users is a situated problem requiring the intersection of multiple disciplines to address social, operational, and technical challenges. However, the explainable artificial intelligence community has not commonly adopted or created tangible design tools that allow interdisciplinary work to develop reliable AI-powered solutions. This paper proposes a formative architecture that defines the explanation space from a user-inspired perspective. The architecture comprises five intertwined components to outline explanation requirements for a task: (1) the end-users' mental models, (2) the end-users' cognitive process, (3) the user interface, (4) the Human-Explainer Agent, and (5) the agent process. We first define each component of the architecture. Then, we present the Abstracted Explanation Space, a modeling tool that aggregates the architecture's components to support designers in systematically aligning explanations with end-users' work practices, needs, and goals. It guides the specifications of what needs to be explained (content: end-users' mental model), why this explanation is necessary (context: end-users' cognitive process), to delimit how to explain it (format: Human-Explainer Agent and user interface), and when the explanations should be given. We then exemplify the tool's use in an ongoing case study in the aircraft maintenance domain. Finally, we discuss possible contributions of the tool, known limitations or areas for improvement, and future work to be done.","[Cabour, Garrick; Morales-Forero, Andres; Bassetto, Samuel] Polytech Montreal, Montreal, PQ, Canada; [Ledoux, Elise] Univ Quebec Montreal, Montreal, PQ, Canada",,"Cabour, G (corresponding author), Polytech Montreal, Montreal, PQ, Canada.",garrick.cabour@polymtl.ca; andres.moralesforero@polymtl.ca; ledoux.elise@uqam.ca; samuel-jean.bassetto@polymtl.ca,,,,,,,,6,6,,,,,,,,,,,APR,2023,38,2,,,,,869,887,,10.1007/s00146-022-01536-6,http://dx.doi.org/10.1007/s00146-022-01536-6,,JUL 2022,,,,,,,,,,2025-05-29,WOS:000830258500001,View Full Record in Web of Science
J,"Naiseh, M; Al-Thani, D; Jiang, N; Ali, R",,,,"Naiseh, Mohammad; Al-Thani, Dena; Jiang, Nan; Ali, Raian",,,How the different explanation classes impact trust calibration: The case of clinical decision support systems,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES,,,,Article,,,,,,,,"Machine learning has made rapid advances in safety-critical applications, such as traffic control, finance, and healthcare. With the criticality of decisions they support and the potential consequences of following their recommendations, it also became critical to provide users with explanations to interpret machine learning models in general, and black-box models in particular. However, despite the agreement on explainability as a necessity, there is little evidence on how recent advances in eXplainable Artificial Intelligence literature (XAI) can be applied in collaborative decision-making tasks, i.e., human decision-maker and an AI system working together, to contribute to the process of trust calibration effectively. This research conducts an empirical study to evaluate four XAI classes for their impact on trust calibration. We take clinical decision support systems as a case study and adopt a within-subject design followed by semi-structured interviews. We gave participants clinical scenarios and XAI interfaces as a basis for decision-making and rating tasks. Our study involved 41 medical practitioners who use clinical decision support systems frequently. We found that users perceive the contribution of explanations to trust calibration differently according to the XAI class and to whether XAI interface design fits their job constraints and scope. We revealed additional requirements on how explanations shall be instantiated and designed to help a better trust calibration. Finally, we build on our findings and present guidelines for designing XAI interfaces.","[Naiseh, Mohammad] Univ Southampton, Fac Elect & Comp Sci, Southampton SO17 1BJ, Hants, England; [Jiang, Nan] Bournemouth Univ, Fac Sci & Technol, Poole BH12 5BB, Dorset, England; [Al-Thani, Dena; Ali, Raian] Hamad Bin Khalifa Univ, Coll Sci & Engn, Doha, Qatar",,"Naiseh, M (corresponding author), Univ Southampton, Fac Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.",m.naiseh@soton.ac.uk,,,,,,,,45,46,,,,,,,,,,,JAN,2023,169,,,,,,,,102941,10.1016/j.ijhcs.2022.102941,http://dx.doi.org/10.1016/j.ijhcs.2022.102941,,OCT 2022,,,,,,,,,,2025-05-29,WOS:000875633200002,View Full Record in Web of Science
J,"Veitch, E; Alsos, OA",,,,"Veitch, Erik; Alsos, Ole Andreas",,,Human-Centered Explainable Artificial Intelligence for Marine Autonomous Surface Vehicles,JOURNAL OF MARINE SCIENCE AND ENGINEERING,,,,Article,,,,,,,,"Explainable Artificial Intelligence (XAI) for Autonomous Surface Vehicles (ASVs) addresses developers' needs for model interpretation, understandability, and trust. As ASVs approach wide-scale deployment, these needs are expanded to include end user interactions in real-world contexts. Despite recent successes of technology-centered XAI for enhancing the explainability of AI techniques to expert users, these approaches do not necessarily carry over to non-expert end users. Passengers, other vessels, and remote operators will have XAI needs distinct from those of expert users targeted in a traditional technology-centered approach. We formulate a concept called 'human-centered XAI' to address emerging end user interaction needs for ASVs. To structure the concept, we adopt a model-based reasoning method for concept formation consisting of three processes: analogy, visualization, and mental simulation, drawing from examples of recent ASV research at the Norwegian University of Science and Technology (NTNU). The examples show how current research activities point to novel ways of addressing XAI needs for distinct end user interactions and underpin the human-centered XAI approach. Findings show how representations of (1) usability, (2) trust, and (3) safety make up the main processes in human-centered XAI. The contribution is the formation of human-centered XAI to help advance the research community's efforts to expand the agenda of interpretability, understandability, and trust to include end user ASV interactions.","[Veitch, Erik; Alsos, Ole Andreas] Norwegian Univ Sci & Technol NTNU, Dept Design, Kolbjorn Hejes Vei 2b, N-7491 Trondheim, Norway",,"Veitch, E (corresponding author), Norwegian Univ Sci & Technol NTNU, Dept Design, Kolbjorn Hejes Vei 2b, N-7491 Trondheim, Norway.",erik.a.veitch@ntnu.no; ole.alsos@ntnu.no,,,,,,,,18,18,,,,,,,,,,,NOV,2021,9,11,,,,,,,1227,10.3390/jmse9111227,http://dx.doi.org/10.3390/jmse9111227,,,,,,,,,,,,2025-05-29,WOS:000834271400001,View Full Record in Web of Science
J,"Saqr, M; López-Pernas, S",,,,"Saqr, Mohammed; Lopez-Pernas, Sonsoles",,,Why explainable AI may not be enough: predictions and mispredictions in decision making in education,SMART LEARNING ENVIRONMENTS,,,,Article,,,,,,,,"In learning analytics and in education at large, AI explanations are always computed from aggregate data of all the students to offer the average picture. Whereas the average may work for most students, it does not reflect or capture the individual differences or the variability among students. Therefore, instance-level predictions-where explanations for each particular student are presented according to their own data-may help understand how and why predictions were estimated and how a student or teacher may act or make decisions. This study aims to examine the utility of individualized instance-level AI, its value in informing decision-making, and-more importantly-how they can be used to offer personalized feedback. Furthermore, the study examines mispredictions, their explanations and how they offer explanations or affect decision making. Using data from a full course with 126 students, five ML algorithms were implemented with explanatory mechanisms, compared and the best performing algorithm (Random Forest) was therefore selected. The results show that AI explanations, while useful, cannot achieve their full potential without a nuanced human involvement (i.e., hybrid human AI collaboration). Instance-level explainability may allow us to understand individual algorithmic decisions but may not very helpful for personalization or individualized support. In case of mispredictions, the explanations show that algorithms decide based on the wrong predictors which underscores the fact that a full data-driven approach cannot be fully trusted with generating plausible recommendations completely on its own and may require human assistance.","[Saqr, Mohammed; Lopez-Pernas, Sonsoles] Univ Eastern Finland, Sch Comp, Joensuu Campus Yliopistokatu 2, FI-80100 Joensuu, Finland",,"Saqr, M (corresponding author), Univ Eastern Finland, Sch Comp, Joensuu Campus Yliopistokatu 2, FI-80100 Joensuu, Finland.",mohammed.saqr@uef.fi,,,,,,,,1,1,,,,,,,,,,,NOV 18,2024,11,1,,,,,,,52,10.1186/s40561-024-00343-4,http://dx.doi.org/10.1186/s40561-024-00343-4,,,,,,,,,,,,2025-05-29,WOS:001357778500001,View Full Record in Web of Science
J,"Humer, C; Ter, AH; Leichtmann, B; Mara, M; Streit, M",,,,"Humer, Christina; Ter, Andreas hinterrei; Leichtmann, Benedikt; Mara, Martina; Streit, Marc",,,"Reassuring, Misleading, Debunking: Comparing Effects of XAI Methods on Human Decisions",ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS,,,,Article,,,,,,,,"Trust calibration is essential in AI-assisted decision-making. If human users understand the rationale on which an AI model has made a prediction, they can decide whether they consider this prediction reasonable. Especially in high-risk tasks such as mushroom hunting (where a wrong decision may be fatal), it is important that users make correct choices to trust or overrule the AI. Various explainable AI (XAI) methods are currently being discussed as potentially useful for facilitating understanding and subsequently calibrating user trust. So far, however, it remains unclear which approaches are most effective. In this article, the effects of XAI methods on human AI-assisted decision-making in the high-risk task of mushroom picking were tested. For that endeavor, the effects of (i) Grad-CAM attributions, (ii) nearest-neighbor examples, and (iii) network-dissection concepts were compared in a between-subjects experiment with N = 501 participants representing end-users of the system. In general, nearest-neighbor examples improved decision correctness the most. However, varying effects for different task items became apparent. All explanations seemed to be particularly effective when they revealed reasons to (i) doubt a specific AI classification when the AI was wrong and (ii) trust a specific AI classification when the AI was correct. Our results suggest that well-established methods, such as Grad-CAM attribution maps, might not be as beneficial to end users as expected and that XAI techniques for use in real-world scenarios must be chosen carefully.","[Humer, Christina; Ter, Andreas hinterrei; Mara, Martina; Streit, Marc] Johannes Kepler Univ Linz, Linz, Austria; [Leichtmann, Benedikt] Ludwig Maximilians Univ Munchen, Munich, Germany",,"Humer, C (corresponding author), Johannes Kepler Univ Linz, Linz, Austria.",,,,,,,,,2,2,,,,,,,,,,,SEP,2024,14,3,,,,,,,16,10.1145/3665647,http://dx.doi.org/10.1145/3665647,,,,,,,,,,,,2025-05-29,WOS:001325864200002,View Full Record in Web of Science
J,"Farahmand, F",,,,"Farahmand, Fariborz",,,Commonsense for AI: an interventional approach to explainability and personalization,AI & SOCIETY,,,,Article; Early Access,,,,,,,,"AI systems are expected to impact the ways we communicate, learn, and interact with technology. However, there are still major concerns about their commonsense reasoning, and personalization. This article computationally explains causal (vs. statistical) inference, at different levels of abstraction, and provides three examples of how we can use do-operator, a mathematical operator for intervention, to address some of these concerns. The first example is from an educational module that I developed and implemented for undergraduate engineering students, as part of an educational research project with the US National Science Foundation. For the first time, to the best of my knowledge, 117 students could successfully use do-operator in a cybersecurity investment decision, according to Bloom's learning taxonomy. Gender did not make a significant difference in the students' performance, according to the Mann-Whitney U test. The second example explains using do-operator in assessing the effectiveness of intelligent tutoring systems, ITS, in receiving higher grades. The third example sheds light on combining online learning and offline learning, in reinforcement learning, to find the optimal policy that maximizes reward. To shed light on future research on explainability and personalization, I offer two recommendations: 1- Learn like System 2, the conscious learner (based on Bengio's proposal for deep learning 2.0), and 2- Preference, a process, not an object (based on preference analysis of 25,646 registrants, entities and individuals purchasing domain names). In conclusion, this article contributes to achieving the goal of human-AI: Machines that think that learn and that create.","[Farahmand, Fariborz] Georgia Inst Technol, Sch Elect & Comp Engn, Klaus Adv Comp Bldg,266 Ferst Dr, Atlanta, GA 30332 USA",,"Farahmand, F (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Klaus Adv Comp Bldg,266 Ferst Dr, Atlanta, GA 30332 USA.",fariborz@ece.gatech.edu,,,,,,,,1,1,,,,,,,,,,,2024 NOV 9,2024,,,,,,,,,,10.1007/s00146-024-02107-7,http://dx.doi.org/10.1007/s00146-024-02107-7,,NOV 2024,,,,,,,,,,2025-05-29,WOS:001350465000002,View Full Record in Web of Science
J,"Tursunalieva, A; Alexander, DLJ; Dunne, R; Li, JM; Riera, L; Zhao, YC",,,,"Tursunalieva, Ainura; Alexander, David L. J.; Dunne, Rob; Li, Jiaming; Riera, Luis; Zhao, Yanchang",,,Making Sense of Machine Learning: A Review of Interpretation Techniques and Their Applications,APPLIED SCIENCES-BASEL,,,,Review,,,,,,,,"Transparency in AI models is essential for promoting human-AI collaboration and ensuring regulatory compliance. However, interpreting these models is a complex process influenced by various methods and datasets. This study presents a comprehensive overview of foundational interpretation techniques, meticulously referencing the original authors and emphasizing their pivotal contributions. Recognizing the seminal work of these pioneers is imperative for contextualizing the evolutionary trajectory of interpretation in the field of AI. Furthermore, this research offers a retrospective analysis of interpretation techniques, critically evaluating their inherent strengths and limitations. We categorize these techniques into model-based, representation-based, post hoc, and hybrid methods, delving into their diverse applications. Furthermore, we analyze publication trends over time to see how the adoption of advanced computational methods within various categories of interpretation techniques has shaped the development of AI interpretability over time. This analysis highlights a notable preference shift towards data-driven approaches in the field. Moreover, we consider crucial factors such as the suitability of these techniques for generating local or global insights and their compatibility with different data types, including images, text, and tabular data. This structured categorization serves as a guide for practitioners navigating the landscape of interpretation techniques in AI. In summary, this review not only synthesizes various interpretation techniques but also acknowledges the contributions of their original authors. By emphasizing the origins of these techniques, we aim to enhance AI model explainability and underscore the importance of recognizing biases, uncertainties, and limitations inherent in the methods and datasets. This approach promotes the ethical and practical use of interpretation insights, empowering AI practitioners, researchers, and professionals to make informed decisions when selecting techniques for responsible AI implementation in real-world scenarios.","[Tursunalieva, Ainura; Alexander, David L. J.; Dunne, Rob; Li, Jiaming; Riera, Luis; Zhao, Yanchang] Commonwealth Sci & Ind Res Org CSIRO, Data61, Canberra, ACT 2601, Australia",,"Zhao, YC (corresponding author), Commonwealth Sci & Ind Res Org CSIRO, Data61, Canberra, ACT 2601, Australia.",ainura.tursunalieva@data61.csiro.au; david.alexander@data61.csiro.au; rob.dunne@data61.csiro.au; jiaming.li@data61.csiro.au; luis.rieragarcia@data61.csiro.au; yanchang.zhao@csiro.au,,,,,,,,13,13,,,,,,,,,,,JAN,2024,14,2,,,,,,,496,10.3390/app14020496,http://dx.doi.org/10.3390/app14020496,,,,,,,,,,,,2025-05-29,WOS:001149399100001,View Full Record in Web of Science
J,"Vasconcelos, H; Bansal, G; Fourney, A; Liao, QV; Vaughan, JW",,,,"Vasconcelos, Helena; Bansal, Gagan; Fourney, Adam; Liao, Q. Vera; Vaughan, Jennifer wortman",,,Generation Probabilities Are Not Enough: Uncertainty Highlighting in AI Code Completions,ACM TRANSACTIONS ON COMPUTER-HUMAN INTERACTION,,,,Article,,,,,,,,"Large-scale generative models have enabled the development of AI-powered code completion tools to assist programmers in writing code. Like all AI-powered tools, these code completion tools are not always accurate and can introduce bugs or even security vulnerabilities into code if not properly detected and corrected by a human programmer. One technique that has been proposed and implemented to help programmers locate potential errors is to highlight uncertain tokens. However, little is known about the effectiveness of this technique. Through a mixed-methods study with 30 programmers, we compare three conditions: providing the AI system's code completion alone, highlighting tokens with the lowest likelihood of being generated by the underlying generative model, and highlighting tokens with the highest predicted likelihood of being edited by a programmer. We find that highlighting tokens with the highest predicted likelihood of being edited leads to faster task completion and more targeted edits and is subjectively preferred by study participants. In contrast, highlighting tokens according to their probability of being generated does not provide any benefit over the baseline with no highlighting. We further explore the design space of how to convey uncertainty in AI-powered code completion tools and find that programmers prefer highlights that are granular, informative, interpretable, and not overwhelming. This work contributes to building an understanding of what uncertainty means for generative models and how to convey it effectively. methodologies - Artificial intelligence; Machine learning; center dot Software and its engineering - Software creation and management; Software notations and tools; Integrated and visual development environments;","[Vasconcelos, Helena] Stanford Univ, Stanford, CA 94305 USA; [Bansal, Gagan; Fourney, Adam; Liao, Q. Vera; Vaughan, Jennifer wortman] Microsoft Res, Redmond, WA USA",,"Vasconcelos, H (corresponding author), Stanford Univ, Stanford, CA 94305 USA.",helenav@cs.stanford.edu; gaganbansal@microsoft.com; adam.fourney@microsoft.com; veraliao@microsoft.com; jenn@microsoft.com,,,,,,,,0,0,,,,,,,,,,,FEB,2025,32,1,,,,,,,4,10.1145/3702320,http://dx.doi.org/10.1145/3702320,,,,,,,,,,,,2025-05-29,WOS:001481492000002,View Full Record in Web of Science
J,"Zeng, YC; Brown, C; Raymond, J; Byari, M; Hotz, R; Rounsevell, M",,,,"Zeng, Yongchao; Brown, Calum; Raymond, Joanna; Byari, Mohamed; Hotz, Ronja; Rounsevell, Mark",,,Exploring the opportunities and challenges of using large language models to represent institutional agency in land system modelling,EARTH SYSTEM DYNAMICS,,,,Article,,,,,,,,"Public policy institutions play crucial roles in the land system, but modelling their policy-making processes is challenging. Large language models (LLMs) offer a novel approach to simulating many different types of human decision-making, including policy choices. This paper aims to investigate the opportunities and challenges that LLMs bring to land system modelling by integrating LLM-powered institutional agents within an agent-based land use model. Four types of LLM agents are examined, all of which, in the examples presented here, use taxes to steer meat production toward a target level. The LLM agents provide simulated reasoning and policy action output. The agents' performance is benchmarked against two baseline scenarios: one without policy interventions and another implementing optimal policy actions determined through a genetic algorithm. The findings show that, while LLM agents perform better than the non-intervention scenario, they fall short of the performance achieved by optimal policy actions. However, LLM agents demonstrate behaviour and decision-making, marked by policy consistency and transparent reasoning. This includes generating strategies such as incrementalism, delayed policy action, proactive policy adjustments, and balancing multiple stakeholder interests. Agents equipped with experiential learning capabilities excel in achieving policy objectives through progressive policy actions. The order in which reasoning and proposed policy actions are output has a notable effect on the agents' performance, suggesting that enforced reasoning both guides and explains LLM decisions. The approach presented here points to promising opportunities and significant challenges. The opportunities include, exploring naturalistic institutional decision-making, handling massive institutional documents, and human-AI cooperation. Challenges mainly lie in the scalability, interpretability, and reliability of LLMs.","[Zeng, Yongchao; Brown, Calum; Raymond, Joanna; Byari, Mohamed; Hotz, Ronja; Rounsevell, Mark] Karlsruhe Inst Technol, Inst Meteorol & Climate Res Atmospher Environm Res, D-82467 Garmisch Partenkirchen, Germany; [Brown, Calum] Highlands Rewilding Ltd, Old Sch House, Drumnadrochit IV63 6XG, Scotland; [Rounsevell, Mark] Karlsruhe Inst Technol, Inst Geog & Geoecol, D-76131 Karlsruhe, Germany; [Rounsevell, Mark] Univ Edinburgh, Sch GeoSci, Drummond St, Edinburgh EH8 9XP, Scotland",,"Zeng, YC (corresponding author), Karlsruhe Inst Technol, Inst Meteorol & Climate Res Atmospher Environm Res, D-82467 Garmisch Partenkirchen, Germany.",yongchao.zeng@kit.edu,,,,,,,,0,0,,,,,,,,,,,MAR 13,2025,16,2,,,,,423,449,,10.5194/esd-16-423-2025,http://dx.doi.org/10.5194/esd-16-423-2025,,,,,,,,,,,,2025-05-29,WOS:001445110500001,View Full Record in Web of Science
J,"Angerschmid, A; Zhou, JL; Theuermann, K; Chen, F; Holzinger, A",,,,"Angerschmid, Alessa; Zhou, Jianlong; Theuermann, Kevin; Chen, Fang; Holzinger, Andreas",,,Fairness and Explanation in AI-Informed Decision Making,MACHINE LEARNING AND KNOWLEDGE EXTRACTION,,,,Article,,,,,,,,"AI-assisted decision-making that impacts individuals raises critical questions about transparency and fairness in artificial intelligence (AI). Much research has highlighted the reciprocal relationships between the transparency/explanation and fairness in AI-assisted decision-making. Thus, considering their impact on user trust or perceived fairness simultaneously benefits responsible use of socio-technical AI systems, but currently receives little attention. In this paper, we investigate the effects of AI explanations and fairness on human-AI trust and perceived fairness, respectively, in specific AI-based decision-making scenarios. A user study simulating AI-assisted decision-making in two health insurance and medical treatment decision-making scenarios provided important insights. Due to the global pandemic and restrictions thereof, the user studies were conducted as online surveys. From the participant's trust perspective, fairness was found to affect user trust only under the condition of a low fairness level, with the low fairness level reducing user trust. However, adding explanations helped users increase their trust in AI-assisted decision-making. From the perspective of perceived fairness, our work found that low levels of introduced fairness decreased users' perceptions of fairness, while high levels of introduced fairness increased users' perceptions of fairness. The addition of explanations definitely increased the perception of fairness. Furthermore, we found that application scenarios influenced trust and perceptions of fairness. The results show that the use of AI explanations and fairness statements in AI applications is complex: we need to consider not only the type of explanations and the degree of fairness introduced, but also the scenarios in which AI-assisted decision-making is used.","[Angerschmid, Alessa; Holzinger, Andreas] Med Univ Graz, Med Informat Stat & Documentat, A-8036 Graz, Austria; [Zhou, Jianlong; Holzinger, Andreas] Univ Nat Resources & Life Sci, Human Ctr Lab, A-1190 Vienna, Austria; [Zhou, Jianlong; Chen, Fang] Univ Technol Sydney, Human Ctr AI Lab, Sydney, NSW 2007, Australia; [Theuermann, Kevin; Holzinger, Andreas] Graz Univ Technol, Doctoral Sch Comp Sci, A-8010 Graz, Austria; [Holzinger, Andreas] Univ Alberta, Alberta Machine Intelligence Inst, XAI Lab, Edmonton, AB T5J 3B1, Canada",,"Zhou, JL (corresponding author), Univ Nat Resources & Life Sci, Human Ctr Lab, A-1190 Vienna, Austria.;Zhou, JL (corresponding author), Univ Technol Sydney, Human Ctr AI Lab, Sydney, NSW 2007, Australia.",alessa.angerschmid@human-centered.ai; jianlong.zhou@uts.edu.au; kevin.theuermann@egiz.gv.at; fang.chen@uts.edu.au; andreas.holzinger@human-centered.ai,,,,,,,,84,86,,,,,,,,,,,JUN,2022,4,2,,,,,556,579,,10.3390/make4020026,http://dx.doi.org/10.3390/make4020026,,,,,,,,,,,,2025-05-29,WOS:000819046000001,View Full Record in Web of Science
J,"Lebovitz, S; Lifshitz-Assaf, H; Levina, N",,,,"Lebovitz, Sarah; Lifshitz-Assaf, Hila; Levina, Natalia",,,To Engage or Not to Engage with Al for Critical Judgments: How Professionals Deal with Opacity When Using AI for Medical Diagnosis,ORGANIZATION SCIENCE,,,,Article,,,,,,,,"Artificial intelligence (AI) technologies promise to transform how professionals conduct knowledge work by augmenting their capabilities for making professional judgments. We know little, however, about how human-AI augmentation takes place in practice. Yet, gaining this understanding is particularly important when professionals use AI tools to form judgments on critical decisions. We conducted an in-depth field study in a major US. hospital where AI tools were used in three departments by diagnostic radiologists making breast cancer, lung cancer, and bone age determinations. The study illustrates the hindering effects of opacity that professionals experienced when using AI tools and explores how these professionals grappled with it in practice. In all three departments, this opacity resulted in professionals experiencing increased uncertainty because AI tool results often diverged from their initial judgment without providing underlying reasoning. Only in one department (of the three) did professionals consistently incorporate AI results into their final judgments, achieving what we call engaged augmentation. These professionals invested in AI interrogation practices-practices enacted by human experts to relate their own knowledge claims to AI knowledge claims. Professionals in the other two departments did not enact such practices and did not incorporate AI inputs into their final decisions, which we call unengaged augmentation. Our study unpacks the challenges involved in augmenting professional judgment with powerful, yet opaque, technologies and contributes to literature on AI adoption in knowledge work.","[Lebovitz, Sarah] Univ Virginia, McIntire Sch Commerce, Charlottesville, VA 22903 USA; [Lifshitz-Assaf, Hila; Levina, Natalia] NYU, Stern Sch Business, New York, NY 10012 USA",,"Lebovitz, S (corresponding author), Univ Virginia, McIntire Sch Commerce, Charlottesville, VA 22903 USA.",sl5xv@comm.virginia.edu; hlassaf@stern.nyu.edu; nlevina@stern.nyu.edu,,,,,,,,179,189,,,,,,,,,,,JAN-FEB,2022,33,1,,,,,126,148,,10.1287/orsc.2021.1549,http://dx.doi.org/10.1287/orsc.2021.1549,,JAN 2022,,,,,,,,,,2025-05-29,WOS:000742881100001,View Full Record in Web of Science
J,"Zhang, ZM; Tian, RR; Sherony, R; Domeyer, J; Ding, ZM",,,,"Zhang, Zhengming; Tian, Renran; Sherony, Rini; Domeyer, Joshua; Ding, Zhengming",,,Attention-Based Interrelation Modeling for Explainable Automated Driving,IEEE TRANSACTIONS ON INTELLIGENT VEHICLES,,,,Article,,,,,,,,"Automated driving desires better performance on tasks like motion planning and interacting with pedestrians in mixed-traffic environments. Deep learning algorithms can achieve high performance in these tasks with remarkable visual scene understanding and generalization abilities. However, when common scene-parsing methods are used to train end-to-end models, limitations of explainability in such algorithms inhibit their implementations in fully automated driving. The main challenges include algorithm performance deficiencies and inconsistencies, insufficient AI transparency, degraded user trust, and undermining human-AI interactions. This research aids the decision-making performance and transparency of automated driving systems by providing multi-modal explanations, especially when interacting with pedestrians. The proposed algorithm combines global visual features and interrelation features by parsing scene images as self-constructed graphs and using an attention-based module to capture the interrelationship among the ego-vehicle and other traffic-related objects. The output modules make decisions while simultaneously generating semantic text explanations. The results show that the fusion of the features from global frames and interrelational graphs improves decision-making and explanation predictions compared to two state-of-the-art benchmark algorithms. The interrelation module also enhances algorithm transparency by disclosing the visual attention used for decision-making. The importance of interrelation features on the two prediction tasks is further revealed along with the underlying mechanism of multitask learning on the datasets with hierarchical labels. The proposed model improves driving decision-making during pedestrian interactions with intelligible reasoning cues for building an appropriate mental model of automated driving performance for human users.","[Zhang, Zhengming] Purdue Univ, Sch Ind Engn, W Lafayette, IN 47907 USA; [Tian, Renran] Indiana Univ Purdue Univ Indianapolis IUPUI, Dept Comp Informat & Graph Technol, Indianapolis, IN 46202 USA; [Sherony, Rini; Domeyer, Joshua] Toyota Motor North Amer, Collaborat Safety Res Ctr, Ann Arbor, MI 75024 USA; [Ding, Zhengming] Tulane Univ, Dept Comp Sci, New Orleans, LA 70118 USA",,"Tian, RR (corresponding author), Indiana Univ Purdue Univ Indianapolis IUPUI, Dept Comp Informat & Graph Technol, Indianapolis, IN 46202 USA.",zhan3988@purdue.edu; rtian@iupui.edu; rini.sherony@toyota.com; joshua.domeyer@toyota.com; zding1@tulane.edu,,,,,,,,19,19,,,,,,,,,,,FEB,2023,8,2,,,,,1564,1573,,10.1109/TIV.2022.3229682,http://dx.doi.org/10.1109/TIV.2022.3229682,,,,,,,,,,,,2025-05-29,WOS:000965638500001,View Full Record in Web of Science
J,"Bashir, Z; Lin, MX; Feragen, A; Mikolaj, K; Taksoe-Vester, C; Christensen, AN; Svendsen, MBS; Fabricius, MH; Andreasen, L; Nielsen, M; Tolsgaard, MG",,,,"Bashir, Zahra; Lin, Manxi; Feragen, Aasa; Mikolaj, Kamil; Taksoe-Vester, Caroline; Christensen, Anders Nymark; Svendsen, Morten B. S.; Fabricius, Mette Hvilshoj; Andreasen, Lisbeth; Nielsen, Mads; Tolsgaard, Martin Gronnebaek",,,"Clinical validation of explainable AI for fetal growth scans through multi-level, cross-institutional prospective end-user evaluation",SCIENTIFIC REPORTS,,,,Article,,,,,,,,"We aimed to develop and evaluate Explainable Artificial Intelligence (XAI) for fetal ultrasound using actionable concepts as feedback to end-users, using a prospective cross-center, multi-level approach. We developed, implemented, and tested a deep-learning model for fetal growth scans using both retrospective and prospective data. We used a modified Progressive Concept Bottleneck Model with pre-established clinical concepts as explanations (feedback on image optimization and presence of anatomical landmarks) as well as segmentations (outlining anatomical landmarks). The model was evaluated prospectively by assessing the following: the model's ability to assess standard plane quality, the correctness of explanations, the clinical usefulness of explanations, and the model's ability to discriminate between different levels of expertise among clinicians. We used 9352 annotated images for model development and 100 videos for prospective evaluation. Overall classification accuracy was 96.3%. The model's performance in assessing standard plane quality was on par with that of clinicians. Agreement between model segmentations and explanations provided by expert clinicians was found in 83.3% and 74.2% of cases, respectively. A panel of clinicians evaluated segmentations as useful in 72.4% of cases and explanations as useful in 75.0% of cases. Finally, the model reliably discriminated between the performances of clinicians with different levels of experience (p- values < 0.01 for all measures) Our study has successfully developed an Explainable AI model for real-time feedback to clinicians performing fetal growth scans. This work contributes to the existing literature by addressing the gap in the clinical validation of Explainable AI models within fetal medicine, emphasizing the importance of multi-level, cross-institutional, and prospective evaluation with clinician end-users. The prospective clinical validation uncovered challenges and opportunities that could not have been anticipated if we had only focused on retrospective development and validation, such as leveraging AI to gauge operator competence in fetal ultrasound.","[Bashir, Zahra; Taksoe-Vester, Caroline; Tolsgaard, Martin Gronnebaek] Univ Copenhagen, Fac Hlth & Med Sci, Dept Clin Med, Copenhagen, Denmark; [Bashir, Zahra; Fabricius, Mette Hvilshoj] Slagelse Hosp, Dept Obstet & Gynecol, Faelledvej 11, DK-4200 Slagelse, Denmark; [Bashir, Zahra; Taksoe-Vester, Caroline; Svendsen, Morten B. S.; Tolsgaard, Martin Gronnebaek] Copenhagen Acad Med Educ & Simulat CAMES, Rigshospitalet, Copenhagen, Denmark; [Lin, Manxi; Feragen, Aasa; Mikolaj, Kamil; Christensen, Anders Nymark] Tech Univ Denmark DTU, Lyngby, Denmark; [Taksoe-Vester, Caroline; Tolsgaard, Martin Gronnebaek] Copenhagen Univ Hosp, Rigshospitalet, Ctr Fetal Med, Dept Obstet, Copenhagen, Denmark; [Andreasen, Lisbeth] Hvidovre Univ Hosp, Dept Obstet & Gynecol, Hvidovre, Denmark; [Nielsen, Mads] Univ Copenhagen, Dept Comp Sci, Copenhagen, Denmark",,"Bashir, Z (corresponding author), Univ Copenhagen, Fac Hlth & Med Sci, Dept Clin Med, Copenhagen, Denmark.;Bashir, Z (corresponding author), Slagelse Hosp, Dept Obstet & Gynecol, Faelledvej 11, DK-4200 Slagelse, Denmark.;Bashir, Z (corresponding author), Copenhagen Acad Med Educ & Simulat CAMES, Rigshospitalet, Copenhagen, Denmark.",zab@regionsjaelland.dk,,,,,,,,0,0,,,,,,,,,,,JAN 15,2025,15,1,,,,,,,2074,10.1038/s41598-025-86536-4,http://dx.doi.org/10.1038/s41598-025-86536-4,,,,,,,,,,,,2025-05-29,WOS:001401742800003,View Full Record in Web of Science
J,"Xie, YB; Pongsakornsathien, N; Gardi, A; Sabatini, R",,,,"Xie, Yibing; Pongsakornsathien, Nichakorn; Gardi, Alessandro; Sabatini, Roberto",,,Explanation of Machine-Learning Solutions in Air-Traffic Management,AEROSPACE,,,,Article,,,,,,,,"Advances in the trusted autonomy of air-traffic management (ATM) systems are currently being pursued to cope with the predicted growth in air-traffic densities in all classes of airspace. Highly automated ATM systems relying on artificial intelligence (AI) algorithms for anomaly detection, pattern identification, accurate inference, and optimal conflict resolution are technically feasible and demonstrably able to take on a wide variety of tasks currently accomplished by humans. However, the opaqueness and inexplicability of most intelligent algorithms restrict the usability of such technology. Consequently, AI-based ATM decision-support systems (DSS) are foreseen to integrate eXplainable AI (XAI) in order to increase interpretability and transparency of the system reasoning and, consequently, build the human operators' trust in these systems. This research presents a viable solution to implement XAI in ATM DSS, providing explanations that can be appraised and analysed by the human air-traffic control operator (ATCO). The maturity of XAI approaches and their application in ATM operational risk prediction is investigated in this paper, which can support both existing ATM advisory services in uncontrolled airspace (Classes E and F) and also drive the inflation of avoidance volumes in emerging performance-driven autonomy concepts. In particular, aviation occurrences and meteorological databases are exploited to train a machine learning (ML)-based risk-prediction tool capable of real-time situation analysis and operational risk monitoring. The proposed approach is based on the XGBoost library, which is a gradient-boost decision tree algorithm for which post-hoc explanations are produced by SHapley Additive exPlanations (SHAP) and Local Interpretable Model-Agnostic Explanations (LIME). Results are presented and discussed, and considerations are made on the most promising strategies for evolving the human-machine interactions (HMI) to strengthen the mutual trust between ATCO and systems. The presented approach is not limited only to conventional applications but also suitable for UAS-traffic management (UTM) and other emerging applications.","[Xie, Yibing; Pongsakornsathien, Nichakorn; Gardi, Alessandro; Sabatini, Roberto] RMIT Univ, Sch Engn, Melbourne, Vic 3083, Australia",,"Sabatini, R (corresponding author), RMIT Univ, Sch Engn, Melbourne, Vic 3083, Australia.",s3758565@student.rmit.edu.au; s3679479@student.rmit.edu.au; alessandro.gardi@rmit.edu.au; roberto.sabatini@rmit.edu.au,,,,,,,,36,37,,,,,,,,,,,AUG,2021,8,8,,,,,,,224,10.3390/aerospace8080224,http://dx.doi.org/10.3390/aerospace8080224,,,,,,,,,,,,2025-05-29,WOS:000688659100001,View Full Record in Web of Science
J,"Moghadasi, N; Valdez, RS; Piran, M; Moghaddasi, N; Linkov, I; Polmateer, TL; Loose, DC; Lambert, JH",,,,"Moghadasi, Negin; Valdez, Rupa S.; Piran, Misagh; Moghaddasi, Negar; Linkov, Igor; Polmateer, Thomas L.; Loose, Davis C.; Lambert, James H.",,,Risk Analysis of Artificial Intelligence in Medicine with a Multilayer Concept of System Order,SYSTEMS,,,,Article,,,,,,,,"Artificial intelligence (AI) is advancing across technology domains including healthcare, commerce, the economy, the environment, cybersecurity, transportation, etc. AI will transform healthcare systems, bringing profound changes to diagnosis, treatment, patient care, data, medicines, devices, etc. However, AI in healthcare introduces entirely new categories of risk for assessment, management, and communication. For this topic, the framing of conventional risk and decision analyses is ongoing. This paper introduces a method to quantify risk as the disruption of the order of AI initiatives in healthcare systems, aiming to find the scenarios that are most and least disruptive to system order. This novel approach addresses scenarios that bring about a re-ordering of initiatives in each of the following three characteristic layers: purpose, structure, and function. In each layer, the following model elements are identified: 1. Typical research and development initiatives in healthcare. 2. The ordering criteria of the initiatives. 3. Emergent conditions and scenarios that could influence the ordering of the AI initiatives. This approach is a manifold accounting of the scenarios that could contribute to the risk associated with AI in healthcare. Recognizing the context-specific nature of risks and highlighting the role of human in the loop, this study identifies scenario s.06-non-interpretable AI and lack of human-AI communications-as the most disruptive across all three layers of healthcare systems. This finding suggests that AI transparency solutions primarily target domain experts, a reasonable inclination given the significance of high-stakes AI systems, particularly in healthcare. Future work should connect this approach with decision analysis and quantifying the value of information. Future work will explore the disruptions of system order in additional layers of the healthcare system, including the environment, boundary, interconnections, workforce, facilities, supply chains, and others.","[Moghadasi, Negin; Valdez, Rupa S.; Polmateer, Thomas L.; Loose, Davis C.; Lambert, James H.] Univ Virginia, Dept Syst & Informat Engn, Charlottesville, VA 22903 USA; [Piran, Misagh] Ruhr Univ Bochum, Heart & Diabet Ctr North Rhine Westphalia, Dept Radiol Nucl Med & Mol Imaging, D-44801 Bochum, Germany; [Moghaddasi, Negar] Western Univ Hlth Sci, Dept Dent, Pomona, CA 91766 USA; [Linkov, Igor] Carnegie Mellon Univ, Dept Engn & Publ Policy, Pittsburgh, PA 15213 USA",,"Moghadasi, N (corresponding author), Univ Virginia, Dept Syst & Informat Engn, Charlottesville, VA 22903 USA.",nm2fs@virginia.edu; mpiran@hdz-nrw.de; ne.moghaddasijahromi@westernu.edu; igor.linkov@usace.army.milf; lambert@virginia.edu,,,,,,,,1,1,,,,,,,,,,,FEB,2024,12,2,,,,,,,47,10.3390/systems12020047,http://dx.doi.org/10.3390/systems12020047,,,,,,,,,,,,2025-05-29,WOS:001172561800001,View Full Record in Web of Science
J,"Baron, S; Latham, AJ; Varga, S",,,,"Baron, Sam; Latham, Andrew J.; Varga, Somogy",,,Explainable AI and stakes in medicine: A user study,ARTIFICIAL INTELLIGENCE,,,,Article,,,,,,,,"The apparent downsides of opaque algorithms have led to a demand for explainable AI (XAI) methods by which a user might come to understand why an algorithm produced the particular output it did, given its inputs. Patients, for example, might find that the lack of explanation of the process underlying the algorithmic recommendations for diagnosis and treatment hinders their ability to provide informed consent. This paper examines the impact of two factors on user perceptions of explanations for AI systems in medical contexts. The factors considered were the stakes of the decision-high versus low-and the decision source-human versus AI. 484 participants were presented with vignettes in which medical diagnosis and treatment plan recommendations were made by humans or by AI. Separate vignettes were used for high stakes scenarios involving life-threatening diseases, and low stakes scenarios involving mild diseases. In each vignette, an explanation for the decision was given. Four explanation types were tested across separate vignettes: no explanation, counterfactual, causal and a novel 'narrative-based' explanation, not previously considered. This yielded a total of 16 conditions, of which each participant saw only one. Individuals were asked to evaluate the explanations they received based on helpfulness, understanding, consent, reliability, trust, interests and likelihood of undergoing treatment. We observed a main effect for stakes on all factors and a main effect for decision source on all factors except for helpfulness and likelihood to undergo treatment. While we observed effects for explanation on helpfulness, understanding, consent, reliability, trust and interests, we by and large did not see any differences between the effects of explanation types. This suggests that the effectiveness of explanations may not depend on type of explanation but instead, on the stakes and decision source.","[Baron, Sam] Univ Melbourne, Melbourne, Australia; [Latham, Andrew J.; Varga, Somogy] Aarhus Univ, Aarhus, Denmark",,"Baron, S (corresponding author), Univ Melbourne, Melbourne, Australia.",s.baron@unimelb.edu.au,,,,,,,,0,0,,,,,,,,,,,MAR,2025,340,,,,,,,,104282,10.1016/j.artint.2025.104282,http://dx.doi.org/10.1016/j.artint.2025.104282,,JAN 2025,,,,,,,,,,2025-05-29,WOS:001402950500001,View Full Record in Web of Science
J,"Zywiolek, J",,,,"Zywiolek, Justyna",,,Building Trust in AI-Human Partnerships: Exploring Preferences and Influences in the Manufacturing Industry,MANAGEMENT SYSTEMS IN PRODUCTION ENGINEERING,,,,Article,,,,,,,,"The incorporation of artificial intelligence (AI) into industrial processes has seen substantial development, characterized by the shift from Industry 4.0 to the future concept of Industry 5.0. The article identifies a significant gap in knowledge regarding how openness in AI engagement influences consumer trust and confidence in news media. This gap highlights the need for further exploration into the relationship between transparency in AI processes and consumer perceptions. The research utilises a combination of qualitative and quantitative approaches, gathering insights from academic literature, industry viewpoints, and actual data. We conduct an extensive analysis of existing literature to investigate the process of incorporating artificial intelligence into news creation and its influence on the level of confidence consumers have in the news. We have identified a significant lack of knowledge about the impact of openness in AI engagement on consumer views and trust in news media. Expanding on this discrepancy, we suggest a systematic methodology that incorporates controlled experiments and surveys to evaluate the influence of different degrees of openness on consumer trust and involvement with AI-generated news content. In addition, the paper examines the difficulties in establishing confidence in artificial intelligence (AI) inside the European Union, including several aspects such as technological, ethical, social, and legal considerations. The document presents a thorough plan to guarantee the secure development and execution of AI, with a focus on the significance of transparency, ethics, and teamwork. The study's results provide vital insights for politicians, news organisations, and industrial businesses as they navigate the intricate process of integrating AI. Comprehensive Plan for Secure AI Development, to address the challenges outlined, the article presents a thorough plan for ensuring the secure development and execution of AI within the European Union. This plan emphasizes the significance of transparency, ethics, and collaboration in building trust and confidence in AI technologies.","[Zywiolek, Justyna] Czestochowa Tech Univ, Fac Management, Ul Dabrowskiego 69, PL-42201 Czestochowa, Poland",,"Zywiolek, J (corresponding author), Czestochowa Tech Univ, Fac Management, Ul Dabrowskiego 69, PL-42201 Czestochowa, Poland.",justyna.zywiolek@wz.pcz.pl,,,,,,,,0,0,,,,,,,,,,,JUN 1,2024,32,2,,,,,244,251,,10.2478/mspe-2024-0024,http://dx.doi.org/10.2478/mspe-2024-0024,,,,,,,,,,,,2025-05-29,WOS:001252204500007,View Full Record in Web of Science
J,"Park, J; Kang, D",,,,"Park, Jiyoung; Kang, Dongheon",,,Artificial Intelligence and Smart Technologies in Safety Management: A Comprehensive Analysis Across Multiple Industries,APPLIED SCIENCES-BASEL,,,,Review,,,,,,,,"The integration of Artificial Intelligence (AI) and smart technologies into safety management is a pivotal aspect of the Fourth Industrial Revolution or Industry 4.0. This study conducts a systematic literature review to identify and analyze how AI and smart technologies enhance safety management across various sectors within the Safety 4.0 paradigm. Focusing on peer-reviewed journal articles that explicitly mention Smart, AI, or Artificial Intelligence in their titles, the research examines key safety management factors, such as accident prevention, risk management, real-time monitoring, and ethical implementation, across sectors, including construction, industrial safety, disaster and public safety, transport and logistics, energy and power, health, smart home and living, and other diverse industries. AI-driven solutions, such as predictive analytics, machine learning algorithms, IoT sensor integration, and digital twin models, are shown to proactively identify and mitigate potential hazards, optimize energy consumption, and enhance operational efficiency. For instance, in the energy and power sector, intelligent gas meters and automated fire suppression systems manage gas-related risks effectively, while in the health sector, AI-powered health monitoring devices and mental health support applications improve patient and worker safety. The analysis reveals a significant trend towards shifting from reactive to proactive safety management, facilitated by the convergence of AI with IoT and Big Data analytics. Additionally, ethical considerations and data privacy emerge as critical challenges in the adoption of AI technologies. The study highlights the transformative role of AI in enhancing safety protocols, reducing accident rates, and improving overall safety outcomes across industries. It underscores the need for standardized protocols, robust AI governance frameworks, and interdisciplinary research to address existing challenges and maximize the benefits of AI in safety management. Future research directions include developing explainable AI models, enhancing human-AI collaboration, and fostering global standardization to ensure the responsible and effective implementation of AI-driven safety solutions.","[Park, Jiyoung] Wonkwang Univ, Dept Safety & Hlth, Iksan 54538, South Korea; [Kang, Dongheon] Minist Hlth & Welf, Dept Healthcare & Publ Hlth Res, Natl Rehabil Ctr, Seoul 01022, South Korea",,"Kang, D (corresponding author), Minist Hlth & Welf, Dept Healthcare & Publ Hlth Res, Natl Rehabil Ctr, Seoul 01022, South Korea.",withji0@wku.ac.kr; luxpooh@gmail.com,,,,,,,,4,4,,,,,,,,,,,DEC,2024,14,24,,,,,,,11934,10.3390/app142411934,http://dx.doi.org/10.3390/app142411934,,,,,,,,,,,,2025-05-29,WOS:001384200500001,View Full Record in Web of Science
J,"Linja, A; Mamun, TI; Mueller, ST",,,,"Linja, Anne; Mamun, Tauseef Ibne; Mueller, Shane T.",,,When Self-Driving Fails: Evaluating Social Media Posts Regarding Problems and Misconceptions about Tesla's FSD Mode,MULTIMODAL TECHNOLOGIES AND INTERACTION,,,,Article,,,,,,,,"With the recent deployment of the latest generation of Tesla's Full Self-Driving (FSD) mode, consumers are using semi-autonomous vehicles in both highway and residential driving for the first time. As a result, drivers are facing complex and unanticipated situations with an unproven technology, which is a central challenge for cooperative cognition. One way to support cooperative cognition in such situations is to inform and educate the user about potential limitations. Because these limitations are not always easily discovered, users have turned to the internet and social media to document their experiences, seek answers to questions they have, provide advice on features to others, and assist other drivers with less FSD experience. In this paper, we explore a novel approach to supporting cooperative cognition: Using social media posts can help characterize the limitations of the automation in order to get information about the limitations of the system and explanations and workarounds for how to deal with these limitations. Ultimately, our goal is to determine the kinds of problems being reported via social media that might be useful in helping users anticipate and develop a better mental model of an AI system that they rely on. To do so, we examine a corpus of social media posts about FSD problems to identify (1) the typical problems reported, (2) the kinds of explanations or answers provided by users, and (3) the feasibility of using such user-generated information to provide training and assistance for new drivers. The results reveal a number of limitations of the FSD system (e.g., lane-keeping and phantom braking) that may be anticipated by drivers, enabling them to predict and avoid the problems, thus allowing better mental models of the system and supporting cooperative cognition of the human-AI system in more situations.","[Linja, Anne; Mamun, Tauseef Ibne; Mueller, Shane T.] Michigan Technol Univ, Dept Cognit & Learning Sci, Houghton, MI 49931 USA",,"Mueller, ST (corresponding author), Michigan Technol Univ, Dept Cognit & Learning Sci, Houghton, MI 49931 USA.",shanem@mtu.edu,,,,,,,,3,5,,,,,,,,,,,OCT,2022,6,10,,,,,,,86,10.3390/mti6100086,http://dx.doi.org/10.3390/mti6100086,,,,,,,,,,,,2025-05-29,WOS:000873238400001,View Full Record in Web of Science
J,"Dong, ZH; Zhang, HM; Chen, YX; Payne, PRO; Li, FH",,,,"Dong, Zehao; Zhang, Heming; Chen, Yixin; Payne, Philip R. O.; Li, Fuhai",,,Interpreting the Mechanism of Synergism for Drug Combinations Using Attention-Based Hierarchical Graph Pooling,CANCERS,,,,Article,,,,,,,,"Simple Summary This paper introduces a novel graph neural network (a hierarchical graph pooling model), SANEpool, to effectively detect core sub-networks of significant genes for predicting the synergy score of drug/drug combinations in cancer. SANEpool successfully addresses the limitations of the un-transparency in the prediction process of previous computational AI models for drug synergy prediction, while providing the superior predictive performance than popular baselines on numerous drug-synergy prediction datasets. The success of SANEpool indicates that significant gene-gene interactions and gene-drug interactions play a crucial role in designing powerful deep learning models to provide accurate prediction and to reveal the mechanism of the synergy (MoS).Abstract Synergistic drug combinations provide huge potentials to enhance therapeutic efficacy and to reduce adverse reactions. However, effective and synergistic drug combination prediction remains an open question because of the unknown causal disease signaling pathways. Though various deep learning (AI) models have been proposed to quantitatively predict the synergism of drug combinations, the major limitation of existing deep learning methods is that they are inherently not interpretable, which makes the conclusions of AI models untransparent to human experts, henceforth limiting the robustness of the model conclusion and the implementation ability of these models in real-world human-AI healthcare. In this paper, we develop an interpretable graph neural network (GNN) that reveals the underlying essential therapeutic targets and the mechanism of the synergy (MoS) by mining the sub-molecular network of great importance. The key point of the interpretable GNN prediction model is a novel graph pooling layer, a self-attention-based node and edge pool (henceforth SANEpool), that can compute the attention score (importance) of genes and connections based on the genomic features and topology. As such, the proposed GNN model provides a systematic way to predict and interpret the drug combination synergism based on the detected crucial sub-molecular network. Experiments on various well-adopted drug-synergy-prediction datasets demonstrate that (1) the SANEpool model has superior predictive ability to generate accurate synergy score prediction, and (2) the sub-molecular networks detected by the SANEpool are self-explainable and salient for identifying synergistic drug combinations.","[Dong, Zehao; Chen, Yixin] Washington Univ St Louis, Dept Comp Sci & Engn, St Louis, MO 63130 USA; [Zhang, Heming; Payne, Philip R. O.; Li, Fuhai] Washington Univ, Inst Informat Data Sci & Biostat, Sch Med, St Louis, MO 63110 USA; [Li, Fuhai] Washington Univ, Sch Med, Dept Pediat, St Louis, MO 63110 USA",,"Li, FH (corresponding author), Washington Univ, Inst Informat Data Sci & Biostat, Sch Med, St Louis, MO 63110 USA.;Li, FH (corresponding author), Washington Univ, Sch Med, Dept Pediat, St Louis, MO 63110 USA.",zehao.dong@wustl.edu; hemingzhang@wustl.edu; chen@cse.wustl.edu; prpayne@wustl.edu; fuhai.li@wustl.edu,,,,,,,,7,7,,,,,,,,,,,SEP,2023,15,17,,,,,,,4210,10.3390/cancers15174210,http://dx.doi.org/10.3390/cancers15174210,,,,,,,,,,,,2025-05-29,WOS:001062443500001,View Full Record in Web of Science
J,"Chun, J",,,,"Chun, Jon",,,MultiSentimentArcs: a novel method to measure coherence in multimodal sentiment analysis for long-form narratives in film,FRONTIERS IN COMPUTER SCIENCE,,,,Article,,,,,,,,"Affective artificial intelligence and multimodal sentiment analysis play critical roles in designing safe and effective human-computer interactions and are in diverse applications ranging from social chatbots to eldercare robots. However emotionally intelligent artificial intelligence can also manipulate, persuade, and otherwise compromise human autonomy. We face a constant stream of ever more capable models that can better understand nuanced, complex, and interrelated sentiments across different modalities including text, vision, and speech. This paper introduces MultiSentimentArcs, combination of an open and extensible multimodal sentiment analysis framework, a challenging movie dataset, and a novel benchmark. This enables the quantitative and qualitative identification, comparison, and prioritization of conflicting sentiments commonly arising from different models and modalities. Diachronic multimodal sentiment analysis is especially challenging in film narratives where actors, directors, cinematographers and editors use dialog, characters, and other elements in contradiction with each other to accentuate dramatic tension. MultiSentimentArcs uses local open-source software models to democratize artificial intelligence. We demonstrate how a simple 2-step pipeline of specialized open-source software with a large multimodal model followed by a large language model can approximate video sentiment analysis of a commercial state-of-the-art Claude 3 Opus. To the best of our knowledge, MultiSentimentArcs is the first fully open-source diachronic multimodal sentiment analysis framework, dataset, and benchmark to enable automatic or human-in-the-loop exploration, analysis, and critique of multimodal sentiment analysis on long-form narratives. We demonstrate two novel coherence metrics and a methodology to identify, quantify, and explain real-world sentiment models and modalities. MultiSentimentArcs integrates artificial intelligence with traditional narrative studies and related fields like film, linguistic and cultural studies. It also contributes to eXplainable artificial intelligence and artificial intelligence safety by enhancing artificial intelligence transparency in surfacing emotional persuasion, manipulation, and deception techniques. Finally, it can filter noisy emotional input and prioritize information rich channels to build more performant real-world human computer interface applications in fields like e-learning and medicine. This research contributes to the field of Digital Humanities by giving non-artificial intelligence experts access to directly engage in analysis and critique of research around affective artificial intelligence and human-AI alignment. Code and non-copyrighted data will be available at https://github.com/jon-chun/multisentimentarcs.","[Chun, Jon] Kenyon Coll, Integrated Program Humane Studies, KDHLab, Gambier, OH 43022 USA",,"Chun, J (corresponding author), Kenyon Coll, Integrated Program Humane Studies, KDHLab, Gambier, OH 43022 USA.",chunj@kenyon.edu,,,,,,,,0,0,,,,,,,,,,,OCT 24,2024,6,,,,,,,,1444549,10.3389/fcomp.2024.1444549,http://dx.doi.org/10.3389/fcomp.2024.1444549,,,,,,,,,,,,2025-05-29,WOS:001348538300001,View Full Record in Web of Science
J,"Vo, V; Chen, G; Aquino, YS; Carter, SM; Do, QN; Woode, ME",,,,"Vo, Vinh; Chen, Gang; Aquino, Yves St James; Carter, Stacy M.; Do, Quynh Nga; Woode, Maame Esi",,,Multi-stakeholder preferences for the use of artificial intelligence in healthcare: A systematic review and thematic analysis,SOCIAL SCIENCE & MEDICINE,,,,Review,,,,,,,,"Introduction: Despite the proliferation of Artificial Intelligence (AI) technology over the last decade, clinician, patient, and public perceptions of its use in healthcare raise a number of ethical, legal and social questions. We systematically review the literature on attitudes towards the use of AI in healthcare from patients, the general public and health professionals' perspectives to understand these issues from multiple perspectives. Methodology: A search for original research articles using qualitative, quantitative, and mixed methods published between 1 Jan 2001 to 24 Aug 2021 was conducted on six bibliographic databases. Data were extracted and classified into different themes representing views on: (i) knowledge and familiarity of AI, (ii) AI benefits, risks, and challenges, (iii) AI acceptability, (iv) AI development, (v) AI implementation, (vi) AI regulations, and (vii) Human - AI relationship. Results: The final search identified 7,490 different records of which 105 publications were selected based on predefined inclusion/exclusion criteria. While the majority of patients, the general public and health professionals generally had a positive attitude towards the use of AI in healthcare, all groups indicated some perceived risks and challenges. Commonly perceived risks included data privacy; reduced professional autonomy; algorithmic bias; healthcare inequities; and greater burnout to acquire AI-related skills. While patients had mixed opinions on whether healthcare workers suffer from job loss due to the use of AI, health professionals strongly indicated that AI would not be able to completely replace them in their professions. Both groups shared similar doubts about AI's ability to deliver empathic care. The need for AI validation, transparency, explainability, and patient and clinical involvement in the development of AI was emphasised. To help successfully implement AI in health care, most participants envisioned that an investment in training and education campaigns was necessary, especially for health professionals. Lack of familiarity, lack of trust, and regulatory uncertainties were identified as factors hindering AI implementation. Regarding AI regulations, key themes included data access and data privacy. While the general public and patients exhibited a willingness to share anonymised data for AI development, there remained concerns about sharing data with insurance or technology companies. One key domain under this theme was the question of who should be held accountable in the case of adverse events arising from using AI. Conclusions: While overall positivity persists in attitudes and preferences toward AI use in healthcare, some prevalent problems require more attention. There is a need to go beyond addressing algorithm-related issues to look at the translation of legislation and guidelines into practice to ensure fairness, accountability, transparency, and ethics in AI.","[Vo, Vinh; Chen, Gang; Woode, Maame Esi] Monash Univ, Ctr Hlth Econ, Melbourne, Australia; [Aquino, Yves St James; Carter, Stacy M.] Univ Wollongong, Australian Ctr Hlth Engagement Evidence & Values, Sch Hlth & Soce, Wollongong, Australia; [Do, Quynh Nga] Monash Univ, Dept Econ, Clayton, Australia; [Woode, Maame Esi] Monash Data Futures Res Inst, Clayton, Australia; [Vo, Vinh] Ctr Hlth Econ, Caulfield, Australia",,"Vo, V (corresponding author), Ctr Hlth Econ, Caulfield, Australia.",vinh.vo@monash.edu,,,,,,,,22,22,,,,,,,,,,,DEC,2023,338,,,,,,,,116357,10.1016/j.socscimed.2023.116357,http://dx.doi.org/10.1016/j.socscimed.2023.116357,,NOV 2023,,,,,,,,,,2025-05-29,WOS:001111374500001,View Full Record in Web of Science
J,"Hua, D; Petrina, N; Sacks, AJ; Young, N; Cho, JG; Smith, R; Poon, SK",,,,"Hua, David; Petrina, Neysa; Sacks, Alan J.; Young, Noel; Cho, Jin-Gun; Smith, Ross; Poon, Simon K.",,,Towards human-AI collaboration in radiology: a multidimensional evaluation of the acceptability of AI for chest radiograph analysis in supporting pulmonary tuberculosis diagnosis,JAMIA OPEN,,,,Article,,,,,,,,"Objective Artificial intelligence (AI) technology promises to be a powerful tool in addressing the global health challenges posed by tuberculosis (TB). However, evidence for its real-world impact is lacking, which may hinder safe, responsible adoption. This case study addresses this gap by assessing the technical performance, usability and workflow aspects, and health impact of implementing a commercial AI system (qXR by Qure.ai) to support Australian radiologists in diagnosing pulmonary TB.Materials and Methods A retrospective diagnostic accuracy evaluation was conducted to establish the technical performance of qXR in detecting TB compared to a human radiologist and microbiological reference standard. A qualitative human factors assessment was performed to investigate the user experience and clinical decision-making process of radiologists using qXR. A task productivity analysis was completed to quantify how the radiological screening turnaround time is impacted.Results qXR displays near-human performance satisfying the World Health Organization's suggested accuracy profile. Radiologists reported high satisfaction with using qXR based on minimal workflow disruptions, respect for their professional autonomy, and limited increases in workload burden despite poor algorithm explainability. qXR delivers considerable productivity gains for normal cases and optimizes resource allocation through redistributing time from normal to abnormal cases.Discussion and Conclusion This study provides preliminary evidence of how an AI system with reasonable diagnostic accuracy and a human-centered user experience can meaningfully augment the TB diagnostic workflow. Future research needs to investigate the impact of AI on clinician accuracy, its relationship with efficiency, and best practices for optimizing the impact of clinician-AI collaboration. Artificial intelligence (AI) technology has the potential to transform radiological practice and increase clinician accuracy and efficiency through its ability to triage patient cases and generate diagnostic recommendations. However, evidence for the impact of AI in real-world settings is limited as past studies have focused on its technical performance in highly controlled laboratory settings. Limited attention has been given to how it affects clinical decision-making and healthcare delivery outcomes. This study builds the evidence base for the real-world impact of AI by evaluating the diagnostic accuracy, clinical workflow implications, and task productivity consequences of implementing a commercial AI system called qXR for supporting Australian radiologists in diagnosing tuberculosis (TB). The results offer promising preliminary evidence that qXR performs comparably to human radiologists, optimizes resource allocation through redistributing time spent from normal to abnormal cases, and is regarded favorably by clinicians because of its human-centered user experience and minimal workflow disruptions. This research provides medical institutions with a blueprint for assessing the suitability of AI products for use in their TB diagnostic workflows and specific clinical context. This framework can be continually used in clinical AI monitoring systems to enable issue detection, performance maintenance, and long-term safety and quality assurance.","[Hua, David; Petrina, Neysa; Smith, Ross; Poon, Simon K.] Univ Sydney, Sch Comp Sci, Sydney, NSW 2006, Australia; [Hua, David] Univ Sydney, Sydney Law Sch, Sydney, NSW 2050, Australia; [Sacks, Alan J.] Our Med Radiol, Sydney, NSW 2065, Australia; [Young, Noel; Cho, Jin-Gun] Lumus Imaging, Sydney, NSW 2000, Australia; [Young, Noel; Cho, Jin-Gun; Poon, Simon K.] Western Sydney Local Hlth Dist, Sydney, NSW 2145, Australia; [Cho, Jin-Gun] Univ Sydney, Sydney Med Sch, Sydney, NSW 2050, Australia",,"Poon, SK (corresponding author), Bldg J12-1 Cleveland St, Sydney, NSW 2006, Australia.",simon.poon@sydney.edu.au,,,,,,,,0,0,,,,,,,,,,,FEB 5,2025,8,1,,,,,,,ooae151,10.1093/jamiaopen/ooae151,http://dx.doi.org/10.1093/jamiaopen/ooae151,,,,,,,,,,,,2025-05-29,WOS:001413223900001,View Full Record in Web of Science
J,"Berzin, T; Leggett, C; Gross, S; Repici, A; Ahmad, OF; Chiang, A; Coelho-Prabhu, N; Cohen, J; Dekker, E; Keswani, RN; Kahn, CE; Hassan, C; Petrick, N; Mountney, P; Ng, J; Riegler, M; Mori, Y; Saito, Y; Thakkar, S; Waxman, I; Wallace, MB; Sharma, P; Parasa, S",,,,"Berzin, Tyler; Leggett, Cadman; Gross, Seth; Repici, Alessandro; Ahmad, Omer F.; Chiang, Austin; Coelho-Prabhu, Nayantara; Cohen, Jonathan; Dekker, Evelien; Keswani, Rajesh N.; Kahn, Charles E.; Hassan, Cesare; Petrick, Nicholas; Mountney, Peter; Ng, Jonathan; Riegler, Michael; Mori, Yuichi; Saito, Yutaka; Thakkar, Shyam; Waxman, Irving; Wallace, Michael Bradley; Sharma, Prateek; Parasa, S.",,,"Consensus statements on the current landscape of artificial intelligence applications in endoscopy, addressing roadblocks, and advancing artificial intelligence in gastroenterology",GASTROINTESTINAL ENDOSCOPY,,,,Article,,,,,,,,"Background and Aims: The American Society for Gastrointestinal Endoscopy (ASGE) AI Task Force along with experts in endoscopy, technology space, regulatory authorities, and other medical subspecialties initiated a consensus process that analyzed the current literature, highlighted potential areas, and outlined the necessary research in artificial intelligence (AI) to allow a clearer understanding of AI as it pertains to endoscopy currently. Methods: A modified Delphi process was used to develop these consensus statements. Results: Statement 1 : Current advances in AI allow for the development of AI-based algorithms that can be applied to endoscopy to augment endoscopist performance in detection and characterization of endoscopic lesions. Statement 2: Computer vision-based algorithms provide opportunities to redefine quality metrics in endoscopy using AI, which can be standardized and can reduce subjectivity in reporting quality metrics. Natural language processing-based algorithms can help with the data abstraction needed for reporting current quality metrics in GI endoscopy effortlessly. Statement 3: AI technologies can support smart endoscopy suites, which may help optimize workflows in the endoscopy suite, including automated documentation. Statement 4: Using AI and machine learning helps in predictive modeling, diagnosis, and prognostication. High-quality data with multidimensionality are needed for risk prediction, prognostication of specific clinical conditions, and their outcomes when using machine learning methods. Statement 5: Big data and cloud-based tools can help advance clinical research in gastroenterology. Multimodal data are key to understanding the maximal extent of the disease state and unlocking treatment options. Statement 6: Understanding how to evaluate AI algorithms in the gastroenterology literature and clinical trials is important for gastroenterologists, trainees, and researchers, and hence education efforts by GI societies are needed. Statement 7: Several challenges regarding integrating AI solutions into the clinical practice of endoscopy exist, including understanding the role of human-AI interaction. Transparency, interpretability, and explainability of AI algorithms play a key role in their clinical adoption in GI endoscopy. Developing appropriate AI governance, data procurement, and tools needed for the AI lifecycle are critical for the successful implementation of AI into clinical practice. Statement 8: For payment of AI in endoscopy, a thorough evaluation of the potential value proposition for AI systems may help guide purchasing decisions in endoscopy. Reliable cost-effectiveness studies to guide reimbursement are needed. Statement 9: Relevant clinical outcomes and performance metrics for AI in gastroenterology are currently not well defined. To improve the quality and interpretability of research in the fi eld, steps need to be taken to define these evidence standards. Statement 10: A balanced view of AI technologies and active collaboration between the medical technology industry, computer scientists, gastroenterologists, and researchers are critical for the meaningful advancement of AI in gastroenterology. Conclusions: The consensus process led by the ASGE AI Task Force and experts from various disciplines has shed light on the potential of AI in endoscopy and gastroenterology. AI-based algorithms have shown promise in augmenting endoscopist performance, redefining quality metrics, optimizing workflows, and aiding in predictive modeling and diagnosis. However, challenges remain in evaluating AI algorithms, ensuring transparency and interpretability, addressing governance and data procurement, determining payment models, defining relevant clinical outcomes, and fostering collaboration between stakeholders. Addressing these challenges while maintaining a balanced perspective is crucial for the meaningful advancement of AI in gastroenterology.","[Parasa, S.] Swedish Med Ctr, Seattle, WA 98122 USA; [Berzin, Tyler] BIDMC HMS, Boston, MA USA; [Leggett, Cadman; Coelho-Prabhu, Nayantara] Mayo Clin, Rochester, MN USA; [Gross, Seth] NYU Langone Hlth, New York, NY USA; [Repici, Alessandro; Hassan, Cesare] Humanitas Univ, Dept Biomed Sci, Via R Levi Montalcini 4, I-20090 Pieve Emanuele, Milan, Italy; [Ahmad, Omer F.] Univ London, London, England; [Chiang, Austin] Santa Clara Univ, Santa Clara, CA 95053 USA; [Cohen, Jonathan] NYU, Sch Med, New York, NY USA; [Dekker, Evelien] Amsterdam UMC, Amsterdam, Netherlands; [Keswani, Rajesh N.] Northwestern Univ, Chicago, IL USA; [Kahn, Charles E.] Univ Penn, Philadelphia, PA USA; [Hassan, Cesare] IRCCS Humanitas Res Hosp, Via Manzoni 56, I-20089 Milan, Italy; [Petrick, Nicholas] US FDA, Ctr Devices & Radiol Hlth, Silver Spring, MD USA; [Mountney, Peter] Odin Vis, London, England; [Ng, Jonathan] Iterat Hlth, Boston, MA USA; [Riegler, Michael] Simulamet, Dept Holist Syst, Oslo, Norway; [Mori, Yuichi] Univ Oslo, Oslo, Norway; [Saito, Yutaka] Natl Canc Ctr, Tokyo, Japan; [Thakkar, Shyam] West Virginia Univ Med, Morgantown, WV USA; [Waxman, Irving] Rush Univ, Chicago, IL USA; [Wallace, Michael Bradley] Sheikh Shakhbout Med City, Abu Dhabi, U Arab Emirates; [Sharma, Prateek] Univ Kansas, Kansas City, KS USA",,"Parasa, S (corresponding author), Swedish Med Ctr, Seattle, WA 98122 USA.",,,,,,,,,5,5,,,,,,,,,,,JAN,2025,101,1,,,,,,,,10.1016/j.gie.2023.12.003,http://dx.doi.org/10.1016/j.gie.2023.12.003,,DEC 2024,,,,,,,,,,2025-05-29,WOS:001392222400001,View Full Record in Web of Science
J,"Henin, C; Le Métayer, D",,,,"Henin, Clement; Le Metayer, Daniel",,,Beyond explainability: justifiability and contestability of algorithmic decision systems,AI & SOCIETY,,,,Article,,,,,,,,"In this paper, we point out that explainability is useful but not sufficient to ensure the legitimacy of algorithmic decision systems. We argue that the key requirements for high-stakes decision systems should be justifiability and contestability. We highlight the conceptual differences between explanations and justifications, provide dual definitions of justifications and contestations, and suggest different ways to operationalize justifiability and contestability.","[Henin, Clement; Le Metayer, Daniel] Univ Lyon, INRIA, INSA Lyon, CITI, Villeurbanne, France; [Henin, Clement] Ecole Ponts ParisTech, Champs Sur Marne, France",,"Henin, C (corresponding author), Univ Lyon, INRIA, INSA Lyon, CITI, Villeurbanne, France.;Henin, C (corresponding author), Ecole Ponts ParisTech, Champs Sur Marne, France.",clement.henin@inria.fr; daniel.le-metayer@inria.fr,,,,,,,,23,24,,,,,,,,,,,DEC,2022,37,4,,,,,1397,1410,,10.1007/s00146-021-01251-8,http://dx.doi.org/10.1007/s00146-021-01251-8,,JUL 2021,,,,,,,,,,2025-05-29,WOS:000679628700002,View Full Record in Web of Science
J,"Brkan, M; Bonnet, G",,,,"Brkan, Maja; Bonnet, Gregory",,,"Legal and Technical Feasibility of the GDPR's Quest for Explanation of Algorithmic Decisions: of Black Boxes, White Boxes and Fata Morganas",EUROPEAN JOURNAL OF RISK REGULATION,,,,Article,,,,,,,,"Understanding of the causes and correlations for algorithmic decisions is currently one of the major challenges of computer science, addressed under an umbrella term explainable AI (XAI). Being able to explain an AI-based system may help to make algorithmic decisions more satisfying and acceptable, to better control and update AI-based systems in case of failure, to build more accurate models, and to discover new knowledge directly or indirectly. On the legal side, the question whether the General Data Protection Regulation (GDPR) provides data subjects with the right to explanation in case of automated decision-making has equally been the subject of a heated doctrinal debate. While arguing that the right to explanation in the GDPR should be a result of interpretative analysis of several GDPR provisions jointly, the authors move this debate forward by discussing the technical and legal feasibility of the explanation of algorithmic decisions. Legal limits, in particular the secrecy of algorithms, as well as technical obstacles could potentially obstruct the practical implementation of this right. By adopting an interdisciplinary approach, the authors explore not only whether it is possible to translate the EU legal requirements for an explanation into the actual machine learning decision-making, but also whether those limitations can shape the way the legal right is used in practice.","[Brkan, Maja] Maastricht Univ, Fac Law, EU Law, Maastricht, Netherlands; [Bonnet, Gregory] Normandy Univ, UNICAEN, ENSICAEN, CNRS,GREYC,Artificial Intelligence, Caen, France",,"Brkan, M (corresponding author), Maastricht Univ, Fac Law, EU Law, Maastricht, Netherlands.",maja.brkan@maastrichtuniversity.nl; gregory.bonnet@unicaen.fr,,,,,,,,36,36,,,,,,,,,,,MAR,2020,11,1,,,,,18,50,,10.1017/err.2020.10,http://dx.doi.org/10.1017/err.2020.10,,,,,,,,,,,,2025-05-29,WOS:000524941500002,View Full Record in Web of Science
J,"Veale, M; Silberman, M; Binns, R",,,,"Veale, Michael; Silberman, Michael 'Six'; Binns, Reuben",,,Fortifying the algorithmic management provisions in the proposed Platform Work Directive,EUROPEAN LABOUR LAW JOURNAL,,,,Article,,,,,,,,"The European Commission proposed a Directive on Platform Work at the end of 2021. While much attention has been placed on its effort to address misclassification of the employed as self-employed, it also contains ambitious provisions for the regulation of the algorithmic management prevalent on these platforms. Overall, these provisions are well-drafted, yet they require extra scrutiny in light of the fierce lobbying and resistance they will likely encounter in the legislative process, in implementation and in enforcement. In this article, we place the proposal in its sociotechnical context, drawing upon wide cross-disciplinary scholarship to identify a range of tensions, potential misinterpretations, and perversions that should be pre-empted and guarded against at the earliest possible stage. These include improvements to ex ante and ex post algorithmic transparency; identifying and strengthening the standard against which human reviewers of algorithmic decisions review; anticipating challenges of representation and organising in complex platform contexts; creating realistic ambitions for digital worker communication channels; and accountably monitoring and evaluating impacts on workers while limiting data collection. We encourage legislators and regulators at both European and national levels to act to fortify these provisions in the negotiation of the Directive, its potential transposition, and in its enforcement.","[Veale, Michael] UCL, Fac Laws, London, England; [Silberman, Michael 'Six'] Univ Oxford, Bonavero Inst Human Rights, Oxford, England; [Binns, Reuben] Univ Oxford, Dept Comp Sci, Oxford, England",,"Veale, M (corresponding author), UCL, Fac Laws, London, England.",m.veale@ucl.ac.uk,,,,,,,,4,4,,,,,,,,,,,JUN,2023,14,2,,,,,308,332,,10.1177/20319525231167983,http://dx.doi.org/10.1177/20319525231167983,,,,,,,,,,,,2025-05-29,WOS:001006990700010,View Full Record in Web of Science
J,"Bae, SW; Chung, T; Zhang, TZ; Dey, AK; Islam, R",,,,"Bae, Sang Won; Chung, Tammy; Zhang, Tongze; Dey, Anind K.; Islam, Rahul",,,"Enhancing Interpretable, Transparent, and Unobtrusive Detection of Acute Marijuana Intoxication in Natural Environments: Harnessing Smart Devices and Explainable AI to Empower Just-In-Time Adaptive Interventions: Longitudinal Observational Study",JMIR AI,,,,Article,,,,,,,,"Background: Acute marijuana intoxication can impair motor skills and cognitive functions such as attention and information processing. However, traditional tests, like blood, urine, and saliva, fail to accurately detect acute marijuana intoxication in real time. Objective: This study aims to explore whether integrating smartphone-based sensors with readily accessible wearable activity trackers, like Fitbit, can enhance the detection of acute marijuana intoxication in naturalistic settings. No previous research has investigated the effectiveness of passive sensing technologies for enhancing algorithm accuracy or enhancing the interpretability of digital phenotyping through explainable artificial intelligence in real-life scenarios. This approach aims to provide insights into how individuals interact with digital devices during algorithmic decision-making, particularly for detecting moderate to intensive marijuana intoxication in real-world contexts. Methods: Sensor data from smartphones and Fitbits, along with self-reported marijuana use, were collected from 33 young adults over a 30-day period using the experience sampling method. Participants rated their level of intoxication on a scale from 1 to 10 within 15 minutes of consuming marijuana and during 3 daily semirandom prompts. The ratings were categorized as not intoxicated (0), low (1-3), and moderate to intense intoxication (4-10). The study analyzed the performance of models using mobile phone data only, Fitbit data only, and a combination of both (MobiFit) in detecting acute marijuana intoxication. Results: The eXtreme Gradient Boosting Machine classifier showed that the MobiFit model, which combines mobile phone and wearable device data, achieved 99% accuracy (area under the curve=0.99; F 1-score=0.85) in detecting acute marijuana intoxication in natural environments. The F 1-score indicated significant improvements in sensitivity and specificity for the combined MobiFit model compared to using mobile or Fitbit data alone. Explainable artificial intelligence revealed that moderate to intense self-reported marijuana intoxication was associated with specific smartphone and Fitbit metrics, including elevated minimum heart rate, reduced macromovement, and increased noise energy around participants. Conclusions: This study demonstrates the potential of using smartphone sensors and wearable devices for interpretable, transparent, and unobtrusive monitoring of acute marijuana intoxication in daily life. Advanced algorithmic decision-making provides valuable insight into behavioral, physiological, and environmental factors that could support timely interventions to reduce marijuana-related harm. Future real-world applications of these algorithms should be evaluated in collaboration with clinical experts to enhance their practicality and effectiveness.","[Bae, Sang Won; Zhang, Tongze; Islam, Rahul] Stevens Inst Technol, Charles V Schaefer Jr Sch Engn & Sci, Human Comp Interact & Human Ctr Syst Lab, Healthcare Lab, 1 Castle Point Terrace, Hoboken, NJ 07030 USA; [Chung, Tammy] Rutgers State Univ, Inst Hlth Healthcare Policy & Aging Res, Newark, NJ USA; [Dey, Anind K.] Univ Washington, Informat Sch, Seattle, WA USA",,"Bae, SW (corresponding author), Stevens Inst Technol, Charles V Schaefer Jr Sch Engn & Sci, Human Comp Interact & Human Ctr Syst Lab, Healthcare Lab, 1 Castle Point Terrace, Hoboken, NJ 07030 USA.",sbae4@stevens.edu,,,,,,,,1,1,,,,,,,,,,,,2025,4,,,,,,,,e52270,10.2196/52270,http://dx.doi.org/10.2196/52270,,,,,,,,,,,,2025-05-29,WOS:001390452700001,View Full Record in Web of Science
J,"Morrison, C; Huckvale, K; Corish, B; Banks, R; Grayson, M; Dorn, J; Sellen, A; Lindley, S",,,,"Morrison, Cecily; Huckvale, Kit; Corish, Bob; Banks, Richard; Grayson, Martin; Dorn, Jonas; Sellen, Abigail; Lindley, Sian",,,Visualizing Ubiquitously Sensed Measures of Motor Ability in Multiple Sclerosis: Reflections on Communicating Machine Learning in Practice,ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS,,,,Article,,,,,,,,"Sophisticated ubiquitous sensing systems are being used to measure motor ability in clinical settings. Intended to augment clinical decision-making, the interpretability of the machine-learning measurements underneath becomes critical to their use. We explore how visualization can support the interpretability of machine-learning measures through the case of Assess MS, a system to support the clinical assessment of Multiple Sclerosis. A substantial design challenge is to make visible the algorithm's decision-making process in a way that allows clinicians to integrate the algorithm's result into their own decision process. To this end, we present a series of design iterations that probe the challenges in supporting interpretability in a real-world system. The key contribution of this article is to illustrate that simply making visible the algorithmic decision-making process is not helpful in supporting clinicians in their own decision-making process. It disregards that people and algorithms make decisions in different ways. Instead, we propose that visualisation can provide context to algorithmic decision-making, rendering observable a range of internal workings of the algorithm from data quality issues to the web of relationships generated in the machine-learning process.","[Morrison, Cecily; Huckvale, Kit; Corish, Bob; Banks, Richard; Grayson, Martin; Dorn, Jonas; Sellen, Abigail; Lindley, Sian] Microsoft Res, Cambridge, England; [Morrison, Cecily; Huckvale, Kit; Corish, Bob; Banks, Richard; Grayson, Martin; Sellen, Abigail; Lindley, Sian] Microsoft Res Cambridge, 21 Stn Rd, Cambridge CB1 2FB, England; [Dorn, Jonas] Novartis Pharma AG, Digital Dev, Novartis Campus,WSJ 027-02-74, CH-4056 Basel, Switzerland",,"Morrison, C (corresponding author), Microsoft Res Cambridge, 21 Stn Rd, Cambridge CB1 2FB, England.",cecilym@microsoft.com; t-chhuck@microsoft.com; rcorish@microsoft.com; rbanks@microsoft.com; mgrayson@microsoft.com; Jonas.dorn@novartis.com; asellen@mircosoft.com; sianl@microsoft.com,,,,,,,,9,11,,,,,,,,,,,JUL,2018,8,2,,,SI,,,,12,10.1145/3181670,http://dx.doi.org/10.1145/3181670,,,,,,,,,,,,2025-05-29,WOS:000439628500006,View Full Record in Web of Science
J,"Kim, TW; Routledge, BR",,,,"Kim, Tae Wan; Routledge, Bryan R.",,,Why a Right to an Explanation of Algorithmic Decision-Making Should Exist: A Trust-Based Approach,BUSINESS ETHICS QUARTERLY,,,,Article,,,,,,,,"Businesses increasingly rely on algorithms that are data-trained sets of decision rules (i.e., the output of the processes often called machine learning) and implement decisions with little or no human intermediation. In this article, we provide a philosophical foundation for the claim that algorithmic decision-making gives rise to a right to explanation. It is often said that, in the digital era, informed consent is dead. This negative view originates from a rigid understanding that presumes informed consent is a static and complete transaction. Such a view is insufficient, especially when data are used in a secondary, noncontextual, and unpredictable manner-which is the inescapable nature of advanced artificial intelligence systems. We submit that an alternative view of informed consent-as an assurance of trust for incomplete transactions-allows for an understanding of why the rationale of informed consent already entails a right to ex post explanation.","[Kim, Tae Wan; Routledge, Bryan R.] Carnegie Mellon Univ, Sch Business, Pittsburgh, PA 15213 USA; [Routledge, Bryan R.] Univ British Columbia, Vancouver, BC, Canada",,"Kim, TW (corresponding author), Carnegie Mellon Univ, Sch Business, Pittsburgh, PA 15213 USA.",,,,,,,,,34,35,,,,,,,,,,,JAN,2022,32,1,,,,,75,102,PII S1052150X21000038,10.1017/beq.2021.3,http://dx.doi.org/10.1017/beq.2021.3,,MAY 2021,,,,,,,,,,2025-05-29,WOS:000743366400001,View Full Record in Web of Science
J,"Chondamrongkul, N; Temdee, P",,,,"Chondamrongkul, Nacha; Temdee, Punnarumol",,,Automatic Extraction of Ontological Explanation for Machine Learning-Based Systems,INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING,,,,Article,,,,,,,,"Machine learning has been implemented as a part of many software systems to support data-driven decisions and recommendations. The prominent machine learning technique is the artificial neural network, which lacks the explanation of how it produces the output. However, many application domains require algorithmic decision making to be transparent so explainability in these systems has been an important challenge. This paper proposes an automated framework that elicits the contributing rules describing how the neural network model makes decisions. The explainability of contributing rules can be measured and it is able to address issues in the training dataset. With the ontology representation of contributing rules, an individual decision can be automatically explained through ontology reasoning. We have developed a tool that supports applying our framework in practice. The evaluation has been conducted to assess the effectiveness of our framework using open datasets from different domains. The results prove that our framework performs well to explain the neural network models, as it can achieve the average accuracy of 81% to explain the subject models. Also, our framework takes significantly less time to process than the other technique.","[Chondamrongkul, Nacha; Temdee, Punnarumol] Mae Fah Luang Univ, Sch Informat Technol, Chiang Rai, Thailand",,"Chondamrongkul, N (corresponding author), Mae Fah Luang Univ, Sch Informat Technol, Chiang Rai, Thailand.",nacha.cho@mfu.ac.th; punnarumol@mfu.ac.th,,,,,,,,0,0,,,,,,,,,,,JAN,2023,33,1,,,,,133,156,,10.1142/S0218194022500802,http://dx.doi.org/10.1142/S0218194022500802,,JAN 2023,,,,,,,,,,2025-05-29,WOS:000923374100001,View Full Record in Web of Science
J,"Marmolejo-Ramos, F; Marrone, R; Korolkiewicz, M; Gabriel, F; Siemens, G; Joksimovic, S; Yamada, Y; Mori, Y; Rahwan, T; Sahakyan, M; Sonna, B; Meirmanov, A; Bolatov, A; Som, B; Ndukaihe, I; Arinze, NC; Kundrat, J; Skanderová, L; Ngo, V; Nguyen, G; Lacia, M; Kung, CC; Irmayanti, M; Muktadir, A; Samosir, FT; Liuzza, MT; Giorgini, R; Khatin-Zadeh, O; Banaruee, H; Özdogru, AA; Ariyabuddhiphongs, K; Rakchai, W; Trujillo, N; Valencia, SM; Janyan, A; Kostov, K; Montoro, PR; Hinojosa, J; Medeiros, K; Hunt, TE; Posada, J; Freitag, RMK; Tejada, J",,,,"Marmolejo-Ramos, Fernando; Marrone, Rebecca; Korolkiewicz, Malgorzata; Gabriel, Florence; Siemens, George; Joksimovic, Srecko; Yamada, Yuki; Mori, Yuki; Rahwan, Talal; Sahakyan, Maria; Sonna, Belona; Meirmanov, Assylbek; Bolatov, Aidos; Som, Bidisha; Ndukaihe, Izuchukwu; Arinze, Nwadiogo C.; Kundrat, Josef; Skanderova, Lenka; Ngo, Van-Giang; Nguyen, Giang; Lacia, Michelle; Kung, Chun-Chia; Irmayanti, Meiselina; Muktadir, Abdul; Samosir, Fransiska Timoria; Liuzza, Marco Tullio; Giorgini, Roberto; Khatin-Zadeh, Omid; Banaruee, Hassan; Ozdogru, Asil Ali; Ariyabuddhiphongs, Kris; Rakchai, Wachirawit; Trujillo, Natalia; Valencia, Stella Maris; Janyan, Armina; Kostov, Kiril; Montoro, Pedro R.; Hinojosa, Jose; Medeiros, Kelsey; Hunt, Thomas E.; Posada, Julian; Freitag, Raquel Meister Ko; Tejada, Julian",,,Factors influencing trust in algorithmic decision-making: an indirect scenario-based experiment,FRONTIERS IN ARTIFICIAL INTELLIGENCE,,,,Article,,,,,,,,"Algorithms are involved in decisions ranging from trivial to significant, but people often express distrust toward them. Research suggests that educational efforts to explain how algorithms work may help mitigate this distrust. In a study of 1,921 participants from 20 countries, we examined differences in algorithmic trust for low-stakes and high-stakes decisions. Our results suggest that statistical literacy is negatively associated with trust in algorithms for high-stakes situations, while it is positively associated with trust in low-stakes scenarios with high algorithm familiarity. However, explainability did not appear to influence trust in algorithms. We conclude that having statistical literacy enables individuals to critically evaluate the decisions made by algorithms, data and AI, and consider them alongside other factors before making significant life decisions. This ensures that individuals are not solely relying on algorithms that may not fully capture the complexity and nuances of human behavior and decision-making. Therefore, policymakers should consider promoting statistical/AI literacy to address some of the complexities associated with trust in algorithms. This work paves the way for further research, including the triangulation of data with direct observations of user interactions with algorithms or physiological measures to assess trust more accurately.","[Marmolejo-Ramos, Fernando] Flinders Univ Adelaide, Coll Educ Psychol & Social Work, Adelaide, SA, Australia; [Marrone, Rebecca; Korolkiewicz, Malgorzata; Gabriel, Florence; Siemens, George; Joksimovic, Srecko] Univ South Australia, Ctr Change & Complex Learning, Adelaide, SA, Australia; [Yamada, Yuki] Kyushu Univ, Fac Arts & Sci, Fukuoka, Japan; [Mori, Yuki] Kyushu Univ, Grad Sch Human Environm Studies, Fukuoka, Japan; [Rahwan, Talal; Sahakyan, Maria] New York Univ Abu Dhabi, Sci Div, Comp Sci, Abu Dhabi, U Arab Emirates; [Sonna, Belona] African Inst Math Sci AIMS, African Masters Machine Intelligence AMMI, Kigali, Rwanda; [Meirmanov, Assylbek] Astana Int Univ, Pedag Inst, Astana 020000, Kazakhstan; [Bolatov, Aidos] Astana Med Univ, Dept Gen & Biol Chem, Beibitshilik str 49a, Astana 010000, Kazakhstan; [Som, Bidisha] Indian Inst Technol Guwahati, Dept Humanities & Social Sci, Gauhati, Assam, India; [Ndukaihe, Izuchukwu; Arinze, Nwadiogo C.] Alex Ekwueme Fed Univ, Ebonyi, Nigeria; [Kundrat, Josef] Univ Ostrava, Fac Arts, Dept Psychol, Ostrava, Czech Republic; [Skanderova, Lenka] Tech Univ Ostrava, Fac Elect Engn & Comp Sci, Dept Comp Sci, Ostrava, Czech Republic; [Ngo, Van-Giang; Nguyen, Giang] Hanoi Univ, English Studies Dept, Hanoi, Vietnam; [Lacia, Michelle] Notre Dame Marbel Univ, Coll Arts & Sci, Alunan Ave, Cotabato 9506, Philippines; [Kung, Chun-Chia] Natl Cheng Kung Univ, Dept Psychol, Tainan, Taiwan; [Irmayanti, Meiselina] Univ Bengkulu, Dept Educ FKIP, Bengkulu, Indonesia; [Irmayanti, Meiselina] Natl Cheng Kung Univ, Int Doctoral Program Principles & Implicat Mind S, Tainan, Taiwan; [Muktadir, Abdul] Univ Bengkulu, Postgrad Program Basic Educ, Bengkulu, Indonesia; [Samosir, Fransiska Timoria] Univ Bengkulu, Lib & Informat Sci, Bengkulu, Indonesia; [Liuzza, Marco Tullio] Univ Padua, Dept Dev Psychol & Socializat, Padua, Italy; [Giorgini, Roberto] Magna Graecia Univ Catanzaro, Dept Med & Surg Sci, Catanzaro, Italy; [Khatin-Zadeh, Omid] Univ Elect Sci & Technol China, Sch Foreign Languages, Chengdu, Peoples R China; [Banaruee, Hassan] Univ Educ Weingarten, Dept Educ Psychol, Weingarten, Germany; Marmara Univ, Dept Dermatol, Istanbul, Turkiye; [Ariyabuddhiphongs, Kris; Rakchai, Wachirawit] Chulalongkorn Univ, Fac Psychol, Bangkok, Thailand; [Trujillo, Natalia; Valencia, Stella Maris] Univ Antioquia, Fac Publ Hlth, Medellin, Colombia; [Janyan, Armina; Kostov, Kiril] New Bulgarian Univ, Dept Cognit Sci & Psychol, Sofia, Bulgaria; [Janyan, Armina] New Bulgarian Univ, Res Ctr Cognit Sci, Sofia, Bulgaria; [Montoro, Pedro R.] Univ Nacl Educ Distancia UNED, Dept Psicol Basica 1, Madrid 28040, Spain; [Hinojosa, Jose] Univ Complutense Madrid, Inst Pluridisciplinar, Madrid, Spain; [Hinojosa, Jose] Univ Nebrija, Ctr Invest Nebrija Cogn CINC, Madrid, Spain; [Medeiros, Kelsey] Univ Nebraska Omaha, Dept Management, Omaha, NE USA; [Hunt, Thomas E.] Univ Derby, Derbyshire Business Sch, Derby, Derby, England; [Posada, Julian] Yale Univ, Dept Amer Studies, New Haven, CT 06520 USA; [Freitag, Raquel Meister Ko; Tejada, Julian] Univ Fed Sergipe, Dept Psicol, Sao Cristovao, Brazil",,"Marmolejo-Ramos, F (corresponding author), Flinders Univ Adelaide, Coll Educ Psychol & Social Work, Adelaide, SA, Australia.",fernando.marmolejoramos@flinders.edu.au,,,,,,,,1,1,,,,,,,,,,,FEB 4,2025,7,,,,,,,,1465605,10.3389/frai.2024.1465605,http://dx.doi.org/10.3389/frai.2024.1465605,,,,,,,,,,,,2025-05-29,WOS:001423376700001,View Full Record in Web of Science
J,"Brughmans, D; Melis, L; Martens, D",,,,"Brughmans, Dieter; Melis, Lissa; Martens, David",,,Disagreement amongst counterfactual explanations: how transparency can be misleading,TOP,,,,Article,,,,,,,,"Counterfactual explanations are increasingly used as an Explainable Artificial Intelligence (XAI) technique to provide stakeholders of complex machine learning algorithms with explanations for data-driven decisions. The popularity of counterfactual explanations resulted in a boom in the algorithms generating them. However, not every algorithm creates uniform explanations for the same instance. Even though in some contexts multiple possible explanations are beneficial, there are circumstances where diversity amongst counterfactual explanations results in a potential disagreement problem among stakeholders. Ethical issues arise when for example, malicious agents use this diversity to fairwash an unfair machine learning model by hiding sensitive features. As legislators worldwide tend to start including the right to explanations for data-driven, high-stakes decisions in their policies, these ethical issues should be understood and addressed. Our literature review on the disagreement problem in XAI reveals that this problem has never been empirically assessed for counterfactual explanations. Therefore, in this work, we conduct a large-scale empirical analysis, on 40 data sets, using 12 explanation-generating methods, for two black-box models, yielding over 192,000 explanations. Our study finds alarmingly high disagreement levels between the methods tested. A malicious user is able to both exclude and include desired features when multiple counterfactual explanations are available. This disagreement seems to be driven mainly by the data set characteristics and the type of counterfactual algorithm. XAI centers on the transparency of algorithmic decision-making, but our analysis advocates for transparency about this self-proclaimed transparency.","[Brughmans, Dieter; Martens, David] Univ Antwerp, Engn Management Dept, Prinsstr 13, B-2000 Antwerp, Belgium; [Melis, Lissa] Penn State Univ, Civil & Environm Engn Dept, 212 Sackett Bldg, University Pk, PA 16802 USA; [Melis, Lissa] Maastricht Univ, Sch Business & Econ, Tongersestr 53, NL-6211 LM Maastricht, Netherlands",,"Melis, L (corresponding author), Penn State Univ, Civil & Environm Engn Dept, 212 Sackett Bldg, University Pk, PA 16802 USA.;Melis, L (corresponding author), Maastricht Univ, Sch Business & Econ, Tongersestr 53, NL-6211 LM Maastricht, Netherlands.",dieter.brughmans@uantwerpen.be; lissa.melis@maastrichtuniversity.nl; david.martens@uantwerpen.be,,,,,,,,4,4,,,,,,,,,,,OCT,2024,32,3,,,SI,,429,462,,10.1007/s11750-024-00670-2,http://dx.doi.org/10.1007/s11750-024-00670-2,,MAY 2024,,,,,,,,,,2025-05-29,WOS:001216045100001,View Full Record in Web of Science
J,"Kaur, D; Uslu, S; Rittichier, KJ; Durresi, A",,,,"Kaur, Davinder; Uslu, Suleyman; Rittichier, Kaley J.; Durresi, Arjan",,,Trustworthy Artificial Intelligence: A Review,ACM COMPUTING SURVEYS,,,,Review,,,,,,,,"Artificial intelligence (AI) and algorithmic decision making are having a profound impact on our daily lives. These systems are vastly used in different high-stakes applications like healthcare, business, government, education, and justice, moving us toward a more algorithmic society. However, despite so many advantages of these systems, they sometimes directly or indirectly cause harm to the users and society. Therefore, it has become essential to make these systems safe, reliable, and trustworthy. Several requirements, such as fairness, explainability, accountability, reliability, and acceptance, have been proposed in this direction to make these systems trustworthy. This survey analyzes all of these different requirements through the lens of the literature. It provides an overview of different approaches that can help mitigate AI risks and increase trust and acceptance of the systems by utilizing the users and society. It also discusses existing strategies for validating and verifying these systems and the current standardization efforts for trustworthy AI. Finally, we present a holistic view of the recent advancements in trustworthy AI to help the interested researchers grasp the crucial facets of the topic efficiently and offer possible future research directions.","[Kaur, Davinder; Uslu, Suleyman; Rittichier, Kaley J.; Durresi, Arjan] Indiana Univ Purdue Univ, Comp & Informat Sci, 723 W Michigan St, Indianapolis, IN 46202 USA",,"Kaur, D (corresponding author), Indiana Univ Purdue Univ, Comp & Informat Sci, 723 W Michigan St, Indianapolis, IN 46202 USA.",davikaur@iu.edu; suslu@iu.edu; krittich@iu.edu; adurresi@iupui.edu,,,,,,,,261,274,,,,,,,,,,,MAR,2023,55,2,,,,,,,39,10.1145/3491209,http://dx.doi.org/10.1145/3491209,,,,,,,,,,,,2025-05-29,WOS:000778458900016,View Full Record in Web of Science
J,"Chauhan, C; Gullapalli, RR",,,,"Chauhan, Chhavi; Gullapalli, Rama R.",,,Ethics of AI in Pathology Current Paradigms and Emerging Issues,AMERICAN JOURNAL OF PATHOLOGY,,,,Review,,,,,,,,"Deep learning has rapidly advanced artificial intelligence (AI) and algorithmic decision-making (ADM) paradigms, affecting many traditional fields of medicine, including pathology, which is a heavily datacentric specialty of medicine. The structured nature of pathology data repositories makes it highly attractive to AI researchers to train deep learning models to improve health care delivery. Additionally, there are enormous financial incentives driving adoption of AI and ADM due to promise of increased efficiency of the health care delivery process. AI, if used unethically, may exacerbate existing inequities of health care, especially if not implemented correctly. There is an urgent need to harness the vast power of AI in an ethically and morally justifiable manner. This review explores the key issues involving AI ethics in pathology. Issues related to ethical design of pathology AI studies and the potential risks associated with implementation of AI and ADM within the pathology workflow are discussed. Three key foundational principles of ethical AI: transparency, accountability, and governance, are described in the context of pathology. The future practice of pathology must be guided by these principles. Pathologists should be aware of the potential of AI to deliver superlative health care and the ethical pitfalls associated with it. Finally, pathologists must have a seat at the table to drive future implementation of ethical AI in the practice of pathology.","[Chauhan, Chhavi] Amer Soc Invest Pathol, Rockville, MD 20852 USA; [Gullapalli, Rama R.] Univ New Mexico, Dept Pathol, Albuquerque, NM 87131 USA; [Gullapalli, Rama R.] Univ New Mexico, Dept Chem & Biol Engn, Albuquerque, NM 87131 USA",,"Chauhan, C (corresponding author), Univ New Mexico, Room 333A,MSC08-4640, Albuquerque, NM 87131 USA.",rgullapalli@salud.unm.edu,,,,,,,,38,38,,,,,,,,,,,OCT,2021,191,10,,,,,1673,1683,,10.1016/j.ajpath.2021.06.011,http://dx.doi.org/10.1016/j.ajpath.2021.06.011,,SEP 2021,,,,,,,,,,2025-05-29,WOS:000701844500003,View Full Record in Web of Science
J,"Nguyen, AP; Vasilaki, S; Martnez, MR",,,,"Nguyen, An-Phi; Vasilaki, Stefania; Martinez, Maria Rodriguez",,,FLAN: feature-wise latent additive neural models for biological applications,BRIEFINGS IN BIOINFORMATICS,,,,Article,,,,,,,,"Motivation: Interpretability has become a necessary feature for machine learning models deployed in critical scenarios, e.g. legal system, healthcare. In these situations, algorithmic decisions may have (potentially negative) long-lasting effects on the end-user affected by the decision. While deep learning models achieve impressive results, they often function as a black-box. Inspired by linear models, we propose a novel class of structurally constrained deep neural networks, which we call FLAN (Feature-wise Latent Additive Networks). Crucially, FLANs process each input feature separately, computing for each of them a representation in a common latent space. These feature-wise latent representations are then simply summed, and the aggregated representation is used for the prediction. These feature-wise representations allow a user to estimate the effect of each individual feature independently from the others, similarly to the way linear models are interpreted.: Results: We demonstrate FLAN on a series of benchmark datasets in different biological domains. Our experiments show that FLAN achieves good performances even in complex datasets (e.g. TCR-epitope binding prediction), despite the structural constraint we imposed. On the other hand, this constraint enables us to interpret FLAN by deciphering its decision process, as well as obtaining biological insights (e.g. by identifying the marker genes of different cell populations). In supplementary experiments, we show similar performances also on non-biological datasets.Code and data availabilityCode and example data are available at .","[Nguyen, An-Phi] Swiss Fed Inst Technol, Zurich, Switzerland; [Vasilaki, Stefania] IBM Res Europe, Computat Syst Biol Grp, Zurich, Switzerland; [Vasilaki, Stefania] Roche, Basel, Switzerland; [Martinez, Maria Rodriguez] IBM Corp, Zurich, Switzerland",,"Nguyen, AP (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.;Martnez, MR (corresponding author), IBM Corp, Zurich, Switzerland.",nguyen.phineas@gmail.com; mrm@zurich.ibm.com,,,,,,,,1,1,,,,,,,,,,,MAY 19,2023,24,3,,,,,,,,10.1093/bib/bbad056,http://dx.doi.org/10.1093/bib/bbad056,,APR 2023,,,,,,,,,,2025-05-29,WOS:000967483900001,View Full Record in Web of Science
J,"Yang, Y; Wu, Y; Chang, XY; Li, M; Tan, Y",,,,"Yang, Yi; Wu, Ying; Chang, Xiangyu; Li, Mei; Tan, Yong",,,Toward a Fairness-Aware Scoring System for Algorithmic Decision-Making,PRODUCTION AND OPERATIONS MANAGEMENT,,,,Article; Early Access,,,,,,,,"Scoring systems, as a type of predictive model, have significant advantages in interpretability and transparency and facilitate quick decision-making. As such, scoring systems have been extensively used in a wide variety of industries, such as healthcare and criminal justice. However, the fairness issues in these models have long been criticized, and the use of big data and machine learning (ML) algorithms in the construction of scoring systems heightens this concern. This article proposes a general framework to create fairness-aware, data-driven scoring systems. First, we develop a social welfare function that incorporates both efficiency and group fairness. Then, we transform the social welfare maximization problem into the risk minimization task in ML, and derive a fairness-aware scoring system with the help of mixed-integer programming. Lastly, several theoretical bounds are derived for providing parameter selection suggestions. Our proposed framework provides a suitable solution to address group fairness concerns in developing scoring systems. It enables policymakers to set and customize their desired fairness requirements as well as other application-specific constraints. We test the proposed algorithm with several empirical data sets. Experimental evidence supports the effectiveness of the proposed scoring system in achieving the optimal welfare of stakeholders and in balancing the needs for interpretability, fairness, and efficiency.","[Yang, Yi] Arizona State Univ, W P Carey Sch Business, Dept Informat Syst, Tempe, AZ USA; [Wu, Ying; Chang, Xiangyu] Xi An Jiao Tong Univ, Sch Management, Dept Informat Syst & Intelligent Business, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China; [Li, Mei] Univ Oklahoma, Price Coll Business, Div Mkt & Supply Chain Management, Norman, OK USA; [Tan, Yong] Univ Washington, Michael G Foster Sch Business, Dept Informat Syst & Operat Management, Seattle, WA USA",,"Chang, XY (corresponding author), Xi An Jiao Tong Univ, Sch Management, Dept Informat Syst & Intelligent Business, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.",xiangyuchang@xjtu.edu.cn,,,,,,,,0,0,,,,,,,,,,,2025 JAN 30,2025,,,,,,,,,,10.1177/10591478251318918,http://dx.doi.org/10.1177/10591478251318918,,JAN 2025,,,,,,,,,,2025-05-29,WOS:001492615200001,View Full Record in Web of Science
J,"Maier, M; Carlotto, H; Saperstein, S; Sanchez, F; Balogun, S; Merritt, S",,,,"Maier, Marc; Carlotto, Hayley; Saperstein, Sara; Sanchez, Freddie; Balogun, Sherriff; Merritt, Sears",,,Improving the Accuracy and Transparency of Underwriting with Artificial Intelligence to Transform the Life-Insurance Industry,AI MAGAZINE,,,,Article,,,,,,,,"Life insurance provides trillions of dollars of financial security for hundreds of millions of individuals and families worldwide. To simultaneously offer affordable products while managing this financial ecosystem, life-insurance companies use an underwriting process to assess the mortality risk posed by individual applicants. Traditional underwriting is largely based on examining an applicant's health and behavioral profile. This manual process is incompatible with expectations of a rapid customer experience through digital capabilities. Fortunately, the availability of large historical data sets and the emergence of new data sources provide an unprecedented opportunity for artificial intelligence to transform underwriting in the life-insurance industry with standard measures of mortality risk. We combined one of the largest application data sets in the industry with a responsible artificial intelligence framework to develop a mortality model and life score. We describe how the life score serves as the primary risk-driving engine of deployed algorithmic underwriting systems and demonstrate its high level of accuracy, yielding a nine-percent reduction in claims within the healthiest pool of applicants. Additionally, we argue that, by embracing transparency, the industry can build consumer trust and respond to a dynamic regulatory environment focused on algorithmic decision-making. We present a consumer-facing tool that uses a state-of-the-art method for interpretable machine learning to off er transparency into the life score.","[Maier, Marc] MassMutual, Data Sci Team, Springfield, MA 01111 USA; [Maier, Marc] MassMutual, Data Sci Dev Program, Springfield, MA 01111 USA; [Carlotto, Hayley; Saperstein, Sara; Balogun, Sherriff] MassMutual, Springfield, MA USA; [Sanchez, Freddie] MassMutual, Customer Journey Grp, Springfield, MA USA; [Balogun, Sherriff] MassMutual, Technol & Experience Org, Springfield, MA USA; [Balogun, Sherriff] Springfield Publ Sch, Springfield, MA USA; [Merritt, Sears] MassMutual, Strategy & Architecture Org, Springfield, MA USA",,"Maier, M (corresponding author), MassMutual, Data Sci Team, Springfield, MA 01111 USA.;Maier, M (corresponding author), MassMutual, Data Sci Dev Program, Springfield, MA 01111 USA.",,,,,,,,,10,11,,,,,,,,,,,FAL,2020,41,3,,,,,78,93,,,,,,,,,,,,,,,2025-05-29,WOS:000574631600006,View Full Record in Web of Science
J,"Chen, CL; Golubchik, L; Pal, R",,,,"Chen, Chien-Lun; Golubchik, Leana; Pal, Ranjan",,,Achieving Transparency Report Privacy in Linear Time,ACM JOURNAL OF DATA AND INFORMATION QUALITY,,,,Article,,,,,,,,"An accountable algorithmic transparency report (ATR) should ideally investigate (a) transparency of the underlying algorithm, and (b) fairness of the algorithmic decisions, and at the same time preserve data subjects' privacy. However, a provably formal study of the impact to data subjects' privacy caused by the utility of releasing an ATR (that investigates transparency and fairness), has yet to be addressed in the literature. The far-fetched benefit of such a study lies in the methodical characterization of privacy-utility trade-offs for release of ATRs in public, and their consequential application-specific impact on the dimensions of society, politics, and economics. In this paper, we first investigate and demonstrate potential privacy hazards brought on by the deployment of transparency and fairness measures in released ATRs. To preserve data subjects' privacy, we then propose a linear-time optimal-privacy scheme, built upon standard linear fractional programming (LFP) theory, for announcing ATRs, subject to constraints controlling the tolerance of privacy perturbation on the utility of transparency schemes. Subsequently, we quantify the privacy-utility trade-offs induced by our scheme, and analyze the impact of privacy perturbation on fairness measures in ATRs. To the best of our knowledge, this is the first analytical work that simultaneously addresses trade-offs between the triad of privacy, utility, and fairness, applicable to algorithmic transparency reports.","[Chen, Chien-Lun; Golubchik, Leana] Univ Southern Calif, 941 Bloom Walk, Los Angeles, CA 90089 USA; [Pal, Ranjan] Univ Michigan, 1301 Beal Ave, Ann Arbor, MI 48109 USA; [Chen, Chien-Lun] Amazon Com Serv LLC, 10300 Campus Point Dr, San Diego, CA 92121 USA",,"Chen, CL (corresponding author), Univ Southern Calif, 941 Bloom Walk, Los Angeles, CA 90089 USA.",chienluc@amazon.com; leana@usc.edu; palr@umich.edu,,,,,,,,1,1,,,,,,,,,,,JUN,2022,14,2,,,SI,,,,8,10.1145/3460001,http://dx.doi.org/10.1145/3460001,,,,,,,,,,,,2025-05-29,WOS:000786545000003,View Full Record in Web of Science
J,"Schmude, T; Koesten, L; Möller, T; Tschiatschek, S",,,,"Schmude, Timothee; Koesten, Laura; Moeller, Torsten; Tschiatschek, Sebastian",,,Information that matters: Exploring information needs of people affected by algorithmic decisions,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES,,,,Article,,,,,,,,"Every AI system that makes decisions about people has a group of stakeholders that are personally affected by these decisions. However, explanations of AI systems rarely address the information needs of this stakeholder group, who often are AI novices. This creates a gap between conveyed information and information that matters to those who are impacted by the system's decisions, such as domain experts and decision subjects. To address this, we present the XAI Novice Question Bank, an extension of the XAI Question Bank (Liao et al., 2020) containing a catalog of information needs from AI novices in two use cases: employment prediction and health monitoring. The catalog covers the categories of data, system context, system usage, and system specifications. We gathered information needs through task based interviews where participants asked questions about two AI systems to decide on their adoption and received verbal explanations in response. Our analysis showed that participants' confidence increased after receiving explanations but that their understanding faced challenges. These included difficulties in locating information and in assessing their own understanding, as well as attempts to outsource understanding. Additionally, participants' prior perceptions of the systems' risks and benefits influenced their information needs. Participants who perceived high risks sought explanations about the intentions behind a system's deployment, while those who perceived low risks rather asked about the system's operation. Our work aims to support the inclusion of AI novices in explainability efforts by highlighting their information needs, aims, and challenges. We summarize our findings as five key implications that can inform the design of future explanations for lay stakeholder audiences.","[Schmude, Timothee; Koesten, Laura; Moeller, Torsten; Tschiatschek, Sebastian] Univ Vienna, Fac Comp Sci, A-1090 Vienna, Austria; [Schmude, Timothee; Moeller, Torsten; Tschiatschek, Sebastian] Univ Vienna, Res Network Data Sci, A-1090 Vienna, Austria; [Schmude, Timothee] Univ Vienna, Doctoral Sch Comp Sci, A-1090 Vienna, Austria",,"Schmude, T (corresponding author), Univ Vienna, Fac Comp Sci, A-1090 Vienna, Austria.;Schmude, T (corresponding author), Univ Vienna, Res Network Data Sci, A-1090 Vienna, Austria.;Schmude, T (corresponding author), Univ Vienna, Doctoral Sch Comp Sci, A-1090 Vienna, Austria.",timothee.schmude@univie.ac.at,,,,,,,,0,0,,,,,,,,,,,JAN,2025,193,,,,,,,,103380,10.1016/j.ijhcs.2024.103380,http://dx.doi.org/10.1016/j.ijhcs.2024.103380,,OCT 2024,,,,,,,,,,2025-05-29,WOS:001334030500001,View Full Record in Web of Science
J,"Panigutti, C; Perotti, A; Panisson, A; Bajardi, P; Pedreschi, D",,,,"Panigutti, Cecilia; Perotti, Alan; Panisson, Andre; Bajardi, Paolo; Pedreschi, Dino",,,FairLens: Auditing black-box clinical decision support systems,INFORMATION PROCESSING & MANAGEMENT,,,,Article,,,,,,,,"The pervasive application of algorithmic decision-making is raising concerns on the risk of unintended bias in AI systems deployed in critical settings such as healthcare. The detection and mitigation of model bias is a very delicate task that should be tackled with care and involving domain experts in the loop. In this paper we introduce FairLens, a methodology for discovering and explaining biases. We show how this tool can audit a fictional commercial black-box model acting as a clinical decision support system (DSS). In this scenario, the healthcare facility experts can use FairLens on their historical data to discover the biases of the model before incorporating it into the clinical decision flow. FairLens first stratifies the available patient data according to demographic attributes such as age, ethnicity, gender and healthcare insurance; it then assesses the model performance on such groups highlighting the most common misclassifications. Finally, FairLens allows the expert to examine one misclassification of interest by explaining which elements of the affected patients' clinical history drive the model error in the problematic group. We validate FairLens' ability to highlight bias in multilabel clinical DSSs introducing a multilabel-appropriate metric of disparity and proving its efficacy against other standard metrics.","[Panigutti, Cecilia] Scuola Normale Super Pisa, Pisa, Italy; [Perotti, Alan; Panisson, Andre; Bajardi, Paolo] ISI Fdn, Turin, Italy; [Pedreschi, Dino] Univ Pisa, Pisa, Italy",,"Panigutti, C (corresponding author), Scuola Normale Super Pisa, Pisa, Italy.",cecilia.panigutti@sns.it,,,,,,,,43,44,,,,,,,,,,,SEP,2021,58,5,,,,,,,102657,10.1016/j.ipm.2021.102657,http://dx.doi.org/10.1016/j.ipm.2021.102657,,JUN 2021,,,,,,,,,,2025-05-29,WOS:000681134700008,View Full Record in Web of Science
J,"Mohammadi, A; Maghsoudi, M",,,,"Mohammadi, Amirmahdi; Maghsoudi, Mehrdad",,,Bridging perspectives on artificial intelligence: a comparative analysis of hopes and concerns in developed and developing countries,AI & SOCIETY,,,,Review; Early Access,,,,,,,,"Artificial intelligence (AI) is transforming industries, generating both enthusiasm and concern. While AI-driven innovations enhance productivity, healthcare, and education, significant ethical issues persist, including misinformation, algorithmic bias, and job displacement. This study examines public perceptions of AI by analyzing large-scale social media discourse and integrating sentiment analysis with expert insights via the Delphi method to assess global perspectives. Findings reveal notable differences across socio-economic contexts. In high-income countries, discussions emphasize AI ethics, governance, and automation risks, whereas in low-income regions, economic challenges and accessibility barriers dominate concerns. Public trust in AI is significantly influenced by governance frameworks, transparency in algorithmic decision-making, and regulatory oversight. Recent advancements in AI governance highlight the increasing role of explainable AI (XAI) and algorithmic fairness, alongside regulatory developments tailored to societal needs. Algorithmic nudging has emerged as a tool for guiding user behavior while maintaining autonomy, and research on user sensemaking in fairness and transparency underscores the importance of interpretability tools in fostering trust and acceptance of AI-driven decisions. These insights emphasize the need for adaptive, context-specific policies that ensure ethical AI deployment while mitigating risks. By bridging public sentiment analysis with governance research, this study provides a comprehensive understanding of AI's societal impact. Findings offer practical implications for policymakers, industry leaders, and researchers, contributing to the development of inclusive, transparent, and accountable AI governance frameworks that align with public expectations.","[Mohammadi, Amirmahdi] Iran Univ Sci & Technol, Tehran, Iran; [Maghsoudi, Mehrdad] Shahed Univ, Tehran, Iran",,"Maghsoudi, M (corresponding author), Shahed Univ, Tehran, Iran.",am_mohammadi77@vu.iust.ac.ir; M_Maghsoudi@sbu.ac.ir,,,,,,,,0,0,,,,,,,,,,,2025 APR 7,2025,,,,,,,,,,10.1007/s00146-025-02331-9,http://dx.doi.org/10.1007/s00146-025-02331-9,,APR 2025,,,,,,,,,,2025-05-29,WOS:001461128500001,View Full Record in Web of Science
J,"Khusainova, E; Dodwell, E; Mitra, R",,,,"Khusainova, Elena; Dodwell, Emily; Mitra, Ritwik",,,SOAR: Simultaneous Or-of-And Rules for classification of positive and negative classes,STAT,,,,Article,,,,,,,,"Algorithmic decision making has proliferated and now impacts our daily lives in both mundane and consequential ways. Machine learning practitioners use a myriad of algorithms for predictive models in applications as diverse as movie recommendations, medical diagnoses, and parole recommendations without delving into the reasons driving specific predictive decisions. The algorithms in such applications are often chosen for their superior performance among a pool of competing algorithms; however, popular choices such as random forest and deep neural networks fail to provide an interpretable understanding of the model's predictions. In recent years, rule-based algorithms have provided a valuable alternative to address this issue. Previous work established an or-of-and (disjunctive normal form) based classification technique that allows for classification rule mining of a single class in a binary classification. In this work, we extend this idea to provide classification rules for both classes simultaneously. That is, we provide a distinct set of rules for each of the positive and negative classes. We also present a novel and complete taxonomy of classifications that clearly capture and quantify the inherent ambiguity of noisy binary classifications in the real world. We show that this approach leads to a more granular formulation of the likelihood model and a simulated annealing-based optimization achieves classification performance competitive with comparable techniques. We apply our method to synthetic and real-world data sets for comparison with other related methods to demonstrate the utility of our contribution.","[Khusainova, Elena; Dodwell, Emily; Mitra, Ritwik] AT&T Data Sci & Res, CDO, New York, NY 10007 USA; [Khusainova, Elena] AT&T, 33 Thomas St, New York, NY 10007 USA",,"Khusainova, E (corresponding author), AT&T, 33 Thomas St, New York, NY 10007 USA.",elena.r.khusainova@gmail.com,,,,,,,,0,0,,,,,,,,,,,JAN,2023,12,1,,,,,,,e577,10.1002/sta4.577,http://dx.doi.org/10.1002/sta4.577,,,,,,,,,,,,2025-05-29,WOS:000986138100001,View Full Record in Web of Science
J,"Alzubaidi, L; Al-Sabaawi, A; Bai, JS; Dukhan, A; Alkenani, AH; Al-Asadi, A; Alwzwazy, HA; Manoufali, M; Fadhel, MA; Albahri, AS; Moreira, C; Ouyang, C; Zhang, JL; Santamaría, J; Salhi, A; Hollman, F; Gupta, A; Duan, Y; Rabczuk, T; Abbosh, A; Gu, YT",,,,"Alzubaidi, Laith; Al-Sabaawi, Aiman; Bai, Jinshuai; Dukhan, Ammar; Alkenani, Ahmed H.; Al-Asadi, Ahmed; Alwzwazy, Haider A.; Manoufali, Mohamed; Fadhel, Mohammed A.; Albahri, A. S.; Moreira, Catarina; Ouyang, Chun; Zhang, Jinglan; Santamaria, Jose; Salhi, Asma; Hollman, Freek; Gupta, Ashish; Duan, Ye; Rabczuk, Timon; Abbosh, Amin; Gu, Yuantong",,,Towards Risk-Free Trustworthy Artificial Intelligence: Significance and Requirements,INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS,,,,Review,,,,,,,,"Given the tremendous potential and influence of artificial intelligence (AI) and algorithmic decision-making (DM), these systems have found wide-ranging applications across diverse fields, including education, business, healthcare industries, government, and justice sectors. While AI and DM offer significant benefits, they also carry the risk of unfavourable outcomes for users and society. As a result, ensuring the safety, reliability, and trustworthiness of these systems becomes crucial. This article aims to provide a comprehensive review of the synergy between AI and DM, focussing on the importance of trustworthiness. The review addresses the following four key questions, guiding readers towards a deeper understanding of this topic: (i) why do we need trustworthy AI? (ii) what are the requirements for trustworthy AI? In line with this second question, the key requirements that establish the trustworthiness of these systems have been explained, including explainability, accountability, robustness, fairness, acceptance of AI, privacy, accuracy, reproducibility, and human agency, and oversight. (iii) how can we have trustworthy data? and (iv) what are the priorities in terms of trustworthy requirements for challenging applications? Regarding this last question, six different applications have been discussed, including trustworthy AI in education, environmental science, 5G-based IoT networks, robotics for architecture, engineering and construction, financial technology, and healthcare. The review emphasises the need to address trustworthiness in AI systems before their deployment in order to achieve the AI goal for good. An example is provided that demonstrates how trustworthy AI can be employed to eliminate bias in human resources management systems. The insights and recommendations presented in this paper will serve as a valuable guide for AI researchers seeking to achieve trustworthiness in their applications.","[Alzubaidi, Laith; Al-Sabaawi, Aiman; Bai, Jinshuai; Dukhan, Ammar; Alkenani, Ahmed H.; Moreira, Catarina; Ouyang, Chun; Zhang, Jinglan; Gu, Yuantong] Queensland Univ Technol, Gardens Point Campus, Brisbane, Qld 4000, Australia; [Alzubaidi, Laith; Fadhel, Mohammed A.; Salhi, Asma] Akunah Co Med Technol, Brisbane, Qld 4120, Australia; [Alzubaidi, Laith; Salhi, Asma; Hollman, Freek; Gupta, Ashish; Gu, Yuantong] Queensland Unit Adv Shoulder Res QUASR, Brisbane, Qld 4000, Australia; [Al-Asadi, Ahmed; Alwzwazy, Haider A.] Univ Missouri, Elect Engn & Comp Sci Dept, Columbia, MO 65211 USA; [Al-Asadi, Ahmed] Univ Technol Baghdad, Commun Engn Dept, Baghdad 10001, Iraq; [Manoufali, Mohamed; Abbosh, Amin] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4067, Australia; [Manoufali, Mohamed] CSIRIO, Space & Astron, Kensington, WA 6151, Australia; [Albahri, A. S.] Univ Pendidikan Sultan Idris UPSI, Fac Comp & Meta Technol FKMT, Tanjung Malim 35900, Malaysia; [Albahri, A. S.] Imam Jaafar Al Sadiq Univ, Coll Informat Technol, Dept Comp Technol Engn, Baghdad 00964, Iraq; [Santamaria, Jose] Univ Jaen, Dept Comp Sci, Jaen 23071, Spain; [Gupta, Ashish] Greenslopes Private Hosp, Brisbane, Qld 4120, Australia; [Gupta, Ashish] Queensland Univ Technol, Brisbane, Qld 4120, Australia; [Duan, Ye] Clemson Univ, Sch Comp, Clemson, SC 29631 USA; [Rabczuk, Timon] Bauhaus Univ Weimar, Inst Struct Mech, D-99423 Weimar, Germany",,"Alzubaidi, L (corresponding author), Queensland Univ Technol, Gardens Point Campus, Brisbane, Qld 4000, Australia.;Alzubaidi, L (corresponding author), Akunah Co Med Technol, Brisbane, Qld 4120, Australia.;Alzubaidi, L (corresponding author), Queensland Unit Adv Shoulder Res QUASR, Brisbane, Qld 4000, Australia.",l.alzubaidi@qut.edu.au; a.alsabaawi@hdr.qut.edu.au; jinshuai.bai@hdr.qut.edu.au; ammar.moufak@gmail.com; ahmedhassan.alkenani@hdr.qut.edu.au; aaabc2@mail.missouri.edu; haiderabd83@gmail.com; mohamed.manoufali@csiro.au; engsuperior@gmail.com; ahmed.bahri1978@gmail.com; catarina.pintomoreira@qut.edu.au; c.ouyang@qut.edu.au; jinglan.zhang@qut.edu.au; jslopez@ujaen.es; asma@akunah.com; freekhollman@gmail.com; ashish@qoc.com.au; duanye@missouri.edu; timon.rabczuk@uni-weimar.de; a.abbosh@uq.edu.au; yuantong.gu@qut.edu.au,,,,,,,,28,28,,,,,,,,,,,OCT 26,2023,2023,,,,,,,,4459198,10.1155/2023/4459198,http://dx.doi.org/10.1155/2023/4459198,,,,,,,,,,,,2025-05-29,WOS:001096335900001,View Full Record in Web of Science
J,"Radovanovic, S; Savic, G; Delibasic, B; Suknovic, M",,,,"Radovanovic, Sandro; Savic, Gordana; Delibasic, Boris; Suknovic, Milija",,,FairDEA-Removing disparate impact from efficiency scores,EUROPEAN JOURNAL OF OPERATIONAL RESEARCH,,,,Article,,,,,,,,"Achieving fairness in algorithmic decision-making tools is an issue constantly gaining in need and popularity. Today, unfair decisions made by such tools can even be subject to legal consequences. We propose a new constraint that integrates fairness into data envelopment analysis (DEA). This allows the calculation of relative efficiency scores of decision-making units (DMUs) with fairness included. The proposed fairness constraint restricts disparate impact to occur in efficiency scores, and enables the creation of a single data envelopment analysis for both privileged and unprivileged groups of DMUs simultaneously. We show that the proposed method FairDEA produces an interpretable model that was tested on a synthetic dataset and two real-world examples, namely the ranking between hybrid and conventional car designs, and the Latin American and Caribbean economies. We provide the interpretation of the FairDEA method by comparing it to the basic DEA and the balanced fairness and efficiency method (BFE DEA). Along with calculating the disparate impact of the model, we performed a Wilcoxon rank-sum test to inspect for fairness in rankings. The results show that the FairDEA method achieves similar efficiency scores as other methods, but without disparate impact. Statistical analysis indicates that the differences in ranking between the groups are not statistically different, which means that the ranking is fair. This method contributes both to the development of data envelopment analysis, and the inclusion of fairness in efficiency analysis. (c) 2021 Elsevier B.V. All rights reserved.","[Radovanovic, Sandro; Savic, Gordana; Delibasic, Boris; Suknovic, Milija] Univ Belgrade, Fac Org Sci, 154 Jove Ilica St, Belgrade, Serbia",,"Radovanovic, S (corresponding author), Univ Belgrade, Fac Org Sci, 154 Jove Ilica St, Belgrade, Serbia.",sandro.radovanovic@fon.bg.ac.rs,,,,,,,,6,6,,,,,,,,,,,SEP 16,2022,301,3,,,,,1088,1098,,10.1016/j.ejor.2021.12.001,http://dx.doi.org/10.1016/j.ejor.2021.12.001,,APR 2022,,,,,,,,,,2025-05-29,WOS:000795495800020,View Full Record in Web of Science
J,"Ferrell, B; Raskin, SE; Zimmerman, EB",,,,"Ferrell, Brian; Raskin, Sarah E.; Zimmerman, Emily B.",,,Calibrating a Transformer-Based Model's Confidence on Community-Engaged Research Studies: Decision Support Evaluation Study,JMIR FORMATIVE RESEARCH,,,,Article,,,,,,,,"Background: Deep learning offers great benefits in classification tasks such as medical imaging diagnostics or stock trading, especially when compared with human-level performances, and can be a viable option for classifying distinct levels within community-engaged research (CEnR). CEnR is a collaborative approach between academics and community partners with the aim of conducting research that is relevant to community needs while incorporating diverse forms of expertise. In the field of deep learning and artificial intelligence (AI), training multiple models to obtain the highest validation accuracy is common practice; however, it can overfit toward that specific data set and not generalize well to a real-world population, which creates issues of bias and potentially dangerous algorithmic decisions. Consequently, if we plan on automating human decision-making, there is a need for creating techniques and exhaustive evaluative processes for these powerful unexplainable models to ensure that we do not incorporate and blindly trust poor AI models to make real-world decisions.Objective: We aimed to conduct an evaluation study to see whether our most accurate transformer-based models derived from previous studies could emulate our own classification spectrum for tracking CEnR studies as well as whether the use of calibrated confidence scores was meaningful.Methods: We compared the results from 3 domain experts, who classified a sample of 45 studies derived from our university's institutional review board database, with those from 3 previously trained transformer-based models, as well as investigated whether calibrated confidence scores can be a viable technique for using AI in a support role for complex decision-making systems.Results: Our findings reveal that certain models exhibit an overestimation of their performance through high confidence scores, despite not achieving the highest validation accuracy.Conclusions: Future studies should be conducted with larger sample sizes to generalize the results more effectively. Although our study addresses the concerns of bias and overfitting in deep learning models, there is a need to further explore methods that allow domain experts to trust our models more. The use of a calibrated confidence score can be a misleading metric when determining our AI model's level of competency.(JMIR Form Res 2023;7:e41516) doi: 10.2196/41516","[Ferrell, Brian] Virginia Commonwealth Univ, Richmond, VA USA; [Raskin, Sarah E.] Virginia Commonwealth Univ, L Douglas Wilder Sch Govt & Publ Affairs, Richmond, VA USA; [Zimmerman, Emily B.] Virginia Commonwealth Univ, Ctr Soc & Hlth, Richmond, VA USA; [Ferrell, Brian] Virginia Commonwealth Univ, 907 Floyd Ave, Richmond, VA 23284 USA",,"Ferrell, B (corresponding author), Virginia Commonwealth Univ, 907 Floyd Ave, Richmond, VA 23284 USA.",ferrellbj@vcu.edu,,,,,,,,1,1,,,,,,,,,,,,2023,7,,,,,,,,,10.2196/41516,http://dx.doi.org/10.2196/41516,,,,,,,,,,,,2025-05-29,WOS:000998428700031,View Full Record in Web of Science
J,"Di Teodoro, G; Monaci, M; Palagi, L",,,,"Di Teodoro, Giulia; Monaci, Marta; Palagi, Laura",,,Unboxing Tree ensembles for interpretability: A hierarchical visualization tool and a multivariate optimal re-built tree,EURO JOURNAL ON COMPUTATIONAL OPTIMIZATION,,,,Article,,,,,,,,"The interpretability of models has become a crucial issue in Machine Learning because of algorithmic decisions' growing impact on real -world applications. Tree ensemble methods, such as Random Forests or XgBoost, are powerful learning tools for classification tasks. However, while combining multiple trees may provide higher prediction quality than a single one, it sacrifices the interpretability property resulting in black -box models. In light of this, we aim to develop an interpretable representation of a tree -ensemble model that can provide valuable insights into its behavior. First, given a target tree -ensemble model, we develop a hierarchical visualization tool based on a heatmap representation of the forest's feature use, considering the frequency of a feature and the level at which it is selected as an indicator of importance. Next, we propose a mixed -integer linear programming (MILP) formulation for constructing a single optimal multivariate tree that accurately mimics the target model predictions. The goal is to provide an interpretable surrogate model based on oblique hyperplane splits, which uses only the most relevant features according to the defined forest's importance indicators. The MILP model includes a penalty on feature selection based on their frequency in the forest to further induce sparsity of the splits. The natural formulation has been strengthened to improve the computational performance of mixed -integer software. Computational experience is carried out on benchmark datasets from the UCI repository using a state-of-the-art off -the -shelf solver. Results show that the proposed model is effective in yielding a shallow interpretable tree approximating the treeensemble decision function.","[Di Teodoro, Giulia; Monaci, Marta; Palagi, Laura] Sapienza Univ Rome, Dept Comp Control & Management Engn Antonio Rubert, I-00185 Rome, Italy",,"Di Teodoro, G (corresponding author), Sapienza Univ Rome, Dept Comp Control & Management Engn Antonio Rubert, I-00185 Rome, Italy.",giulia.diteodoro@uniroma1.it; marta.monaci@uniroma1.it; laura.palagi@uniroma1.it,,,,,,,,3,3,,,,,,,,,,,,2024,12,,,,,,,,100084,10.1016/j.ejco.2024.100084,http://dx.doi.org/10.1016/j.ejco.2024.100084,,JAN 2024,,,,,,,,,,2025-05-29,WOS:001166643700001,View Full Record in Web of Science
J,"Shin, D; Rasul, A; Fotiadis, A",,,,"Shin, Dongheea; Rasul, Azmat; Fotiadis, Anestis",,,Why am I seeing this? Deconstructing algorithm literacy through the lens of users,INTERNET RESEARCH,,,,Article,,,,,,,,"Purpose As algorithms permeate nearly every aspect of digital life, artificial intelligence (AI) systems exert a growing influence on human behavior in the digital milieu. Despite its popularity, little is known about the roles and effects of algorithmic literacy (AL) on user acceptance. The purpose of this study is to contextualize AL in the AI environment by empirically examining the role of AL in developing users' information processing in algorithms. The authors analyze how users engage with over-the-top (OTT) platforms, what awareness the user has of the algorithmic platform and how awareness of AL may impact their interaction with these systems. Design/methodology/approach This study employed multiple-group equivalence methods to compare two group invariance and the hypotheses concerning differences in the effects of AL. The method examined how AL helps users to envisage, understand and work with algorithms, depending on their understanding of the control of the information flow embedded within them. Findings Our findings clarify what functions AL plays in the adoption of OTT platforms and how users experience algorithms, particularly in contexts where AI is used in OTT algorithms to provide personalized recommendations. The results point to the heuristic functions of AL in connection with its ties in trust and ensuing attitude and behavior. Heuristic processes using AL strongly affect the credibility of recommendations and the way users understand the accuracy and personalization of results. The authors argue that critical assessment of AL must be understood not just about how it is used to evaluate the trust of service, but also regarding how it is performatively related in the modeling of algorithmic personalization. Research limitations/implications The relation of AL and trust in an algorithm lends strategic direction in developing user-centered algorithms in OTT contexts. As the AI industry has faced decreasing credibility, the role of user trust will surely give insights on credibility and trust in algorithms. To better understand how to cultivate a sense of literacy regarding algorithm consumption, the AI industry could provide examples of what positive engagement with algorithm platforms looks like. Originality/value User cognitive processes of AL provide conceptual frameworks for algorithm services and a practical guideline for the design of OTT services. Framing the cognitive process of AL in reference to trust has made relevant contributions to the ongoing debate surrounding algorithms and literacy. While the topic of AL is widely recognized, empirical evidence on the effects of AL is relatively rare, particularly from the user's behavioral perspective. No formal theoretical model of algorithmic decision-making based on the dual processing model has been researched.","[Shin, Dongheea; Rasul, Azmat] Zayed Univ, Abu Dhabi, U Arab Emirates; [Fotiadis, Anestis] Zayed Univ, Coll Business, Abu Dhabi, U Arab Emirates",,"Shin, D (corresponding author), Zayed Univ, Abu Dhabi, U Arab Emirates.",dshin1030@gmail.com; azmat.rasul@zu.ac.ae; anestis.fotiadis@zu.ac.ae,,,,,,,,52,55,,,,,,,,,,,JUL 4,2022,32,4,,,,,1214,1234,,10.1108/INTR-02-2021-0087,http://dx.doi.org/10.1108/INTR-02-2021-0087,,SEP 2021,,,,,,,,,,2025-05-29,WOS:000699817600001,View Full Record in Web of Science
J,"Taylor, I",,,,"Taylor, Isaac",,,Is explainable AI responsible AI?,AI & SOCIETY,,,,Article,,,,,,,,"When artificial intelligence (AI) is used to make high-stakes decisions, some worry that this will create a morally troubling responsibility gap-that is, a situation in which nobody is morally responsible for the actions and outcomes that result. Since the responsibility gap might be thought to result from individuals lacking knowledge of the future behavior of AI systems, it can be and has been suggested that deploying explainable artificial intelligence (XAI) techniques will help us to avoid it. These techniques provide humans with certain forms of understanding of the systems in question. In this paper, I consider whether existing XAI techniques can indeed close the responsibility gap. I identify a number of significant limits to their ability to do so. Ensuring that responsibility for AI-assisted outcomes is maintained may require using different techniques in different circumstances, and potentially also developing new techniques that can avoid each of the issues identified.","[Taylor, Isaac] Stockholm Univ, Dept Philosophy, S-10691 Stockholm, Sweden",,"Taylor, I (corresponding author), Stockholm Univ, Dept Philosophy, S-10691 Stockholm, Sweden.",isaac.taylor@philosophy.su.se,,,,,,,,7,7,,,,,,,,,,,MAR,2025,40,3,,,,,1695,1704,,10.1007/s00146-024-01939-7,http://dx.doi.org/10.1007/s00146-024-01939-7,,APR 2024,,,,,,,,,,2025-05-29,WOS:001205934500001,View Full Record in Web of Science
J,"Kisten, M; Ezugwu, AE; Olusanya, MO",,,,"Kisten, Melvin; Ezugwu, Absalom El-Shamir; Olusanya, Micheal O.",,,Explainable Artificial Intelligence Model for Predictive Maintenance in Smart Agricultural Facilities,IEEE ACCESS,,,,Article,,,,,,,,"Artificial Intelligence (AI) in Smart Agricultural Facilities (SAF) often lacks explainability, hindering farmers from taking full advantage of their capabilities. This study tackles this gap by introducing a model that combines eXplainable Artificial Intelligence (XAI), with Predictive Maintenance (PdM). The model aims to provide both predictive insights and explanations across four key dimensions, namely data, model, outcome, and end-user. This approach marks a shift in agricultural AI, reshaping how these technologies are understood and applied. The model outperforms related studies, showing quantifiable improvements. Specifically, the Long-Short-Term Memory (LSTM) classifier shows a 5.81% rise in accuracy. The eXtreme Gradient Boosting (XGBoost) classifier exhibits a 7.09% higher F1 score, 10.66% increased accuracy, and a 4.29% increase in Receiver Operating Characteristic-Area Under the Curve (ROC-AUC). These results could lead to more precise maintenance predictions in real-world settings. This study also provides insights into data purity, global and local explanations, and counterfactual scenarios for PdM in SAF. It advances AI by emphasising the importance of explainability beyond traditional accuracy metrics. The results confirm the superiority of the proposed model, marking a significant contribution to PdM in SAF. Moreover, this study promotes the understanding of AI in agriculture, emphasising explainability dimensions. Future research directions are advocated, including multi-modal data integration and implementing Human-in-the-Loop (HITL) systems aimed at improving the effectiveness of AI and addressing ethical concerns such as Fairness, Accountability, and Transparency (FAT) in agricultural AI applications.","[Kisten, Melvin; Ezugwu, Absalom El-Shamir] North West Univ, Unit Data Sci & Comp, ZA-2520 Potchefstroom, South Africa; [Olusanya, Micheal O.] Sol Plaatje Univ, Dept Comp Sci & Informat Technol, ZA-8300 Kimberley, South Africa",,"Ezugwu, AE (corresponding author), North West Univ, Unit Data Sci & Comp, ZA-2520 Potchefstroom, South Africa.",absalom.ezugwu@nwu.ac.za,,,,,,,,8,8,,,,,,,,,,,,2024,12,,,,,,24348,24367,,10.1109/ACCESS.2024.3365586,http://dx.doi.org/10.1109/ACCESS.2024.3365586,,,,,,,,,,,,2025-05-29,WOS:001164104200001,View Full Record in Web of Science
J,"Silva, A; Schrum, M; Hedlund-Botti, E; Gopalan, N; Gombolay, M",,,,"Silva, Andrew; Schrum, Mariah; Hedlund-Botti, Erin; Gopalan, Nakul; Gombolay, Matthew",,,Explainable Artificial Intelligence: Evaluating the Objective and Subjective Impacts of xAI on Human-Agent Interaction,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,,,,Article,,,,,,,,"Intelligent agents must be able to communicate intentions and explain their decision-making processes to build trust, foster confidence, and improve human-agent team dynamics. Recognizing this need, academia and industry are rapidly proposing new ideas, methods, and frameworks to aid in the design of more explainable AI. Yet, there remains no standardized metric or experimental protocol for benchmarking new methods, leaving researchers to rely on their own intuition or ad hoc methods for assessing new concepts. In this work, we present the first comprehensive (n = 286) user study testing a wide range of approaches for explainable machine learning, including feature importance, probability scores, decision trees, counterfactual reasoning, natural language explanations, and case-based reasoning, as well as a baseline condition with no explanations. We provide the first large-scale empirical evidence of the effects of explainability on human-agent teaming. Our results will help to guide the future of explainability research by highlighting the benefits of counterfactual explanations and the shortcomings of confidence scores for explainability. We also propose a novel questionnaire to measure explainability with human participants, inspired by relevant prior work and correlated with human-agent teaming metrics.","[Silva, Andrew; Schrum, Mariah; Hedlund-Botti, Erin; Gopalan, Nakul; Gombolay, Matthew] Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA",,"Silva, A (corresponding author), Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA.",andrew.silva@gatech.edu,,,,,,,,46,47,,,,,,,,,,,APR 21,2023,39,7,,,SI,,1390,1404,,10.1080/10447318.2022.2101698,http://dx.doi.org/10.1080/10447318.2022.2101698,,AUG 2022,,,,,,,,,,2025-05-29,WOS:000837658200001,View Full Record in Web of Science
J,"Alami, J; El Iskandarani, M; Riggs, SL",,,,"Alami, Jawad; El Iskandarani, Mohamad; Riggs, Sara Lu",,,The Effect of Workload and Task Priority on Multitasking Performance and Reliance on Level 1 Explainable AI (XAI) Use,HUMAN FACTORS,,,,Article; Early Access,,,,,,,,"Objective This study investigates the effects of workload and task priority on multitasking performance and reliance on Level 1 Explainable Artificial Intelligence (XAI) systems in high-stakes decision environments.Background Operators in critical settings manage multiple tasks under varying levels of workload and priority, potentially leading to performance degradation. XAI offers opportunities to support decision making by providing insights into AI's reasoning, yet its adoption and effectiveness in multitasking scenarios remain underexplored.Method Thirty participants engaged in a simulated multitasking environment, involving UAV command and control tasks, with the assistance of a Level 1 (i.e., basic perceptual information) XAI system on one of the tasks. The study utilized a within-subjects experimental design, manipulating workload (low, medium, and high) and AI-supported-task priority (low and high) across six conditions. Participants' accuracy, use of automatic rerouting, AI miss detection, false alert identification, and use of AI explanations were measured and analyzed across the different experimental conditions.Results Workload significantly hindered performance on the AI-assisted task and increased reliance on the AI system especially when the AI-assisted task was given low priority. The use of AI explanations was significantly affected by task priority only.Conclusion An increase in workload led to proper offloading by relying on the AI's alerts, but it also led to a lower rate of alert verification despite the alert feature's high false alert rate.Application The findings from the present work help inform AI system designers on how to design their systems for high-stakes environments such that reliance on AI is properly calibrated.","[Alami, Jawad; El Iskandarani, Mohamad; Riggs, Sara Lu] Univ Virginia, Dept Syst & Informat Engn, Charlottesville, VA USA",,"El Iskandarani, M (corresponding author), Univ Virginia, Olsson Hall,151 Engineers Way, Charlottesville, VA 22903 USA.;Riggs, SL (corresponding author), Univ Virginia, Olsson Hall,151 Engineers Way, Charlottesville, VA 22904 USA.",anz8av@virginia.edu; sr4ex@virginia.edu,,,,,,,,0,0,,,,,,,,,,,2025 MAR 12,2025,,,,,,,,,,10.1177/00187208251323478,http://dx.doi.org/10.1177/00187208251323478,,MAR 2025,,,,,,,,,,2025-05-29,WOS:001442897000001,View Full Record in Web of Science
J,"Andres, A; Martinez-Seras, A; Laña, I; Del Ser, J",,,,"Andres, Alain; Martinez-Seras, Aitor; Lana, Ibai; Del Ser, Javier",,,On the black-box explainability of object detection models for safe and trustworthy industrial applications,RESULTS IN ENGINEERING,,,,Article,,,,,,,,"In the realm of human-machine interaction, artificial intelligence has become a powerful tool for accelerating data modeling tasks. Object detection methods have achieved outstanding results and are widely used in critical domains like autonomous driving and video surveillance. However, their adoption in high-risk applications, where errors may cause severe consequences, remains limited. Explainable Artificial Intelligence methods to address this issue, but many existing techniques are model-specific and designed for classification making them less effective for object detection and difficult for non-specialists to interpret. In this work focus on model-agnostic explainability methods for object detection models and propose D-MFPP, an extension of the Morphological Fragmental Perturbation Pyramid (MFPP) technique based on segmentation-based to generate explanations. Additionally, we introduce D-Deletion, a novel metric combining faithfulness localization, adapted specifically to meet the unique demands of object detectors. We evaluate these methods on real-world industrial and robotic datasets, examining the influence of parameters such as the number masks, model size, and image resolution on the quality of explanations. Our experiments use single-stage detection models applied to two safety-critical robotic environments: i) a shared human-robot workspace safety is of paramount importance, and ii) an assembly area of battery kits, where safety is critical due potential for damage among high-risk components. Our findings evince that D-Deletion effectively gauges performance of explanations when multiple elements of the same class appear in a scene, while D-MFPP provides a promising alternative to D-RISE when fewer masks are used.","[Andres, Alain; Martinez-Seras, Aitor; Lana, Ibai; Del Ser, Javier] TECNALIA, Basque Res & Technol Alliance BRTA, Mikeletegi Pasealekua 2, Donostia San Sebastian 20009, Spain; [Andres, Alain; Lana, Ibai] Univ Deusto, Donostia San Sebastian 20012, Spain; [Del Ser, Javier] Univ Basque Country, UPV EHU, Bilbao 48013, Spain",,"Andres, A (corresponding author), TECNALIA, Basque Res & Technol Alliance BRTA, Mikeletegi Pasealekua 2, Donostia San Sebastian 20009, Spain.",alain.andres@tecnalia.com,,,,,,,,2,2,,,,,,,,,,,DEC,2024,24,,,,,,,,103498,10.1016/j.rineng.2024.103498,http://dx.doi.org/10.1016/j.rineng.2024.103498,,NOV 2024,,,,,,,,,,2025-05-29,WOS:001368644800001,View Full Record in Web of Science
J,"Turner, CJ; Garn, W",,,,"Turner, Chris J.; Garn, Wolfgang",,,Next generation DES simulation: A research agenda for human centric manufacturing systems,JOURNAL OF INDUSTRIAL INFORMATION INTEGRATION,,,,Article,,,,,,,,"In this paper we introduce a research agenda to guide the development of the next generation of Discrete Event Simulation (DES) systems. Interfaces to digital twins are projected to go beyond physical representations to become blueprints for the actual objects and an active dashboard for their control. The role and importance of real-time interactive animations presented in an Extended Reality (XR) format will be explored. The need for using game engines, particularly their physics engines and AI within interactive simulated Extended Reality is expanded on. Importing and scanning real-world environments is assumed to become more efficient when using AR. Exporting to VR and AR is recommended to be a default feature. A technology framework for the next generation simulators is presented along with a proposed set of implementation guidelines. The need for more human centric technology approaches, nascent in Industry 4.0, are now central to the emerging Industry 5.0 paradigm; an agenda that is discussed in this research as part of a human in the loop future, supported by DES. The potential role of Explainable Artificial Intelligence is also explored along with an audit trail approach to provide a justification of complex and automated decision-making systems with relation to DES. A technology framework is proposed, which brings the above together and can serve as a guide for the next generation of holistic simulators for manufacturing.","[Turner, Chris J.; Garn, Wolfgang] Surrey Business Sch Univ Surrey, Guildford GU30 7GW, Surrey, England",,"Turner, CJ (corresponding author), Surrey Business Sch Univ Surrey, Guildford GU30 7GW, Surrey, England.",christopher.turner@surrey.ac.uk; w.garn@surrey.ac.uk,,,,,,,,38,38,,,,,,,,,,,JUL,2022,28,,,,,,,,100354,10.1016/j.jii.2022.100354,http://dx.doi.org/10.1016/j.jii.2022.100354,,APR 2022,,,,,,,,,,2025-05-29,WOS:000800377800005,View Full Record in Web of Science
J,"Auzine, MM; Khan, MHM; Baichoo, S; Sahib, NG; Bissoonauth-Daiboo, P; Gao, XH; Heetun, Z",,,,"Auzine, Muhammad Muzzammil; Heenaye-Mamode Khan, Maleika; Baichoo, Sunilduth; Sahib, Nuzhah Gooda; Bissoonauth-Daiboo, Preeti; Gao, Xiaohong; Heetun, Zaid",,,Development of an ensemble CNN model with explainable AI for the classification of gastrointestinal cancer,PLOS ONE,,,,Article,,,,,,,,"The implementation of AI assisted cancer detection systems in clinical environments has faced numerous hurdles, mainly because of the restricted explainability of their elemental mechanisms, even though such detection systems have proven to be highly effective. Medical practitioners are skeptical about adopting AI assisted diagnoses as due to the latter's inability to be transparent about decision making processes. In this respect, explainable artificial intelligence (XAI) has emerged to provide explanations for model predictions, thereby overcoming the computational black box problem associated with AI systems. In this particular research, the focal point has been the exploration of the Shapley additive explanations (SHAP) and local interpretable model-agnostic explanations (LIME) approaches which enable model prediction explanations. This study used an ensemble model consisting of three convolutional neural networks(CNN): InceptionV3, InceptionResNetV2 and VGG16, which was based on averaging techniques and by combining their respective predictions. These models were trained on the Kvasir dataset, which consists of pathological findings related to gastrointestinal cancer. An accuracy of 96.89% and F1-scores of 96.877% were attained by our ensemble model. Following the training of the ensemble model, we employed SHAP and LIME to analyze images from the three classes, aiming to provide explanations regarding the deterministic features influencing the model's predictions. The results obtained from this analysis demonstrated a positive and encouraging advancement in the exploration of XAI approaches, specifically in the context of gastrointestinal cancer detection within the healthcare domain.","[Auzine, Muhammad Muzzammil; Heenaye-Mamode Khan, Maleika; Baichoo, Sunilduth; Sahib, Nuzhah Gooda; Bissoonauth-Daiboo, Preeti] Univ Mauritius, Dept Software & Informat Syst, Reduit, Mauritius; [Gao, Xiaohong] Middlesex Univ London, Dept Comp Sci, London, England; [Heetun, Zaid] Dr Abdool Gaffoor Jeetoo Hosp, Ctr Gastroenterol & Hepatol, Port Louis, Mauritius",,"Auzine, MM (corresponding author), Univ Mauritius, Dept Software & Informat Syst, Reduit, Mauritius.",mmuzzammil.auzine@gmail.com,,,,,,,,3,3,,,,,,,,,,,JUN 25,2024,19,6,,,,,,,e0305628,10.1371/journal.pone.0305628,http://dx.doi.org/10.1371/journal.pone.0305628,,,,,,,,,,,,2025-05-29,WOS:001253508900099,View Full Record in Web of Science
J,"Sheu, RK; Pardeshi, MS",,,,"Sheu, Ruey-Kai; Pardeshi, Mayuresh Sunil",,,"A Survey on Medical Explainable AI (XAI): Recent Progress, Explainability Approach, Human Interaction and Scoring System",SENSORS,,,,Review,,,,,,,,"The emerging field of eXplainable AI (XAI) in the medical domain is considered to be of utmost importance. Meanwhile, incorporating explanations in the medical domain with respect to legal and ethical AI is necessary to understand detailed decisions, results, and current status of the patient's conditions. Successively, we will be presenting a detailed survey for the medical XAI with the model enhancements, evaluation methods, significant overview of case studies with open box architecture, medical open datasets, and future improvements. Potential differences in AI and XAI methods are provided with the recent XAI methods stated as (i) local and global methods for preprocessing, (ii) knowledge base and distillation algorithms, and (iii) interpretable machine learning. XAI characteristics details with future healthcare explainability is included prominently, whereas the pre-requisite provides insights for the brainstorming sessions before beginning a medical XAI project. Practical case study determines the recent XAI progress leading to the advance developments within the medical field. Ultimately, this survey proposes critical ideas surrounding a user-in-the-loop approach, with an emphasis on human-machine collaboration, to better produce explainable solutions. The surrounding details of the XAI feedback system for human rating-based evaluation provides intelligible insights into a constructive method to produce human enforced explanation feedback. For a long time, XAI limitations of the ratings, scores and grading are present. Therefore, a novel XAI recommendation system and XAI scoring system are designed and approached from this work. Additionally, this paper encourages the importance of implementing explainable solutions into the high impact medical field.","[Sheu, Ruey-Kai] Tunghai Univ, Dept Comp Sci, 1727,Sect 4,Taiwan Blvd, Taichung 407224, Taiwan; [Pardeshi, Mayuresh Sunil] Tunghai Univ, AI Ctr, 1727,Sect 4,Taiwan Blvd, Taichung 407224, Taiwan",,"Pardeshi, MS (corresponding author), Tunghai Univ, AI Ctr, 1727,Sect 4,Taiwan Blvd, Taichung 407224, Taiwan.",mayuresh@thu.edu.tw,,,,,,,,40,40,,,,,,,,,,,OCT,2022,22,20,,,,,,,8068,10.3390/s22208068,http://dx.doi.org/10.3390/s22208068,,,,,,,,,,,,2025-05-29,WOS:000873722100001,View Full Record in Web of Science
J,"Roque, A; Damodaran, SK",,,,"Roque, Antonio; Damodaran, Suresh K.",,,Explainable AI for Security of Human-Interactive Robots,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,,,,Article,,,,,,,,"This article considers the ways that explainable AI can be used to help secure human-interactive robots. To do so, we acknowledge that robots interact with a variety of people. For example, some people may operate robots that perform tasks in their homes or offices, while other people may be tasked with defending robots from potential attackers. We describe how explainable AI can be used to help the human operators of robots appropriately calibrate the trust they have in their systems, and we demonstrate this through an implementation. We also describe a novel generalizable human-in-the-loop framework based on control loops to characterize and explain attacks on robots to a robot defender. We explore the utility of such a framework through an analysis of its application in the incident management process, applied to robots. This framework allows formal definition of explainability, and the necessary condition for explainability in robots. The overarching goal of this article is to introduce the application of explainability for security of robotics as a novel area of research, therefore, we also discuss several open research problems we uncovered while applying explainable AI to security of robots.","[Roque, Antonio] Tufts Univ, Human Robot Interact Lab, Medford, MA 02155 USA; [Damodaran, Suresh K.] Mitre Corp, Burlington Rd, Bedford, MA 01730 USA",,"Damodaran, SK (corresponding author), Mitre Corp, Burlington Rd, Bedford, MA 01730 USA.",sdamodaran@mitre.org,,,,,,,,5,5,,,,,,,,,,,DEC 14,2022,38,18-20,,,SI,,1789,1807,,10.1080/10447318.2022.2066246,http://dx.doi.org/10.1080/10447318.2022.2066246,,MAY 2022,,,,,,,,,,2025-05-29,WOS:000804599800001,View Full Record in Web of Science
J,"Dandolo, D; Masiero, C; Carletti, M; Pezze, DD; Susto, GA",,,,"Dandolo, David; Masiero, Chiara; Carletti, Mattia; Pezze, Davide Dalle; Susto, Gian Antonio",,,AcME-Accelerated model-agnostic explanations: Fast whitening of the machine-learning black box,EXPERT SYSTEMS WITH APPLICATIONS,,,,Article,,,,,,,,"In the context of human-in-the-loop Machine Learning applications, like Decision Support Systems, inter-pretability approaches should provide actionable insights without making the users wait. In this paper, we propose Accelerated Model-agnostic Explanations (AcME), an interpretability approach that quickly provides feature importance scores both at the global and the local level. AcME can be applied a posteriori to each regression or classification model based on tabular data. Not only AcME computes feature ranking, but it also provides a what-if analysis tool to assess how changes in features values would affect model predictions. We evaluated the proposed approach on synthetic and real-world datasets, also in comparison with SHapley Additive exPlanations (SHAP), the approach we drew inspiration from, which is currently one of the state-of-the-art model-agnostic interpretability approaches. We achieved comparable results in terms of quality of produced explanations while reducing dramatically the computational time and providing consistent visualization for global and local interpretations. To foster research in this field, and for the sake of reproducibility, we also provide a repository with the code used for the experiments.","[Dandolo, David; Masiero, Chiara] Statwolf Data Sci, Padua, Italy; [Carletti, Mattia; Pezze, Davide Dalle; Susto, Gian Antonio] Univ Padua, Padua, Italy",,"Susto, GA (corresponding author), Univ Padua, Padua, Italy.",david.dandolo@statwolf.com; chiara.masiero@statwolf.com; mattia.carletti@unipd.it; davide.dallepezze@phd.unipd.it; gianantonio.susto@unipd.it,,,,,,,,15,15,,,,,,,,,,,MAR 15,2023,214,,,,,,,,119115,10.1016/j.eswa.2022.119115,http://dx.doi.org/10.1016/j.eswa.2022.119115,,NOV 2022,,,,,,,,,,2025-05-29,WOS:000890677400006,View Full Record in Web of Science
J,"Mualla, Y; Tchappi, I; Kampik, T; Najjar, A; Calvaresi, D; Abbas-Turki, A; Galland, S; Nicolle, C",,,,"Mualla, Yazan; Tchappi, Igor; Kampik, Timotheus; Najjar, Amro; Calvaresi, Davide; Abbas-Turki, Abdeljalil; Galland, Stephane; Nicolle, Christophe",,,The quest of parsimonious XAI: A human-agent architecture for explanation formulation,ARTIFICIAL INTELLIGENCE,,,,Article,,,,,,,,"With the widespread use of Artificial Intelligence (AI), understanding the behavior of intelligent agents and robots is crucial to guarantee successful human-agent collaboration since it is not straightforward for humans to understand an agent's state of mind. Recent empirical studies have confirmed that explaining a system's behavior to human users fosters the latter's acceptance of the system. However, providing overwhelming or unnecessary information may also confuse the users and cause failure. For these reasons, parsimony has been outlined as one of the key features allowing successful human-agent interaction with parsimonious explanation defined as the simplest explanation (i.e. least complex) that describes the situation adequately (i.e. descriptive adequacy). While parsimony is receiving growing attention in the literature, most of the works are carried out on the conceptual front. This paper proposes a mechanism for parsimonious eXplainable AI (XAI). In particular, it introduces the process of explanation formulation and proposes HAExA, a human-agent explainability architecture allowing to make it operational for remote robots. To provide parsimonious explanations, HAExA relies on both contrastive explanations and explanation filtering. To evaluate the proposed architecture, several research hypotheses are investigated in an empirical user study that relies on well-established XAI metrics to estimate how trustworthy and satisfactory the explanations provided by HAExA are. The results are analyzed using parametric and non-parametric statistical testing. (C) 2021 Elsevier B.V. All rights reserved.","[Mualla, Yazan; Tchappi, Igor; Abbas-Turki, Abdeljalil; Galland, Stephane] Univ Bourgogne Franche Comte, CIAD UMR 7533, UTBM, F-90010 Belfort, France; [Tchappi, Igor] Orange Lab, 6 Ave Albert Durand, F-31700 Blagnac, France; [Tchappi, Igor] Univ Ngaoundere, Fac Sci, Ngaoundere 454, Cameroon; [Kampik, Timotheus] Umea Univ, Dept Comp Sci, S-90187 Umea, Sweden; [Najjar, Amro] Univ Luxembourg, AIRobolab ICR, Comp Sci & Communicat, L-4365 Luxembourg, Luxembourg; [Calvaresi, Davide] Univ Appl Sci & Arts Western Switzerland, Sierre, Switzerland; [Nicolle, Christophe] Univ Bourgogne Franche Comte, CIAD UMR 7533, F-21000 Dijon, France",,"Mualla, Y (corresponding author), Univ Bourgogne Franche Comte, CIAD UMR 7533, UTBM, F-90010 Belfort, France.",yazan.mualla@utbm.fr,,,,,,,,19,21,,,,,,,,,,,JAN,2022,302,,,,,,,,103573,10.1016/j.artint.2021.103573,http://dx.doi.org/10.1016/j.artint.2021.103573,,SEP 2021,,,,,,,,,,2025-05-29,WOS:000701878300002,View Full Record in Web of Science
J,"Lash, MT",,,,"Lash, Michael T.",,,HEX: Human-in-the-loop explainability via deep reinforcement learning,DECISION SUPPORT SYSTEMS,,,,Article,,,,,,,,"The use of machine learning (ML) models in decision-making contexts, particularly those used in high-stakes decision-making, are fraught with issue and peril since a person - not a machine - must ultimately be held accountable for the consequences of decisions made using such systems. Machine learning explainability (MLX) promises to provide decision-makers with prediction-specific rationale, assuring them that the model-elicited predictions are made for the right reasons and are thus reliable. Few works explicitly consider this key human-in the-loop (HITL) component, however. In this work we propose HEX, a human-in-the-loop deep reinforcement learning approach to MLX. HEX incorporates 0-distrust projection to synthesize decider-specific explainers that produce explanations strictly in terms of a decider's preferred explanatory features using any classification model. Our formulation explicitly considers the decision boundary of the ML model in question using proposed explanatory point mode of explanation, thus ensuring explanations are specific to the ML model in question. We empirically evaluate HEX against other competing methods, finding that HEX is competitive with the state-of-the-art and outperforms other methods in human-in-the-loop scenarios. We conduct a randomized, controlled laboratory experiment utilizing actual explanations elicited from both HEX and competing methods. We causally establish that our method increases decider's trust and tendency to rely on trusted features.","[Lash, Michael T.] Univ Kansas, Sch Business, Analyt Informat & Operat Area, 1654 Naismith Dr, Lawrence, KS 66045 USA",,"Lash, MT (corresponding author), Univ Kansas, Sch Business, Analyt Informat & Operat Area, 1654 Naismith Dr, Lawrence, KS 66045 USA.",michael.lash@ku.edu,,,,,,,,0,0,,,,,,,,,,,DEC,2024,187,,,,,,,,114304,10.1016/j.dss.2024.114304,http://dx.doi.org/10.1016/j.dss.2024.114304,,OCT 2024,,,,,,,,,,2025-05-29,WOS:001342927900001,View Full Record in Web of Science
J,"Weng, LX; Liu, S; Zhu, H; Sun, JS; Kam-Kwai, W; Han, DM; Zhu, MF; Chen, W",,,,"Weng, Luoxuan; Liu, Shi; Zhu, Hang; Sun, Jiashun; Kam-Kwai, Wong; Han, Dongming; Zhu, Minfeng; Chen, Wei",,,Towards an understanding and explanation for mixed-initiative artificial scientific text detection,INFORMATION VISUALIZATION,,,,Article,,,,,,,,"Large language models (LLMs) have gained popularity in various fields for their exceptional capability of generating human-like text. Their potential misuse has raised social concerns about plagiarism in academic contexts. However, effective artificial scientific text detection is a non-trivial task due to several challenges, including (1) the lack of a clear understanding of the differences between machine-generated and human-written scientific text, (2) the poor generalization performance of existing methods caused by out-of-distribution issues, and (3) the limited support for human-machine collaboration with sufficient interpretability during the detection process. In this paper, we first identify the critical distinctions between machine-generated and human-written scientific text through a quantitative experiment. Then, we propose a mixed-initiative workflow that combines human experts' prior knowledge with machine intelligence, along with a visual analytics system to facilitate efficient and trustworthy scientific text detection. Finally, we demonstrate the effectiveness of our approach through two case studies and a controlled user study. We also provide design implications for interactive artificial text detection tools in high-stakes decision-making scenarios.","[Weng, Luoxuan; Liu, Shi; Zhu, Hang; Sun, Jiashun; Han, Dongming; Zhu, Minfeng; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China; [Kam-Kwai, Wong] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; [Zhu, Minfeng] Zhejiang Univ, 866 Yuhangtang Rd, Hangzhou 310058, Zhejiang, Peoples R China; [Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, 866 Yuhangtang Rd, Hangzhou 310058, Zhejiang, Peoples R China",,"Zhu, MF (corresponding author), Zhejiang Univ, 866 Yuhangtang Rd, Hangzhou 310058, Zhejiang, Peoples R China.;Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, 866 Yuhangtang Rd, Hangzhou 310058, Zhejiang, Peoples R China.",minfeng_zhu@zju.edu.cn; chenvis@zju.edu.cn,,,,,,,,1,1,,,,,,,,,,,JUL,2024,23,3,,,,,,,,10.1177/14738716241240156,http://dx.doi.org/10.1177/14738716241240156,,APR 2024,,,,,,,,,,2025-05-29,WOS:001198947700001,View Full Record in Web of Science
J,"Kotsiopoulos, T; Papakostas, G; Vafeiadis, T; Dimitriadis, V; Nizamis, A; Bolzoni, A; Bellinati, D; Ioannidis, D; Votis, K; Tzovaras, D; Sarigiannidis, P",,,,"Kotsiopoulos, Thanasis; Papakostas, Gerasimos; Vafeiadis, Thanasis; Dimitriadis, Vasileios; Nizamis, Alexandros; Bolzoni, Andrea; Bellinati, Davide; Ioannidis, Dimosthenis; Votis, Konstantinos; Tzovaras, Dimitrios; Sarigiannidis, Panagiotis",,,"Revolutionizing defect recognition in hard metal industry through AI explainability, human-in-the-loop approaches and cognitive mechanisms",EXPERT SYSTEMS WITH APPLICATIONS,,,,Article,,,,,,,,"Defect detection is one of the main areas that Industry 4.0 concepts like automation, IoT, digitization and AI aimed to provide solutions. In this work, a platform that extends the aforementioned concepts with ones coming from Industry 5.0 like reconciliation and collaboration between humans and machines is introduced. The proposed platform provides defect detection and localization services for hard metal industry by extending current AI solutions with exponentially growing technologies such as interpretable and explainable AI (XAI), human-in-the-loop (HITL) approaches and cognitive retraining mechanisms. In particular, the platform, that is built on a micro-service architecture to enable its software sustainability, is powered by machine and deep learning models for defect detection and localization. These models are able to recognize the defects, locate them with high precision and present them to end users so to maximize resiliency in quality inspection processes. Alongside the state-of-the-art AI algorithms that are utilized by the platform, the human in the loop mechanisms and interfaces that enable human experts to inject their knowledge for AI models training are considered as key innovative aspects of this work. To enhance further the human and AI collaboration, XAI mechanisms are included in the platform,to enable the experts to gain useful insights regarding the operation of the AI models in order to be able to provide further feedback that can trigger on-the-fly platform's cognition mechanisms to improve models' accuracy and performance.","[Kotsiopoulos, Thanasis; Papakostas, Gerasimos; Vafeiadis, Thanasis; Dimitriadis, Vasileios; Nizamis, Alexandros; Ioannidis, Dimosthenis; Votis, Konstantinos; Tzovaras, Dimitrios] Ctr Res & Technol Hellas, Informat Technol Inst, Thessaloniki 57001, Greece; [Kotsiopoulos, Thanasis; Sarigiannidis, Panagiotis] Univ Western Macedonia, Dept Elect & Comp Engn, Karamanli & Ligeris St, Kozani 50100, Greece; [Bolzoni, Andrea; Bellinati, Davide] Bonfiglioli Slovakia sro, Povazska Bystrica 01701, Slovakia",,"Kotsiopoulos, T (corresponding author), Ctr Res & Technol Hellas, Informat Technol Inst, Thessaloniki 57001, Greece.;Kotsiopoulos, T (corresponding author), Univ Western Macedonia, Dept Elect & Comp Engn, Karamanli & Ligeris St, Kozani 50100, Greece.",kotsiopoulos@iti.gr; gpapakos@iti.gr; thanvaf@iti.gr; dimvasdim@iti.gr; alnizami@iti.gr; andrea.bolzoni@bonfiglioli.com; davide.bellinati@bonfiglioli.com; djoannid@iti.gr; kvotis@iti.gr; dimitrios.tzovaras@iti.gr; p.sarigiannidis@uowm.gr,,,,,,,,6,6,,,,,,,,,,,DEC 1,2024,255,,D,,,,,,124839,10.1016/j.eswa.2024.124839,http://dx.doi.org/10.1016/j.eswa.2024.124839,,JUL 2024,,,,,,,,,,2025-05-29,WOS:001284293500001,View Full Record in Web of Science
J,"Reis, MI; Gonçalves, JNC; Cortez, P; Carvalho, MS; Fernandes, JM",,,,"Reis, Marcelo I.; Goncalves, Joao N. C.; Cortez, Paulo; Carvalho, M. Sameiro; Fernandes, Joao M.",,,A context-aware decision support system for selecting explainable artificial intelligence methods in business organizations,COMPUTERS IN INDUSTRY,,,,Article,,,,,,,,"Explainable Artificial Intelligence (XAI) methods are valuable tools for promoting understanding, trust, efficient use of Artificial Intelligence (AI) systems in business organizations. However, the question of how organizations should select suitable XAI methods fora given task and business context remains a challenge, particularly when the number of methods available in the literature continues to increase. Here, we propose a context-aware decision support system (DSS) to select, from a given set of XAI methods, those with higher suitability to the needs of stakeholders operating in a given AI-based business problem. By including the human in-the-loop, our DSS comprises an application-grounded analytical metric designed to facilitate the selection XAI methods that align with the business stakeholders' desiderata and promote a deeper understanding of results generated by a given machine learning model. The proposed system was tested on areal supply chain demand problem, using real data and real users. The results provide evidence on the usefulness of our metric in selecting XAI methods based on the feedback and analytical maturity of stakeholders from the deployment context. We believe that our DSS is sufficiently flexible and understandable to be applied in a variety business contexts, with stakeholders with varying degrees of AI literacy.","[Reis, Marcelo I.; Cortez, Paulo] Univ Minho, Dept Informat Syst, ALGORITMI LASI, Guimaraes, Portugal; [Reis, Marcelo I.] Univ Catolica Salvador, Salvador, Brazil; [Goncalves, Joao N. C.] Univ Catolica Portuguesa, CEGE Res Ctr Management & Econ, Porto, Portugal; [Carvalho, M. Sameiro] Univ Minho, ALGORITMI LASI, Dept Prod & Syst, Braga, Portugal; [Fernandes, Joao M.] Univ Minho, ALGORITMI, Braga, Portugal; [Fernandes, Joao M.] Univ Minho, CCG ZGDV Inst, Dept Informat, Braga, Portugal",,"Reis, MI (corresponding author), Univ Catolica Salvador, Salvador, Brazil.",mindior@gmail.com; jngoncalves@ucp.pt; pcortez@dsi.uminho.pt; sameiro@dps.uminho.pt; jmf@di.uminho.pt,,,,,,,,0,0,,,,,,,,,,,FEB,2025,165,,,,,,,,104233,10.1016/j.compind.2024.104233,http://dx.doi.org/10.1016/j.compind.2024.104233,,DEC 2024,,,,,,,,,,2025-05-29,WOS:001401385700001,View Full Record in Web of Science
J,"Vouros, GA",,,,"Vouros, George A.",,,Explainable Deep Reinforcement Learning: State of the Art and Challenges,ACM COMPUTING SURVEYS,,,,Article,,,,,,,,"Interpretability, explainability, and transparency are key issues to introducing artificial intelligence methods in many critical domains. This is important due to ethical concerns and trust issues strongly connected to reliability, robustness, auditability, and fairness, and has important consequences toward keeping the human in the loop in high levels of automation, especially in critical cases for decision making, where both (human and the machine) play important roles. Although the research community has given much attention to explainability of closed (or black) prediction boxes, there are tremendous needs for explainability of closed-box methods that support agents to act autonomously in the real world. Reinforcement learning methods, and especially their deep versions, are such closed-box methods. In this article, we aim to provide a review of state-of-the-art methods for explainable deep reinforcement learning methods, taking also into account the needs of human operators-that is, of those who make the actual and critical decisions in solving real-world problems. We provide a formal specification of the deep reinforcement learning explainability problems, and we identify the necessary components of a general explainable reinforcement learning framework. Based on these, we provide a comprehensive review of state-of-the-art methods, categorizing them into classes according to the paradigm they follow, the interpretable models they use, and the surface representation of explanations provided. The article concludes by identifying open questions and important challenges.","[Vouros, George A.] Univ Piraeus, Gr Lambraki 126, Piraeus, Greece",,"Vouros, GA (corresponding author), Univ Piraeus, Gr Lambraki 126, Piraeus, Greece.",georgev@unipi.gr,,,,,,,,55,56,,,,,,,,,,,JUN,2023,55,5,,,,,,,92,10.1145/3527448,http://dx.doi.org/10.1145/3527448,,,,,,,,,,,,2025-05-29,WOS:000892356400006,View Full Record in Web of Science
J,"Neupane, S; Ables, J; Anderson, W; Mittal, S; Rahimi, S; Banicescu, I; Seale, M",,,,"Neupane, Subash; Ables, Jesse; Anderson, William; Mittal, Sudip; Rahimi, Shahram; Banicescu, Ioana; Seale, Maria",,,"Explainable Intrusion Detection Systems (X-IDS): A Survey of Current Methods, Challenges, and Opportunities",IEEE ACCESS,,,,Article,,,,,,,,"The application of Artificial Intelligence (AI) and Machine Learning (ML) to cybersecurity challenges has gained traction in industry and academia, partially as a result of widespread malware attacks on critical systems such as cloud infrastructures and government institutions. Intrusion Detection Systems (IDS), using some forms of AI, have received widespread adoption due to their ability to handle vast amounts of data with a high prediction accuracy. These systems are hosted in the organizational Cyber Security Operation Center (CSoC) as a defense tool to monitor and detect malicious network flow that would otherwise impact the Confidentiality, Integrity, and Availability (CIA). CSoC analysts rely on these systems to make decisions about the detected threats. However, IDSs designed using Deep Learning (DL) techniques are often treated as black box models and do not provide a justification for their predictions. This creates a barrier for CSoC analysts, as they are unable to improve their decisions based on the model's predictions. One solution to this problem is to design explainable IDS (X-IDS). This survey reviews the state-of-the-art in explainable AI (XAI) for IDS, its current challenges, and discusses how these challenges span to the design of an X-IDS. In particular, we discuss black box and white box approaches comprehensively. We also present the tradeoff between these approaches in terms of their performance and ability to produce explanations. Furthermore, we propose a generic architecture that considers human-in-the-loop which can be used as a guideline when designing an X-IDS. Research recommendations are given from three critical viewpoints: the need to define explainability for IDS, the need to create explanations tailored to various stakeholders, and the need to design metrics to evaluate explanations.","[Neupane, Subash; Ables, Jesse; Anderson, William; Mittal, Sudip; Rahimi, Shahram; Banicescu, Ioana] Mississippi State Univ, Dept Comp Sci & Engn, Mississippi State, MS 39762 USA; [Seale, Maria] US Army, Engineer Res & Dev Ctr, Vicksburg, MS 39180 USA",,"Neupane, S (corresponding author), Mississippi State Univ, Dept Comp Sci & Engn, Mississippi State, MS 39762 USA.",sn922@msstate.edu,,,,,,,,58,59,,,,,,,,,,,,2022,10,,,,,,112392,112415,,10.1109/ACCESS.2022.3216617,http://dx.doi.org/10.1109/ACCESS.2022.3216617,,,,,,,,,,,,2025-05-29,WOS:000878113700001,View Full Record in Web of Science
J,"Sloane, M; Wüllhorst, E",,,,"Sloane, Mona; Wullhorst, Elena",,,"A systematic review of regulatory strategies and transparency mandates in AI regulation in Europe, the United States, and Canada",DATA & POLICY,,,,Article,,,,,,,,"In this paper, we provide a systematic review of existing artificial intelligence (AI) regulations in Europe, the United States, and Canada. We build on the qualitative analysis of 129 AI regulations (enacted and not enacted) to identify patterns in regulatory strategies and in AI transparency requirements. Based on the analysis of this sample, we suggest that there are three main regulatory strategies for AI: AI-focused overhauls of existing regulation, the introduction of novel AI regulation, and the omnibus approach. We argue that although these types emerge as distinct strategies, their boundaries are porous as the AI regulation landscape is rapidly evolving. We find that across our sample, AI transparency is effectively treated as a central mechanism for meaningful mitigation of potential AI harms. We therefore focus on AI transparency mandates in our analysis and identify six AI transparency patterns: human in the loop, assessments, audits, disclosures, inventories, and red teaming. We contend that this qualitative analysis of AI regulations and AI transparency patterns provides a much needed bridge between the policy discourse on AI, which is all too often bound up in very detailed legal discussions and applied sociotechnical research on AI fairness, accountability, and transparency.","[Sloane, Mona] Univ Virginia, Sch Data Sci, Charlottesville, VA 22904 USA; [Sloane, Mona] Univ Virginia, Dept Media Studies, Charlottesville, VA 22904 USA; [Wullhorst, Elena] Kings Coll London, London, England",,"Sloane, M (corresponding author), Univ Virginia, Sch Data Sci, Charlottesville, VA 22904 USA.;Sloane, M (corresponding author), Univ Virginia, Dept Media Studies, Charlottesville, VA 22904 USA.",mona.sloane@virginia.edu,,,,,,,,1,1,,,,,,,,,,,,2025,7,,,,,,,,,10.1017/dap.2024.54,http://dx.doi.org/10.1017/dap.2024.54,,,,,,,,,,,,2025-05-29,WOS:001415584500004,View Full Record in Web of Science
J,"Wood, NG",,,,"Wood, Nathan Gabriel",,,Explainable AI in the military domain,ETHICS AND INFORMATION TECHNOLOGY,,,,Article,,,,,,,,"Artificial intelligence (AI) has become nearly ubiquitous in modern society, from components of mobile applications to medical support systems, and everything in between. In societally impactful systems imbued with AI, there has been increasing concern related to opaque AI, that is, artificial intelligence where it is unclear how or why certain decisions are reached. This has led to a recent boom in research on explainable AI (XAI), or approaches to making AI more explainable and understandable to human users. In the military domain, numerous bodies have argued that autonomous and AI-enabled weapon systems ought not incorporate unexplainable AI, with the International Committee of the Red Cross and the United States Department of Defense both explicitly including explainability as a relevant factor in the development and use of such systems. In this article, I present a cautiously critical assessment of this view, arguing that explainability will be irrelevant for many current and near-future autonomous systems in the military (which do not incorporate any AI), that it will be trivially incorporated into most military systems which do possess AI (as these generally possess simpler AI systems), and that for those systems with genuinely opaque AI, explainability will prove to be of more limited value than one might imagine. In particular, I argue that explainability, while indeed a virtue in design, is a virtue aimed primarily at designers and troubleshooters of AI-enabled systems, but is far less relevant for users and handlers actually deploying these systems. I further argue that human-machine teaming is a far more important element of responsibly using AI for military purposes, adding that explainability may undermine efforts to improve human-machine teamings by creating a prima facie sense that the AI, due to its explainability, may be utilized with little (or less) potential for mistakes. I conclude by clarifying that the arguments are not against XAI in the military, but are instead intended as a caution against over-inflating the value of XAI in this domain, or ignoring the limitations and potential pitfalls of this approach.","[Wood, Nathan Gabriel] Czech Acad Sci, Inst Philosophy, Jilska 1, Prague, Czech Republic",,"Wood, NG (corresponding author), Czech Acad Sci, Inst Philosophy, Jilska 1, Prague, Czech Republic.",wood@flu.cas.cz,,,,,,,,1,1,,,,,,,,,,,JUN,2024,26,2,,,,,,,29,10.1007/s10676-024-09762-w,http://dx.doi.org/10.1007/s10676-024-09762-w,,,,,,,,,,,,2025-05-29,WOS:001203946100001,View Full Record in Web of Science
J,"Aloisi, C",,,,"Aloisi, Cesare",,,The future of standardised assessment: Validity and trust in algorithms for assessment and scoring,EUROPEAN JOURNAL OF EDUCATION,,,,Article,,,,,,,,"This article considers the challenges of using artificial intelligence (AI) and machine learning (ML) to assist high-stakes standardised assessment. It focuses on the detrimental effect that even state-of-the-art AI and ML systems could have on the validity of national exams of secondary education, and how lower validity would negatively affect trust in the system. To reach this conclusion, three unresolved issues in AI (unreliability, low explainability and bias) are addressed, to show how each of them would compromise the interpretations and uses of exam results (i.e., exam validity). Furthermore, the article relates validity to trust, and specifically to the ABI+ model of trust. Evidence gathered as part of exam validation supports each of the four trust-enabling components of the ABI+ model (ability, benevolence, integrity and predictability). It is argued, therefore, that the three AI barriers to exam validity limit the extent to which an AI-assisted exam system could be trusted. The article suggests that addressing the issues of AI unreliability, low explainability and bias should be sufficient to put AI-assisted exams on par with traditional ones, but might not go as far as fully reassure the public. To achieve this, it is argued that changes to the quality assurance mechanisms of the exam system will be required. This may involve, for example, integrating principled AI frameworks in assessment policy and regulation.","[Aloisi, Cesare] AQA, Manchester, England; [Aloisi, Cesare] AQA, Devas St, Manchester M15 6EX, England",,"Aloisi, C (corresponding author), AQA, Devas St, Manchester M15 6EX, England.",caloisi@aqa.org.uk,,,,,,,,13,14,,,,,,,,,,,MAR,2023,58,1,,,SI,,98,110,,10.1111/ejed.12542,http://dx.doi.org/10.1111/ejed.12542,,JAN 2023,,,,,,,,,,2025-05-29,WOS:000914686000001,View Full Record in Web of Science
J,"Bui, LV",,,,"Bui, Luong Vu",,,"Advancing patent law with generative AI: Human-in-the-loop systems for AI-assisted drafting, prior art search, and multimodal IP protection",WORLD PATENT INFORMATION,,,,Article,,,,,,,,"Generative AI and Large Language Models (LLMs) are transforming patent law by automating complex tasks that traditionally demand significant legal and technical expertise. This paper examines AI-assisted systems designed to enhance patent drafting, prior art searches, and multimodal intellectual property (IP) protection. Human-inthe-Loop (HITL) frameworks play a crucial role in ensuring that AI-generated outputs remain accurate, legally compliant, and ethically sound, augmenting human expertise rather than replacing it. We evaluate the applicability of LLMs such as GPT-4, Claude, and Gemini for patent-related tasks, highlighting their advantages and limitations. The study also explores critical challenges, including GDPR compliance, issues of interpretability, and the impact of outdated training data. Furthermore, strategies to mitigate AI-generated hallucinations and optimize prompt engineering for patent-specific applications are discussed. A comparative analysis of industry-leading platforms like Google Patents, PatSnap, and LexisNexis illustrates how AI tools are being integrated into patent workflows. The paper provides both theoretical insights and practical recommendations for integrating AI into legal systems. By addressing the technical and ethical implications of AI-generated inventions, the study underscores the importance of transparency, accountability, and robust human oversight. This research aims to guide the seamless integration of AI technologies into patent law, promoting efficiency, accuracy, and compliance in an increasingly complex innovation landscape.","[Bui, Luong Vu] UWE Bristol UK, Bristol Law Sch, Bristol BS16 1QY, England; [Bui, Luong Vu] Vietnam Natl Univ Hanoi, Int Sch, Hanoi 100000, Vietnam",,"Bui, LV (corresponding author), UWE Bristol UK, Bristol Law Sch, Bristol BS16 1QY, England.",luong2.bui@live.uwe.ac.uk,,,,,,,,3,3,,,,,,,,,,,MAR,2025,80,,,,,,,,102341,10.1016/j.wpi.2025.102341,http://dx.doi.org/10.1016/j.wpi.2025.102341,,FEB 2025,,,,,,,,,,2025-05-29,WOS:001426207300001,View Full Record in Web of Science
J,"Finkelstein, J; Gabriel, A; Schmer, S; Truong, TT; Dunn, A",,,,"Finkelstein, Joseph; Gabriel, Aileen; Schmer, Susanna; Truong, Tuyet-Trinh; Dunn, Andrew",,,Identifying Facilitators and Barriers to Implementation of AI-Assisted Clinical Decision Support in an Electronic Health Record System,JOURNAL OF MEDICAL SYSTEMS,,,,Article,,,,,,,,"Recent advancements in computing have led to the development of artificial intelligence (AI) enabled healthcare technologies. AI-assisted clinical decision support (CDS) integrated into electronic health records (EHR) was demonstrated to have a significant potential to improve clinical care. With the rapid proliferation of AI-assisted CDS, came the realization that a lack of careful consideration of socio-technical issues surrounding the implementation and maintenance of these tools can result in unanticipated consequences, missed opportunities, and suboptimal uptake of these potentially useful technologies. The 48-h Discharge Prediction Tool (48DPT) is a new AI-assisted EHR CDS to facilitate discharge planning. This study aimed to methodologically assess the implementation of 48DPT and identify the barriers and facilitators of adoption and maintenance using the validated implementation science frameworks. The major dimensions of RE-AIM (Reach, Effectiveness, Adoption, Implementation, Maintenance) and the constructs of the Consolidated Framework for Implementation Research (CFIR) frameworks have been used to analyze interviews of 24 key stakeholders using 48DPT. The systematic assessment of the 48DPT implementation allowed us to describe facilitators and barriers to implementation such as lack of awareness, lack of accuracy and trust, limited accessibility, and transparency. Based on our evaluation, the factors that are crucial for the successful implementation of AI-assisted EHR CDS were identified. Future implementation efforts of AI-assisted EHR CDS should engage the key clinical stakeholders in the AI tool development from the very inception of the project, support transparency and explainability of the AI models, provide ongoing education and onboarding of the clinical users, and obtain continuous input from clinical staff on the CDS performance.","[Finkelstein, Joseph; Gabriel, Aileen] Univ Utah, Dept Biomed Informat, 421 Wakara Way,Rm 2028, Salt Lake City, UT 84108 USA; [Schmer, Susanna] Mt Sinai Hlth Syst, Dept Case Management, New York, NY USA; [Truong, Tuyet-Trinh; Dunn, Andrew] Icahn Sch Med Mt Sinai, Div Hosp Med, New York, NY USA",,"Finkelstein, J (corresponding author), Univ Utah, Dept Biomed Informat, 421 Wakara Way,Rm 2028, Salt Lake City, UT 84108 USA.",Joseph.Finkelstein@utah.edu,,,,,,,,5,5,,,,,,,,,,,SEP 18,2024,48,1,,,,,,,89,10.1007/s10916-024-02104-9,http://dx.doi.org/10.1007/s10916-024-02104-9,,,,,,,,,,,,2025-05-29,WOS:001315136400001,View Full Record in Web of Science
J,"Vijayvargiya, A; Singh, P; Kumar, R; Dey, N",,,,"Vijayvargiya, Ankit; Singh, Puneet; Kumar, Rajesh; Dey, Nilanjan",,,Hardware Implementation for Lower Limb Surface EMG Measurement and Analysis Using Explainable AI for Activity Recognition,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,,,Article,,,,,,,,"Electromyography (EMG) signals are gaining popularity for several biomedical applications, including pattern recognition, disease detection, human-machine interfaces, medical image processing, and robotic limb or exoskeleton fabrication. In this study, a two-channel data acquisition system for measuring EMG signals is proposed for human lower limb activity recognition. Five leg activities have been accomplished to measure EMG signals from two lower limb muscles to validate the developed hardware. Five subjects (three males and two females) were chosen to acquire EMG signals during these activities. The raw EMG signal was first denoised using a hybrid of Wavelet Decomposition with Ensemble Empirical Mode Decomposition (WD-EEMD) approach to classify the recorded EMG dataset. Then, eight time-domain (TD) features were extracted using the overlapping windowing technique. An investigation into the comparative effectiveness of several classifiers is presented, although it was hard to distinguish how the classifiers predicted the activities. Having a trustworthy explanation for the outcomes of these classifiers would be quite beneficial overall. An approach known as explainable artificial intelligence (XAI) was introduced to produce trustworthy predictive modeling results and applied the XAI technique known as local interpretable model-agnostic explanations (LIME) to a straightforward human interpretation. LIME investigates how extracted features are anticipated and which features are most responsible for each action. The accuracy of the extra tree classifier gives the highest accuracy of the other studied algorithms for identifying different human lower limb activities from sEMG signals.","[Vijayvargiya, Ankit; Kumar, Rajesh] Malaviya Natl Inst Technol, Dept Elect Engn, Jaipur 302017, Rajasthan, India; [Vijayvargiya, Ankit] Swami Keshvanand Inst Technol Management & Gramot, Dept Elect Engn, Jaipur 302017, Rajasthan, India; [Singh, Puneet] Malaviya Natl Inst Technol, Dept Elect & Commun Engn, Jaipur 302017, Rajasthan, India; [Dey, Nilanjan] JIS Univ, Dept Comp Sci & Engn, Kolkata 700109, India",,"Vijayvargiya, A (corresponding author), Malaviya Natl Inst Technol, Dept Elect Engn, Jaipur 302017, Rajasthan, India.;Vijayvargiya, A (corresponding author), Swami Keshvanand Inst Technol Management & Gramot, Dept Elect Engn, Jaipur 302017, Rajasthan, India.",ankitvijayvargiya29@gmail.com; 2019uec1355@mnit.ac.in; rkumar.ee@mnit.ac.in; neelanjan.dey@gmail.com,,,,,,,,36,37,,,,,,,,,,,,2022,71,,,,,,,,2004909,10.1109/TIM.2022.3198443,http://dx.doi.org/10.1109/TIM.2022.3198443,,,,,,,,,,,,2025-05-29,WOS:000848255000004,View Full Record in Web of Science
J,"Saranti, A; Hudec, M; Mináriková, E; Takác, Z; Grossschedl, U; Koch, C; Pfeifer, B; Angerschmid, A; Holzinger, A",,,,"Saranti, Anna; Hudec, Miroslav; Minarikova, Erika; Takac, Zdenko; Grossschedl, Udo; Koch, Christoph; Pfeifer, Bastian; Angerschmid, Alessa; Holzinger, Andreas",,,Actionable Explainable AI (AxAI): A Practical Example with Aggregation Functions for Adaptive Classification and Textual Explanations for Interpretable Machine Learning,MACHINE LEARNING AND KNOWLEDGE EXTRACTION,,,,Article,,,,,,,,"In many domains of our daily life (e.g., agriculture, forestry, health, etc.), both laymen and experts need to classify entities into two binary classes (yes/no, good/bad, sufficient/insufficient, benign/malign, etc.). For many entities, this decision is difficult and we need another class called maybe, which contains a corresponding quantifiable tendency toward one of these two opposites. Human domain experts are often able to mark any entity, place it in a different class and adjust the position of the slope in the class. Moreover, they can often explain the classification space linguistically-depending on their individual domain experience and previous knowledge. We consider this human-in-the-loop extremely important and call our approach actionable explainable AI. Consequently, the parameters of the functions are adapted to these requirements and the solution is explained to the domain experts accordingly. Specifically, this paper contains three novelties going beyond the state-of-the-art: (1) A novel method for detecting the appropriate parameter range for the averaging function to treat the slope in the maybe class, along with a proposal for a better generalisation than the existing solution. (2) the insight that for a given problem, the family of t-norms and t-conorms covering the whole range of nilpotency is suitable because we need a clear no or yes not only for the borderline cases. Consequently, we adopted the Schweizer-Sklar family of t-norms or t-conorms in ordinal sums. (3) A new fuzzy quasi-dissimilarity function for classification into three classes: Main difference, irrelevant difference and partial difference. We conducted all of our experiments with real-world datasets.","[Saranti, Anna; Angerschmid, Alessa; Holzinger, Andreas] Univ Nat Resources & Life Sci, Human Ctr AI Lab, Inst Forest Engn, Dept Forest & Soil Sci, A-1190 Vienna, Austria; [Saranti, Anna; Hudec, Miroslav; Pfeifer, Bastian; Angerschmid, Alessa; Holzinger, Andreas] Med Univ Graz, Inst Med Informat, A-8036 Graz, Austria; [Hudec, Miroslav; Minarikova, Erika] Univ Econ Bratislava, Fac Econ Informat, Bratislava 852355, Slovakia; [Takac, Zdenko] Slovak Univ Technol Bratislava, Fac Chem & Food Technol, Bratislava 812431, Slovakia; [Grossschedl, Udo; Koch, Christoph; Holzinger, Andreas] Graz Univ Technol, Inst Interact Syst & Data Sci, A-8010 Graz, Austria; [Holzinger, Andreas] Univ Alberta, Alberta Machine Intelligence Inst, xAI Lab, Edmonton, AB T5J 3B1, Canada",,"Holzinger, A (corresponding author), Univ Nat Resources & Life Sci, Human Ctr AI Lab, Inst Forest Engn, Dept Forest & Soil Sci, A-1190 Vienna, Austria.;Holzinger, A (corresponding author), Med Univ Graz, Inst Med Informat, A-8036 Graz, Austria.;Holzinger, A (corresponding author), Graz Univ Technol, Inst Interact Syst & Data Sci, A-8010 Graz, Austria.;Holzinger, A (corresponding author), Univ Alberta, Alberta Machine Intelligence Inst, xAI Lab, Edmonton, AB T5J 3B1, Canada.",andreas.holzinger@human-centered.ai,,,,,,,,17,17,,,,,,,,,,,DEC,2022,4,4,,,,,924,953,,10.3390/make4040047,http://dx.doi.org/10.3390/make4040047,,,,,,,,,,,,2025-05-29,WOS:000902726900001,View Full Record in Web of Science
J,"Wang, MH; Cui, JZ; Lee, SMY; Lin, ZY; Zeng, PJ; Li, XY; Liu, HY; Liu, YX; Xu, Y; Wang, YP; Alves, JLCD; Hou, GH; Fang, JB; Yu, XR; Chong, KKL; Pan, Y",,,,"Han Wang, Mini; Cui, Jiazheng; Lee, Simon Ming-Yuen; Lin, Zhiyuan; Zeng, Peijin; Li, Xinyue; Liu, Haoyang; Liu, Yunxiao; Xu, Yang; Wang, Yapeng; Alves, Jose Lopes Camilo Da Costa; Hou, Guanghui; Fang, Junbin; Yu, Xiangrong; Chong, Kelvin Kam-Lung; Pan, Yi",,,Applied machine learning in intelligent systems: knowledge graph-enhanced ophthalmic contrastive learning with clinical profile prompts,FRONTIERS IN ARTIFICIAL INTELLIGENCE,,,,Article,,,,,,,,"Introduction The integration of artificial intelligence (AI) into ophthalmic diagnostics has the potential to significantly enhance diagnostic accuracy and interpretability, thereby supporting clinical decision-making. However, a major challenge in AI-driven medical applications is the lack of transparency, which limits clinicians' trust in automated recommendations. This study investigates the application of machine learning techniques by integrating knowledge graphs with contrastive learning and utilizing clinical profile prompts to refine the performance of the ophthalmology-specific large language model, MeEYE, which is built on the CHATGLM3-6B architecture. This approach aims to improve the model's ability to capture clinically relevant features while enhancing both the accuracy and explainability of diagnostic predictions.Methods This study employs a novel methodological framework that incorporates domain-specific knowledge through knowledge graphs and enhances feature representation using contrastive learning. The MeEYE model is fine-tuned with structured clinical knowledge, enabling it to better distinguish subtle yet significant ophthalmic features. Additionally, clinical profile prompts are incorporated to further improve contextual understanding and diagnostic precision. The proposed method is evaluated through comprehensive performance benchmarking, including quantitative assessments and clinical case studies, to ensure its efficacy in real-world ophthalmic diagnosis.Results The experimental findings demonstrate that integrating knowledge graphs and contrastive learning into the MeEYE model significantly improves both diagnostic accuracy and model interpretability. Comparative analyses against baseline models reveal that the proposed approach enhances the identification of ophthalmic conditions with higher precision and clarity. Furthermore, the model's ability to generate transparent and clinically relevant AI recommendations is substantiated through rigorous evaluation, highlighting its potential for real-world clinical implementation.Discussion The results underscore the importance of explainable AI in medical diagnostics, particularly in ophthalmology, where model transparency is critical for clinical acceptance and utility. By incorporating domain-specific knowledge with advanced machine learning techniques, the proposed approach not only enhances model performance but also ensures that AI-generated insights are interpretable and reliable for clinical decision-making. These findings suggest that integrating structured medical knowledge with machine learning frameworks can address key challenges in AI-driven diagnostics, ultimately contributing to improved patient outcomes. Future research should explore the adaptability of this approach across various medical domains to further advance AI-assisted diagnostic systems.","[Han Wang, Mini] Jinan Univ, Zhuhai Peoples Hosp, Beijing Inst Technol, Zhuhai Precis Med Ctr,Affiliated Hosp,Zhuhai Clin, Zhuhai, Peoples R China; [Han Wang, Mini; Chong, Kelvin Kam-Lung] Chinese Univ Hong Kong, Dept Ophthalmol & Visual Sci, Shatin, Hong Kong, Peoples R China; [Cui, Jiazheng] Chinese Acad Sci, Zhuhai Inst Adv Technol, Zhuhai 519000, Peoples R China; [Cui, Jiazheng] Beijing Normal Univ Hong Kong Baptist Univ United, Zhuhai, Peoples R China; [Lee, Simon Ming-Yuen] Hong Kong Polytech Univ, Dept Food Sci & Nutr, Kowloon, Hong Kong, Peoples R China; [Lin, Zhiyuan; Zeng, Peijin] Perspect Technol Grp, Zhuhai, Peoples R China; [Zeng, Peijin; Xu, Yang] Beijing Inst Technol, Zhuhai, Peoples R China; [Li, Xinyue] Tianjin Med Univ, Tianjin, Peoples R China; [Liu, Haoyang; Liu, Yunxiao; Wang, Yapeng] Macao Polytech Univ, Fac Appl Sci, Macau, Peoples R China; [Liu, Haoyang; Liu, Yunxiao] Macau Univ Sci & Technol, Taipa, Macao, Peoples R China; [Alves, Jose Lopes Camilo Da Costa] City Univ Macau, Fac Business, Macau, Peoples R China; [Hou, Guanghui] Zhuhai Aier Eye Hosp, Zhuhai, Peoples R China; [Fang, Junbin] Jinan Univ, Coll Sci & Engn, Shenzhen, Peoples R China; [Yu, Xiangrong] Jinan Univ, Zhuhai Peoples Hosp, Zhuhai Clin Med Coll, Zhuhai, Peoples R China; [Pan, Yi] Shenzhen Inst Adv Technol, Shenzhen Key Lab Intelligent Bioinformat, Shenzhen, Peoples R China",,"Wang, MH (corresponding author), Jinan Univ, Zhuhai Peoples Hosp, Beijing Inst Technol, Zhuhai Precis Med Ctr,Affiliated Hosp,Zhuhai Clin, Zhuhai, Peoples R China.;Wang, MH; Chong, KKL (corresponding author), Chinese Univ Hong Kong, Dept Ophthalmol & Visual Sci, Shatin, Hong Kong, Peoples R China.;Hou, GH (corresponding author), Zhuhai Aier Eye Hosp, Zhuhai, Peoples R China.;Fang, JB (corresponding author), Jinan Univ, Coll Sci & Engn, Shenzhen, Peoples R China.;Yu, XR (corresponding author), Jinan Univ, Zhuhai Peoples Hosp, Zhuhai Clin Med Coll, Zhuhai, Peoples R China.;Pan, Y (corresponding author), Shenzhen Inst Adv Technol, Shenzhen Key Lab Intelligent Bioinformat, Shenzhen, Peoples R China.",d20092100037@cityu.mo; Houguanghui901@163.com; tjunbinfang@jnu.edu.cn; yxr00125040@126.com; chongkamlung@cuhk.edu.hk; yi.pan@siat.ac.cn,,,,,,,,0,0,,,,,,,,,,,MAR 12,2025,8,,,,,,,,1527010,10.3389/frai.2025.1527010,http://dx.doi.org/10.3389/frai.2025.1527010,,,,,,,,,,,,2025-05-29,WOS:001455088700001,View Full Record in Web of Science
J,"Retzlaff, CO; Das, S; Wayllace, C; Mousavi, P; Afshari, M; Yang, TP; Saranti, A; Angerschmid, A; Taylor, ME; Holzinger, A",,,,"Retzlaff, Carl Orge; Das, Srijita; Wayllace, Christabel; Mousavi, Payam; Afshari, Mohammad; Yang, Tianpei; Saranti, Anna; Angerschmid, Alessa; Taylor, Matthew E.; Holzinger, Andreas",,,"Human-in-the-Loop Reinforcement Learning: A Survey and Position on Requirements, Challenges, and Opportunities",JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH,,,,Article,,,,,,,,"Artificial intelligence (AI) and especially reinforcement learning (RL) have the potential to enable agents to learn and perform tasks autonomously with superhuman performance. However, we consider RL as fundamentally a Human -in -the -Loop (HITL) paradigm, even when an agent eventually performs its task autonomously. In cases where the reward function is challenging or impossible to define, HITL approaches are considered particularly advantageous. The application of Reinforcement Learning from Human Feedback (RLHF) in systems such as ChatGPT demonstrates the effectiveness of optimizing for user experience and integrating their feedback into the training loop. In HITL RL, human input is integrated during the agent's learning process, allowing iterative updates and fine-tuning based on human feedback, thus enhancing the agent's performance. Since the human is an essential part of this process, we argue that human -centric approaches are the key to successful RL, a fact that has not been adequately considered in the existing literature. This paper aims to inform readers about current explainability methods in HITL RL. It also shows how the application of explainable AI (xAI) and specific improvements to existing explainability approaches can enable a better human -agent interaction in HITL RL for all types of users, whether for lay people, domain experts, or machine learning specialists. Accounting for the workflow in HITL RL and based on software and machine learning methodologies, this article identifies four phases for human involvement for creating HITL RL systems: (1) Agent Development, (2) Agent Learning, (3) Agent Evaluation, and (4) Agent Deployment. We highlight human involvement, explanation requirements, new challenges, and goals for each phase. We furthermore identify low -risk, high -return opportunities for explainability research in HITL RL and present long-term research goals to advance the field. Finally, we propose a vision of human -robot collaboration that allows both parties to reach their full potential and cooperate effectively.","[Retzlaff, Carl Orge; Saranti, Anna; Angerschmid, Alessa; Holzinger, Andreas] Univ Nat Resources & Life Sci Vienna, Human Ctr AI Lab, Vienna, Austria; [Das, Srijita; Afshari, Mohammad; Yang, Tianpei; Taylor, Matthew E.] Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada; [Wayllace, Christabel] New Mexico State Univ, Dept Comp Sci, Las Cruces, NM USA; [Mousavi, Payam; Taylor, Matthew E.] Alberta Machine Intelligence Inst Amii, Edmonton, AB, Canada; AI Redefined, Montreal, PQ, Canada; [Holzinger, Andreas] Univ Alberta, Alberta Machine Intelligence Inst, xAI Lab, Edmonton, AB, Canada",,"Retzlaff, CO (corresponding author), Univ Nat Resources & Life Sci Vienna, Human Ctr AI Lab, Vienna, Austria.",CARL.RETZLAFF@HUMAN-CENTERED.AI; SRIJITA1@UALBERTA.CA; CWAYLLAC@NMSU.EDU; PAYAM.MOUSAVI@AMII.CA; MAFSHARI@UALBERTA.CA; TIANPEI.YANG@UALBERTA.CA; ANNA.SARANTI@HUMAN-CENTERED.AI; ALESSA.ANGERSCHMID@HUMAN-CENTERED.AI; MATTHEW.E.TAYLOR@UALBERTA.CA; ANDREAS.HOLZINGER@HUMAN-CENTERED.AI,,,,,,,,33,33,,,,,,,,,,,,2024,79,,,,,,359,415,,,,,,,,,,,,,,,2025-05-29,WOS:001157178000001,View Full Record in Web of Science
J,"Ling, SH; Zhang, YT; Du, N",,,,"Ling, Shihong; Zhang, Yutong; Du, Na",,,More Is Not Always Better: Impacts of AI-Generated Confidence and Explanations in Human-Automation Interaction,HUMAN FACTORS,,,,Article,,,,,,,,"Objective The study aimed to enhance transparency in autonomous systems by automatically generating and visualizing confidence and explanations and assessing their impacts on performance, trust, preference, and eye-tracking behaviors in human-automation interaction.Background System transparency is vital to maintaining appropriate levels of trust and mission success. Previous studies presented mixed results regarding the impact of displaying likelihood information and explanations, and often relied on hand-created information, limiting scalability and failing to address real-world dynamics.Method We conducted a dual-task experiment involving 42 university students who operated a simulated surveillance testbed with assistance from intelligent detectors. The study used a 2 (confidence visualization: yes vs. no) x 3 (visual explanations: none, bounding boxes, bounding boxes and keypoints) mixed design. Task performance, human trust, preference for intelligent detectors, and eye-tracking behaviors were evaluated.Results Visual explanations using bounding boxes and keypoints improved detection task performance when confidence was not displayed. Meanwhile, visual explanations enhanced trust and preference for the intelligent detector, regardless of the explanation type. Confidence visualization did not influence human trust in and preference for the intelligent detector. Moreover, both visual information slowed saccade velocities.Conclusion The study demonstrated that visual explanations could improve performance, trust, and preference in human-automation interaction without confidence visualization partially by changing the search strategies. However, excessive information might cause adverse effects.Application These findings provide guidance for the design of transparent automation, emphasizing the importance of context-appropriate and user-centered explanations to foster effective human-machine collaboration.","[Ling, Shihong; Zhang, Yutong; Du, Na] Univ Pittsburgh, Sch Comp & Informat, Dept Informat & Networked Syst, Pittsburgh, PA 15213 USA; [Du, Na] Univ Pittsburgh, Dept Informat & Networked Syst, 135 N Bellefield Ave, Pittsburgh, PA 15213 USA",,"Du, N (corresponding author), Univ Pittsburgh, Dept Informat & Networked Syst, 135 N Bellefield Ave, Pittsburgh, PA 15213 USA.",na.du@pitt.edu,,,,,,,,1,1,,,,,,,,,,,DEC,2024,66,12,,,,,2606,2620,,10.1177/00187208241234810,http://dx.doi.org/10.1177/00187208241234810,,MAR 2024,,,,,,,,,,2025-05-29,WOS:001178659300001,View Full Record in Web of Science
J,"Bocklisch, F; Bocklisch, SF; Grimm, M; Lampke, T; Joshi, S",,,,"Bocklisch, Franziska; Bocklisch, Steffen F.; Grimm, Maximilian; Lampke, Thomas; Joshi, Shrikant",,,Hybrid decision-making in atmospheric plasma spraying enables human-machine teaming,INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,,,,Article,,,,,,,,"With the development of human-cyber-physical-production systems in intelligent manufacturing, cyber-supported production based on artificial intelligence is becoming an increasingly powerful means of controlling machines and collaborating with human users. Semi-autonomous systems with a medium degree of automation enable human-centered, flexible, and sustainable production, for instance, in hybrid decision-making. Especially in applications that do not meet the requirements for full automation and when humans are to be involved in their role as qualified decision-makers, teaming-capable systems are desirable and offer considerable advantages. This paper outlines the transdisciplinary concept of human-machine teaming and the role of human cognition in engineering tasks with multi-criteria decision-making. An illustrative real-life example from thermal spray technology is used to show how explainable artificial intelligence models offer targeted, hybrid cyber decision support. This new approach based on fuzzy pattern classifiers combines expert knowledge- and data-based modeling and enables a transparent interpretation of the results by the human user, as shown here using the example of test data from atmospheric plasma spraying. The method outlined can potentially be used to provide hybrid decision support for a variety of manufacturing processes and form the basis for advanced automation or teaming of humans and cyber-physical-production systems.","[Bocklisch, Franziska; Grimm, Maximilian; Lampke, Thomas] Tech Univ Chemnitz, Inst Mat Sci & Engn, Mat & Surface Engn Grp, D-09107 Chemnitz, Germany; [Bocklisch, Steffen F.] Tech Univ Chemnitz, Inst Elect Engn, Automat Control & Syst Dynam Grp, D-09107 Chemnitz, Germany; [Joshi, Shrikant] Univ West, Dept Engn Sci, S-46132 Trollhattan, Sweden",,"Bocklisch, F (corresponding author), Tech Univ Chemnitz, Inst Mat Sci & Engn, Mat & Surface Engn Grp, D-09107 Chemnitz, Germany.",franziska.bocklisch@mb.tu-chemnitz.de,,,,,,,,3,3,,,,,,,,,,,JUN,2024,132,9-10,,,,,4941,4963,,10.1007/s00170-024-13595-8,http://dx.doi.org/10.1007/s00170-024-13595-8,,APR 2024,,,,,,,,,,2025-05-29,WOS:001208649600005,View Full Record in Web of Science
J,"Qian, K; Popa, L; Sen, P",,,,"Qian, Kun; Popa, Lucian; Sen, Prithviraj",,,SystemER: A Human-in-the-loop System for Explainable Entity Resolution,PROCEEDINGS OF THE VLDB ENDOWMENT,,,,Article,,,,,,,,"Entity Resolution (ER) is the task of identifying different representations of the same real-world object. To achieve scalability and the desired level of quality, the typical ER pipeline includes multiple steps that may involve low-level coding and extensive human labor. We present SystemER, a tool for learning explainable ER models that reduces the human labor all throughout the stages of the ER pipeline. SystemER achieves explainability by learning rules that not only perform a given ER task but are human-comprehensible; this provides transparency into the learning process, and further enables verification and customization of the learned model by the domain experts. By leveraging a human in the loop and active learning, SystemER also ensures that a small number of labeled examples is sufficient to learn high-quality ER models. SystemER is a full-fledged tool that includes an easy to use interface, support for both flat files and semistructured data, and scale-out capabilities by distributing computation via Apache Spark.","[Qian, Kun; Popa, Lucian; Sen, Prithviraj] IBM Res Almaden, San Jose, CA 95120 USA",,"Qian, K (corresponding author), IBM Res Almaden, San Jose, CA 95120 USA.",qian.kun@ibm.com; lpopa@us.ibm.com; senp@us.ibm.com,,,,,,,,15,17,,,,,,,,,,,AUG,2019,12,12,,,,,1794,1797,,10.14778/3352063.3352068,http://dx.doi.org/10.14778/3352063.3352068,,,,,,,,,,,,2025-05-29,WOS:000497646000005,View Full Record in Web of Science
J,"Rheem, H; Lee, J; Lee, JD; Szczerba, JF; Tsimhoni, O",,,,"Rheem, Hansol; Lee, Joonbum; Lee, John D.; Szczerba, Joseph F.; Tsimhoni, Omer",,,Explaining Automated Vehicle Behavior at an Appropriate Abstraction Level and Timescale to Maintain Common Ground,JOURNAL OF COGNITIVE ENGINEERING AND DECISION MAKING,,,,Article,,,,,,,,"Automation is becoming increasingly complex, playing a larger role in driving and expanding its operational design domain to dynamic urban roads. Explainable AI (XAI) research in computer science aims to craft explanations of automation that help people understand the behavior of complex algorithms. However, many XAI approaches rely on fixed-format explanations, which may not effectively support drivers with varying levels of automation knowledge and tasks with different timescales. Maintaining common ground is a multilevel process, in which individuals and automation must adjust communication format and abstraction based on knowledge and time constraints. We first draw on existing research to suggest that common ground is a shared understanding between drivers and automation that requires constant maintenance. We applied the abstraction hierarchy (AH) modeling method, which describes complex systems across multiple abstraction levels to match drivers' cognitive capacity. We modified it to translate vehicle and traffic data into multilevel explanations of automation behavior. We expanded the model into the abstraction-decomposition space, naming it the Driver-Automation Teaming model, designed to generate explanations that account for task timescale. With this modified model, we developed three human-machine interface concepts to demonstrate how it can improve XAI's support for driver-automation collaboration.","[Rheem, Hansol; Lee, Joonbum; Lee, John D.] Univ Wisconsin Madison, Madison, WI USA; [Szczerba, Joseph F.; Tsimhoni, Omer] Gen Motors Global Res & Dev Ctr, Warren, MI USA; [Rheem, Hansol] Kennesaw State Univ, Kennesaw, GA USA",,"Rheem, H (corresponding author), Kennesaw State Univ, Dept Psychol Sci, 385 Cobb Ave NW, Kennesaw, GA 30144 USA.",hrheem@kennesaw.edu,,,,,,,,0,0,,,,,,,,,,,JUN,2025,19,2,,,,,174,199,,10.1177/15553434251318477,http://dx.doi.org/10.1177/15553434251318477,,FEB 2025,,,,,,,,,,2025-05-29,WOS:001421428900001,View Full Record in Web of Science
J,"Sobrie, L; Verschelde, M",,,,"Sobrie, Leon; Verschelde, Marijn",,,Real-time decision support for human-machine interaction in digital railway control rooms,DECISION SUPPORT SYSTEMS,,,,Article,,,,,,,,"This study proposes a real -time Decision Support System (DSS) using machine learning to enhance proactive management of Human-Machine Interaction (HMI) in safety-critical digital control rooms. The DSS provides explainable predictions and recommendations regarding near-future automation usage, customized for the railway control room management, who supervise the operations of traffic controllers (TCs). In this setting, TCs decide on the spot whether to manually or automatically open signals to regulate railway traffic, a critical aspect of ensuring punctuality and safety. This time -setting specific HMI differs across TCs and is not yet supported by a data -driven tool. The proposed DSS includes agreement levels for predictions among different modeling paradigms: linear models, tree-based models, and deep neural networks. SHAP (SHapley Additive exPlanations) values are deployed to assess the agreement level in explainability between these different modeling paradigms. The prescriptions are based on the HMI of well-performing peers. We implement the DSS as proof of concept at the Belgian railway infrastructure company and report end-user feedback on the perception, the operational impact, and the inclusion of agreement levels.","[Sobrie, Leon] Univ Ghent, Fac Econ & Business Adm, Sint Pieterspl 7, B-9000 Ghent, Belgium; [Verschelde, Marijn] Univ Lille, IESEG Sch Management, CNRS, UMR 9221 LEM Lille Econ Management, F-59000 Lille, France; [Sobrie, Leon] Sint Pieterspl 7, B-9000 Ghent, Belgium",,"Sobrie, L (corresponding author), Sint Pieterspl 7, B-9000 Ghent, Belgium.",leon.sobrie@ugent.be; m.verschelde@ieseg.fr,,,,,,,,3,3,,,,,,,,,,,JUN,2024,181,,,,,,,,114216,10.1016/j.dss.2024.114216,http://dx.doi.org/10.1016/j.dss.2024.114216,,APR 2024,,,,,,,,,,2025-05-29,WOS:001226485300001,View Full Record in Web of Science
J,"Matarese, M; Rea, F; Rohlfing, KJ; Sciutti, A",,,,"Matarese, Marco; Rea, Francesco; Rohlfing, Katharina J.; Sciutti, Alessandra",,,How informative is your XAI? Assessing the quality of explanations through information power,FRONTIERS IN COMPUTER SCIENCE,,,,Article,,,,,,,,"A growing consensus emphasizes the efficacy of user-centered and personalized approaches within the field of explainable artificial intelligence (XAI). The proliferation of diverse explanation strategies in recent years promises to improve the interaction between humans and explainable agents. This poses the challenge of assessing the goodness and efficacy of the proposed explanation, which so far has primarily relied on indirect measures, such as the user's task performance. We introduce an assessment task designed to objectively and quantitatively measure the goodness of XAI systems, specifically in terms of their information power. This metric aims to evaluate the amount of information the system provides to non-expert users during the interaction. This work has a three-fold objective: to propose the Information Power assessment task, provide a comparison between our proposal and other XAI goodness measures with respect to eight characteristics, and provide detailed instructions to implement it based on researchers' needs.","[Matarese, Marco; Rea, Francesco; Sciutti, Alessandra] Italian Inst Technol, CONTACT Unit, Genoa, Italy; [Rohlfing, Katharina J.] Paderborn Univ, Fac Arts & Humanities, Paderborn, Germany",,"Matarese, M (corresponding author), Italian Inst Technol, CONTACT Unit, Genoa, Italy.",marco.matarese@iit.it,,,,,,,,0,0,,,,,,,,,,,JAN 8,2025,6,,,,,,,,1412341,10.3389/fcomp.2024.1412341,http://dx.doi.org/10.3389/fcomp.2024.1412341,,,,,,,,,,,,2025-05-29,WOS:001402784600001,View Full Record in Web of Science
J,"Papagni, G; de Pagter, J; Zafari, S; Filzmoser, M; Koeszegi, ST",,,,"Papagni, Guglielmo; de Pagter, Jesse; Zafari, Setareh; Filzmoser, Michael; Koeszegi, Sabine T.",,,Artificial agents' explainability to support trust: considerations on timing and context,AI & SOCIETY,,,,Article,,,,,,,,"Strategies for improving the explainability of artificial agents are a key approach to support the understandability of artificial agents' decision-making processes and their trustworthiness. However, since explanations are not inclined to standardization, finding solutions that fit the algorithmic-based decision-making processes of artificial agents poses a compelling challenge. This paper addresses the concept of trust in relation to complementary aspects that play a role in interpersonal and human-agent relationships, such as users' confidence and their perception of artificial agents' reliability. Particularly, this paper focuses on non-expert users' perspectives, since users with little technical knowledge are likely to benefit the most from post-hoc, everyday explanations. Drawing upon the explainable AI and social sciences literature, this paper investigates how artificial agent's explainability and trust are interrelated at different stages of an interaction. Specifically, the possibility of implementing explainability as a trust building, trust maintenance and restoration strategy is investigated. To this extent, the paper identifies and discusses the intrinsic limits and fundamental features of explanations, such as structural qualities and communication strategies. Accordingly, this paper contributes to the debate by providing recommendations on how to maximize the effectiveness of explanations for supporting non-expert users' understanding and trust.","[Papagni, Guglielmo; de Pagter, Jesse; Zafari, Setareh; Filzmoser, Michael; Koeszegi, Sabine T.] TU Wien, Inst Management Sci, Vienna, Austria",,"Papagni, G (corresponding author), TU Wien, Inst Management Sci, Vienna, Austria.",guglielmo.papagni@tuwien.ac.at; jesse.de.pagter@tuwien.ac.at; setareh.zafari@tuwien.ac.at; michael.filzmoser@tuwien.ac.at; sabine.koeszegi@tuwien.ac.at,,,,,,,,11,13,,,,,,,,,,,APR,2023,38,2,,,,,947,960,,10.1007/s00146-022-01462-7,http://dx.doi.org/10.1007/s00146-022-01462-7,,JUN 2022,,,,,,,,,,2025-05-29,WOS:000817047900003,View Full Record in Web of Science
J,"Akhtar, M; Nehal, N; Gull, A; Parveen, R; Khan, S; Khan, S; Ali, J",,,,"Akhtar, Masheera; Nehal, Nida; Gull, Azka; Parveen, Rabea; Khan, Sana; Khan, Saba; Ali, Javed",,,Explicating the transformative role of artificial intelligence in designing targeted nanomedicine,EXPERT OPINION ON DRUG DELIVERY,,,,Review; Early Access,,,,,,,,"IntroductionArtificial intelligence (AI) has emerged as a transformative force in nanomedicine, revolutionizing drug delivery, diagnostics, and personalized treatment. While nanomedicine offers precise targeted drug delivery and reduced toxic effects, its clinical translation is hindered by biological complexity, unpredictable in vivo behavior, and inefficient trial-and-error approaches.Areas coveredThis review covers the application of AI and Machine Learning (ML) across the nanomedicine development pipeline, starting from drug and target identification to nanoparticle design, toxicity prediction, and personalized dosing. Different AI/ML models like QSAR, MTK-QSBER, and Alchemite, along with data sources and high-throughput screening methods, have been explored. Real-world applications are critically discussed, including AI-assisted drug repurposing, controlled-release formulations, and cancer-specific delivery systems.Expert opinionAI has emerged as an essential component in designing next-generation nanomedicine. Efficiently handling multidimensional datasets, optimizing formulations, and personalizing treatment regimens, it has sped up the innovation process. However, challenges like data heterogeneity, model transparency, and regulatory gaps remain. Addressing these hurdles through interdisciplinary efforts and emerging innovations like explainable AI and federated learning will pave the way for the clinical translation of AI-driven nanomedicine.","[Akhtar, Masheera; Nehal, Nida; Gull, Azka; Parveen, Rabea; Khan, Saba; Ali, Javed] Sch Pharmaceut Educ & Res, Dept Pharmaceut, New Delhi 110062, India; [Khan, Sana] Sch Pharmaceut Educ & Res, Dept Pharmacol, New Delhi, India",,"Khan, S; Ali, J (corresponding author), Sch Pharmaceut Educ & Res, Dept Pharmaceut, New Delhi 110062, India.",sabakhan027@gmail.com; jali@jamiahamdard.ac.in,,,,,,,,0,0,,,,,,,,,,,2025 MAY 23,2025,,,,,,,,,,10.1080/17425247.2025.2502022,http://dx.doi.org/10.1080/17425247.2025.2502022,,MAY 2025,,,,,,,,,,2025-05-29,WOS:001492339300001,View Full Record in Web of Science
J,"Srinivasan, K; Currim, F; Ram, S",,,,"Srinivasan, Karthik; Currim, Faiz; Ram, Sudha",,,A Human-in-the-Loop Segmented Mixed-Effects Modeling Method for Analyzing Wearables Data,ACM TRANSACTIONS ON MANAGEMENT INFORMATION SYSTEMS,,,,Article,,,,,,,,"Wearables are an important source of big data, as they provide real-time high-resolution data logs of health indicators of individuals. Higher-order associations between pairs of variables is common in wearables data. Representing higher-order association curves as piecewise linear segments in a regression modelmakes them more interpretable. However, existing methods for identifying the change points for segmented modeling either overfit or have low external validity for wearables data containing repeated measures. Therefore, we propose a human-in-the-loop method for segmented modeling of higher-order pairwise associations between variables in wearables data. Our method uses the smooth function estimated by a generalized additive mixed model to allowthe analyst to annotate change point estimates for a segmented mixed-effects model, and thereafter employs Brent's constrained optimization procedure to fine-tune the manually provided estimates. We validate our method using three real-world wearables datasets. Our method not only outperforms state-of-the-art modeling methods in terms of prediction performance but also provides more interpretable results. Our study contributes to health data science in terms of developing a new method for interpretable modeling of wearables data. Our analysis uncovers interesting insights on higher-order associations for health researchers.","[Srinivasan, Karthik] Univ Kansas, Sch Business, 1654 Naismith Dr, Lawrence, KS 66045 USA; [Currim, Faiz; Ram, Sudha] Univ Arizona, Eller Coll Management, 1130 E Helen St, Tucson, AZ 85721 USA",,"Srinivasan, K (corresponding author), Univ Kansas, Sch Business, 1654 Naismith Dr, Lawrence, KS 66045 USA.",karthiks@ku.edu; fcurrim@eller.arizona.edu; ram@eller.arizona.edu,,,,,,,,0,0,,,,,,,,,,,JUN,2023,14,2,,,,,,,18,10.1145/3564276,http://dx.doi.org/10.1145/3564276,,,,,,,,,,,,2025-05-29,WOS:000952306800007,View Full Record in Web of Science
J,"Raikov, A; Giretti, A; Pirani, M; Spalazzi, L; Guo, M",,,,"Raikov, Aleksandr; Giretti, Alberto; Pirani, Massimiliano; Spalazzi, Luca; Guo, Meng",,,Accelerating human-computer interaction through convergent conditions for LLM explanation,FRONTIERS IN ARTIFICIAL INTELLIGENCE,,,,Review,,,,,,,,"The article addresses the accelerating human-machine interaction using the large language model (LLM). It goes beyond the traditional logical paradigms of explainable artificial intelligence (XAI) by considering poor-formalizable cognitive semantical interpretations of LLM. XAI is immersed in a hybrid space, where humans and machines have crucial distinctions during the digitisation of the interaction process. The author's convergent methodology ensures the conditions for making XAI purposeful and sustainable. This methodology is based on the inverse problem-solving method, cognitive modeling, genetic algorithm, neural network, causal loop dynamics, and eigenform realization. It has been shown that decision-makers need to create unique structural conditions for information processes, using LLM to accelerate the convergence of collective problem solving. The implementations have been carried out during the collective strategic planning in situational centers. The study is helpful for the advancement of explainable LLM in many branches of economy, science and technology.","[Raikov, Aleksandr; Guo, Meng] Jinan Inst Supercomp Technol, Jinan 250103, Shandong, Peoples R China; [Giretti, Alberto] Univ Politecn Marche, Dept Construct Civil Engn & Architecture DICEA, Ancona, Italy; [Pirani, Massimiliano; Spalazzi, Luca] Univ Politecn Marche, Dept Informat Engn DII, Ancona, Italy",,"Pirani, M (corresponding author), Univ Politecn Marche, Dept Informat Engn DII, Ancona, Italy.",massimiliano.pirani@gmail.com,,,,,,,,3,3,,,,,,,,,,,MAY 30,2024,7,,,,,,,,1406773,10.3389/frai.2024.1406773,http://dx.doi.org/10.3389/frai.2024.1406773,,,,,,,,,,,,2025-05-29,WOS:001246169000001,View Full Record in Web of Science
J,"Yera, R; Alzahrani, AA; Martinez, L",,,,"Yera, Raciel; Alzahrani, Ahmad A.; Martinez, Luis",,,Exploring post-hoc agnostic models for explainable cooking recipe recommendations,KNOWLEDGE-BASED SYSTEMS,,,,Article,,,,,,,,"The need of increasing trustworthiness and transparency in artificial intelligence (AI)-based systems that adhere ethical principles of respect for human autonomy, prevention of harm, fairness, and ex-plainability; has boosting the development of systems that incorporate such issues as a key component. Recommender systems (RSs) are included in such AI-based systems, because they use intelligent algorithms for providing the most suitable items to active users according to other users' preferences. The RSs success is based on how much customers trust on the system, therefore recommendation explainability has become a crucial dimension for RSs adoption in real-world scenarios. Among the different successful applications of RS, it is remarkable the recent and exponential importance of recommendations for health and wellness areas. Hence, this paper aims at exploring, adapting and applying explanations for nutrition/recipes recommendations, that not only explain why the recommendation is enjoyable but also, it is aware of how healthy is the recommendation. Among the different methodologies to explain recommendations, this paper is focused on post-hoc explainability approaches and its adaptation, application and evaluation for nutrition/recipes recommendation. Eventually, it is included a comprehensive experimental study for characterizing the strengths and weaknesses of such explainability approaches in the recipe recommendation context. (C) 2022 The Author(s). Published by Elsevier B.V.","[Yera, Raciel; Martinez, Luis] Univ Jaen, Comp Sci Dept, Jaen, Spain; [Alzahrani, Ahmad A.] King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia",,"Martinez, L (corresponding author), Univ Jaen, Comp Sci Dept, Jaen, Spain.",ryera@ujaen.es; aalzahrani8@kau.edu.sa; martin@ujaen.es,,,,,,,,22,22,,,,,,,,,,,SEP 5,2022,251,,,,,,,,109216,10.1016/j.knosys.2022.109216,http://dx.doi.org/10.1016/j.knosys.2022.109216,,JUN 2022,,,,,,,,,,2025-05-29,WOS:000830076700005,View Full Record in Web of Science
J,"Xu, M; Yue, YB; Li, ZZ; Li, YH; Li, GY; Liang, HH; Liu, D; Xu, XH",,,,"Xu, Ming; Yue, Yubiao; Li, Zhenzhang; Li, Yinhong; Li, Guoying; Liang, Haihua; Liu, Di; Xu, Xiaohong",,,Development and Validation of Explainable Artificial Intelligence System for Automatic Diagnosis of Cervical Lymphadenopathy From Ultrasound Images,INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS,,,,Article,,,,,,,,"Clinical diagnosis of cervical lymphadenopathy (CLA) using ultrasound images is a time-consuming and laborious process that heavily relies on expert experience. This study aimed to develop an intelligent computer-aided diagnosis (CAD) system using deep learning models (DLMs) to enhance the efficiency of ultrasound screening and diagnostic accuracy of CLA. We retrospectively collected 4089 ultrasound images of cervical lymph nodes across four categories from two hospitals: normal, benign CLA, primary malignant CLA, and metastatic malignant CLA. We employed transfer learning, data augmentation, and five-fold cross-validation to evaluate the diagnostic performance of DLMs with different architectures. To boost the application potential of DLMs, we investigated the potential impact of various optimizers and machine learning classifiers on their diagnostic performance. Our findings revealed that EfficientNet-B1 with transfer learning and root-mean-square-propagation optimizer achieved state-of-the-art performance, with overall accuracies of 97.0% and 90.8% on the internal and external test sets, respectively. Additionally, human-machine comparison experiments and the implementation of explainable artificial intelligence technology further enhance the reliability and safety of DLMs and help clinicians easily understand the DLM results. Finally, we developed an application that can be implemented in systems running Microsoft Windows. However, additional prospective studies are required to validate the clinical utility of the developed application. All pretrained DLMs, codes, and application are available at .","[Xu, Ming; Yue, Yubiao; Li, Yinhong; Xu, Xiaohong] Guangzhou Med Univ, Affiliated Hosp 2, Dept Stomatol, Dept Med Ultrasound, Guangzhou 510260, Peoples R China; [Li, Zhenzhang] Guangzhou Med Univ, Sch Biomed Engn, Guangzhou 511495, Peoples R China; [Yue, Yubiao; Li, Zhenzhang; Liang, Haihua] Guangdong Polytech Normal Univ, Coll Math & Syst Sci, Guangzhou 510665, Peoples R China; [Li, Guoying] Guangzhou Med Univ, Affiliated Hosp 1, Dept Med Ultrasound, Guangzhou 510120, Peoples R China; [Liu, Di] Guangzhou Maritime Univ, Dept Basic Courses, Guangzhou 510725, Peoples R China",,"Xu, XH (corresponding author), Guangzhou Med Univ, Affiliated Hosp 2, Dept Stomatol, Dept Med Ultrasound, Guangzhou 510260, Peoples R China.",2952450562@qq.com,,,,,,,,0,0,,,,,,,,,,,,2025,2025,1,,,,,,,5432766,10.1155/int/5432766,http://dx.doi.org/10.1155/int/5432766,,,,,,,,,,,,2025-05-29,WOS:001439035400001,View Full Record in Web of Science
J,"Liu, JX; Niu, JH; Li, WF; Li, X; He, BB; Zhou, H; Liu, YJ; Li, D; Wang, B; Zhang, WS",,,,"Liu, Jiaxi; Niu, Jinghao; Li, Weifeng; Li, Xin; He, Binbin; Zhou, Hao; Liu, Yanjuan; Li, Ding; Wang, Bo; Zhang, Wensheng",,,XFMP: A Benchmark for Explainable Fine-Grained Abnormal Behavior Recognition on Medical Personal Protective Equipment,IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY,,,,Article,,,,,,,,"The proper use of medical personal protective equipment (MPPE) is critical for frontline healthcare workers (HCWs) to handle highly contagious diseases. Due to the complexity of PPE donning and doffing protocols, public health organizations typically recommend having trained observers monitor the entire PPE donning and doffing process, preventing self-contamination and transmission. However, the high costs of manual monitoring impede the implementation of this practice, which makes AI-assisted PPE monitoring highly valuable. Some studies have applied computer vision techniques to PPE monitoring, but they have only focused on limited integrity checks at donning completion, which is unable to provide real-time warnings for abnormal actions during the doffing process. Furthermore, model practicality and user-friendliness are constrained by the lack of explainability. To address this, we propose an explainable and fine-grained dataset for MPPE doffing monitoring called the XFMP dataset. The dataset contains 3596 expert-annotated samples over three sub-tasks: doffing stage classification (DSC), abnormal action recognition (AAR), and critical region localization (CRL). Accordingly, we introduce multi-dimensional evaluation metrics for XFMP and a multitask human behavior semantic attention network (MHBSAN). Experiments demonstrate that MHBSAN outperforms alternative approaches, achieving 0.968/0.855 accuracy for stage/action classification and 0.791 Top-1 Loc@0.5 for CRL sub-task. Moreover, it demonstrates exceptional adaptability across different healthcare environments. Ablation studies and case analyses further validate the contributions and efficacy of the proposed model regarding classification and explainability.","[Liu, Jiaxi] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 101408, Peoples R China; [Liu, Jiaxi; Niu, Jinghao; Wang, Bo; Zhang, Wensheng] Chinese Acad Sci, Inst Automat, State Key Lab Multimodal Artificial Intelligence S, Beijing 100190, Peoples R China; [Li, Weifeng; Li, Xin; He, Binbin; Zhou, Hao; Liu, Yanjuan] Southern Med Univ, Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Dept Emergency Med, Guangzhou 510080, Peoples R China; [Li, Ding] PhiGent Robot Technol Co Ltd, Beijing 100083, Peoples R China; [Zhang, Wensheng] Guangzhou Univ, Sch Comp Sci & Cyber Engn, Guangzhou 510006, Peoples R China",,"Niu, JH; Zhang, WS (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Multimodal Artificial Intelligence S, Beijing 100190, Peoples R China.;Li, X (corresponding author), Southern Med Univ, Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Dept Emergency Med, Guangzhou 510080, Peoples R China.",liujiaxi2021@ia.ac.cn; niujinghao2015@ia.ac.cn; liweifeng2736@gdph.org.cn; xlidoct@qq.com; hebinbin.85@163.com; 522892340@qq.com; 13632398523@163.com; lidingdean@foxmail.com; bo.wang@ia.ac.cn; zhangwenshengia@hotmail.com,,,,,,,,1,1,,,,,,,,,,,OCT,2024,34,10,,,,,10250,10265,,10.1109/TCSVT.2024.3405998,http://dx.doi.org/10.1109/TCSVT.2024.3405998,,,,,,,,,,,,2025-05-29,WOS:001346503100032,View Full Record in Web of Science
J,"Rubinstein, B; Matos, S",,,,"Rubinstein, Beny; Matos, Sergio",,,Value Creation for Healthcare Ecosystems through Artificial Intelligence Applied to Physician-to-Physician Communication: A Systematic Review,NEURAL PROCESSING LETTERS,,,,Article,,,,,,,,"This study reviews the role of artificial intelligence (AI) in enhancing healthcare through an analysis of physician-to-physician communication. It seeks to identify the best practices for extracting value from professional medical chats (PMCs) and assess the impact of AI on patient outcomes and healthcare systems, emphasizing the integration of ethical and responsible AI practices. We conducted an extensive systematic literature review using the Web of Science Core Collection. Searches encompassed English-language articles published between January 2019 and July 2023 using keywords related to AI, machine learning, natural language processing, and physician communication. Of the 247 articles screened, 13 met the inclusion criteria given their in-depth analysis of AI in healthcare communication, methodological soundness, and relevance to clinical outcomes. The review provides insights into interprofessional communication dynamics, the advancement of NLP and deep learning in medical dialogues, and strategies for effective human-machine collaboration. Ethical considerations and the need for transparency in AI applications are key to these central findings. This study highlights the untapped potential of physician-generated real-world data in creating value for healthcare ecosystems. It advocates for a multidisciplinary strategy encompassing communication, education, and collaboration to advance AI in healthcare responsibly. Moreover, it suggests that by combining existing techniques in the AI discipline, including neural networks, generative AI, and genetic algorithms, as well as keeping a physician in the loop when building AI systems, we can have a significant impact on healthcare delivery and medical research.","[Rubinstein, Beny; Matos, Sergio] Univ Aveiro, Aveiro, Portugal; [Matos, Sergio] Univ Aveiro, DETI, IEETA, LASI, Aveiro, Portugal",,"Rubinstein, B (corresponding author), Univ Aveiro, Aveiro, Portugal.",BenyR@ua.pt; aleixomatos@ua.pt,,,,,,,,0,0,,,,,,,,,,,JAN 20,2025,57,1,,,,,,,6,10.1007/s11063-025-11725-1,http://dx.doi.org/10.1007/s11063-025-11725-1,,,,,,,,,,,,2025-05-29,WOS:001400428900002,View Full Record in Web of Science
J,"Wang, KR; Hou, WJ; Hong, LY; Guo, JY",,,,"Wang, Keran; Hou, Wenjun; Hong, Leyi; Guo, Jinyu",,,Smart Transparency: A User-Centered Approach to Improving Human-Machine Interaction in High-Risk Supervisory Control Tasks,ELECTRONICS,,,,Article,,,,,,,,"In supervisory control tasks, particularly in high-risk fields, operators need to collaborate with automated intelligent agents to manage dynamic, time-sensitive, and uncertain information. Effective human-agent collaboration relies on transparent interface communication to align with the operator's cognition and enhance trust. This paper proposes a human-centered adaptive transparency information design framework (ATDF), which dynamically adjusts the display of transparency information based on the operator's needs and the task type. This ensures that information is accurately conveyed at critical moments, thereby enhancing trust, task performance, and interface usability. Additionally, the paper introduces a novel user research method, Heu-Kano, to explore the prioritization of transparency needs and presents a model based on eye-tracking and machine learning to identify different types of human-agent interactions. This research provides new insights into human-centered explainability in supervisory control tasks.","[Wang, Keran] Beijing Univ Posts & Telecommun, Sch Intelligent Engn & Automat, 1 Nanfeng Rd,Shahe Higher Educ Pk,Shahe Area, Beijing 102206, Peoples R China; [Hou, Wenjun; Hong, Leyi] Beijing Univ Posts & Telecommun, Sch Digital Media & Design Arts, 10 Xitucheng Rd, Beijing 100876, Peoples R China; [Hou, Wenjun] Beijing Key Lab Network Syst & Network Culture, 10 Xitucheng Rd, Beijing 100876, Peoples R China; [Hou, Wenjun] Minist Culture & Tourism, Key Lab Interact Technol & Experience Syst, 10 Xitucheng Rd, Beijing 100876, Peoples R China; [Guo, Jinyu] Univ Elect Sci & Technol China, Sch Informat & Software Engn, 2006 Xiyuan Ave, Chengdu 611731, Peoples R China",,"Hou, WJ (corresponding author), Beijing Univ Posts & Telecommun, Sch Digital Media & Design Arts, 10 Xitucheng Rd, Beijing 100876, Peoples R China.;Hou, WJ (corresponding author), Beijing Key Lab Network Syst & Network Culture, 10 Xitucheng Rd, Beijing 100876, Peoples R China.;Hou, WJ (corresponding author), Minist Culture & Tourism, Key Lab Interact Technol & Experience Syst, 10 Xitucheng Rd, Beijing 100876, Peoples R China.",evakr1206@bupt.edu.cn; hwj1505@bupt.edu.cn; hllly_hyuk@bupt.edu.cn; guojinyu@uestc.edu.cn,,,,,,,,1,1,,,,,,,,,,,FEB,2025,14,3,,,,,,,420,10.3390/electronics14030420,http://dx.doi.org/10.3390/electronics14030420,,,,,,,,,,,,2025-05-29,WOS:001418550200001,View Full Record in Web of Science
J,"Terranova, N; Renard, D; Shahin, MH; Menon, S; Cao, YF; Hop, CECA; Hayes, S; Madrasi, K; Stodtmann, S; Tensfeldt, T; Vaddady, P; Ellinwood, N; Lu, JM",,,,"Terranova, Nadia; Renard, Didier; Shahin, Mohamed H.; Menon, Sujatha; Cao, Youfang; Hop, Cornelis E. C. A.; Hayes, Sean; Madrasi, Kumpal; Stodtmann, Sven; Tensfeldt, Thomas; Vaddady, Pavan; Ellinwood, Nicholas; Lu, James",,,Artificial Intelligence for Quantitative Modeling in Drug Discovery and Development: An Innovation and Quality Consortium Perspective on Use Cases and Best Practices,CLINICAL PHARMACOLOGY & THERAPEUTICS,,,,Article,,,,,,,,"Recent breakthroughs in artificial intelligence (AI) and machine learning (ML) have ushered in a new era of possibilities across various scientific domains. One area where these advancements hold significant promise is model-informed drug discovery and development (MID3). To foster a wider adoption and acceptance of these advanced algorithms, the Innovation and Quality (IQ) Consortium initiated the AI/ML working group in 2021 with the aim of promoting their acceptance among the broader scientific community as well as by regulatory agencies. By drawing insights from workshops organized by the working group and attended by key stakeholders across the biopharma industry, academia, and regulatory agencies, this white paper provides a perspective from the IQ Consortium. The range of applications covered in this white paper encompass the following thematic topics: (i) AI/ML-enabled Analytics for Pharmacometrics and Quantitative Systems Pharmacology (QSP) Workflows; (ii) Explainable Artificial Intelligence and its Applications in Disease Progression Modeling; (iii) Natural Language Processing (NLP) in Quantitative Pharmacology Modeling; and (iv) AI/ML Utilization in Drug Discovery. Additionally, the paper offers a set of best practices to ensure an effective and responsible use of AI, including considering the context of use, explainability and generalizability of models, and having human-in-the-loop. We believe that embracing the transformative power of AI in quantitative modeling while adopting a set of good practices can unlock new opportunities for innovation, increase efficiency, and ultimately bring benefits to patients.","[Terranova, Nadia] Merck KGaA, Quant Pharmacol, Lausanne, Switzerland; [Renard, Didier] Novartis Pharm AG, Full Dev Pharmacometr, Basel, Switzerland; [Shahin, Mohamed H.; Menon, Sujatha; Tensfeldt, Thomas] Pfizer Inc, Clin Pharmacol, Groton, CT USA; [Cao, Youfang] Eisai Inc, Clin Pharmacol & Translat Med, Nutley, NJ USA; [Hop, Cornelis E. C. A.] Genentech Inc, DMPK, South San Francisco, CA USA; [Hayes, Sean] Merck & Co Inc, Quantitat Pharmacol & Pharmacometr, Rahway, NJ USA; [Madrasi, Kumpal] Sanofi, Modeling & Simulat, Bridgewater, NJ USA; [Stodtmann, Sven] AbbVie Deutschland GmbH & Co KG, Pharmacometr, Ludwigshafen, Germany; [Vaddady, Pavan] Daiichi Sankyo Inc, Quantitat Clin Pharmacol, Basking Ridge, NJ USA; [Ellinwood, Nicholas] Eli Lilly & Co, Global PK PD & Pharmacometr, Indianapolis, IN 46225 USA; [Lu, James] Genentech Inc, Clin Pharmacol, South San Francisco, CA 94080 USA",,"Ellinwood, N (corresponding author), Eli Lilly & Co, Global PK PD & Pharmacometr, Indianapolis, IN 46225 USA.;Lu, JM (corresponding author), Genentech Inc, Clin Pharmacol, South San Francisco, CA 94080 USA.",n.ellinwood@lilly.com; lu.james@gene.com,,,,,,,,25,26,,,,,,,,,,,APR,2024,115,4,,,,,658,672,,10.1002/cpt.3053,http://dx.doi.org/10.1002/cpt.3053,,OCT 2023,,,,,,,,,,2025-05-29,WOS:001076276600001,View Full Record in Web of Science
J,"Sheth, A; Khandelwal, V; Roy, K; Pallagani, V; Chakraborty, M; Sheth, A",,,,"Sheth, Amit; Khandelwal, Vedant; Roy, Kaushik; Pallagani, Vishal; Chakraborty, Megha; Sheth, Amit",,,NeuroSymbolic Knowledge-Grounded Planning and Reasoning in Artificial Intelligence Systems,IEEE INTELLIGENT SYSTEMS,,,,Article,,,,,,,,"Decision-support systems in AI-assisted health care require robust, interpretable, and user-centric processes that effectively handle natural language inputs. While large language models (LLMs) excel at generating coherent text, they struggle with complex reasoning and multistep planning tasks. In response, we propose a neurosymbolic framework that integrates LLMs with symbolic knowledge graphs, graph-based reasoners, and constraint-aware planning modules. This hybrid approach leverages LLMs for initial plan formulation while refining outcomes with structured, domain-specific representations that enforce safety standards, ensure regulatory compliance, and maintain logical consistency. Demonstrated through examples in health care and manufacturing, our method bridges the gap between unstructured language generation and formal reasoning, enhancing reliability in high-stakes applications and supporting dynamic, context-aware decision-making. The framework offers a scalable, trustworthy solution for complex, constraint-driven environments. By combining generative creativity with formal logic, our approach addresses the key limitations of LLMs, making it suitable for diverse, high-impact domains.","[Sheth, Amit; Khandelwal, Vedant; Roy, Kaushik; Pallagani, Vishal; Chakraborty, Megha; Sheth, Amit] Univ South Carolina, Artificial Intelligence Inst South Carolina, Columbia, SC 29208 USA",,"Sheth, A (corresponding author), Univ South Carolina, Artificial Intelligence Inst South Carolina, Columbia, SC 29208 USA.",amit@sc.edu; vedant@email.sc.edu; kaushikr@email.sc.edu; vishalp@email.sc.edu; meghac@email.sc.edu; amit@sc.edu,,,,,,,,0,0,,,,,,,,,,,MAR-APR,2025,40,2,,,,,27,34,,10.1109/MIS.2025.3544943,http://dx.doi.org/10.1109/MIS.2025.3544943,,,,,,,,,,,,2025-05-29,WOS:001465467800003,View Full Record in Web of Science
J,"Oyedeji, MO; Okafor, E; Samma, H; Alfarraj, M",,,,"Oyedeji, Mojeed Opeyemi; Okafor, Emmanuel; Samma, Hussein; Alfarraj, Motaz",,,Interpretable Deep Learning for Classifying Skin Lesions,INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS,,,,Article,,,,,,,,"The global prevalence of skin cancer necessitates the development of AI-assisted technologies for accurate and interpretable diagnosis of skin lesions. This study presents a novel deep learning framework for enhancing the interpretability and reliability of skin lesion predictions from clinical images, which are more inclusive, accessible, and representative of real-world conditions than dermoscopic images. We comprehensively analyzed 13 deep learning models from four main convolutional neural network architecture classes: DenseNet, ResNet, MobileNet, and EfficientNet. Different data augmentation strategies and model optimization algorithms were explored to access the performances of the deep learning models in binary and multiclass classification scenarios. In binary classification, the DenseNet-161 model, initialized with random weights, obtained a top accuracy of 79.40%, while the EfficientNet-B7 model, initialized with pretrained weights from ImageNet, reached an accuracy of 85.80%. Furthermore, in the multiclass classification experiments, DenseNet121, initialized with random weights and trained with AdamW, obtained the best accuracy of 65.1%. Likewise, when initialized with pretrained weights, the DenseNet121 model attained a top accuracy of 75.07% in multiclass classification. Detailed interpretability analyses were carried out leveraging the SHAP and CAM algorithms to provide insights into the decision rationale of the investigated models. The SHAP algorithm was beneficial in understanding the feature attributions by visualizing how specific regions of the input image influenced the model predictions. Our study emphasizes using clinical images for developing AI algorithms for skin lesion diagnosis, highlighting the practicality and relevance in real-world applications, especially where dermoscopic tools are not readily accessible. Beyond accessibility, these developments also ensure that AI-assisted diagnostic tools are deployed in diverse clinical settings, thus promoting inclusiveness and ultimately improving early detection and treatment of skin cancers.","[Oyedeji, Mojeed Opeyemi; Okafor, Emmanuel; Samma, Hussein; Alfarraj, Motaz] King Fahd Univ Petr & Minerals, SDAIA KFUPM Joint Res Ctr Artificial Intelligence, Dhahran 31261, Saudi Arabia; [Alfarraj, Motaz] King Fahd Univ Petr & Minerals, Elect Engn Dept, Dhahran 31261, Saudi Arabia; [Alfarraj, Motaz] King Fahd Univ Petr & Minerals, Informat & Comp Sci Dept, Dhahran 31261, Saudi Arabia",,"Oyedeji, MO (corresponding author), King Fahd Univ Petr & Minerals, SDAIA KFUPM Joint Res Ctr Artificial Intelligence, Dhahran 31261, Saudi Arabia.",mojeed.oyedeji@gmail.com,,,,,,,,0,0,,,,,,,,,,,,2025,2025,1,,,,,,,2751767,10.1155/int/2751767,http://dx.doi.org/10.1155/int/2751767,,,,,,,,,,,,2025-05-29,WOS:001477824600001,View Full Record in Web of Science
J,"Nnawuchi, U; George, C",,,,"Nnawuchi, Uchenna; George, Carlisle",,,Decoding accountability: the importance of explainability in liability frameworks for smart border systems,DISCOVER COMPUTING,,,,Review,,,,,,,,"This paper examines the challenges posed by Automated Decision-Making systems (ADMs) in border control, focusing on the limitations of the proposed AI Liability Directive (AILD)-now withdrawn- in addressing potential harms. We identify key issues within the AILD, including the plausibility requirement, knowledge paradox, and the exclusion of human-in-the-loop, which create significant barriers for claimants seeking redress. Although now withdrawn, the commission is contemplating putting up a new proposal for the AI Liability regime; if the new proposal is anything like the AILD (now withdrawn), there is a need to address the substantial shortcomings discovered in the AILD. To address these shortcomings, we propose integrating sui generis explainability requirements into the AILD framework or mandatory compliance with Article 86 of the Artificial Intelligence Act (AIA), notwithstanding its ineffectiveness. This approach aims to bridge knowledge and liability gaps, empower claimants, and enhance transparency in AI decision-making processes. Our recommendations include expanding the disclosure requirements to incorporate a sui generis explainability requirement, implementing a tiered plausibility standard, and introducing regulatory sandboxes. These measures seek to engender accountability and fairness. With the refinement of the AILD in mind, these considerations aim to influence and make recommendations for any future proposals for an AI liability regime and to foster a regulatory environment that encourages both the development and use of AI technologies to be responsible and accountable, ensuring that AI-driven or smart border control systems enhance security and efficiency while upholding fundamental rights and human dignity.","[Nnawuchi, Uchenna; George, Carlisle] Middlesex Univ, Fac Sci & Technol, Dept Comp Sci, ALERT Res Grp, London, England",,"Nnawuchi, U (corresponding author), Middlesex Univ, Fac Sci & Technol, Dept Comp Sci, ALERT Res Grp, London, England.",UN055@live.mdx.ac.uk; c.george@mdx.ac.uk,,,,,,,,0,0,,,,,,,,,,,MAY 4,2025,28,1,,,,,,,64,10.1007/s10791-025-09559-5,http://dx.doi.org/10.1007/s10791-025-09559-5,,,,,,,,,,,,2025-05-29,WOS:001481136700001,View Full Record in Web of Science
J,"Balla, J; Huang, SH; Dugan, O; Dangovski, R; Soljacic, M",,,,"Balla, Julia; Huang, Sihao; Dugan, Owen; Dangovski, Rumen; Soljacic, Marin",,,AI-assisted discovery of quantitative and formal models in social science,HUMANITIES & SOCIAL SCIENCES COMMUNICATIONS,,,,Article,,,,,,,,"In social science, formal and quantitative models, ranging from ones that describe economic growth to collective action, are used to formulate mechanistic explanations of the observed phenomena, provide predictions, and uncover new research questions. Here, we demonstrate the use of a machine learning system to aid the discovery of symbolic models that capture non-linear and dynamical relationships in social science datasets. By extending neuro-symbolic methods to find compact functions and differential equations in noisy and longitudinal data, we show that our system can be used to discover interpretable models from real-world data in economics and sociology. Augmenting existing workflows with symbolic regression can help uncover novel relationships and explore counterfactual models during the scientific process. We propose that this AI-assisted framework can bridge parametric and non-parametric models commonly employed in social science research by systematically exploring the space of non-linear models and enabling fine-grained control over expressivity and interpretability.","[Balla, Julia; Dangovski, Rumen] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA; [Balla, Julia; Dugan, Owen; Dangovski, Rumen; Soljacic, Marin] NSF Inst Artificial Intelligence & Fundamental Int, Cambridge, MA 02139 USA; [Huang, Sihao] Univ Oxford, Dept Polit & Int Relat, Oxford, England; [Huang, Sihao; Dugan, Owen; Soljacic, Marin] MIT, Dept Phys, Cambridge, MA USA",,"Balla, J (corresponding author), MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.;Balla, J (corresponding author), NSF Inst Artificial Intelligence & Fundamental Int, Cambridge, MA 02139 USA.",jballa@mit.edu,,,,,,,,0,0,,,,,,,,,,,JAN 31,2025,12,1,,,,,,,114,10.1057/s41599-025-04405-x,http://dx.doi.org/10.1057/s41599-025-04405-x,,,,,,,,,,,,2025-05-29,WOS:001410485200001,View Full Record in Web of Science
J,"Bousdekis, A; Apostolou, D; Mentzas, G",,,,"Bousdekis, Alexandros; Apostolou, Dimitris; Mentzas, Gregoris",,,A human cyber physical system framework for operator 4.0 - artificial intelligence symbiosis,MANUFACTURING LETTERS,,,,Article,,,,,,,,"The emergence of Artificial Intelligence (AI) reveals new opportunities in Industry 4.0 environments. However, the lack of appropriate data and the requirements for trustworthiness pose significant challenges in the applicability and the effectiveness of AI systems in manufacturing environments. On the other hand, Industry 4.0 enables new types of interactions between humans and AI, but also between digital and physical worlds in the context of Cyber Physical Systems (CPS). In this paper, a Human Cyber Physical System (HCPS) framework for Operator 4.0 - Artificial Intelligence Symbiosis is proposed and its main architectural building blocks are described. (C) 2020 Society of Manufacturing Engineers (SME). Published by Elsevier Ltd. All rights reserved.","[Bousdekis, Alexandros; Apostolou, Dimitris; Mentzas, Gregoris] Natl Tech Univ Athens NTUA, Inst Commun & Comp Syst ICCS, Informat Management Unit IMU, 9 Iroon Polytech Str, Athens 15780, Greece; [Apostolou, Dimitris] Univ Piraeus, Dept Informat, Piraeus, Greece",,"Bousdekis, A (corresponding author), Natl Tech Univ Athens NTUA, Inst Commun & Comp Syst ICCS, Informat Management Unit IMU, 9 Iroon Polytech Str, Athens 15780, Greece.",albous@mail.ntua.gr,,,,,,,,37,41,,,,,,,,,,,AUG,2020,25,,,,,,10,15,,10.1016/j.mfglet.2020.06.001,http://dx.doi.org/10.1016/j.mfglet.2020.06.001,,,,,,,,,,,,2025-05-29,WOS:000645124000003,View Full Record in Web of Science
J,"Barnett, AJ; Schwartz, FR; Tao, CF; Chen, CF; Ren, YH; Lo, JY; Rudin, C",,,,"Barnett, Alina Jade; Schwartz, Fides Regina; Tao, Chaofan; Chen, Chaofan; Ren, Yinhao; Lo, Joseph Y.; Rudin, Cynthia",,,A case-based interpretable deep learning model for classification of mass lesions in digital mammography,NATURE MACHINE INTELLIGENCE,,,,Article,,,,,,,,"Interpretability in machine learning models is important in high-stakes decisions such as whether to order a biopsy based on a mammographic exam. Mammography poses important challenges that are not present in other computer vision tasks: datasets are small, confounding information is present and it can be difficult even for a radiologist to decide between watchful waiting and biopsy based on a mammogram alone. In this work we present a framework for interpretable machine learning-based mammography. In addition to predicting whether a lesion is malignant or benign, our work aims to follow the reasoning processes of radiologists in detecting clinically relevant semantic features of each image, such as the characteristics of the mass margins. The framework includes a novel interpretable neural network algorithm that uses case-based reasoning for mammography. Our algorithm can incorporate a combination of data with whole image labelling and data with pixel-wise annotations, leading to better accuracy and interpretability even with a small number of images. Our interpretable models are able to highlight the classification-relevant parts of the image, whereas other methods highlight healthy tissue and confounding information. Our models are decision aids-rather than decision makers-and aim for better overall human-machine collaboration. We do not observe a loss in mass margin classification accuracy over a black box neural network trained on the same data. The black-box nature of neural networks is a concern for high-stakes medical applications in which decisions must be based on medically relevant features. The authors develop an interpretable machine learning-based framework that aims to follow the reasoning processes of radiologists in providing predictions for cancer diagnosis in mammography.","[Barnett, Alina Jade; Tao, Chaofan; Rudin, Cynthia] Duke Univ, Dept Comp Sci, Durham, NC 27708 USA; [Schwartz, Fides Regina; Lo, Joseph Y.] Duke Univ, Dept Radiol, Durham, NC 27710 USA; [Tao, Chaofan] Univ Maine, Sch Comp & Informat Sci, Orono, ME USA; [Ren, Yinhao; Lo, Joseph Y.] Duke Univ, Dept Biomed Engn, Durham, NC 27706 USA; [Lo, Joseph Y.; Rudin, Cynthia] Duke Univ, Dept Elect & Comp Engn, Durham, NC USA; [Rudin, Cynthia] Duke Univ, Dept Stat Sci, Durham, NC USA; [Rudin, Cynthia] Duke Univ, Dept Biostatist Bioinformat, Durham, NC USA",,"Barnett, AJ (corresponding author), Duke Univ, Dept Comp Sci, Durham, NC 27708 USA.",alina.barnett@duke.edu,,,,,,,,71,77,,,,,,,,,,,DEC,2021,3,12,,,,,1061,+,,10.1038/s42256-021-00423-x,http://dx.doi.org/10.1038/s42256-021-00423-x,,DEC 2021,,,,,,,,,,2025-05-29,WOS:000730505100002,View Full Record in Web of Science
J,"Razavi, S",,,,"Razavi, Saman",,,"Deep learning, explained: Fundamentals, explainability, and bridgeability to process-based modelling",ENVIRONMENTAL MODELLING & SOFTWARE,,,,Article,,,,,,,,"Recent breakthroughs in artificial intelligence (AI), and particularly in deep learning (DL), have created tremendous excitement and opportunities in the earth and environmental sciences communities. To leverage these new 'data-driven' technologies, however, one needs to understand the fundamental concepts that give rise to DL and how they differ from 'process-based', mechanistic modelling. This paper revisits those fundamentals and addresses 10 questions that might be posed by earth and environmental scientists, and with the aid of a real world modelling experiment, it explains some critical, but often ignored, issues DL may face in practice. The overarching objective is to contribute to a future of AI-assisted earth and environmental sciences where AI models can (1) embrace the typically ignored knowledge base available, (2) function credibly in 'true' out-of sample prediction, and (3) handle non-stationarity in earth and environmental systems. Comparing and contrasting earth and environmental problems with prominent AI applications, such as playing chess and trading in stock markets, provides critical insights for better directing future research in this field.","[Razavi, Saman] Univ Saskatchewan, Sch Environm & Sustainabil, Dept Civil Geol & Environm Engn, Saskatoon, SK, Canada; [Razavi, Saman] Univ Saskatchewan, Global Inst Water Secur, Saskatoon, SK, Canada",,"Razavi, S (corresponding author), Univ Saskatchewan, Sch Environm & Sustainabil, Dept Civil Geol & Environm Engn, Saskatoon, SK, Canada.;Razavi, S (corresponding author), Univ Saskatchewan, Global Inst Water Secur, Saskatoon, SK, Canada.",saman.razavi@usask.ca,,,,,,,,103,107,,,,,,,,,,,OCT,2021,144,,,,,,,,105159,10.1016/j.envsoft.2021.105159,http://dx.doi.org/10.1016/j.envsoft.2021.105159,,SEP 2021,,,,,,,,,,2025-05-29,WOS:000696696700004,View Full Record in Web of Science
J,"Estivill-Castro, V; Gilmore, E; Hexel, R",,,,"Estivill-Castro, Vladimir; Gilmore, Eugene; Hexel, Rene",,,Constructing Explainable Classifiers from the Start-Enabling Human-in-the Loop Machine Learning,INFORMATION,,,,Article,,,,,,,,"Interactive machine learning (IML) enables the incorporation of human expertise because the human participates in the construction of the learned model. Moreover, with human-in-the-loop machine learning (HITL-ML), the human experts drive the learning, and they can steer the learning objective not only for accuracy but perhaps for characterisation and discrimination rules, where separating one class from others is the primary objective. Moreover, this interaction enables humans to explore and gain insights into the dataset as well as validate the learned models. Validation requires transparency and interpretable classifiers. The huge relevance of understandable classification has been recently emphasised for many applications under the banner of explainable artificial intelligence (XAI). We use parallel coordinates to deploy an IML system that enables the visualisation of decision tree classifiers but also the generation of interpretable splits beyond parallel axis splits. Moreover, we show that characterisation and discrimination rules are also well communicated using parallel coordinates. In particular, we report results from the largest usability study of a IML system, confirming the merits of our approach.","[Estivill-Castro, Vladimir] Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona 08018, Spain; [Gilmore, Eugene; Hexel, Rene] Griffith Univ, Sch Informat & Commun Technol, Brisbane, Qld 4111, Australia",,"Gilmore, E (corresponding author), Griffith Univ, Sch Informat & Commun Technol, Brisbane, Qld 4111, Australia.",eugene.gilmore@alumni.griffithuni.edu.au,,,,,,,,1,1,,,,,,,,,,,OCT,2022,13,10,,,,,,,464,10.3390/info13100464,http://dx.doi.org/10.3390/info13100464,,,,,,,,,,,,2025-05-29,WOS:000875297600001,View Full Record in Web of Science
J,"Cheng, CS; Behzadan, AH; Noshadravan, A",,,,"Cheng, Chih-Shen; Behzadan, Amir H.; Noshadravan, Arash",,,Uncertainty-aware convolutional neural network for explainable artificial intelligence-assisted disaster damage assessment,STRUCTURAL CONTROL & HEALTH MONITORING,,,,Article,,,,,,,,"Accurate damage assessment is a critical step in post-disaster risk assessment, mitigation, and recovery. Current practices performed by experts and reconnaissance teams in the form of field evaluation require considerable time and resources. Recent advances in remote sensing imagery, artificial intelligence (AI), and computer vision have enhanced automated and rapid disaster damage assessment. Recent literature has shown promising progress in AI-assisted aerial damage assessment. However, accounting for the uncertainty in the outcome for improved quantification of confidence and enhanced model explainability for human decision-makers remains one of the key challenges. Overlooking uncertainty can lead to erroneous decisions, especially in highly-consequential tasks such as damage assessment. The aim of this study is to develop uncertainty-aware deep learning models for the assessment of post-disaster damage using aerial imaging. Within the framework of variational Bayesian inference, Monte Carlo dropout sampling technique is used to propagate epistemic uncertainty in model predictions. With this stochastic setting, the model produces damage prediction labels with softmax as random variables, which helps quantify confidence in the model outcome using appropriate measures of uncertainty. Two networks are implemented and trained separately on two different disaster damage datasets consisting of unmanned aerial vehicle building footage as well as satellite-captured post-disaster imagery. The first network attains 59.4% accuracy in building classification, and the second network gives an accuracy of 55.1%. Results from uncertainty analysis, model confidence quantification, and analyzing model attention zone can lead to more explainable and risk-informed automated damage assessment outcomes using AI technology.","[Cheng, Chih-Shen; Noshadravan, Arash] Texas A&M Univ, Zachry Dept Civil & Environm Engn, College Stn, TX 77843 USA; [Behzadan, Amir H.] Texas A&M Univ, Dept Construct Sci, College Stn, TX 77843 USA",,"Noshadravan, A (corresponding author), Texas A&M Univ, Zachry Dept Civil & Environm Engn, College Stn, TX 77843 USA.",noshadravan@tamu.edu,,,,,,,,19,19,,,,,,,,,,,OCT,2022,29,10,,,,,,,e3019,10.1002/stc.3019,http://dx.doi.org/10.1002/stc.3019,,JUN 2022,,,,,,,,,,2025-05-29,WOS:000806161900001,View Full Record in Web of Science
J,"Zace, D; Semeraro, F; Schnaubelt, S; Montomoli, J; Ristagno, G; Fijacko, N; Gamberini, L; Bignami, EG; Greif, R; Monsieurs, KG; Scapigliati, A",,,,"Zace, Drieda; Semeraro, Federico; Schnaubelt, Sebastian; Montomoli, Jonathan; Ristagno, Giuseppe; Fijacko, Nino; Gamberini, Lorenzo; Bignami, Elena G.; Greif, Robert; Monsieurs, Koenraad G.; Scapigliati, Andrea",,,Artificial intelligence in resuscitation: a scoping review,RESUSCITATION PLUS,,,,Review,,,,,,,,"Background: Artificial intelligence (AI) is increasingly applied in medicine, with growing interest in its potential to improve outcomes in cardiac arrest (CA). However, the scope and characteristics of current AI applications in resuscitation remain unclear. Methods: This scoping review aims to map the existing literature on AI applications in CA and resuscitation and identify research gaps for further investigation. PRISMA-ScR framework and ILCOR guidelines were followed. A systematic literature search across PubMed, EMBASE, and Cochrane identified AI applications in resuscitation. Articles were screened and classified by AI methodology, study design, outcomes, and implementation settings. AI-assisted data extraction was manually validated for accuracy. Results: Out of 4046 records, 197 studies met inclusion criteria. Most were retrospective (90%), with only 16 prospective studies and 2 randomised controlled trials. AI was predominantly applied in prediction of CA, rhythm classification, and post-resuscitation outcome prognostication. Machine learning was the most commonly used method (50% of studies), followed by deep learning and, less frequently, natural language processing. Reported performance was generally high, with AUROC values often exceeding 0.85; however, external validation was rare and real-world implementation limited. Conclusions: While AI applications in resuscitation demonstrate encouraging performance in prediction and decision support tasks, clear evidence of improved patient outcomes or routine clinical use remains limited. Future research should focus on prospective validation, equity in data sources, explainability, and seamless integration of AI tools into clinical workflows.","[Zace, Drieda] Univ Roma Tor Vergata, Dept Syst Med, Rome, Italy; [Semeraro, Federico; Gamberini, Lorenzo] Maggiore Hosp Carlo Alberto Pizzardi, Dept Anaesthesia Intens Care & Prehosp Emergency, Bologna, Italy; [Schnaubelt, Sebastian] PULS Austrian Cardiac Arrest Awareness Assoc, Vienna, Austria; [Schnaubelt, Sebastian] Emergency Med Serv Vienna, Vienna, Austria; [Schnaubelt, Sebastian] Med Univ Vienna, Dept Emergency Med, Vienna, Austria; [Montomoli, Jonathan] Infermi Hosp, Romagna Local Hlth Author, Dept Anaesthesia & Intens Care, Rimini, Italy; [Ristagno, Giuseppe] Univ Milan, Dept Pathophysiol & Transplantat, Milan, Italy; [Ristagno, Giuseppe] Fdn IRCCS Ca Granda Osped Maggiore Policlin, Milan, Italy; [Fijacko, Nino] Univ Maribor, Fac Hlth Sci, Maribor, Slovenia; [Greif, Robert] Univ Bern, Fac Med, Bern, Switzerland; [Greif, Robert] Univ Torino, Dept Surg Sci, Turin, Italy; [Monsieurs, Koenraad G.] Antwerp Univ Hosp, Dept Emergency Med, Antwerp, Belgium; [Monsieurs, Koenraad G.] Univ Antwerp, Antwerp, Belgium; [Scapigliati, Andrea] Univ Cattolica Sacro Cuore, Fdn Policlin Univ A Gemelli, IRCCS, Inst Anaesthesia & Intens Care, Rome, Italy",,"Bignami, EG (corresponding author), Univ Parma, Dept Med & Surg, Anesthesiol Crit Care & Pain Med Div, Parma, Italy.",elenagiovanna.bignami@unipr.it,,,,,,,,0,0,,,,,,,,,,,JUL,2025,24,,,,,,,,100973,10.1016/j.resplu.2025.100973,http://dx.doi.org/10.1016/j.resplu.2025.100973,,,,,,,,,,,,2025-05-29,WOS:001492234400003,View Full Record in Web of Science
J,"Omeiza, D; Webb, H; Jirotka, M; Kunze, L",,,,"Omeiza, Daniel; Webb, Helena; Jirotka, Marina; Kunze, Lars",,,Explanations in Autonomous Driving: A Survey,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,,,,Article,,,,,,,,"The automotive industry has witnessed an increasing level of development in the past decades; from manufacturing manually operated vehicles to manufacturing vehicles with a high level of automation. With the recent developments in Artificial Intelligence (AI), automotive companies now employ blackbox AI models to enable vehicles to perceive their environment and make driving decisions with little or no input from a human. With the hope to deploy autonomous vehicles (AV) on a commercial scale, the acceptance of AV by society becomes paramount and may largely depend on their degree of transparency, trustworthiness, and compliance with regulations. The assessment of the compliance of AVs to these acceptance requirements can be facilitated through the provision of explanations for AVs' behaviour. Explainability is therefore seen as an important requirement for AVs. AVs should be able to explain what they have `seen', done, and might do in environments in which they operate. In this paper, we provide a comprehensive survey of the existing work in explainable autonomous driving. First, we open by providing a motivation for explanations by highlighting the importance of transparency, accountability, and trust in AVs; and examining existing regulations and standards related to AVs. Second, we identify and categorise the different stakeholders involved in the development, use, and regulation of AVs and elicit their AV explanation requirements. Third, we provide a rigorous review of previous work on explanations for the different AV operations (i.e., perception, localisation, planning, vehicle control, and system management). Finally, we discuss pertinent challenges and provide recommendations including a conceptual framework for AV explainability. This survey aims to provide the fundamental knowledge required of researchers who are interested in explanation provisions in autonomous driving.","[Omeiza, Daniel; Jirotka, Marina] Univ Oxford, Dept Comp Sci, Oxford OX1 2JD, England; [Webb, Helena] Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England; [Kunze, Lars] Univ Oxford, Oxford Robot Inst, Dept Engn Sci, Oxford OX1 2JD, England",,"Omeiza, D (corresponding author), Univ Oxford, Dept Comp Sci, Oxford OX1 2JD, England.",daniel.omeiza@cs.ox.ac.uk; helena.webb@nottingham.ac.uk; lars@robots.ox.ac.uk,,,,,,,,159,167,,,,,,,,,,,AUG,2022,23,8,,,,,10142,10162,,10.1109/TITS.2021.3122865,http://dx.doi.org/10.1109/TITS.2021.3122865,,NOV 2021,,,,,,,,,,2025-05-29,WOS:000732330800001,View Full Record in Web of Science
J,"Lawless, WF; Mittu, R; Sofge, D; Hiatt, L",,,,"Lawless, W. F.; Mittu, Ranjeev; Sofge, Donald; Hiatt, Laura",,,"Artificial Intelligence, Autonomy, and Human-Machine Teams: Interdependence, Context, and Explainable AI",AI MAGAZINE,,,,Article,,,,,,,,"Because in military situations, as well as for self-driving cars, information must be processed faster than humans can achieve, determination of context computationally, also known as situational assessment, is increasingly important. In this article, we introduce the topic of context, and we discuss what is known about the heretofore intractable research problem on the effects of interdependence, present in the best of human teams; we close by proposing that interdependence must be mastered mathematically to operate human-machine teams efficiently, to advance theory, and to make the machine actions directed by AI explainable to learn members and society. The special topic articles in this issue and a subsequent issue of AI Magazine review ongoing mature research and operational programs that address context for human-machine learns.","[Lawless, W. F.] US DOE, Savannah River Site, Aiken, SC 29802 USA; [Mittu, Ranjeev] US Naval Res Lab, Informat Management & Decis Architectures Branch, Informat Technol Div, Washington, DC USA; [Sofge, Donald] US Naval Res Lab, NRL, Washington, DC USA; [Hiatt, Laura] US Naval Res Lab, Washington, DC USA",,"Lawless, WF (corresponding author), US DOE, Savannah River Site, Aiken, SC 29802 USA.",,,,,,,,,26,26,,,,,,,,,,,FAL,2019,40,3,,,,,5,13,,10.1609/aimag.v40i3.2866,http://dx.doi.org/10.1609/aimag.v40i3.2866,,,,,,,,,,,,2025-05-29,WOS:000492858200003,View Full Record in Web of Science
J,"Nakao, Y; Stumpf, S; Ahmed, S; Naseer, A; Strappelli, L",,,,"Nakao, Yuri; Stumpf, Simone; Ahmed, Subeida; Naseer, Aisha; Strappelli, Lorenzo",,,Toward Involving End-users in Interactive Human-in-the-loop AI Fairness,ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS,,,,Article,,,,,,,,"Ensuring fairness in artificial intelligence (AI) is important to counteract bias and discrimination in far-reaching applications. Recent work has started to investigate how humans judge fairness and how to support machine learning experts in making their AI models fairer. Drawing inspiration from an Explainable AI approach called explanatory debugging used in interactive machine learning, our work explores designing interpretable and interactive human-in-the-loop interfaces that allow ordinary end-users without any technical or domain background to identify potential fairness issues and possibly fix them in the context of loan decisions. Through workshops with end-users, we co-designed and implemented a prototype system that allowed end-users to see why predictions were made, and then to change weights on features to debug fairness issues. We evaluated the use of this prototype system through an online study. To investigate the implications of diverse human values about fairness around the globe, we also explored how cultural dimensions might play a role in using this prototype. Our results contribute to the design of interfaces to allow end-users to be involved in judging and addressing AI fairness through a human-in-the-loop approach.","[Nakao, Yuri] Fujitsu Ltd, Res Ctr AI Eth, Kawasaki, Kanagawa, Japan; [Stumpf, Simone] Univ Glasgow, Glasgow, Lanark, Scotland; [Ahmed, Subeida; Strappelli, Lorenzo] City Univ London, London, England; [Naseer, Aisha] Fujitsu Res Europe Ltd, Hayes, England",,"Nakao, Y (corresponding author), Fujitsu Ltd, Res Ctr AI Eth, Kawasaki, Kanagawa, Japan.",nakao.yuri@fujitsu.com; simone.stumpf@glasgow.ac.uk; subeida.ahmed@city.ac.uk; aisha.naseer@uk.fujitsu.com; lorenzo.strappelli@city.ac.uk,,,,,,,,26,26,,,,,,,,,,,SEP,2022,12,3,,,,,,,18,10.1145/3514258,http://dx.doi.org/10.1145/3514258,,,,,,,,,,,,2025-05-29,WOS:000842011600002,View Full Record in Web of Science
J,"Wagle, V; Kaur, K; Kamat, P; Patil, S; Kotecha, K",,,,"Wagle, Vidisha; Kaur, Kulveen; Kamat, Pooja; Patil, Shruti; Kotecha, Ketan",,,Explainable AI for Multimodal Credibility Analysis: Case Study of Online Beauty Health (Mis)-Information,IEEE ACCESS,,,,Article,,,,,,,,"One person's data or experience is another person's information this has become the golden rule of the 21st century which has resulted in a massive reservoir of data and immense amounts of information generation. However, there is no control over the source of this information, accessibility of this information, or the quality of it, which has given rise to the presence of misinformation. The research community has reacted by proposing frameworks and difficulties, which are helpful for (different subtasks of) recognizing misinformation. Most of these frameworks, however, fail to consider all the aspects that can contribute to making information credible. Furthermore, a valid explanation for each considered feature's contribution to the model's decision stands missing in most work. With this in mind, the authors have attempted to produce a system that yields highly accurate decisions, thus effectively separating credible health blogs from their non-credible counterparts while providing valid user-friendly explanations. The study proposes an Explainable AI-assisted Multimodal Credibility Assessment System that examines the credibility of the platform where the blog is hosted, the credibility of the author of the blog and the credibility of the images that contribute to the blog. This novel framework contributes to the existing body of knowledge by assessing the credibility of misleading beauty blogs using multiple crucial modalities which would lead to an insightful information consumption by the users. The proposed pipeline was successfully implemented on multiple carefully curated datasets and correctly identified 274 non credible blogs out of 321 blogs with an accuracy of 97.5%, Precision of 0.973 & F1score of 0.986. Further, the Explainable AI model, with the help of several visualizations displayed the feature contributions for each blog & it's impact and magnitude in a concise comprehensible format. The framework can be further customized and applied to various domains where presence of misinformation is of high concern such as pharmaceutical drug information, pandemic management, financial advisories, online healthcare services and cyber frauds.","[Wagle, Vidisha; Kaur, Kulveen; Kamat, Pooja] Symbiosis Int Deemed Univ, Symbiosis Inst Technol, Pune 412115, Maharashtra, India; [Patil, Shruti; Kotecha, Ketan] Symbiosis Int Deemed Univ, Symbiosis Ctr Appl Artificial Intelligence, Symbiosis Inst Technol, Pune 412115, Maharashtra, India",,"Patil, S; Kotecha, K (corresponding author), Symbiosis Int Deemed Univ, Symbiosis Ctr Appl Artificial Intelligence, Symbiosis Inst Technol, Pune 412115, Maharashtra, India.",shruti.patil@sitpune.edu.in; director@sitpune.edu.in,,,,,,,,7,7,,,,,,,,,,,,2021,9,,,,,,127985,128022,,10.1109/ACCESS.2021.3111527,http://dx.doi.org/10.1109/ACCESS.2021.3111527,,,,,,,,,,,,2025-05-29,WOS:000697810600001,View Full Record in Web of Science
J,"Gammulle, H; Ahmedt-Aristizabal, D; Denman, S; Tychsen-Smith, L; Petersson, L; Fookes, C",,,,"Gammulle, Harshala; Ahmedt-Aristizabal, David; Denman, Simon; Tychsen-Smith, Lachlan; Petersson, Lars; Fookes, Clinton",,,Continuous Human Action Recognition for Human-machine Interaction: A Review,ACM COMPUTING SURVEYS,,,,Review,,,,,,,,"With advances in data-driven machine learning research, a wide variety of prediction models have been proposed to capture spatio-temporal features for the analysis of video streams. Recognising actions and detecting action transitions within an input video are challenging but necessary tasks for applications that require real-time human-machine interaction. By reviewing a large body of recent related work in the literature, we thoroughly analyse, explain, and compare action segmentation methods and provide details on the feature extraction and learning strategies that are used on most state-of-the-art methods. We cover the impact of the performance of object detection and tracking techniques on human action segmentation methodologies. We investigate the application of such models to real-world scenarios and discuss several limitations and key research directions towards improving interpretability, generalisation, optimisation, and deployment.","[Gammulle, Harshala; Denman, Simon; Fookes, Clinton] Queensland Univ Technol QUT, 2 George St, Brisbane, Qld 4000, Australia; [Ahmedt-Aristizabal, David; Tychsen-Smith, Lachlan; Petersson, Lars] CSIRO Data61, Epping, NSW, Australia; [Ahmedt-Aristizabal, David; Tychsen-Smith, Lachlan; Petersson, Lars] Commonwealth Sci & Ind Res Org CSIRO, 101 Clunies Ross St, Canberra, ACT 2601, Australia",,"Gammulle, H (corresponding author), Queensland Univ Technol QUT, 2 George St, Brisbane, Qld 4000, Australia.",pranali.gammule@qut.edu.au; david.ahmedtaristizabal@data61.csiro.auqut.edu.au; s.denaman@qut.edu.au; lachlan.tychsen-smith@data61.csiro.au; lars.peterson@data61.csiro.au; c.fookes@qut.edu.au,,,,,,,,16,17,,,,,,,,,,,DEC,2023,55,13S,,,,,,,272,10.1145/3587931,http://dx.doi.org/10.1145/3587931,,,,,,,,,,,,2025-05-29,WOS:001056300600010,View Full Record in Web of Science
J,"Ma, JY; Kang, TW; Xu, XL",,,,"Ma, Jing-Yan; Kang, Tae-Won; Xu, Xiao-Long",,,A Study on the Effects of AI Healthcare Services on Consumer Behavior Intentions: Business Opportunities for Korea,JOURNAL OF KOREA TRADE,,,,Article,,,,,,,,"Purpose - Medical Artificial Intelligence (AI) is improving healthcare services. The purpose of this study is to understand the factors influencing consumer intentions to use it, with the goal of aiding its successful integration into the healthcare ecosystem. Design/Methodology - This study utilized empirical analysis and conducted structural equation analysis. Findings - The characteristics of AI healthcare management services (compatibility, usability, security) positively influence consumer usage intentions, with dynamic capabilities and trust mediating, and interactivity moderating the effect. Originality/value - When implementing AI healthcare solutions, effective human-machine interactions can enhance consumer perceptions of the dynamic capabilities of AI technology, promoting the trust and acceptance of AI healthcare among consumers","[Ma, Jing-Yan; Kang, Tae-Won] Kunsan Natl Univ, Dept Supply Chain & Logist, Gunsan, South Korea; [Xu, Xiao-Long] Kunsan Natl Univ, Coll Humanities, Dept Chinese Studies, Gunsan, South Korea",,"Kang, TW (corresponding author), Kunsan Natl Univ, Dept Supply Chain & Logist, Gunsan, South Korea.",twkang@kunsan.ac.kr,,,,,,,,0,0,,,,,,,,,,,AUG,2024,28,5,,,,,,,,10.35611/jkt.2024.28.5.185,http://dx.doi.org/10.35611/jkt.2024.28.5.185,,,,,,,,,,,,2025-05-29,WOS:001322415600008,View Full Record in Web of Science
J,"Heimerl, A; Weitz, K; Baur, T; André, E",,,,"Heimerl, Alexander; Weitz, Katharina; Baur, Tobias; Andre, Elisabeth",,,Unraveling ML Models of Emotion With NOVA: Multi-Level Explainable AI for Non-Experts,IEEE TRANSACTIONS ON AFFECTIVE COMPUTING,,,,Article,,,,,,,,"In this article, we introduce a next-generation annotation tool called NOVA for emotional behaviour analysis, which implements a workflow that interactively incorporates the 'human in the loop'. A main aspect of NOVA is the possibility of applying semi-supervised active learning where Machine Learning techniques are used already during the annotation process by giving the possibility to pre-label data automatically. Furthermore, NOVA implements recent eXplainable AI (XAI) techniques to provide users with both, a confidence value of the automatically predicted annotations, as well as visual explanations. We investigate how such techniques can assist non-experts in terms of trust, perceived self-efficacy, cognitive workload as well as creating correct mental models about the system by conducting a user study with 53 participants. The results show that NOVA can easily be used by non-experts and lead to a high computer self-efficacy. Furthermore, the results indicate that XAI visualisations help users to create more correct mental models about the machine learning system compared to the baseline condition. Nevertheless, we suggest that explanations in the field of AI have to be more focused on user-needs as well as on the classification task and the model they want to explain.","[Heimerl, Alexander; Weitz, Katharina; Baur, Tobias; Andre, Elisabeth] Augsburg Univ, Lab Human Ctr AI, D-86159 Augsburg, Germany",,"Heimerl, A (corresponding author), Augsburg Univ, Lab Human Ctr AI, D-86159 Augsburg, Germany.",heimerl@hcm-lab.de; weitz@hcm-lab.de; baur@hcm-lab.de; andre@hcm-lab.de,,,,,,,,22,22,,,,,,,,,,,JUL-SEP,2022,13,3,,,,,1155,1167,,10.1109/TAFFC.2020.3043603,http://dx.doi.org/10.1109/TAFFC.2020.3043603,,,,,,,,,,,,2025-05-29,WOS:000849263500003,View Full Record in Web of Science
J,"El Arab, RA; Almoosa, Z; Alkhunaizi, M; Abuadas, FH; Somerville, J",,,,"El Arab, Rabie Adel; Almoosa, Zainab; Alkhunaizi, May; Abuadas, Fuad H.; Somerville, Joel",,,Artificial intelligence in hospital infection prevention: an integrative review,FRONTIERS IN PUBLIC HEALTH,,,,Review,,,,,,,,"Background Hospital-acquired infections (HAIs) represent a persistent challenge in healthcare, contributing to substantial morbidity, mortality, and economic burden. Artificial intelligence (AI) offers promising potential for improving HAIs prevention through advanced predictive capabilities. Objective To evaluate the effectiveness, usability, and challenges of AI models in preventing, detecting, and managing HAIs. Methods This integrative review synthesized findings from 42 studies, guided by the SPIDER framework for inclusion criteria. We assessed the quality of included studies by applying the TRIPOD checklist to individual predictive studies and the AMSTAR 2 tool for reviews. Results AI models demonstrated high predictive accuracy for the detection, surveillance, and prevention of multiple HAIs, with models for surgical site infections and urinary tract infections frequently achieving area-under-the-curve (AUC) scores exceeding 0.80, indicating strong reliability. Comparative data suggest that while both machine learning and deep learning approaches perform well, some deep learning models may offer slight advantages in complex data environments. Advanced algorithms, including neural networks, decision trees, and random forests, significantly improved detection rates when integrated with EHRs, enabling real-time surveillance and timely interventions. In resource-constrained settings, non-real-time AI models utilizing historical EHR data showed considerable scalability, facilitating broader implementation in infection surveillance and control. AI-supported surveillance systems outperformed traditional methods in accurately identifying infection rates and enhancing compliance with hand hygiene protocols. Furthermore, Explainable AI (XAI) frameworks and interpretability tools such as Shapley additive explanations (SHAP) values increased clinician trust and facilitated actionable insights. AI also played a pivotal role in antimicrobial stewardship by predicting the emergence of multidrug-resistant organisms and guiding optimal antibiotic usage, thereby reducing reliance on second-line treatments. However, challenges including the need for comprehensive clinician training, high integration costs, and ensuring compatibility with existing workflows were identified as barriers to widespread adoption. Discussion The integration of AI in HAI prevention and management represents a potentially transformative shift in enhancing predictive capabilities and supporting effective infection control measures. Successful implementation necessitates standardized validation protocols, transparent data reporting, and the development of user-friendly interfaces to ensure seamless adoption by healthcare professionals. Variability in data sources and model validations across studies underscores the necessity for multicenter collaborations and external validations to ensure consistent performance across diverse healthcare environments. Innovations in non-real-time AI frameworks offer viable solutions for scaling AI applications in low- and middle-income countries (LMICs), addressing the higher prevalence of HAIs in these regions. Conclusions Artificial Intelligence stands as a transformative tool in the fight against hospital-acquired infections, offering advanced solutions for prevention, surveillance, and management. To fully realize its potential, the healthcare sector must prioritize rigorous validation standards, comprehensive data quality reporting, and the incorporation of interpretability tools to build clinician confidence. By adopting scalable AI models and fostering interdisciplinary collaborations, healthcare systems can overcome existing barriers, integrating AI seamlessly into infection control policies and ultimately enhancing patient safety and care quality. Further research is needed to evaluate cost-effectiveness, real-world applications, and strategies (e.g., clinician training and the integration of explainable AI) to improve trust and broaden clinical adoption.","[El Arab, Rabie Adel; Alkhunaizi, May] Almoosa Coll Hlth Sci, Al Mubarraz, Saudi Arabia; [Almoosa, Zainab] Almoosa Specialist Hosp, Dept Infect Dis, Al Mubarraz, Saudi Arabia; [Alkhunaizi, May] Almoosa Specialist Hosp, Dept Orthoped, Al Mubarraz, Saudi Arabia; [Abuadas, Fuad H.] Jouf Univ, Coll Nursing, Dept Community Hlth Nursing, Sakaka, Saudi Arabia; [Somerville, Joel] Univ Highlands & Isl, Inverness Coll, Inverness, Scotland; [Somerville, Joel] Glasgow Caledonian Univ, Glasgow, Scotland",,"El Arab, RA (corresponding author), Almoosa Coll Hlth Sci, Al Mubarraz, Saudi Arabia.",r.adel@almoosacollege.edu.sa,,,,,,,,0,0,,,,,,,,,,,APR 2,2025,13,,,,,,,,1547450,10.3389/fpubh.2025.1547450,http://dx.doi.org/10.3389/fpubh.2025.1547450,,,,,,,,,,,,2025-05-29,WOS:001468534300001,View Full Record in Web of Science
J,"Baur, T; Heimerl, A; Lingenfelser, F; Wagner, J; Valstar, MF; Schuller, B; André, E",,,,"Baur, Tobias; Heimerl, Alexander; Lingenfelser, Florian; Wagner, Johannes; Valstar, Michel F.; Schuller, Bjoern; Andre, Elisabeth",,,eXplainable Cooperative Machine Learning with NOVA,KUNSTLICHE INTELLIGENZ,,,,Article,,,,,,,,"In the following article, we introduce a novel workflow, which we subsume under the term explainable cooperative machine learning and show its practical application in a data annotation and model training tool called NOVA. The main idea of our approach is to interactively incorporate the 'human in the loop' when training classification models from annotated data. In particular, NOVA offers a collaborative annotation backend where multiple annotators join their workforce. A main aspect is the possibility of applying semi-supervised active learning techniques already during the annotation process by giving the possibility to pre-label data automatically, resulting in a drastic acceleration of the annotation process. Furthermore, the user-interface implements recent eXplainable AI techniques to provide users with both, a confidence value of the automatically predicted annotations, as well as visual explanation. We show in an use-case evaluation that our workflow is able to speed up the annotation process, and further argue that by providing additional visual explanations annotators get to understand the decision making process as well as the trustworthiness of their trained machine learning models.","[Baur, Tobias; Heimerl, Alexander; Lingenfelser, Florian; Wagner, Johannes; Schuller, Bjoern; Andre, Elisabeth] Augsburg Univ, Univ Str 6a, Augsburg, Germany; [Valstar, Michel F.] Univ Nottingham, Nottingham, England",,"Baur, T (corresponding author), Augsburg Univ, Univ Str 6a, Augsburg, Germany.",baur@hcm-lab.de,,,,,,,,25,25,,,,,,,,,,,JUN,2020,34,2,,,SI,,143,164,,10.1007/s13218-020-00632-3,http://dx.doi.org/10.1007/s13218-020-00632-3,,JAN 2020,,,,,,,,,,2025-05-29,WOS:000507933200001,View Full Record in Web of Science
J,"Nallakaruppan, MK; Balusamy, B; Shri, ML; Malathi, V; Bhattacharyya, S",,,,"Nallakaruppan, M. K.; Balusamy, Balamurugan; Shri, M. Lawanya; Malathi, V.; Bhattacharyya, Siddhartha",,,An Explainable AI framework for credit evaluation and analysis,APPLIED SOFT COMPUTING,,,,Article,,,,,,,,"Loan Facility is a profitable venture for the banking industry and can render great financial support to the beneficiary. The Global banking systems with secured private cloud are making the service reachable around the world around the clock. Loan acceptance and disbursal are governed by the protocol of the banks with the highest degree of privacy and integrity. As per the report of Experian, the loan acceptance rate of the banks has been reduced to 61%-70%, and it is further reduced to 50% post -pandemic since there is a huge financial setback and a higher rate of defaulters. The banks are not in a position to explain the reasoning behind the rejection since the rejection further diminishes the customers' credit scores. With the parallel improvements in Industry 5.0, futuristic banking could evolve around Non Fungible Tokens (NFT) integrated Explainable AI (XAI) framework which can interact with the customer through the human -machine interface in the meta -verse. For such a kind of system, the proposed work could be a driving application which provides explanations for the loan rejection, with the Random Forest integrated XAI framework that provides the reasons for acceptance and rejection of the loan. The proposed Random Forest -based approach rendered the highest accuracy, sensitivity and specificity of 0.998, 0.998, and 0.997, respectively. The LIME and SHAPELY Explainers provide explanations with local and global surrogates of various parameters on the features.","[Nallakaruppan, M. K.; Shri, M. Lawanya] Vellore Inst Technol, Sch Comp Sci Engn & Informat Syst, Vellore 632014, TamilNadu, India; [Balusamy, Balamurugan] Shiv Nadar Inst Eminence, Delhi NCR, Greater Noida 201314, Uttar Pradesh, India; [Malathi, V.] Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 600119, Tamilnadu, India; [Bhattacharyya, Siddhartha] VSB Tech Univ Ostrava, Fac Elect Engn & Comp Sci, Ostrava 70800, Czech Republic; [Bhattacharyya, Siddhartha] Algebra Univ Coll, Zagreb 10000, Croatia",,"Bhattacharyya, S (corresponding author), VSB Tech Univ Ostrava, Fac Elect Engn & Comp Sci, Ostrava 70800, Czech Republic.",siddhartha.bhattacharyya@vsb.cz,,,,,,,,8,8,,,,,,,,,,,MAR,2024,153,,,,,,,,111307,10.1016/j.asoc.2024.111307,http://dx.doi.org/10.1016/j.asoc.2024.111307,,JAN 2024,,,,,,,,,,2025-05-29,WOS:001173520500001,View Full Record in Web of Science
J,"Sheu, RK; Pardeshi, MS; Pai, KC; Chen, LC; Wu, CL; Chen, WC",,,,"Sheu, Ruey-Kai; Pardeshi, Mayuresh Sunil; Pai, Kai-Chih; Chen, Lun-Chi; Wu, Chieh-Liang; Chen, Wei-Cheng",,,Interpretable Classification of Pneumonia Infection Using eXplainable AI (XAI-ICP),IEEE ACCESS,,,,Article,,,,,,,,"Open-box models in the medical domain have high acceptance and demand by many medical examiners. Even though the accuracy predicted by most of convolutional neural network (CNN) models is high, it is still not convincing as the detailed discussion regarding the outcome is semi-transparent in the functioning process. Pneumonia is known as one of the top contagious infections that makes most of the population affected due to low immunity. Therefore, the goal of this paper is to implement an interpretable classification of pneumonia infection using eXplainable AI (XAI-ICP). Thus, XAI-ICP is the highly efficient system designed to solve this challenge by adapting to the recent population health conditions. The aim is to design an interpretable deep classification and transfer learning based evaluation for pneumonia infection classification. The model is primarily pre-trained using the open Chest X-Ray (CXR) dataset from National Institutes of Health (NIH). Whereas, the training input and testing given to this system is Taichung Veterans General Hospital (TCVGH) for independent learning, Taiwan + VinDr open dataset for transfer learning of pneumonia affected patients with labeled CXR images possessing three features of infiltrate, cardiomegaly and effusion. The data labeling is performed by the medical examiners with the XAI human-in-the-loop approach. XAI-ICP demonstrates the XAI based reconfigurable DCNN with human-in-the-loop as a novel approach. The interpretable deep classification provides detailed transparency analysis and transfer learning for competitive accuracy. The purpose of this work, to design a re-configurable model that can continuously improve itself by using a feedback system and provide feasibility for the model deployment across multiple countries to provide an efficient system for the pneumonia infection classification. The designed model then provides detailed decisions taken at each step as transparency and features used within the algorithm for the pneumonia classification during the hospitalization. Thus, the scope can be given as explainable AI usage for the diagnosis classification using data preprocessing and interpretable deep convolutional neural network by the CXR evaluation. The accuracy achieved by using independent learning classification is 92.14% and is further improved based on successive transfer learning based evaluation is 93.29%. The XAI-ICP model adapts to the different populations by using transfer learning, while providing competitive results to the affected conditions.","[Sheu, Ruey-Kai; Chen, Wei-Cheng] Tunghai Univ, Dept Comp Sci, Taichung 407224, Taiwan; [Pardeshi, Mayuresh Sunil] Tunghai Univ, Artificial Intelligence AI Ctr, Taichung 407224, Taiwan; [Pai, Kai-Chih; Chen, Lun-Chi] Tunghai Univ, Coll Engn, Taichung 407224, Taiwan; [Wu, Chieh-Liang] Taichung Vet Gen Hosp, Dept Crit Care Med, Taichung 40705, Taiwan; [Wu, Chieh-Liang] Tunghai Univ, Dept Ind Engn & Enterprise Informat, Taichung 407224, Taiwan; [Wu, Chieh-Liang] Feng Chia Univ, Dept Automat Control Engn, Taichung 40724, Taiwan",,"Pardeshi, MS (corresponding author), Tunghai Univ, Artificial Intelligence AI Ctr, Taichung 407224, Taiwan.",mayuresh@thu.edu.tw,,,,,,,,17,17,,,,,,,,,,,,2023,11,,,,,,28896,28919,,10.1109/ACCESS.2023.3255403,http://dx.doi.org/10.1109/ACCESS.2023.3255403,,,,,,,,,,,,2025-05-29,WOS:000966723200001,View Full Record in Web of Science
J,"Bhattacharya, M; Penica, M; O'Connell, E; Southern, M; Hayes, M",,,,"Bhattacharya, Mangolika; Penica, Mihai; O'Connell, Eoin; Southern, Mark; Hayes, Martin",,,Human-in-Loop: A Review of Smart Manufacturing Deployments,SYSTEMS,,,,Review,,,,,,,,"The recent increase in computational capability has led to an unprecedented increase in the range of new applications where machine learning can be used in real time. Notwithstanding the range of use cases where automation is now feasible, humans are likely to retain a critical role in the operation and certification of manufacturing systems for the foreseeable future. This paper presents a use case review of how human operators affect the performance of cyber-physical systems within a 'smart' or 'cognitive' setting. Such applications are classified using Industry 4.0 (I4.0) or 5.0 (I5.0) terminology. The authors argue that, as there is often no general agreement as to when a specific use case moves from being an I4.0 to an I5.0 example, the use of a hybrid Industry X.0 notation at the intersection between I4.0 and I5.0 is warranted. Through a structured review of the literature, the focus is on how secure human-mediated autonomous production can be performed most effectively to augment and optimise machine operation.","[Bhattacharya, Mangolika; Penica, Mihai; O'Connell, Eoin; Hayes, Martin] Univ Limerick, Dept Elect & Comp Engn, Limerick V94T9PX, Ireland; [Southern, Mark] Univ Limerick, Enterprise Res Ctr, Sch Engn, Limerick V94T9PX, Ireland",,"Bhattacharya, M (corresponding author), Univ Limerick, Dept Elect & Comp Engn, Limerick V94T9PX, Ireland.",mango.bhattacharya@ul.ie,,,,,,,,25,26,,,,,,,,,,,JAN,2023,11,1,,,,,,,35,10.3390/systems11010035,http://dx.doi.org/10.3390/systems11010035,,,,,,,,,,,,2025-05-29,WOS:000927761600001,View Full Record in Web of Science
J,"Verhagen, RS; Neerincx, MA; Tielman, ML",,,,"Verhagen, Ruben S. S.; Neerincx, Mark A. A.; Tielman, Myrthe L. L.",,,The influence of interdependence and a transparent or explainable communication style on human-robot teamwork,FRONTIERS IN ROBOTICS AND AI,,,,Article,,,,,,,,"Humans and robots are increasingly working together in human-robot teams. Teamwork requires communication, especially when interdependence between team members is high. In previous work, we identified a conceptual difference between sharing what you are doing (i.e., being transparent) and why you are doing it (i.e., being explainable). Although the second might sound better, it is important to avoid information overload. Therefore, an online experiment (n = 72) was conducted to study the effect of communication style of a robot (silent, transparent, explainable, or adaptive based on time pressure and relevancy) on human-robot teamwork. We examined the effects of these communication styles on trust in the robot, workload during the task, situation awareness, reliance on the robot, human contribution during the task, human communication frequency, and team performance. Moreover, we included two levels of interdependence between human and robot (high vs. low), since mutual dependency might influence which communication style is best. Participants collaborated with a virtual robot during two simulated search and rescue tasks varying in their level of interdependence. Results confirm that in general robot communication results in more trust in and understanding of the robot, while showing no evidence of a higher workload when the robot communicates or adds explanations to being transparent. Providing explanations, however, did result in more reliance on RescueBot. Furthermore, compared to being silent, only being explainable results a higher situation awareness when interdependence is high. Results further show that being highly interdependent decreases trust, reliance, and team performance while increasing workload and situation awareness. High interdependence also increases human communication if the robot is not silent, human rescue contribution if the robot does not provide explanations, and the strength of the positive association between situation awareness and team performance. From these results, we can conclude that robot communication is crucial for human-robot teamwork, and that important differences exist between being transparent, explainable, or adaptive. Our findings also highlight the fundamental importance of interdependence in studies on explainability in robots.","[Verhagen, Ruben S. S.; Neerincx, Mark A. A.; Tielman, Myrthe L. L.] Delft Univ Technol, Intelligent Syst Dept, Interact Intelligence, Delft, Netherlands; [Neerincx, Mark A. A.] Netherlands Org Appl Sci Res TNO, Human Machine Teaming, Amsterdam, Netherlands",,"Verhagen, RS (corresponding author), Delft Univ Technol, Intelligent Syst Dept, Interact Intelligence, Delft, Netherlands.",R.S.Verhagen@tudelft.nl,,,,,,,,10,10,,,,,,,,,,,SEP 8,2022,9,,,,,,,,993997,10.3389/frobt.2022.993997,http://dx.doi.org/10.3389/frobt.2022.993997,,,,,,,,,,,,2025-05-29,WOS:000857305100001,View Full Record in Web of Science
J,"Meng, XD; Wang, QH; Chen, S; Zhang, SJ; Yu, JG; Li, HB; Chen, XK; Wang, ZY; Yu, WZ; Zheng, Z; Zhou, HD; Luo, J; Wang, ZL; Chen, HY; Wu, N; Hu, D; Chen, SH; Wei, Y; Cui, HB; Song, HP; Chen, HJ; Wang, Y; Zhong, J; Chen, Z; Zhang, HK; Yang, TT; Li, MX; Liu, YY; Dong, X; Du, M; Wang, XH; Yao, XY; Lin, HT; Li, MJ; Yan, H",,,,"Meng, Xiangda; Wang, Qihua; Chen, Song; Zhang, Shijie; Yu, Jinguo; Li, Haibo; Chen, Xinkang; Wang, Zhaoyang; Yu, Wenzhen; Zheng, Zhi; Zhou, Heding; Luo, Jing; Wang, Zhiliang; Chen, Haoyu; Wu, Nan; Hu, Dan; Chen, Suihua; Wei, Yong; Cui, Haibin; Song, Huping; Chen, Huijin; Wang, Yun; Zhong, Jie; Chen, Zhen; Zhang, Haokun; Yang, Tiantian; Li, Mengxuan; Liu, Yuanyuan; Dong, Xue; Du, Mei; Wang, Xiaohong; Yao, Xuyang; Lin, Haotian; Li, Mulin Jun; Yan, Hua",,,An interpretable model predicts visual outcomes of no light perception eyes after open globe injury,BRITISH JOURNAL OF OPHTHALMOLOGY,,,,Article,,,,,,,,"BackgroundThe visual outcome of open globe injury (OGI)-no light perception (NLP) eyes is unpredictable traditionally. This study aimed to develop a model to predict the visual outcomes of vitrectomy surgery in OGI-NLP eyes using a machine learning algorithm and to provide an interpretable system for the prediction results. MethodsClinical data of 459 OGI-NLP eyes were retrospectively collected from 19 medical centres across China to establish a training data set for developing a model, called 'VisionGo', which can predict the visual outcome of the patients involved and compare with the Ocular Trauma Score (OTS). Another 72 cases were retrospectively collected and used for human-machine comparison, and an additional 27 cases were prospectively collected for real-world validation of the model. The SHapley Additive exPlanations method was applied to analyse feature contribution to the model. An online platform was built for real-world application. ResultsThe area under the receiver operating characteristic curve (AUC) of VisionGo was 0.75 and 0.90 in previtrectomy and intravitrectomy application scenarios, which was much higher than the OTS (AUC=0.49). VisionGo showed better performance than ophthalmologists in both previtrectomy and intravitrectomy application scenarios (AUC=0.73 vs 0.57 and 0.87 vs 0.64). In real-world validation, VisionGo achieved an AUC of 0.60 and 0.91 in previtrectomy and intravitrectomy application scenarios. Feature contribution analysis indicated that wound length-related indicators, vitreous status and retina-related indicators contributed highly to visual outcomes. ConclusionsVisionGo has achieved an accurate and reliable prediction in visual outcome after vitrectomy for OGI-NLP eyes.","[Meng, Xiangda; Wang, Qihua; Chen, Song; Yu, Jinguo; Zhang, Haokun; Yang, Tiantian; Li, Mengxuan; Liu, Yuanyuan; Dong, Xue; Yan, Hua] Tianjin Med Univ Gen Hosp, Dept Ophthalmol, Tianjin, Peoples R China; [Wang, Qihua] Tsinghua Univ, Beijing Tsinghua Changgung Hosp, Sch Clin Med, Dept Ophthalmol, Beijing, Peoples R China; [Zhang, Shijie; Chen, Xinkang; Du, Mei; Wang, Xiaohong; Li, Mulin Jun] Tianjin Med Univ, Sch Basic Med Sci, Dept Pharmacol, Tianjin Key Lab Inflammat Biol, Tianjin, Peoples R China; [Li, Haibo] Xiamen Univ, Dept Ocular Trauma, Xiamen Eye Ctr, Xiamen, Fujian, Peoples R China; [Wang, Zhaoyang] Tongji Univ, Shanghai Peoples Hosp 10, Sch Med, Dept Ophthalmol, Shanghai, Peoples R China; [Yu, Wenzhen] Peking Univ Peoples Hosp, Dept Ophthalmol, Beijing, Peoples R China; [Zheng, Zhi] Shanghai Jiao Tong Univ, Shanghai Gen Hosp, Dept Ophthalmol, Shanghai, Peoples R China; [Zhou, Heding] Ningbo Eye Hosp, Dept Ophthalmol, Ningbo, Zhejiang, Peoples R China; [Luo, Jing] Cent South Univ, Xiangya Hosp 2, Dept Ophthalmol, Changsha, Peoples R China; [Wang, Zhiliang] Sun Yat sen Univ, Dept Ophthalmol, Zhongshan Sch Med, Guangzhou, Guangdong, Peoples R China; [Chen, Haoyu] Sun Yat sen Univ, Zhongshan Sch Med, Dept Genet & Biomed Informat, Shantou, Guangdong, Peoples R China; [Wu, Nan] Tianjin Med Univ, Prov & Minist Cosponsored Collaborat Innovat Ctr M, Southwest Hosp, Dept Ophthalmol, Chongqing, Peoples R China; [Hu, Dan] Fourth Mil Med Univ, Xijing Hosp, Eye Inst Chinese PLA, Dept Ophthalmol, Xian, Shaanxi, Peoples R China; [Chen, Suihua] Gen Hosp Eastern Theater Command, Dept Ophthalmol, Nanjing, Jiangsu, Peoples R China; [Wei, Yong] Wenzhou Med Univ, Eye Hosp, Natl Clin Res Ctr Ocular Dis, Wenzhou, Zhejiang, Peoples R China; [Cui, Haibin] Heilongjiang Prov Ophthalmol Hosp, Dept Ocular Trauma, Harbin, Heilongjiang, Peoples R China; [Song, Huping] Xian Peoples Hosp, Xian Hosp 4, Dept Ophthalmol, Xian, Shaanxi, Peoples R China; [Chen, Huijin] Peking Univ Third Hosp, Dept Ophthalmol, Beijing Key Lab Restorat Damaged Ocular Nerve, Beijing, Peoples R China; [Wang, Yun] Xining First Peoples Hosp, Dept Ophthalmol, Xining, Qinghai, Peoples R China; [Zhong, Jie] Univ Elect Sci & Technol China, Sichuan Prov Peoples Hosp, Dept Ophthalmol, Chengdu, Sichuan, Peoples R China; [Chen, Zhen] Wuhan Univ, Eye Ctr, Renmin Hosp, Wuhan, Hubei, Peoples R China; [Dong, Xue; Du, Mei; Wang, Xiaohong; Yan, Hua] Tianjin Med Univ, Lab Mol Ophthalmol, Tianjin, Peoples R China; [Dong, Xue; Du, Mei; Wang, Xiaohong; Yan, Hua] Tianjin Med Univ, Tianjin Key Lab Ocular Trauma, Tianjin, Peoples R China; [Yao, Xuyang] Tianjin Med Univ, Eye Hosp, Eye Inst, Tianjin, Peoples R China; [Yao, Xuyang] Sch Optometry & Ophthalmol, Tianjin, Peoples R China; [Lin, Haotian] Sun Yat sen Univ, Guangdong Prov Clin Res Ctr Ocular Dis, Guangdong Prov Key Lab Ophthalmol & Vis Sci, State Key Lab Ophthalmol,Zhongshan Ophthalm Ctr, Guangzhou, Guangdong, Peoples R China; [Lin, Haotian] Sun Yat sen Univ, Hainan Eye Hosp, Zhongshan Ophthalm Ctr, Haikou, Hainan, Peoples R China; [Lin, Haotian] Sun Yat sen Univ, Zhongshan Ophthalm Ctr, Key Lab Ophthalmol, Haikou, Hainan, Peoples R China",,"Yan, H (corresponding author), Tianjin Med Univ Gen Hosp, Dept Ophthalmol, Tianjin, Peoples R China.;Li, MJ (corresponding author), Tianjin Med Univ, Sch Basic Med Sci, Dept Pharmacol, Tianjin Key Lab Inflammat Biol, Tianjin, Peoples R China.;Yan, H (corresponding author), Tianjin Med Univ, Lab Mol Ophthalmol, Tianjin, Peoples R China.;Lin, HT (corresponding author), Sun Yat sen Univ, Guangdong Prov Clin Res Ctr Ocular Dis, Guangdong Prov Key Lab Ophthalmol & Vis Sci, State Key Lab Ophthalmol,Zhongshan Ophthalm Ctr, Guangzhou, Guangdong, Peoples R China.",linht5@mail.sysu.edu.cn; mulin@tmu.edu.cn; zyyyanhua@tmu.edu.cn,,,,,,,,2,2,,,,,,,,,,,FEB,2024,108,2,,,,,285,293,,10.1136/bjo-2022-322753,http://dx.doi.org/10.1136/bjo-2022-322753,,JAN 2023,,,,,,,,,,2025-05-29,WOS:000907628300001,View Full Record in Web of Science
J,"Beltrán, S; Castro, A; Irizar, I; Naveran, G; Yeregui, I",,,,"Beltran, Sergio; Castro, Alain; Irizar, Ion; Naveran, Gorka; Yeregui, Imanol",,,Framework for collaborative intelligence in forecasting day-ahead electricity price,APPLIED ENERGY,,,,Article,,,,,,,,"Electricity price forecasting in wholesale markets is an essential asset for deciding bidding strategies and operational schedules. The decision making process is limited if no understanding is given on how and why such electricity price points have been forecast. The present article proposes a novel framework that promotes human-machine collaboration in forecasting day-ahead electricity price in wholesale markets. The framework is based on a new model architecture that uses a plethora of statistical and machine learning models, a wide range of exogenous features, a combination of several time series decomposition methods and a collection of time series characteristics based on signal processing and time series analysis methods. The model architecture is supported by open-source automated machine learning platforms that provide a baseline reference used for comparison purposes. The objective of the framework is not only to provide forecasts, but to promote a human-in-the-loop approach by providing a data story based on a collection of model-agnostic methods aimed at interpreting the mechanisms and behavior of the new model architecture and its predictions. The framework has been applied to the Spanish wholesale market. The forecasting results show good accuracy on mean absolute error (1.859, 95% HDI [0.575, 3.924] EUR (MWh)(-1) ) and mean absolute scaled error (0.378, 95% HDI [0.091, 0.934]). Moreover, the framework demonstrates its human-centric capabilities by providing graphical and numeric explanations that augments understanding on the model and its electricity price point forecasts.","[Beltran, Sergio; Castro, Alain; Irizar, Ion] Basque Res & Technol Alliance BRTA, Ceit, Manuel Lardizabal 15, Donostia San Sebastian 20018, Spain; [Beltran, Sergio; Castro, Alain; Irizar, Ion] Univ Navarra, Tecnun, Manuel Lardizabal 13, Donostia San Sebastian 20018, Spain; [Naveran, Gorka] Giroa Veolia Serv Norte SA, Laida Bidea Edificio 407, Zamudio 48170, Spain; [Yeregui, Imanol] Genelek Sistemas SL, Plaza Urola, Zumaia 20750, Spain",,"Beltrán, S (corresponding author), Basque Res & Technol Alliance BRTA, Ceit, Manuel Lardizabal 15, Donostia San Sebastian 20018, Spain.",sbeltran@ceit.es,,,,,,,,26,28,,,,,,,,,,,JAN 15,2022,306,,A,,,,,,118049,10.1016/j.apenergy.2021.118049,http://dx.doi.org/10.1016/j.apenergy.2021.118049,,OCT 2021,,,,,,,,,,2025-05-29,WOS:000711977900002,View Full Record in Web of Science
J,"Ott, T; Dabrock, P",,,,"Ott, Tabea; Dabrock, Peter",,,Transparent human - (non-) transparent technology? The Janus-faced call for transparency in AI-based health care technologies,FRONTIERS IN GENETICS,,,,Article,,,,,,,,"The use of Artificial Intelligence and Big Data in health care opens up new opportunities for the measurement of the human. Their application aims not only at gathering more and better data points but also at doing it less invasive. With this change in health care towards its extension to almost all areas of life and its increasing invisibility and opacity, new questions of transparency arise. While the complex human-machine interactions involved in deploying and using AI tend to become non-transparent, the use of these technologies makes the patient seemingly transparent. Papers on the ethical implementation of AI plead for transparency but neglect the factor of the transparent patient  as intertwined with AI. Transparency in this regard appears to be Janus-faced: The precondition for receiving help - e.g., treatment advice regarding the own health - is to become transparent for the digitized health care system. That is, for instance, to donate data and become visible to the AI and its operators. The paper reflects on this entanglement of transparent patients and (non-) transparent technology. It argues that transparency regarding both AI and humans is not an ethical principle per se but an infraethical concept. Further, it is no sufficient basis for avoiding harm and human dignity violations. Rather, transparency must be enriched by intelligibility following Judith Butler's use of the term. Intelligibility is understood as an epistemological presupposition for recognition and the ensuing humane treatment. Finally, the paper highlights ways to testify intelligibility in dealing with AI in health care ex ante, ex post, and continuously.","[Ott, Tabea; Dabrock, Peter] Friedrich Alexander Univ Erlangen Nurnberg, Fac Humanities Social Sci & Theol, Chair Systemat Theol Eth 2, Erlangen, Germany",,"Ott, T (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Fac Humanities Social Sci & Theol, Chair Systemat Theol Eth 2, Erlangen, Germany.",labea.ott@fau.de,,,,,,,,1,1,,,,,,,,,,,AUG 22,2022,13,,,,,,,,902960,10.3389/fgene.2022.902960,http://dx.doi.org/10.3389/fgene.2022.902960,,,,,,,,,,,,2025-05-29,WOS:000874015300001,View Full Record in Web of Science
J,"Nandanwar, H; Katarya, R",,,,"Nandanwar, Himanshu; Katarya, Rahul",,,Securing Industry 5.0: An explainable deep learning model for intrusion detection in cyber-physical systems,COMPUTERS & ELECTRICAL ENGINEERING,,,,Article,,,,,,,,"Cyber-physical systems (CPS) security is critical, particularly with the advent of Industry 5.0, which seeks to revolutionize industrial ecosystems through enhanced automation, connectivity, and human-machine collaboration. While this shift promises increased efficiency and productivity, it exposes systems to advanced cyber threats. This paper introduces Cyber-Sentinet, a Deep Learning-based Intrusion Detection System (IDS) designed explicitly for CPS in industrial IoT environments to address these challenges. Unlike traditional IDS models, Cyber-Sentinet integrates Shapley Additive Explanations (SHAP) to enhance the interpretability of its decisionmaking process, allowing security experts to understand better and trust the system's detections. Rigorous experimentation on the Edge-IIoT-2022 dataset, which covers various cyberattacks (e.g., DDoS, SQL injection, MITM), validates Cyber-Sentinet effectiveness. The model achieves an accuracy of 97.46 %, precision of 97.7 %, and recall of 97.2 %, with a low loss of 0.182. These results demonstrate Cyber-Sentinet ability to offer high-performance intrusion detection and valuable insights into network security, making it a robust solution for protecting Industry 5.0 CPS against sophisticated cyber threats.","[Nandanwar, Himanshu; Katarya, Rahul] Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi, India",,"Katarya, R (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi, India.",himanshunandanwar9cm0@gmail.com; rahulkatarya@dtu.ac.in,,,,,,,,1,1,,,,,,,,,,,APR,2025,123,,C,,,,,,110161,10.1016/j.compeleceng.2025.110161,http://dx.doi.org/10.1016/j.compeleceng.2025.110161,,FEB 2025,,,,,,,,,,2025-05-29,WOS:001431500000001,View Full Record in Web of Science
J,"Waqar, A",,,,"Waqar, Ahsan",,,Intelligent decision support systems in construction engineering: An artificial intelligence and machine learning approaches,EXPERT SYSTEMS WITH APPLICATIONS,,,,Review,,,,,,,,"Intelligent Decision Support Systems (DSS) have gained considerable interest within the field of construction engineering through the utilization of Artificial Intelligence (AI) and Machine Learning (ML) methodologies. These systems possess the capacity to enhance decision-making processes and optimize the results of projects. Nevertheless, it is imperative to conduct a thorough and inclusive examination that incorporates and evaluates the various methodologies employed within this particular discipline, thereby bridging the existing void in research. The current state of research in the field of AI and ML in construction engineering is characterized by a dearth of comprehensive reviews that encompass the wide array of methodologies utilized. Although certain studies have delved into specific facets of this subject, there remains a novelty and research gap in terms of a holistic examination of the topic. The objective of this review is to conduct a comprehensive analysis of AI and ML methodologies in the field of construction engineering, with a specific emphasis on their practical applications, advantages, and constraints. The study also ascertains potential areas for future research and improvement in the domain of Intelligent DSS. This study employed a rigorous approach that involved an extensive review of scholarly literature and empirical investigations from 2001 to June 2023. The findings of the analysis indicate a noticeable increase in the number of research papers focusing on Intelligent DSS within the field of construction engineering during the last twenty years. The field has witnessed the emergence of key research areas, namely the utilization of Internet of Things (IoT), explainable AI, supply chain optimization, sustainable construction practices, and human-machine collaboration. The results of this study hold significant implications for the construction industry. The incorporation of AI and ML techniques within Intelligent DSS can effectively tackle various issues such as cost overruns, project delays, and safety concerns.","[Waqar, Ahsan] Univ Teknol PETRONAS, Dept Civil & Environm Engn, Bandar Seri Iskandar, Perak, Malaysia",,"Waqar, A (corresponding author), Univ Teknol PETRONAS, Dept Civil & Environm Engn, Bandar Seri Iskandar, Perak, Malaysia.",ahsan_21002791@utp.edu.my,,,,,,,,19,19,,,,,,,,,,,SEP 1,2024,249,,A,,,,,,123503,10.1016/j.eswa.2024.123503,http://dx.doi.org/10.1016/j.eswa.2024.123503,,FEB 2024,,,,,,,,,,2025-05-29,WOS:001198292800001,View Full Record in Web of Science
J,"Hillig, S; Müller, R",,,,"Hillig, Stefanie; Mueller, Romy",,,How do conversational case-based reasoning systems interact with their users: a literature review,BEHAVIOUR & INFORMATION TECHNOLOGY,,,,Review,,,,,,,,"Conversational case-based reasoning (CCBR) systems retrieve past cases that are similar to a current problem by eliciting situation descriptions in interactive dialogues with their users. To find out how such human-machine cooperation is put into practice, the present article reviews the CCBR literature and extracts a list of dialogue principles - interaction techniques by means of which CCBR systems communicate with their users. Seven dialogue principles are identified and explained: mixed initiative, question selection and ordering, dealing with abstraction and expertise, explanations, visualisation and highlighting, dialogue termination, and evaluation support. The results reveal that current CCBR systems already make great efforts to put user needs into the centre of the interaction. At the same time, the current implementation of dialogue principles that adjust CCBR systems to user needs raise questions about who should be in control of these adjustments, what levels of human-computer interaction should be adjusted, and what goals should guide adjustment decisions. Moreover, the present review highlights a number of limitations concerning the methodology and contents of CCBR research, and points out questions for future research on human-computer interaction in CCBR systems.","[Hillig, Stefanie; Mueller, Romy] Tech Univ Dresden, Fac Psychol Engn Psychol & Appl Cognit Res, Dresden, Germany",,"Müller, R (corresponding author), Tech Univ, Engn Psychol & Appl Cognit Res, Helmholtzstr 10, D-01069 Dresden, Germany.",romy.mueller@tu-dresden.de,,,,,,,,5,5,,,,,,,,,,,OCT 26,2021,40,14,,,,,1544,1563,,10.1080/0144929X.2020.1767207,http://dx.doi.org/10.1080/0144929X.2020.1767207,,MAY 2020,,,,,,,,,,2025-05-29,WOS:000534939100001,View Full Record in Web of Science
J,"Moyle, S; Martin, A; Allott, N",,,,"Moyle, Steve; Martin, Andrew; Allott, Nicholas",,,XAI Human-Machine collaboration applied to network security,FRONTIERS IN COMPUTER SCIENCE,,,,Article,,,,,,,,"Cyber attacking is easier than cyber defending-attackers only need to find one breach, while the defenders must successfully repel all attacks. This research demonstrates how cyber defenders can increase their capabilities by joining forces with eXplainable-AI (XAI) utilizing interactive human-machine collaboration. With a global shortfall of cyber defenders there is a need to amplify their skills using AI. Cyber asymmetries make propositional machine learning techniques impractical. Human reasoning and skill is a key ingredient in defense and must be embedded in the AI framework. For Human-Machine collaboration to work requires that the AI is an ultra-strong machine learner and can explain its models. Unlike Deep Learning, Inductive Logic Programming can communicate what it learns to a human. An empirical study was undertaken using six months of eavesdropped network traffic from an organization generating up-to 562K network events daily. Easier-to-defend devices were identified using a form of the Good-Turing Frequency estimator which is a promising form of volatility measure. A behavioral cloning grammar in explicit symbolic form was then produced from a single device's network activity using the compression algorithm SEQUITUR. A novel visualization was generated to allow defenders to identify network sequences they wish to explain. Interactive Inductive Logic Programming (the XAI) is supplied the network traffic meta data, sophisticated pre-existing cyber security background knowledge, and one recurring sequence of events from a single device to explain. A co-inductive process between the human cyber defender and the XAI where the human is able to understand, then refute and shape the XAI's developing model, to produce a model that conforms with the data as well as the original device designers programming. The acceptable model is in a form that can be deployed as an ongoing active cyber defense.","[Moyle, Steve; Martin, Andrew] Univ Oxford, Dept Comp Sci, Oxford, England; [Allott, Nicholas] NquiringMinds, Southampton, England",,"Moyle, S (corresponding author), Univ Oxford, Dept Comp Sci, Oxford, England.",steve@moyle.info,,,,,,,,0,0,,,,,,,,,,,MAY 13,2024,6,,,,,,,,1321238,10.3389/fcomp.2024.1321238,http://dx.doi.org/10.3389/fcomp.2024.1321238,,,,,,,,,,,,2025-05-29,WOS:001230932100001,View Full Record in Web of Science
J,"Harfouche, A; Quinio, B; Saba, M; Saba, PB",,,,"Harfouche, Antoine; Quinio, Bernard; Saba, Mario; Saba, Peter Bou",,,The Recursive Theory of Knowledge Augmentation: Integrating human intuition and knowledge in Artificial Intelligence to augment organizational knowledge,INFORMATION SYSTEMS FRONTIERS,,,,Article,,,,,,,,"Artificial intelligence (AI) has increased the ability of organizations to accumulate tacit and explicit knowledge to inform management decision-making. Despite the hype and popularity of AI, there is a noticeable scarcity of research focusing on AI's potential role in enriching and augmenting organizational knowledge. This paper develops a recursive theory of knowledge augmentation in organizations (the KAM model) based on a synthesis of extant literature and a four-year revised canonical action research project. The project aimed to design and implement a human-centric AI (called Project) to solve the lack of integration of tacit and explicit knowledge in a scientific research center (SRC). To explore the patterns of knowledge augmentation in organizations, this study extends Nonaka's SECI (socialization, externalization, combination, and internalization) model by incorporating the human-in-the-loop Informed Artificial Intelligence (IAI) approach. The proposed design offers the possibility to integrate experts' intuition and domain knowledge in AI in an explainable way. The findings show that organizational knowledge can be augmented through a recursive process enabled by the design and implementation of human-in-the-loop IAI. The study has important implications for research and practice.","[Harfouche, Antoine; Quinio, Bernard] Paris Nanterre Univ, 200 Av Republ, F-92000 Nanterre, France; [Saba, Mario] Business Sch Lausanne, Rte La Maladiere 21, CH-1022 Chavannes Pres Renens, Switzerland; [Saba, Peter Bou] Leonard Vinci Pole Univ, Res Ctr, F-92916 Paris, France",,"Harfouche, A (corresponding author), Paris Nanterre Univ, 200 Av Republ, F-92000 Nanterre, France.",antoine.h@parisnanterre.fr,,,,,,,,16,17,,,,,,,,,,,FEB,2023,25,1,,,SI,,55,70,,10.1007/s10796-022-10352-8,http://dx.doi.org/10.1007/s10796-022-10352-8,,OCT 2022,,,,,,,,,,2025-05-29,WOS:000871875900001,View Full Record in Web of Science
J,"Zhang, R; Du, XB; Yan, JC; Zhang, SH",,,,"Zhang, Rui; Du, Xingbo; Yan, Junchi; Zhang, Shihua",,,The Decoupling Concept Bottleneck Model,IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,,,,Article,,,,,,,,"The Concept Bottleneck Model (CBM) is an interpretable neural network that leverages high-level concepts to explain model decisions and conduct human-machine interaction. However, in real-world scenarios, the deficiency of informative concepts can impede the model's interpretability and subsequent interventions. This paper proves that insufficient concept information can lead to an inherent dilemma of concept and label distortions in CBM. To address this challenge, we propose the Decoupling Concept Bottleneck Model (DCBM), which comprises two phases: 1) DCBM for prediction and interpretation, which decouples heterogeneous information into explicit and implicit concepts while maintaining high label and concept accuracy, and 2) DCBM for human-machine interaction, which automatically corrects labels and traces wrong concepts via mutual information estimation. The construction of the interaction system can be formulated as a light min-max optimization problem. Extensive experiments expose the success of alleviating concept/label distortions, especially when concepts are insufficient. In particular, we propose the Concept Contribution Score (CCS) to quantify the interpretability of DCBM. Numerical results demonstrate that CCS can be guaranteed by the Jensen-Shannon divergence constraint in DCBM. Moreover, DCBM expresses two effective human-machine interactions, including forward intervention and backward rectification, to further promote concept/label accuracy via interaction with human experts.","[Zhang, Rui; Zhang, Shihua] Chinese Acad Sci, Acad Math & Syst Sci, Beijing 100190, Peoples R China; [Zhang, Rui; Zhang, Shihua] Univ Chinese Acad Sci, Sch Math Sci, Beijing 100049, Peoples R China; [Du, Xingbo; Yan, Junchi] Shanghai Jiao Tong Univ, Sch Artificial Intelligence, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China",,"Zhang, SH (corresponding author), Chinese Acad Sci, Acad Math & Syst Sci, Beijing 100190, Peoples R China.;Yan, JC (corresponding author), Shanghai Jiao Tong Univ, Sch Artificial Intelligence, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.",rayzhang@amss.ac.cn; duxingbo@sjtu.edu.cn; yanjunchi@sjtu.edu.cn; zsh@amss.ac.cn,,,,,,,,0,1,,,,,,,,,,,FEB,2025,47,2,,,,,1250,1265,,10.1109/TPAMI.2024.3489597,http://dx.doi.org/10.1109/TPAMI.2024.3489597,,,,,,,,,,,,2025-05-29,WOS:001395340500011,View Full Record in Web of Science
J,"Wallkötter, S; Tulli, S; Castellano, G; Paiva, A; Chetouani, M",,,,"Wallkotter, Sebastian; Tulli, Silvia; Castellano, Ginevra; Paiva, Ana; Chetouani, Mohamed",,,Explainable Embodied Agents Through Social Cues: A Review,ACM TRANSACTIONS ON HUMAN-ROBOT INTERACTION,,,,Review,,,,,,,,"The issue of how to make embodied agents explainable has experienced a surge of interest over the past 3 years, and there are many terms that refer to this concept, such as transparency and legibility. One reason for this high variance in terminology is the unique array of social cues that embodied agents can access in contrast to that accessed by non-embodied agents. Another reason is that different authors use these terms in different ways. Hence, we review the existing literature on explainability and organize it by (1) providing an overview of existing definitions, (2) showing how explainability is implemented and how it exploits different social cues, and (3) showing how the impact of explainability is measured. Additionally, we present a list of open questions and challenges that highlight areas that require further investigation by the community. This provides the interested reader with an overview of the current state of the art.","[Wallkotter, Sebastian; Tulli, Silvia; Castellano, Ginevra] Uppsala Univ, Box 337, S-75105 Uppsala, Sweden; [Wallkotter, Sebastian; Tulli, Silvia] Inst Super Tecn, INESC ID, P-2744016 Lisbon, Portugal; [Paiva, Ana] INESC ID, Lisbon, Portugal; [Paiva, Ana] Inst Super Tecn, Lisbon, Portugal; [Chetouani, Mohamed] Sorbonne Univ, Inst Intelligent Syst & Robot, UMR 7222, CNRS, 4 Pl Jussieu 65, F-75005 Paris, France; [Paiva, Ana] Inst Super Tecn, INESC ID, P-2744016 Porto Salvo, Portugal; [Tulli, Silvia] Sorbonne Univ, Inst Intelligent Syst & Robot, Paris, France; [Paiva, Ana] Harvard Univ, Radcliffe Inst Adv Study, Cambridge, MA 02138 USA",,"Wallkötter, S (corresponding author), Uppsala Univ, Box 337, S-75105 Uppsala, Sweden.;Wallkötter, S (corresponding author), Inst Super Tecn, INESC ID, P-2744016 Lisbon, Portugal.",sebastian.wallkotter@it.uu.se; silvia.tulli@gaips.inesc-id.pt; ginevra.castellano@it.uu.se; Ana.Paiva@inesc-id.pt; mohamed.chetouani@sorbonne-universite.fr,,,,,,,,44,45,,,,,,,,,,,JUL,2021,10,3,,,SI,,,,27,10.1145/3457188,http://dx.doi.org/10.1145/3457188,,,,,,,,,,,,2025-05-29,WOS:000731456900009,View Full Record in Web of Science
J,"Chae, YH; Kim, SG; Choi, J; Koo, SR; Kim, J",,,,"Chae, Young Ho; Kim, Seung Geun; Choi, Jeonghun; Koo, Seo Ryong; Kim, Jonghyun",,,Enhancing nuclear power plant diagnostics: A comparative analysis of XAI-based feature selection methods for abnormal and emergency scenario detection,PROGRESS IN NUCLEAR ENERGY,,,,Article,,,,,,,,"This study introduces the application of explainable artificial intelligence (XAI) techniques to enhance nuclear power plant diagnostics through effective feature selection. We compared various XAI methods, including gradient-based techniques, layer-wise relevance propagation, DeepSHAP, integrated gradients, local interpretable model-agnostic explanation(LIME), and saliency maps, with traditional approaches such as principal component analysis (PCA). By applying these methods to data from an IAEA iPWR simulator, which includes 35 abnormal and emergency scenarios with 116 state variables, we demonstrated the superiority of XAI-based methods in selecting features that effectively distinguish between different plant conditions. Our approach successfully reduced the input dimensionality from 116 to 20 features while maintaining high diagnostic accuracy. XAI methods, particularly saliency map and DeepSHAP, outperformed traditional techniques by revealing distinct patterns for various abnormal situations. This reduction in dimensionality offers several benefits, including enhanced cybersecurity, improved human-machine interfaces, and increased computational efficiency. The findings have significant implications for developing more accurate, efficient, and interpretable diagnostic systems in nuclear power plants, potentially improving safety and operational effectiveness. Future work will focus on validating these methods across diverse plant designs and integrating this approach with advanced AI techniques for real-time adaptive diagnostics.","[Chae, Young Ho; Kim, Seung Geun; Choi, Jeonghun; Koo, Seo Ryong] Korea Atom Energy Res Inst 34057, 111,Daedeok daero 989Beon gil, Daejeon 34057, South Korea; [Kim, Jonghyun] Korea Adv Inst Sci & Technol 34141, 291,Daehak Ro, Daejeon 34141, South Korea",,"Chae, YH (corresponding author), Korea Atom Energy Res Inst 34057, 111,Daedeok daero 989Beon gil, Daejeon 34057, South Korea.",yhchae@kaeri.re.kr,,,,,,,,1,1,,,,,,,,,,,JUL,2025,185,,,,,,,,105759,10.1016/j.pnucene.2025.105759,http://dx.doi.org/10.1016/j.pnucene.2025.105759,,MAR 2025,,,,,,,,,,2025-05-29,WOS:001458392700001,View Full Record in Web of Science
J,"van der Waa, J; Verdult, S; van den Bosch, K; van Diggelen, J; Haije, T; van der Stigchel, B; Cocu, I",,,,"van der Waa, Jasper; Verdult, Sabine; van den Bosch, Karel; van Diggelen, Jurriaan; Haije, Tjalling; van der Stigchel, Birgit; Cocu, Ioana",,,Moral Decision Making in Human-Agent Teams: Human Control and the Role of Explanations,FRONTIERS IN ROBOTICS AND AI,,,,Article,,,,,,,,"With the progress of Artificial Intelligence, intelligent agents are increasingly being deployed in tasks for which ethical guidelines and moral values apply. As artificial agents do not have a legal position, humans should be held accountable if actions do not comply, implying humans need to exercise control. This is often labeled as Meaningful Human Control (MHC). In this paper, achieving MHC is addressed as a design problem, defining the collaboration between humans and agents. We propose three possible team designs (Team Design Patterns), varying in the level of autonomy on the agent's part. The team designs include explanations given by the agent to clarify its reasoning and decision-making. The designs were implemented in a simulation of a medical triage task, to be executed by a domain expert and an artificial agent. The triage task simulates making decisions under time pressure, with too few resources available to comply with all medical guidelines all the time, hence involving moral choices. Domain experts (i.e., health care professionals) participated in the present study. One goal was to assess the ecological relevance of the simulation. Secondly, to explore the control that the human has over the agent to warrant moral compliant behavior in each proposed team design. Thirdly, to evaluate the role of agent explanations on the human's understanding in the agent's reasoning. Results showed that the experts overall found the task a believable simulation of what might occur in reality. Domain experts experienced control over the team's moral compliance when consequences were quickly noticeable. When instead the consequences emerged much later, the experts experienced less control and felt less responsible. Possibly due to the experienced time pressure implemented in the task or over trust in the agent, the experts did not use explanations much during the task; when asked afterwards they however considered these to be useful. It is concluded that a team design should emphasize and support the human to develop a sense of responsibility for the agent's behavior and for the team's decisions. The design should include explanations that fit with the assigned team roles as well as the human cognitive state.","[van der Waa, Jasper; van Diggelen, Jurriaan; Haije, Tjalling; van der Stigchel, Birgit; Cocu, Ioana] TNO, Perceptual & Cognit Syst, Soesterberg, Netherlands; [van der Waa, Jasper] Delft Univ Technol, Interact Intelligence, Delft, Netherlands; [Verdult, Sabine; van den Bosch, Karel] TNO, Training & Performance Innovat, Soesterberg, Netherlands; [van der Stigchel, Birgit] Radboud Univ Nijmegen, Artificial Intelligence, Nijmegen, Netherlands",,"van der Waa, J (corresponding author), TNO, Perceptual & Cognit Syst, Soesterberg, Netherlands.;van der Waa, J (corresponding author), Delft Univ Technol, Interact Intelligence, Delft, Netherlands.",jasper.vanderwaa@tno.nl,,,,,,,,13,14,,,,,,,,,,,MAY 27,2021,8,,,,,,,,640647,10.3389/frobt.2021.640647,http://dx.doi.org/10.3389/frobt.2021.640647,,,,,,,,,,,,2025-05-29,WOS:000659515500001,View Full Record in Web of Science
J,"Din, M; Daga, K; Saoud, J; Wood, D; Kierkegaard, P; Brex, P; Booth, TC",,,,"Din, Munaib; Daga, Karan; Saoud, Jihad; Wood, David; Kierkegaard, Patrick; Brex, Peter; Booth, Thomas C.",,,Clinicians' perspectives on the use of artificial intelligence to triage MRI brain scans,EUROPEAN JOURNAL OF RADIOLOGY,,,,Article,,,,,,,,"Artificial intelligence (AI) tools can triage radiology scans to streamline the patient pathway and also relieve clinician workload. Validated AI tools can mitigate the delays in reporting scans by flagging time-sensitive and actionable findings. In this study, we aim to investigate current stakeholder perspectives and identify obstacles to integrating AI in clinical pathways. We created a survey to ascertain the perspectives of 133 clinicians across the United Kingdom regarding the acceptability of an AI tool that triages MRI brain scans into 'normal' and 'abnormal'. As part of this survey, we supplied clinicians with information on training and validation case numbers, model performance, validation using unseen data, and explainability saliency maps. With regards to the specific use case of AI in MRI brain scans, 71% of respondents preferred the use of an AI-assisted triage compared to the current system without triage, typically chronologically. Notably, information that explained and helped visualise the AI model's decision making was found to improve clinician confidence. When shown a heatmap, 60% of participants felt more confident in the AI's decision. The results of this short communication demonstrate a positive support for the implementation of AI-assistive tools in triage.","[Din, Munaib; Daga, Karan; Saoud, Jihad; Wood, David; Booth, Thomas C.] Kings Coll London, Sch Biomed Engn & Imaging Sci, London, England; [Din, Munaib] Guys & St Thomas NHS Fdn Trust, Dept Radiol, Guys & St, London, England; [Kierkegaard, Patrick] Inst Canc Res, CRUK Convergence Sci Ctr, London, England; [Kierkegaard, Patrick] Imperial Coll London, London, England; [Brex, Peter] Kings Coll Hosp NHS Fdn Trust, Dept Neurol, London, England; [Booth, Thomas C.] Kings Coll Hosp Natl Hlth Serv Fdn Trust, Dept Neuroradiol, London, England",,"Booth, TC (corresponding author), Kings Coll London, Sch Biomed Engn & Imaging Sci, London, England.",thomas.booth@kcl.ac.uk,,,,,,,,1,1,,,,,,,,,,,FEB,2025,183,,,,,,,,111921,10.1016/j.ejrad.2025.111921,http://dx.doi.org/10.1016/j.ejrad.2025.111921,,JAN 2025,,,,,,,,,,2025-05-29,WOS:001399499800001,View Full Record in Web of Science
J,"Lim, S; Kim, J; Lee, T",,,,"Lim, Suengbum; Kim, Jingang; Lee, Taejin",,,Shapelet-Based Sensor Fault Detection and Human-Centered Explanations in Industrial Control System,IEEE ACCESS,,,,Article,,,,,,,,"With the development of information and communication technology, industrial control systems (ICSs) that operate in closed environments are now operating in smart environments, and external threats are increasing. To predict failure and respond to threats, anomaly detection and fault detection using artificial intelligence (AI) are being introduced, but the issue of the reliability of AI prediction is emerging. For anomaly detection, the operator must check thousands of sensors. In addition, practical operational constraints exist because AI predictions are not always accurate. This study proposes shapelet-based anomaly detection and automatic fault sensor description technology to overcome these limitations. Through intuitive abnormality detection and interpretation based on these representative patterns, when an abnormal situation occurs, operators can immediately intuitively determine which sensor causes the problem and how much the sensor differs from the pattern. This was verified with the HIL-based Augmented ICS Security Dataset (HAI) and Secure Water Treatment (SWaT) dataset, which is widely used in the ICS field. In the case of the HAI Dataset, 95.12% of the failed sensors were analyzed by extracting and inspecting only 4% of the total sensors. In the case of the SWaT Dataset, only 7% of the sensors were extracted and inspected, confirming that 84% of the failed sensors could be analyzed. We expect that intuitive explanations and anomaly detection will enable more effective technological operations in industrial environments.","[Lim, Suengbum; Kim, Jingang; Lee, Taejin] Hoseo Univ, Dept Informat Secur, Asan 31499, South Korea",,"Lee, T (corresponding author), Hoseo Univ, Dept Informat Secur, Asan 31499, South Korea.",kinjecs0@gmail.com,,,,,,,,2,2,,,,,,,,,,,,2023,11,,,,,,138033,138051,,10.1109/ACCESS.2023.3339500,http://dx.doi.org/10.1109/ACCESS.2023.3339500,,,,,,,,,,,,2025-05-29,WOS:001123832000001,View Full Record in Web of Science
J,"Khare, SK; Blanes-Vidal, V; Booth, BB; Petersen, LK; Nadimi, ES",,,,"Khare, Smith K.; Blanes-Vidal, Victoria; Booth, Berit Bargum; Petersen, Lone Kjeld; Nadimi, Esmaeil S.",,,A systematic review and research recommendations on artificial intelligence for automated cervical cancer detection,WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY,,,,Review,,,,,,,,"Early diagnosis of abnormal cervical cells enhances the chance of prompt treatment for cervical cancer (CrC). Artificial intelligence (AI)-assisted decision support systems for detecting abnormal cervical cells are developed because manual identification needs trained healthcare professionals, and can be difficult, time-consuming, and error-prone. The purpose of this study is to present a comprehensive review of AI technologies used for detecting cervical pre-cancerous lesions and cancer. The review study includes studies where AI was applied to Pap Smear test (cytological test), colposcopy, sociodemographic data and other risk factors, histopathological analyses, magnetic resonance imaging-, computed tomography-, and positron emission tomography-scan-based imaging modalities. We performed searches on Web of Science, Medline, Scopus, and Inspec. The preferred reporting items for systematic reviews and meta-analysis guidelines were used to search, screen, and analyze the articles. The primary search resulted in identifying 9745 articles. We followed strict inclusion and exclusion criteria, which include search windows of the last decade, journal articles, and machine/deep learning-based methods. A total of 58 studies have been included in the review for further analysis after identification, screening, and eligibility evaluation. Our review analysis shows that deep learning models are preferred for imaging techniques, whereas machine learning-based models are preferred for sociodemographic data. The analysis shows that convolutional neural network-based features yielded representative characteristics for detecting pre-cancerous lesions and CrC. The review analysis also highlights the need for generating new and easily accessible diverse datasets to develop versatile models for CrC detection. Our review study shows the need for model explainability and uncertainty quantification to increase the trust of clinicians and stakeholders in the decision-making of automated CrC detection models. Our review suggests that data privacy concerns and adaptability are crucial for deployment hence, federated learning and meta-learning should also be explored. This article is categorized under: Fundamental Concepts of Data and Knowledge > Explainable AI Technologies > Machine Learning Technologies > Classification","[Khare, Smith K.; Blanes-Vidal, Victoria; Nadimi, Esmaeil S.] Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Fac Engn, Appl AI & Data Sci Unit, Odense, Denmark; [Khare, Smith K.; Nadimi, Esmaeil S.] Odense Univ Hosp, Ctr Clin Artificial Intelligence, Odense, Denmark; [Booth, Berit Bargum] Odense Univ Hosp, Dept Gynecol & Obstet, Odense, Denmark; [Petersen, Lone Kjeld] Odense Univ Hosp, Res Unit Gynecol & Obstet Odense, Odense, Denmark",,"Khare, SK (corresponding author), Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Fac Engn, Appl AI & Data Sci Unit, Odense, Denmark.",smkh@mmmi.sdu.dk,,,,,,,,4,4,,,,,,,,,,,NOV,2024,14,6,,,,,,,,10.1002/widm.1550,http://dx.doi.org/10.1002/widm.1550,,JUL 2024,,,,,,,,,,2025-05-29,WOS:001272508300001,View Full Record in Web of Science
J,"Ding, YH; Jia, LS; Du, N",,,,"Ding, Yaohan; Jia, Lesong; Du, Na",,,Watch Out for Explanations: Information Type and Error Type Affect Trust and Situational Awareness in Automated Vehicles,IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS,,,,Article; Early Access,,,,,,,,"Trust and situational awareness (SA) are critical for the acceptance and safety of automated vehicles (AVs). While AV explanations with different information types have been studied to enhance drivers' trust and SA, their effectiveness remains unclear when AVs make errors that do not trigger takeover requests. This study investigated the effects of information type, error type, and their interaction on drivers' trust in AVs, SA, and their relationships. We recruited 300 participants in an online video study with a 3 (information type: why, how, why + how) x 3 (error type: false alarm, miss, correct [no error]) mixed design. How information describes the vehicle's action, while why information refers to the reason for the vehicle's action. Linear mixed models showed that false alarms and misses were associated with lower SA compared with correct scenarios, but possibly due to different reasons. Compared with correct scenarios, both false alarms and misses were associated with lower trust, with misses even lower than false alarms, possibly due to the varying severity of potential consequences. Compared with why and why + how information, how information was generally associated with lower SA and a higher potential of overtrust in false alarms. Trust and SA had a negative linear relationship in misses and false alarms, while no correlations were found in correct scenarios. To mitigate potential overtrust and misinterpretation of situations when AVs make errors, it is crucial to maintain higher SA. We recommend including why information in AV explanations and deploying AV decision systems that are less miss-prone.","[Ding, Yaohan; Jia, Lesong; Du, Na] Univ Pittsburgh, Sch Comp & Informat, Pittsburgh, PA 15260 USA",,"Du, N (corresponding author), Univ Pittsburgh, Sch Comp & Informat, Pittsburgh, PA 15260 USA.",yad30@pitt.edu; lej50@pitt.edu; na.du@pitt.edu,,,,,,,,0,0,,,,,,,,,,,2025 MAY 1,2025,,,,,,,,,,10.1109/THMS.2025.3558437,http://dx.doi.org/10.1109/THMS.2025.3558437,,MAY 2025,,,,,,,,,,2025-05-29,WOS:001480610000001,View Full Record in Web of Science
J,"Leiva, MA; García, AJ; Shakarian, P; Simari, GI",,,,"Leiva, Mario A.; Garcia, Alejandro J.; Shakarian, Paulo; Simari, Gerardo, I",,,Argumentation-Based Query Answering under Uncertainty with Application to Cybersecurity,BIG DATA AND COGNITIVE COMPUTING,,,,Article,,,,,,,,"Decision support tools are key components of intelligent sociotechnical systems, and their successful implementation faces a variety of challenges, including the multiplicity of information sources, heterogeneous format, and constant changes. Handling such challenges requires the ability to analyze and process inconsistent and incomplete information with varying degrees of associated uncertainty. Moreover, some domains require the system's outputs to be explainable and interpretable; an example of this is cyberthreat analysis (CTA) in cybersecurity domains. In this paper, we first present the P-DAQAP system, an extension of a recently developed query-answering platform based on defeasible logic programming (DeLP) that incorporates a probabilistic model and focuses on delivering these capabilities. After discussing the details of its design and implementation, and describing how it can be applied in a CTA use case, we report on the results of an empirical evaluation designed to explore the effectiveness and efficiency of a possible world sampling-based approximate query answering approach that addresses the intractability of exact computations.","[Leiva, Mario A.; Garcia, Alejandro J.; Simari, Gerardo, I] Univ Nacl Sur UNS, Dept Comp Sci & Engn, RA-8000 Bahia Blanca, Buenos Aires, Argentina; [Leiva, Mario A.; Garcia, Alejandro J.; Simari, Gerardo, I] Inst Comp Sci & Engn UNS CONICET, RA-8000 Bahia Blanca, Buenos Aires, Argentina; [Shakarian, Paulo; Simari, Gerardo, I] Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85281 USA",,"Simari, GI (corresponding author), Univ Nacl Sur UNS, Dept Comp Sci & Engn, RA-8000 Bahia Blanca, Buenos Aires, Argentina.;Simari, GI (corresponding author), Inst Comp Sci & Engn UNS CONICET, RA-8000 Bahia Blanca, Buenos Aires, Argentina.;Simari, GI (corresponding author), Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85281 USA.",gis@cs.uns.edu.ar,,,,,,,,5,5,,,,,,,,,,,SEP,2022,6,3,,,,,,,91,10.3390/bdcc6030091,http://dx.doi.org/10.3390/bdcc6030091,,,,,,,,,,,,2025-05-29,WOS:000858494800001,View Full Record in Web of Science
J,"Ferenc, G; Timotijevic, D; Tanasijevic, I; Simic, D",,,,"Ferenc, Goran; Timotijevic, Dragoje; Tanasijevic, Ivana; Simic, Danijela",,,Towards Enhanced Autonomous Driving Takeovers: Fuzzy Logic Perspective for Predicting Situational Awareness,APPLIED SCIENCES-BASEL,,,,Article,,,,,,,,"This paper investigates the application of fuzzy logic to enhance situational awareness in Advanced Driver Assistance Systems (ADAS). Situational awareness is critical for drivers to respond appropriately to dynamic driving scenarios. As car automation increases, monitoring situational awareness ensures that drivers can effectively take control of the vehicle when needed. Our study explores whether fuzzy logic can accurately assess situational awareness using a set of 14 critical predictors categorized into time decision, criticality, eye-related metrics, and driver experience. We based our work on prior research that used machine learning (ML) models to achieve high accuracy. Our proposed fuzzy logic system aims to match the predictive accuracy of ML models while providing additional benefits in terms of interpretability and robustness. This approach emphasizes a fresh perspective on situational awareness within ADAS, potentially improving safety and efficiency in real-world driving scenarios.","[Ferenc, Goran] Univ Belgrade, Sch Elect Engn, Bulevar Kralja Aleksandra 73, Belgrade 11120, Serbia; [Timotijevic, Dragoje; Tanasijevic, Ivana; Simic, Danijela] Syrmia LLC, Bulevar Milutina Milankov 19b, Belgrade 11070, Serbia",,"Ferenc, G (corresponding author), Univ Belgrade, Sch Elect Engn, Bulevar Kralja Aleksandra 73, Belgrade 11120, Serbia.",goran.ferenc@syrmia.com; dragoje.timotijevic@syrmia.com; ivana.tanasijevic@syrmia.com; danijela.simic@syrmia.com,,,,,,,,2,2,,,,,,,,,,,JUL,2024,14,13,,,,,,,5697,10.3390/app14135697,http://dx.doi.org/10.3390/app14135697,,,,,,,,,,,,2025-05-29,WOS:001266472200001,View Full Record in Web of Science
J,"Hastings, N; Samuel, D; Ansari, AN; Kaurani, P; Winston, JJ; Bhandary, VS; Gautam, P; Purayil, ALT; Hassan, T; Eshwar, MD; Nuthalapati, BST; Pothuri, JK; Ali, N",,,,"Hastings, Natasha; Samuel, Dany; Ansari, Aariz N.; Kaurani, Purvi; Winston, J. Jenkin; Bhandary, Vaibhav S.; Gautam, Prabin; Purayil, Afsal Latheef Tayyil; Hassan, Taimur; Eshwar, Mummareddi Dinesh; Nuthalapati, Bala Sai Teja; Pothuri, Jeevan Kumar; Ali, Noor",,,The Role of Artificial Intelligence-Powered Imaging in Cerebrovascular Accident Detection,CUREUS JOURNAL OF MEDICAL SCIENCE,,,,Article,,,,,,,,"Cerebrovascular accidents (CVAs) often occur suddenly and abruptly, leaving patients with long-lasting disabilities that place a huge emotional and economic burden on everyone involved. CVAs result when emboli or thrombi travel to the brain and impede blood flow; the subsequent lack of oxygen supply leads to ischemia and eventually tissue infarction. The most important factor determining the prognosis of CVA patients is time, specifically the time from the onset of disease to treatment. Artificial intelligence (AI)assisted neuroimaging alleviates the time constraints of analysis faced using traditional diagnostic imaging modalities, thus shortening the time from diagnosis to treatment. Numerous recent studies support the increased accuracy and processing capabilities of AI-assisted imaging modalities. However, the learning curve is steep, and huge barriers still exist preventing a full-scale implementation of this technology. Thus, the potential for AI to revolutionize medicine and healthcare delivery demands attention. This paper aims to elucidate the progress of AI-powered imaging in CVA diagnosis while considering traditional imaging techniques and suggesting methods to overcome adoption barriers in the hope that AI-assisted neuroimaging will be considered normal practice in the near future. There are multiple modalities for AI neuroimaging, all of which require collecting sufficient data to establish inclusive, accurate, and uniform detection platforms. Future efforts must focus on developing methods for data harmonization and standardization. Furthermore, transparency in the explainability of these technologies needs to be established to facilitate trust between physicians and AI-powered technology. This necessitates considerable resources, both financial and expertise wise which are not available everywhere.","[Hastings, Natasha] St Georges Univ, Sch Med, St Georges, Grenada; [Samuel, Dany] Med Univ Varna, Radiol, Varna, Italy; [Ansari, Aariz N.] Eras Lucknow Med Coll & Hosp, Internal Med, Lucknow, India; [Kaurani, Purvi] Dnyandeo Yashwantrao DY Patil Univ, Sch Med, Neurol, Navi Mumbai, India; [Winston, J. Jenkin] Karunya Inst Technol & Sci, Elect & Commun Engn, Coimbatore, India; [Bhandary, Vaibhav S.] Srinivas Inst Med Sci & Res Ctr, Radiol, Mangaluru, India; [Gautam, Prabin] Kettering & Dist Gen Hosp, Emergency Med, Kettering, England; [Purayil, Afsal Latheef Tayyil] Barking Havering Redbridge Univ Hosp NHS Trus, Surg, London, England; [Hassan, Taimur] Houston Methodist Neurol Inst, Neurosurg, Houston, TX USA; [Eshwar, Mummareddi Dinesh] Mahavir Inst Med Sci, Gen Med, Vikarabad, India; [Nuthalapati, Bala Sai Teja] Maheshwara Med Coll, Internal Med, Patancheru, India; [Pothuri, Jeevan Kumar] Govt Med Coll Suryapet, Radiol, Suryapet, India; [Ali, Noor] Dubai Med Coll, Med & Surg, Dubai, U Arab Emirates",,"Ali, N (corresponding author), Dubai Med Coll, Med & Surg, Dubai, U Arab Emirates.",noorali.obgyn@gmail.com,,,,,,,,2,2,,,,,,,,,,,MAY 6,2024,16,5,,,,,,,e59768,10.7759/cureus.59768,http://dx.doi.org/10.7759/cureus.59768,,,,,,,,,,,,2025-05-29,WOS:001235770500003,View Full Record in Web of Science
J,"Pickhardt, PJ; Summers, RM; Garrett, JW; Krishnaraj, A; Agarwal, S; Dreyer, KJ; Nicola, GN",,,,"Pickhardt, Perry J.; Summers, Ronald M.; Garrett, John W.; Krishnaraj, Arun; Agarwal, Sheela; Dreyer, Keith J.; Nicola, Gregory N.",,,Opportunistic Screening: Radiology Scientific Expert Panel,RADIOLOGY,,,,Article,,,,,,,,"Radiologic tests often contain rich imaging data not relevant to the clinical indication. Opportunistic screening refers to the practice of systematically leveraging these incidental imaging findings. Although opportunistic screening can apply to imaging modalities such as conventional radiography, US, and MRI, most attention to date has focused on body CT by using artificial intelligence (AI)-assisted methods. Body CT represents an ideal high-volume modality whereby a quantitative assessment of tissue composition (eg, bone, muscle, fat, and vascular calcium) can provide valuable risk stratification and help detect unsuspected presymptomatic disease. The emergence of explainable AI algorithms that fully automate these measurements could eventually lead to their routine clinical use. Potential barriers to widespread implementation of opportunistic CT screening include the need for buy-in from radiologists, referring providers, and patients. Standardization of acquiring and reporting measures is needed, in addition to expanded normative data according to age, sex, and race and ethnicity. Regulatory and reimbursement hurdles are not insurmountable but pose substantial challenges to commercialization and clinical use. Through demonstration of improved population health outcomes and cost-effectiveness, these opportunistic CT-based measures should be attractive to both payers and health care systems as value-based reimbursement models mature. If highly successful, opportunistic screening could eventually justify a practice of standalone intended CT screening.","[Pickhardt, Perry J.; Garrett, John W.] Univ Wisconsin, Sch Med & Publ Hlth, Dept Radiol, E3-311 Clinical Sci Ctr,600 Highland Ave, Madison, WI 53792 USA; [Garrett, John W.] Univ Wisconsin, Sch Med & Publ Hlth, Dept Med Phys, E3-311 Clinical Sci Ctr,600 Highland Ave, Madison, WI 53792 USA; [Summers, Ronald M.] NIH, Imaging Biomarkers & Comp Aided Diag Lab, Radiol & Imaging Sci, Clin Ctr, Bethesda, MD USA; [Krishnaraj, Arun] Univ Virginia, Dept Radiol & Med Imaging, Sch Med, Charlottesville, VA USA; [Agarwal, Sheela] Lenox Hill Radiol, New York, NY USA; [Dreyer, Keith J.] Harvard Med Sch, Boston, MA USA; [Dreyer, Keith J.] Mass Gen Brigham, Boston, MA USA; [Nicola, Gregory N.] Hackensack Radiol Grp, Hackensack, NJ USA",,"Pickhardt, PJ (corresponding author), Univ Wisconsin, Sch Med & Publ Hlth, Dept Radiol, E3-311 Clinical Sci Ctr,600 Highland Ave, Madison, WI 53792 USA.",ppickhardt2@uwhealth.org,,,,,,,,54,54,,,,,,,,,,,JUN,2023,307,5,,,,,,,e222044,10.1148/radiol.222044,http://dx.doi.org/10.1148/radiol.222044,,,,,,,,,,,,2025-05-29,WOS:001061457800012,View Full Record in Web of Science
J,"Wilchek, M; Hanley, W; Lim, J; Luther, K; Batarseh, FA",,,,"Wilchek, Matthew; Hanley, Will; Lim, Jude; Luther, Kurt; Batarseh, Feras A.",,,Human-in-the-loop for computer vision assurance: A survey,ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,,,,Article,,,,,,,,"Human-in-the-loop (HITL), a key branch of Human-Computer Interaction (HCI), is increasingly proposed in the research literature as a key assurance method for automated analyses and predictive application designs. As the need increases to improve methods in Artificial Intelligence (AI) model training, optimize systems performance, provide AI explainability, and monitor AI system operations, the concept of HITL is gaining traction due to its value in solving these challenges. This survey of existing works on HITL from a computer vision system design perspective focuses on the following AI assurance principles: (1) improved data assurance, such as data preparation or automated data labeling; (2) algorithmic assurance, such as managing uncertainty and AI trustworthiness; and (3) critical limitations and capabilities introduced by HITL into a system's operational efficiency. We survey prior work within these foci, including technical strengths and weaknesses of novel approaches and ongoing research. This review of the state of the art in HITL computer vision research supports an informed discussion of considerations and future opportunities in this critical space.","[Wilchek, Matthew; Lim, Jude; Luther, Kurt] Virginia Tech, Dept Comp Sci, 900 N Glebe Rd, Arlington, VA 22203 USA; [Hanley, Will; Luther, Kurt; Batarseh, Feras A.] Virginia Tech, Natl Secur Inst, 290 Coll Ave, Blacksburg, VA 24061 USA; [Batarseh, Feras A.] Virginia Tech, Dept Biol Syst Engn, 900 N Glebe Rd, Arlington, VA 22203 USA",,"Batarseh, FA (corresponding author), Virginia Tech, Natl Secur Inst, 290 Coll Ave, Blacksburg, VA 24061 USA.;Batarseh, FA (corresponding author), Virginia Tech, Dept Biol Syst Engn, 900 N Glebe Rd, Arlington, VA 22203 USA.",batarseh@vt.edu,,,,,,,,4,4,,,,,,,,,,,AUG,2023,123,,B,,,,,,106376,10.1016/j.engappai.2023.106376,http://dx.doi.org/10.1016/j.engappai.2023.106376,,MAY 2023,,,,,,,,,,2025-05-29,WOS:001009058200001,View Full Record in Web of Science
J,"Preece, A; Webberley, W; Braines, D; Zaroukian, EG; Bakdash, JZ",,,,"Preece, Alun; Webberley, William; Braines, Dave; Zaroukian, Erin G.; Bakdash, Jonathan Z.",,,SHERLOCK: Experimental Evaluation of a Conversational Agent for Mobile Information Tasks,IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS,,,,Article,,,,,,,,"Controlled natural language (CNL) has great potential to support human-machine interaction (HMI) because it provides an information representation that is both human readable and machine processable. We investigated the effectiveness of a CNL-based conversational interface forHMIin a behavioral experiment called simple human experiment regarding locally observed collective knowledge (SHERLOCK). In SHERLOCK, individuals acted in groups to discover and report information to the machine using natural language (NL), which the machine then processed into CNL. The machine fused responses from different users to form a common operating picture, a dashboard showing the level of agreement for distinct information. To obtain information to add to this dashboard, users explored the real world in a simulated crowd-sourced sensing scenario. This scenario represented a simplified controlled analog for tactical intelligence (i.e., direct intelligence of the environment), which is key for rapidly planning military, law enforcement, and emergency operations. Overall, despite close to zero training, 74% of the users inputted NL that was machine interpretable and addressed the assigned tasks. An experimental manipulation aimed to increase user-machine interaction, however, did not improve performance as hypothesized. Nevertheless, results indicate that the conversational interface may be effective in assisting humans with collection and fusion of information in a crowdsourcing context.","[Preece, Alun; Webberley, William] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3XQ, S Glam, Wales; [Braines, Dave] IBM United Kingdom Ltd, Emerging Technol Serv, Winchester SO21 2JN, Hants, England; [Zaroukian, Erin G.; Bakdash, Jonathan Z.] US Army, Res Lab, Human Res & Engn Directorate, Adelphi, MD 20783 USA",,"Preece, A (corresponding author), Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3XQ, S Glam, Wales.",PreeceAD@cardiff.ac.uk; WebberleyWM@cardiff.ac.uk; dave_braines@uk.ibm.com; erin.g.zaroukian.ctr@mail.mil; jonathan.z.bakdash.civ@mail.mil,,,,,,,,12,12,,,,,,,,,,,DEC,2017,47,6,,,,,1017,1028,,10.1109/THMS.2017.2700625,http://dx.doi.org/10.1109/THMS.2017.2700625,,,,,,,,,,,,2025-05-29,WOS:000415153100025,View Full Record in Web of Science
J,"Chakraborti, T; Fadnis, KP; Talamadupula, K; Dholakia, M; Srivastava, B; Kephart, JO; Bellamy, RKE",,,,"Chakraborti, Tathagata; Fadnis, Kshitij P.; Talamadupula, Kartik; Dholakia, Mishal; Srivastava, Biplav; Kephart, Jeffrey O.; Bellamy, Rachel K. E.",,,"Planning and visualization for a smart meeting room assistant A case study in the Cognitive Environments Laboratory at IBM TJ Waston Research Center, Yorktown",AI COMMUNICATIONS,,,,Article,,,,,,,,"In this paper, we report on the planning and visualization capabilities of Mr. Jones - a proactive orchestrator and decision-support agent for a collaborative decision making setting embodied by a smart room. The duties of such an agent may range across interactive problem solving with other agents in the environment, developing automated summaries of meetings, visualization of the internal decision-making process, proactive data and resource management, and so on. Specifically, we focus on how the visualization of the planning and plan recognition processes forms a key component of the smart assistant, and establishes transparency in the decision-making process. We also highlight how these processes contribute to the proactive nature of the agent. We demonstrate some of these functionalities in a successful deployment of the system in the CEL - the Cognitive Environments Laboratory at IBM's T.J. Watson Research Center (Yorktown, USA), and report on emerging deployments of the system that have turned into success stories.","[Chakraborti, Tathagata] IBM Corp, IBM Res AI, Cambridge, MA 02142 USA; [Fadnis, Kshitij P.; Talamadupula, Kartik; Dholakia, Mishal; Srivastava, Biplav; Kephart, Jeffrey O.; Bellamy, Rachel K. E.] IBM Corp, IBM Res AI, Yorktown Hts, NY USA",,"Chakraborti, T (corresponding author), IBM Corp, IBM Res AI, Cambridge, MA 02142 USA.",tchakra2@ibm.com; kpfadnis@us.ibm.com; krtalamad@us.ibm.com; mishal.dholakia1@ibm.com; biplavs@us.ibm.com; kephart@us.ibm.com; rachel@us.ibm.com,,,,,,,,5,5,,,,,,,,,,,,2019,32,1,,,,,91,99,,10.3233/AIC-180609,http://dx.doi.org/10.3233/AIC-180609,,,,,,,,,,,,2025-05-29,WOS:000461511300006,View Full Record in Web of Science
J,"Balaji, B; Ebrahimi, F; Domingo, NG; Vunnava, VSG; Faridee, A; Ramalingam, S; Gupta, S; Wang, AR; Gupta, H; Belcastro, D; Axten, K; Hakian, J; Kramer, J; Srinivasan, A; Tu, QS",,,,"Balaji, Bharathan; Ebrahimi, Fahimeh; Domingo, Nina Gabrielle; Vunnava, Venkata Sai Gargeya; Faridee, Abu-Zaher; Ramalingam, Soma; Gupta, Shikha; Wang, Anran; Gupta, Harsh; Belcastro, Domenic; Axten, Kellen; Hakian, Jeremie; Kramer, Jared; Srinivasan, Aravind; Tu, Qingshi",,,Emission Factor Recommendation for Life Cycle Assessments with Generative AI,ENVIRONMENTAL SCIENCE & TECHNOLOGY,,,,Article,,,,,,,,"Accurately quantifying greenhouse gas (GHG) emissions is crucial for organizations to measure and mitigate their environmental impact. Life cycle assessment (LCA) estimates the environmental impacts throughout a product's entire lifecycle, from raw material extraction to end-of-life. Measuring the emissions outside a product owner's control is challenging, and practitioners rely on emission factors (EFs)-estimations of GHG emissions per unit of activity-to model and estimate indirect impacts. However, the current practice of manually selecting appropriate EFs from databases is time-consuming and error-prone and requires expertise. We present an AI-assisted method leveraging natural language processing and machine learning to automatically recommend EFs with human-interpretable justifications. Our algorithm can assist experts by providing a ranked list of EFs or operating in a fully automated manner, where the top recommendation is selected as final. Benchmarks across multiple real-world data sets show our method recommends the correct EF with an average precision of 86.9% in the fully automated case and shows the correct EF in the top 10 recommendations with an average precision of 93.1%. By streamlining EF selection, our approach enables scalable and accurate quantification of GHG emissions, supporting organizations' sustainability initiatives and progress toward net-zero emissions targets across industries.","[Balaji, Bharathan; Ebrahimi, Fahimeh; Ramalingam, Soma; Gupta, Shikha; Wang, Anran; Belcastro, Domenic; Axten, Kellen; Hakian, Jeremie; Kramer, Jared] Amazon, Seattle, WA 98121 USA; [Domingo, Nina Gabrielle; Vunnava, Venkata Sai Gargeya] Amazon, New York, NY 10018 USA; [Faridee, Abu-Zaher] Amazon, Arlington, VA 22202 USA; [Gupta, Harsh] Amazon, East Palo Alto, CA 94303 USA; [Srinivasan, Aravind] Univ Maryland, College Pk, MD 20742 USA; [Srinivasan, Aravind] Amazon, College Pk, MD 20742 USA; [Tu, Qingshi] Univ British Columbia, Vancouver, BC V6T 1Z4, Canada",,"Balaji, B (corresponding author), Amazon, Seattle, WA 98121 USA.",bhabalaj@amazon.com,,,,,,,,0,0,,,,,,,,,,,MAR 21,2025,59,18,,,,,9113,9122,,10.1021/acs.est.4c12667,http://dx.doi.org/10.1021/acs.est.4c12667,,MAR 2025,,,,,,,,,,2025-05-29,WOS:001450129200001,View Full Record in Web of Science
J,"Sun, JW; Wei, MQ; Feng, JT; Yu, FH; Li, Q; Zou, R",,,,"Sun, Jianwen; Wei, Mengqi; Feng, Jintian; Yu, Fenghua; Li, Qing; Zou, Rui",,,Progressive knowledge tracing: Modeling learning process from abstract to concrete,EXPERT SYSTEMS WITH APPLICATIONS,,,,Article,,,,,,,,"Artificial intelligence has the potential to revolutionize education by providing personalized learning experi-ences that support the dream of teaching students according to their aptitude. Knowledge tracing (KT) is a critical research topic in intelligent education and is a powerful tool for achieving AI-assisted education. Both the learning process and the response result are important for KT. However, existing KT methods rarely employ a stage-based modeling approach to dissect the learning process. We propose Progressive Knowledge Tracing (PKT), which models the learning process in stages. PKT decomposes the learning process into three relatively independent but progressively related stages: concept mastery, question solving, and answering behavior. Inspired by constructivist learning theory and item response theory, PKT incorporates interpretable parameters with educational significance. Compared with existing KT methods, this staged modeling method that integrates educational theory has more reasonable interpretability. Experiments on six real-world datasets demonstrate that PKT outperforms baseline methods. Several experiments show that PKT reasonably models the learning process. For example, it more reasonably estimates the trend of concept mastery over time, analyzes the reasons why learners make mistakes on specific questions, and provides estimates of question difficulty that are closer to reality. We also find the intuitive phenomenon that the difficulty of a question is positively correlated with the number of associated concepts.","[Zou, Rui] Cent China Normal Univ, Natl Engn Res Ctr Educ Big Data, Wuhan 430079, Peoples R China; Cent China Normal Univ, Fac Artificial Intelligence Educ, Wuhan 430079, Peoples R China",,"Zou, R (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr Educ Big Data, Wuhan 430079, Peoples R China.",sunjw@ccnu.edu.cn; weimengqi@mails.ccnu.edu.cn; fjt2018@mails.ccnu.edu.cn; ayu2anqi@mails.ccnu.edu.cn; viven_a@ccnu.edu.cn; zouruixyz@mails.ccnu.edu.cn,,,,,,,,9,9,,,,,,,,,,,MAR 15,2024,238,,F,,,,,,122280,10.1016/j.eswa.2023.122280,http://dx.doi.org/10.1016/j.eswa.2023.122280,,NOV 2023,,,,,,,,,,2025-05-29,WOS:001107286800001,View Full Record in Web of Science
J,"Wanna, S; Parra, F; Valner, R; Kruusamaee, K; Pryor, M",,,,"Wanna, Selma; Parra, Fabian; Valner, Robert; Kruusamaee, Karl; Pryor, Mitch",,,Unlocking underrepresented use-cases for large language model-driven human-robot task planning,ADVANCED ROBOTICS,,,,Article,,,,,,,,"Large language models (LLM) are now the de facto task planners for Embodied AI (EAI) systems. This shift can be attributed to LLMs' powerful, emergent properties which enable their adaptation to downstream tasks with minimal to no fine tuning via prompting. However, we find that LLM-driven task planning is not a solved problem. In this work we measure the extent to which these models can be adapted to complex and domain-specific task planning via few-shot prompting. Additionally, we contribute quantitative and qualitative analysis on prompt robustness. Lastly, to meet the challenges of adapting EAI systems to real-world, industrial domains, we adopt a human-in-the-loop approach to guarantee safe and interpretable task planning and execution. We successfully demonstrate co-located, human-robot teaming where an Augmented Reality (AR) headset mediates information exchanged between an EAI agent and human operator for a variety of inspection tasks. To our knowledge the use of an AR headset for multimodal grounding and the application of EAI to industrial tasks are novel contributions within Embodied AI research.","[Wanna, Selma; Parra, Fabian; Pryor, Mitch] Univ Texas Austin, Dept Mech Engn, Austin, TX 78712 USA; [Valner, Robert; Kruusamaee, Karl] Univ Tartu, Robot Engn & Nooruse, Tartu, Estonia",,"Wanna, S (corresponding author), Univ Texas Austin, Dept Mech Engn, Austin, TX 78712 USA.",slwanna@utexas.edu,,,,,,,,1,1,,,,,,,,,,,SEP 16,2024,38,18,,,SI,,1335,1348,,10.1080/01691864.2024.2366974,http://dx.doi.org/10.1080/01691864.2024.2366974,,JUL 2024,,,,,,,,,,2025-05-29,WOS:001263051600001,View Full Record in Web of Science
J,"Gaffney, H; Mirza, KM",,,,"Gaffney, Harry; Mirza, Kamran M.",,,Pathology in the artificial intelligence era: Guiding innovation and implementation to preserve human insight,ACADEMIC PATHOLOGY,,,,Article,,,,,,,,"The integration of artificial intelligence in pathology has ignited discussions about the role of technology in diagnostics-whether artificial intelligence serves as a tool for augmentation or risks replacing human expertise. This manuscript explores artificial intelligence's evolving contributions to pathology, emphasizing its potential capacity to enhance, rather than eclipse, the pathologist's role. Through historical comparisons, such as the transition from analog to digital in radiology, this paper highlights how technological advancements have historically expanded professional capabilities without diminishing the essential human element. Current applications of artificial intelligence in pathology-from diagnostic standardization to workflow efficiency-demonstrate its potential to augment diagnostic accuracy, expedite processes, and improve consistency across institutions. However, challenges remain in algorithmic bias, regulatory oversight, and maintaining interpretive skills among pathologists. The discussion underscores the importance of comprehensive governance frameworks, evolving educational curricula, and public engagement initiatives to ensure artificial intelligence in pathology remains a collaborative endeavor that empowers professionals, upholds ethical standards, and enhances patient outcomes. This manuscript ultimately advocates for a balanced approach where artificial intelligence and human expertise work in concert to advance the future of diagnostic medicine.","[Gaffney, Harry] Univ Sydney, Fac Med & Hlth, Concord Clin Sch, Sydney, NSW, Australia; [Mirza, Kamran M.] Univ Michigan, Michigan Med, Programs & Commun, Div Training, Ann Arbor, MI USA",,"Gaffney, H (corresponding author), 1 Parramatta Rd Camperdown, Sydney, NSW 2050, Australia.",harry.gaffney@health.nsw.gov.au,,,,,,,,0,0,,,,,,,,,,,JAN-MAR,2025,12,1,,,,,,,100166,10.1016/j.acpath.2025.100166,http://dx.doi.org/10.1016/j.acpath.2025.100166,,FEB 2025,,,,,,,,,,2025-05-29,WOS:001437197900001,View Full Record in Web of Science
J,"Wellsandt, S; Klein, K; Hribernik, K; Lewandowski, M; Bousdekis, A; Mentzas, G; Thoben, KD",,,,"Wellsandt, Stefan; Klein, Konstantin; Hribernik, Karl; Lewandowski, Marco; Bousdekis, Alexandros; Mentzas, Gregoris; Thoben, Klaus-Dieter",,,Hybrid-augmented intelligence in predictive maintenance with digital intelligent assistants,ANNUAL REVIEWS IN CONTROL,,,,Review,,,,,,,,"Industrial maintenance strategies increasingly rely on artificial intelligence to predict asset conditions and prescribe maintenance actions. The related maintenance software and human maintenance actors can form a hybrid-augmented intelligence system where each side benefits from and enhances the other side's intelligence. This system requires optimized human-machine interfaces to help users express their knowledge and retrieve information from difficult-to-use software. Therefore, this article proposes a novel approach for maintenance experts and operators to interact with a predictive maintenance system through a digital intelligent assistant. This assistant is artificial intelligence (AI) that could help its users interact with the system via natural language and collect their feedback about the success of maintenance interventions. Implementing hybrid-augmented intelligence in a predictive maintenance system faces several technical, social, economic, organizational, and legal challenges. The benefits, limitations, and risks of hybrid-augmented intelligence must be clear to all employees to advocate its use. AI-focused change management and employee training could be techniques to address these challenges. The success of the proposed approach also relies on the continuous improvement of natural language understanding. Such a process will need conversation-driven development where actual interactions with the assistant provide accurate training data for language and dialog models. Future research has to be interdisciplinary and may cover the integration of explainable AI, suitable AI laws, operationalized trustworthy AI, efficient design for human-computer interaction, and natural language processing adapted to predictive maintenance.","[Wellsandt, Stefan; Klein, Konstantin; Hribernik, Karl; Lewandowski, Marco] Bremer Inst Prod & Logist GmbH Univ Bremen BIBA, Hochschulring 20, D-28359 Bremen, Germany; [Bousdekis, Alexandros; Mentzas, Gregoris] Natl Tech Univ Athens NTUA, Inst Commun & Comp Syst ICCS, Informat Management Unit IMU, 9 Iroon Polytech str, Athens 15780, Greece; [Thoben, Klaus-Dieter] Univ Bremen, Fac Prod Engn, Badgasteinerstr 1, D-28359 Bremen, Germany",,"Wellsandt, S (corresponding author), Bremer Inst Prod & Logist GmbH Univ Bremen BIBA, Hochschulring 20, D-28359 Bremen, Germany.",wel@biba.uni-bremen.de; kle@biba.uni-bremen.de; hri@biba.uni-bremen.de; lew@biba.uni-bremen.de; albous@mail.ntua.gr; gmentzas@mail.ntua.gr; tho@biba.uni-bremen.de,,,,,,,,29,30,,,,,,,,,,,,2022,53,,,,,,382,390,,10.1016/j.arcontrol.2022.04.001,http://dx.doi.org/10.1016/j.arcontrol.2022.04.001,,MAY 2022,,,,,,,,,,2025-05-29,WOS:000807345600025,View Full Record in Web of Science
J,"Qian, ZH; Shi, C",,,,"Qian, Zehang; Shi, Chao",,,Large language model-empowered paradigm for automated geotechnical site planning and geological characterization,AUTOMATION IN CONSTRUCTION,,,,Article,,,,,,,,"A sound site investigation scheme must satisfy requirements of various local, regional, or national codes, and it is imperative to have an efficient system for information retrieval, summarization, and reasoning along with a rapid interpretation tool for real-time risk-informed decision-making. Emerging large language models (LLMs) offer a promising solution for automatically processing unstructured natural languages and facilitating collaborative reasoning between humans and machines. This paper develops a customized LLM-based agent named Geologist to streamline geotechnical site planning and subsequent geological interpretation. A Multihop-RetrievalAugmented Generation system is proposed to retrieve site-specific requirements from multiple site investigation design codes. Moreover, a progressive human-machine collaboration scheme is orchestrated for interpretable geological modelling. The efficiency of the proposed LLM-guided paradigm is validated through illustrative examples and real-world case histories. Results show that the proposed workflow facilitates real-time and accurate information retrieval as well as automatic development of subsurface geological cross-sections with quantified stratigraphic uncertainty.","[Qian, Zehang; Shi, Chao] Nanyang Technol Univ, Sch Civil & Environm Engn, Singapore 639798, Singapore",,"Shi, C (corresponding author), Nanyang Technol Univ, Sch Civil & Environm Engn, Singapore 639798, Singapore.",zehang.qian@ntu.edu.sg; chao.shi@ntu.edu.sg,,,,,,,,0,0,,,,,,,,,,,MAY,2025,173,,,,,,,,106103,10.1016/j.autcon.2025.106103,http://dx.doi.org/10.1016/j.autcon.2025.106103,,MAR 2025,,,,,,,,,,2025-05-29,WOS:001443710900001,View Full Record in Web of Science
J,"Yablonsky, S",,,,"Yablonsky, Sergey",,,AI-driven platform enterprise maturity: from human led to machine governed,KYBERNETES,,,,Article,,,,,,,,"Purpose To be more effective, artificial intelligence (AI) requires a broad overall view of the design and transformation of enterprise architecture and capabilities. Maturity models (MMs) are the recognized tools to identify strengths and weaknesses of certain domains of an organization. They consist of multiple, archetypal levels of maturity of a certain domain and can be used for organizational assessment and development. In the case of AI, quite a few numbers of MMs have been proposed. Generally, the links between AI technology, AI usage and organizational performance stay unclear. To address these gaps, this paper aims to introduce the complete details of the AI maturity model (AIMM) for AI-driven platform companies. The associated AI-Driven Platform Enterprise Maturity framework proposed here can help to achieve most of the AI-driven platform companies' objectives. Design/methodology/approach Qualitative research is performed in two stages. In the first stage, a review of the existing literature is performed to identify the types, barriers, drivers, challenges and opportunities of MMs in AI, Advanced Analytics and Big Data domains. In the second stage, a research framework is proposed to align company value chain with AI technologies and levels of the platform enterprise maturity. Findings The paper proposes a new five level AI-Driven Platform Enterprise Maturity framework by constructing a formal organizational value chain taxonomy model that explains a vast group of MM phenomena related with the AI-Driven Platform Enterprises. In addition, this study proposes a clear and precise description and structuring of the information in the multidimensional Platform, AI, Advanced Analytics and Big Data domains. The AI-Driven Platform Enterprise Maturity framework assists in identification, creation, assessment and disclosure research of AI-driven platform business organizations. Research limitations/implications This research is focused on the basic dimensions of AI value chain. The full reference model of AI consists of much more concepts. In the last few years, AI has achieved a notable drive that, if connected appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in machine learning, especially in deep neural networks, the entire community stands in front of the barrier of explainability. Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models in industry. Our prospects lead toward the concept of a methodology for the large-scale implementation of AI methods in platform organizations with fairness, model explainability and accountability at its core. Practical implications AI-driven platform enterprise maturity framework can be used for better communicate to clients the value of AI capabilities through the lens of changing human-machine interactions and in the context of legal, ethical and societal norms. Social implications The authors discuss AI in the enterprise platform stack including talent platform, human capital management and recruiting. Originality/value The AI value chain and AI-Driven Platform Enterprise Maturity framework are original and represent an effective tools for assessing AI-driven platform enterprises.","[Yablonsky, Sergey] St Petersburg State Univ, Grad Sch Management, St Petersburg, Russia",,"Yablonsky, S (corresponding author), St Petersburg State Univ, Grad Sch Management, St Petersburg, Russia.",yablonsky.serge@gmail.com,,,,,,,,13,13,,,,,,,,,,,OCT 29,2021,50,10,,,SI,,2753,2789,,10.1108/K-06-2020-0384,http://dx.doi.org/10.1108/K-06-2020-0384,,JUN 2021,,,,,,,,,,2025-05-29,WOS:000661901700001,View Full Record in Web of Science
J,"Sun, MY; Cui, WG; Zhang, Y; Yu, SY; Liao, XF; Hu, B; Li, Y",,,,"Sun, Mingyi; Cui, Weigang; Zhang, Yue; Yu, Shuyue; Liao, Xiaofeng; Hu, Bin; Li, Yang",,,Attention-Rectified and Texture-Enhanced Cross-Attention Transformer Feature Fusion Network for Facial Expression Recognition,IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,,,,Article,,,,,,,,"Facial expression recognition (FER) in the wild is a challenging task for affective computing in human-machine interaction fields. However, most of the existing methods fail to learn the most prominent regions of facial images by simple cross-entropy loss due to the imbalance problem commonly existing in FER datasets, which limits the robustness and interpretability of the model. In addition, these methods only capture local features of original images with multisize shallow convolution and ignore facial texture characteristics, leading to a suboptimal recognition performance. To address these issues, in this article, we propose a novel FER network, named the attention-rectified and texture-enhanced cross-attention transformer feature fusion network (AR-TE-CATFFNet). Specifically, an attention-rectified convolution block is first designed to assist multiple convolution heads to focus on the critical areas of human faces and improve the model generalization. Second, we investigate a texture enhancement block to capture texture features through local binary pattern and gray-level co-occurrence matrix, which solves the limitation of insufficient texture information. Finally, a cross-attention transformer feature fusion block is employed to deeply integrate red, green, blue (RGB) features and texture features globally, which is beneficial to boost the accuracy of recognition. Competitive experimental results on three public datasets validate the efficacy of the proposed method, indicating that our proposed method achieves superior classification performance of 89.50% on real-world affective faces database (RAF-DB) dataset, 65.66% on AffectNet dataset, and 74.84% on FER2013 dataset against the existing methods.","[Sun, Mingyi; Zhang, Yue; Li, Yang] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China; [Cui, Weigang] Beihang Univ, Sch Engn Med, Beijing 100191, Peoples R China; [Yu, Shuyue] Beijing Aerosp Measurement & Control Technol Co L, Beijing 100024, Peoples R China; [Liao, Xiaofeng] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China; [Hu, Bin] Lanzhou Univ, Sch Informat Sci & Engn, Gansu Prov Key Lab Wearable Comp, Lanzhou 730000, Peoples R China; [Li, Yang] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China",,"Li, Y (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China.",sunmingyi@buaa.edu.cn; cuiweigang94@foxmail.com; zhangyue_ustb@163.com; ysy_ivy@163.com; xfliao@cqu.edu.cn; bh@lzu.edu.cn; liyang@buaa.edu.cn,,,,,,,,22,22,,,,,,,,,,,DEC,2023,19,12,,,,,11823,11832,,10.1109/TII.2023.3253188,http://dx.doi.org/10.1109/TII.2023.3253188,,,,,,,,,,,,2025-05-29,WOS:001163613800018,View Full Record in Web of Science
J,"Rodríguez, M; Córdova, C; Benjumeda, I; San Martín, S",,,,"Rodriguez, Mariangel; Cordova, Claudio; Benjumeda, Isabel; San Martin, Sebastian",,,Automated Cervical Cancer Screening Using Single-Cell Segmentation and Deep Learning: Enhanced Performance with Liquid-Based Cytology,COMPUTATION,,,,Article,,,,,,,,"Cervical cancer (CC) remains a significant health issue, especially in low- and middle-income countries (LMICs). While Pap smears are the standard screening method, they have limitations, like low sensitivity and subjective interpretation. Liquid-based cytology (LBC) offers improvements but still relies on manual analysis. This study explored the potential of deep learning (DL) for automated cervical cell classification using both Pap smears and LBC samples. A novel image segmentation algorithm was employed to extract single-cell patches for training a ResNet-50 model. The model trained on LBC images achieved remarkably high sensitivity (0.981), specificity (0.979), and accuracy (0.980), outperforming previous CNN models. However, the Pap smear dataset model achieved significantly lower performance (0.688 sensitivity, 0.762 specificity, 0.8735 accuracy). This suggests that noisy and poor cell definition in Pap smears pose challenges for automated classification, whereas LBC provides better classifiable cells patches. These findings demonstrate the potential of AI-powered cervical cell classification for improving CC screening, particularly with LBC. The high accuracy and efficiency of DL models combined with effective segmentation can contribute to earlier detection and more timely intervention. Future research should focus on implementing explainable AI models to increase clinician trust and facilitate the adoption of AI-assisted CC screening in LMICs.","[Rodriguez, Mariangel] Univ Valparaiso, Fac Med Engn Sci, PhD Program Hlth Sci & Engn, Vina Del Mar 2540064, Chile; [Cordova, Claudio; San Martin, Sebastian] Univ Valparaiso, Fac Med, Ctr Interdisciplinary Biomed & Engn Res Hlth MEDIN, Sch Med, Vina Del Mar 2540064, Chile; [Benjumeda, Isabel] Adolfo Ibanez Univ, Fac Liberal Arts, Dept Sci, Vina Del Mar 2200055, Chile; [Rodriguez, Mariangel] Univ Valparaiso, Fac Med, Sch Med, Vina Del Mar 2540064, Chile",,"San Martín, S (corresponding author), Univ Valparaiso, Fac Med, Ctr Interdisciplinary Biomed & Engn Res Hlth MEDIN, Sch Med, Vina Del Mar 2540064, Chile.",mariangel.rodriguez@postgrado.uv.cl; claudio.cordova@uv.cl; isabel.benjumeda@uai.cl; sebastian.sanmartin@uv.cl,,,,,,,,0,0,,,,,,,,,,,DEC,2024,12,12,,,,,,,232,10.3390/computation12120232,http://dx.doi.org/10.3390/computation12120232,,,,,,,,,,,,2025-05-29,WOS:001383807000001,View Full Record in Web of Science
J,"Alvarez, OP",,,,"Alvarez, Omar Puertas",,,"The Crystal Ball: AI Predictive Analytics in Arbitration: Navigating Promise, Pitfalls, and Paradigm Shifts",GLOBAL TRADE AND CUSTOMS JOURNAL,,,,Article,,,,,,,,"The article discusses the increasing role of artificial intelligence (AI) in international arbitration, noting its potential to make the process more efficient and data-driven through predictive analytics and machine learning. However, AI may struggle with the complexities of arbitration, such as witness credibility and arbitrator biases, which are difficult to quantify. There are also risks like over-reliance on AI and potential impacts on due process. To responsibly integrate AI, certain strategies are suggested, such as developing ethical guidelines, enhancing AI literacy, implementing disclosure requirements, and ensuring human oversight. The need to preserve core values such as fairness, justice, and transparency is stressed. As AI becomes more prevalent, arbitration practitioners must adapt by acquiring new skills and focusing on a balanced approach that combines AI with human judgment. This balance is crucial to enhancing the arbitration process while maintaining its integrity and fairness.","[Alvarez, Omar Puertas] Cuatrecasas, Litigat & Arbitrat Dept, Madrid, Spain",,"Alvarez, OP (corresponding author), Cuatrecasas, Litigat & Arbitrat Dept, Madrid, Spain.",omar.puertas@cuatrecasas.com,,,,,,,,0,0,,,,,,,,,,,NOV,2024,19,11-12,,,,,738,747,,,,,,,,,,,,,,,2025-05-29,WOS:001340462500009,View Full Record in Web of Science
J,"Zhang, J; Wu, WL; Tang, JH; Zhu, YW; Zhang, JH; Yin, Z",,,,"Zhang, Jing; Wu, Wenlong; Tang, Jiehao; Zhu, Yiwen; Zhang, Jianhua; Yin, Zhong",,,Enhancing generic cognitive workload recognition with a dynamic hierarchical 3-D attention network and EEG features,EXPERT SYSTEMS WITH APPLICATIONS,,,,Article,,,,,,,,"In the present study, we introduced a novel approach, the dynamic hierarchical pattern learning network (DHPLNet), to assess operators' cognitive workload in a human-machine collaboration setting across multiple individuals using electroencephalogram (EEG) data. The DHPL-Net incorporates a 3-D global feature learning module and a dynamical pattern learning module to capture EEG feature correlations in spatial, statistical, frequency, and temporal domains utilizing position-based adjacency matrices. To enhance generalization across individuals, a regularization term based on Kullback-Leibler divergence and double dropout operations were integrated into the training loss. We developed a new EEG database that includes an N-back task and utilized the publicly available STEW database for algorithm validation. The DHPL-Net achieved 70.11 % accuracy for individual-independent and 97.73 % for individual-dependent binary cognitive workload level recognition in the N-back task. For the STEW database, the accuracies were 78.59 % and 98.77 %, respectively. The results demonstrated that the DHPL-Net exhibited competitive performance and interpretability compared to traditional workload classifiers. The EEG database (N-back) and deep learning models created in this study are publicly accessible (https://github.com/CFSRgroup/NBACK-DHPL) to support further research in EEG-based workload assessment. The proposed lightweight DHPL-Net offers significant potential for real-time cognitive workload assessment in safety-critical human-machine collaboration environments, particularly in aviation, healthcare, and industrial operations. Moreover, this framework can support the development of adaptive systems that dynamically adjust task demands against interference from the individual variability in neurophysiological signals.","[Zhang, Jing; Wu, Wenlong; Tang, Jiehao; Zhu, Yiwen; Yin, Zhong] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China; [Zhang, Jing; Wu, Wenlong; Tang, Jiehao; Zhu, Yiwen; Yin, Zhong] Univ Shanghai Sci & Technol, Engn Res Ctr Opt Instrument & Syst, Shanghai Key Lab Modern Opt Syst, Minist Educ, Shanghai 200093, Peoples R China; [Zhang, Jianhua] Oslo Metropolitan Univ, Dept Comp Sci, OsloMet Artificial Intelligence Lab, N-0130 Oslo, Norway",,"Yin, Z (corresponding author), Jungong Rd 516, Shanghai 200093, Peoples R China.",202440470@st.usst.edu.cn; 232260471@st.usst.edu.cn; 212240459@usst.edu.cn; 23112020172@m.fudan.edu.cn; jianhuaz@oslomet.no; yinzhong@usst.edu.cn,,,,,,,,0,0,,,,,,,,,,,JUN 25,2025,280,,,,,,,,127563,10.1016/j.eswa.2025.127563,http://dx.doi.org/10.1016/j.eswa.2025.127563,,APR 2025,,,,,,,,,,2025-05-29,WOS:001465320600001,View Full Record in Web of Science
J,"Hosseini, I; Dietz, T",,,,"Hosseini, Ilia; Dietz, Thomas",,,GNN4GC-Graph Neural Networks for Grid Control,ELEKTROTECHNIK UND INFORMATIONSTECHNIK,,,,Article,,,,,,,,"The increasing electrification of various sectors and industries and challenges of the energy transition presents complex tasks for transmission system operators. Transmission systems serve as the core infrastructure for transmission electricity across regions, nations, and even continents, playing a crucial role in ensuring a steady and save power supply. However, operators face significant challenges due to the increasing power demand and the fact that the current speed of network expansion cannot keep up with the changed market situation. Additionally, the fluctuating power generation from renewable energy causes congestion in the transmission grid and overloading of transmission lines. Currently, operators resort to measures like redispatch to alleviate these issues, which proves to be unfavorable due to high expenses and regulatory challenges. The GNN4GC (Graph Neural Networks for Grid Control) project, a collaborative effort by Fraunhofer IEE, the University of Kassel, and transmission system operators (TenneT TSO GmbH, 50Hertz, TenneT TSO B.V), aims to address these challenges by leveraging Artificial Intelligence, particularly Graph Neural Networks (GNNs) and Deep Reinforcement Learning (DRL). The goal of GNN4GC is to develop GNN models to optimize load flow calculations and subsequently select optimal topology configurations. By combining GNNs with DRL, the project aims to create self-learning agents capable of recommending optimal topology changes, enhancing grid control and efficiency to support network operators with specific action recommendations. GNNs are particularly well-suited for this task due to their compatibility with network structures, enabling rapid grid calculations and power flow approximations [1]. Human-in-the-Loop and Explainable AI (XAI) methods are integral to the project, ensuring transparency and optimal adaptation of AI solutions. Continuous evaluation with grid operators will ensure practical implementation, fostering a close collaboration between research and industry.","[Hosseini, Ilia; Dietz, Thomas] TenneT TSO GmbH, Syst Operat, Bernecker Str 70, D-95448 Bayreuth, Bayern, Germany",,"Hosseini, I (corresponding author), TenneT TSO GmbH, Syst Operat, Bernecker Str 70, D-95448 Bayreuth, Bayern, Germany.",ilia.hosseini@tennet.eu; Thomas.Dietz@tennet.eu,,,,,,,,0,0,,,,,,,,,,,DEC,2024,141,7-8,,,,,464,467,,10.1007/s00502-024-01291-0,http://dx.doi.org/10.1007/s00502-024-01291-0,,DEC 2024,,,,,,,,,,2025-05-29,WOS:001375765400001,View Full Record in Web of Science
J,"Xu, CY; Li, X; Zhang, XY; Wu, RL; Zhou, YX; Zhao, QH; Zhang, Y; Geng, SJ; Gu, Y; Hong, SD",,,,"Xu, Chenyang; Li, Xin; Zhang, Xinyue; Wu, Ruilin; Zhou, Yuxi; Zhao, Qinghao; Zhang, Yong; Geng, Shijia; Gu, Yue; Hong, Shenda",,,Cardiac murmur grading and risk analysis of cardiac diseases based on adaptable heterogeneous-modality multi-task learning,HEALTH INFORMATION SCIENCE AND SYSTEMS,,,,Article,,,,,,,,"Cardiovascular disease (CVDs) has become one of the leading causes of death, posing a significant threat to human life. The development of reliable Artificial Intelligence (AI) assisted diagnosis algorithms for cardiac sounds is of great significance for early detection and treatment of CVDs. However, there is scarce research in this field. Existing research mainly faces three major challenges: (1) They mainly limited to murmur classification and cannot achieve murmur grading, but attempting both classification and grading may lead to negative effects between different multi-tasks. (2) They mostly pay attention to unstructured cardiac sound modality and do not consider the structured demographic modality, as it is difficult to balance the influence of heterogeneous modalities. (3) Deep learning methods lack interpretability, which makes it challenging to apply them clinically. To tackle these challenges, we propose a method for cardiac murmur grading and cardiac risk analysis based on heterogeneous modality adaptive multi-task learning. Specifically, a Hierarchical Multi-Task learning-based cardiac murmur detection and grading method (HMT) is proposed to prevent negative interference between different tasks. In addition, a cardiac risk analysis method based on Heterogeneous Multi-modal feature impact Adaptation (HMA) is also proposed, which transforms unstructured modality into structured modality representation, and utilizes an adaptive mode weight learning mechanism to balance the impact between unstructured modality and structured modality, thus enhancing the performance of cardiac risk prediction. Finally, we propose a multi-task interpretability learning module that incorporates an important evaluation using random masks. This module utilizes SHAP graphs to visualize crucial murmur segments in cardiac sound and employs a multi-factor risk decoupling model based on nomograms. And then we gain insights into the cardiac disease risk in both pre-decoupled multi-modality and post-decoupled single-modality scenarios, thus providing a solid foundation for AI assisted cardiac murmur grading and risk analysis. Experimental results on a large real-world CirCor DigiScope PCG dataset demonstrate that the proposed method outperforms the state-of-the-art (SOTA) method in murmur detection, grading, and cardiac risk analysis, while also providing valuable diagnostic evidence.","[Xu, Chenyang; Zhang, Xinyue; Wu, Ruilin; Zhou, Yuxi; Gu, Yue] Tianjin Univ Technol, Dept Comp Sci, Tianjin, Peoples R China; [Li, Xin] Tsinghua Univ, Beijing Tsinghua Changgung Hosp, Sch Clin Med, Dept Rehabil Med, Beijing, Peoples R China; [Zhou, Yuxi; Zhang, Yong] Tsinghua Univ, Inst Internet Ind, DCST, BNRist,RIIT, Beijing, Peoples R China; [Zhao, Qinghao] Peking Univ Peoples Hosp, Dept Cardiol, Beijing, Peoples R China; [Hong, Shenda] Peking Univ, Natl Inst Hlth Data Sci, Beijing, Peoples R China; [Hong, Shenda] Peking Univ, Inst Med Technol, Beijing, Peoples R China; [Geng, Shijia] HeartVoice Med Technol, Hefei, Peoples R China",,"Zhou, YX (corresponding author), Tianjin Univ Technol, Dept Comp Sci, Tianjin, Peoples R China.;Zhou, YX (corresponding author), Tsinghua Univ, Inst Internet Ind, DCST, BNRist,RIIT, Beijing, Peoples R China.;Hong, SD (corresponding author), Peking Univ, Natl Inst Hlth Data Sci, Beijing, Peoples R China.;Hong, SD (corresponding author), Peking Univ, Inst Med Technol, Beijing, Peoples R China.",joy_yuxi@pku.edu.cn; hongshenda@pku.edu.cn,,,,,,,,5,5,,,,,,,,,,,DEC 1,2023,12,1,,,,,,,2,10.1007/s13755-023-00249-4,http://dx.doi.org/10.1007/s13755-023-00249-4,,,,,,,,,,,,2025-05-29,WOS:001118316700001,View Full Record in Web of Science
J,"Sokol, K; Flach, P",,,,"Sokol, Kacper; Flach, Peter",,,One Explanation Does Not Fit All The Promise of Interactive Explanations for Machine Learning Transparency,KUNSTLICHE INTELLIGENZ,,,,Article,,,,,,,,"The need for transparency of predictive systems based on Machine Learning algorithms arises as a consequence of their ever-increasing proliferation in the industry. Whenever black-box algorithmic predictions influence human affairs, the inner workings of these algorithms should be scrutinised and their decisions explained to the relevant stakeholders, including the system engineers, the system's operators and the individuals whose case is being decided. While a variety of interpretability and explainability methods is available, none of them is a panacea that can satisfy all diverse expectations and competing objectives that might be required by the parties involved. We address this challenge in this paper by discussing the promises of Interactive Machine Learning for improved transparency of black-box systems using the example of contrastive explanations-a state-of-the-art approach to Interpretable Machine Learning. Specifically, we show how to personalise counterfactual explanations by interactively adjusting their conditional statements and extract additional explanations by asking follow-up What if? questions. Our experience in building, deploying and presenting this type of system allowed us to list desired properties as well as potential limitations, which can be used to guide the development of interactive explainers. While customising the medium of interaction, i.e., the user interface comprising of various communication channels, may give an impression of personalisation, we argue that adjusting the explanation itself and its content is more important. To this end, properties such as breadth, scope, context, purpose and target of the explanation have to be considered, in addition to explicitly informing the explainee about its limitations and caveats. Furthermore, we discuss the challenges of mirroring the explainee's mental model, which is the main building block of intelligible human-machine interactions. We also deliberate on the risks of allowing the explainee to freely manipulate the explanations and thereby extracting information about the underlying predictive model, which might be leveraged by malicious actors to steal or game the model. Finally, building an end-to-end interactive explainability system is a challenging engineering task; unless the main goal is its deployment, we recommend Wizard of Oz studies as a proxy for testing and evaluating standalone interactive explainability algorithms.","[Sokol, Kacper; Flach, Peter] Univ Bristol, Dept Comp Sci, Bristol, Avon, England",,"Sokol, K (corresponding author), Univ Bristol, Dept Comp Sci, Bristol, Avon, England.",K.Sokol@bristol.ac.uk; Peter.Flach@bristol.ac.uk,,,,,,,,94,100,,,,,,,,,,,JUN,2020,34,2,,,SI,,235,250,,10.1007/s13218-020-00637-y,http://dx.doi.org/10.1007/s13218-020-00637-y,,FEB 2020,,,,,,,,,,2025-05-29,WOS:000511061800002,View Full Record in Web of Science
J,"Schrank, A; Kettwich, C; Oehl, M",,,,"Schrank, Andreas; Kettwich, Carmen; Oehl, Michael",,,Aiding Automated Shuttles with Their Driving Tasks as an On-Board Operator: A Case Study on Different Automated Driving Systems in Three Living Labs,APPLIED SCIENCES-BASEL,,,,Article,,,,,,,,"Highly automated shuttle vehicles (SAE Level 4) have the potential to enhance public transport services by decreasing the demand for drivers, enabling more frequent and flexible ride options. However, at least in a transitionary phase, safety operators that supervise and support the shuttles with their driving tasks may be required on board the vehicle from a technical or legal point of view. A crucial component for executing supervisory and intervening tasks is the human-machine interface between an automated vehicle and its on-board operator. This research presents in-depth case studies from three heterogenous living laboratories in Germany that deployed highly automated shuttle vehicles with on-board operators on public roads. The living labs differed significantly regarding the on-board operators' tasks and the design of the human-machine interfaces. Originally considered a provisional solution until the vehicle automation is fully capable of running without human support, these interfaces were, in general, not designed in a user-centered way. However, since technological progress has been slower than expected, on-board operator interfaces are likely to persist in the mid-term at least. Hence, this research aims to assess the aptitude of interfaces that are in practical use for the on-board operators' tasks, in order to determine the user-centered design of future interfaces. Completing questionnaires and undergoing comprehensive, semi-structured interviews, nine on-board operators evaluated their human-machine interfaces in light of the respective tasks they complete regarding user variables such as work context, acceptance, system transparency, and trust. The results were highly diverse across laboratories and underlined that the concrete system setup, encompassing task and interface design, has a considerable impact on these variables. Ergonomics, physical demand, and system transparency were identified as the most significant deficits. These findings and derived recommendations may inform the design of on-board operator workspaces, and bear implications for remote operation workstations as well.","[Schrank, Andreas; Oehl, Michael] German Aerosp Ctr DLR, Inst Transportat Syst, Lilienthalpl 7, D-38108 Braunschweig, Germany; [Kettwich, Carmen] City Brunswick, Dept Urban Dev Stat & Project Planning, Pl Deutsch Einheit 1, D-38100 Braunschweig, Germany",,"Schrank, A (corresponding author), German Aerosp Ctr DLR, Inst Transportat Syst, Lilienthalpl 7, D-38108 Braunschweig, Germany.",andreas.schrank@dlr.de; carmen.kettwich@braunschweig.de; michael.oehl@dlr.de,,,,,,,,2,2,,,,,,,,,,,APR,2024,14,8,,,,,,,3336,10.3390/app14083336,http://dx.doi.org/10.3390/app14083336,,,,,,,,,,,,2025-05-29,WOS:001258365800001,View Full Record in Web of Science
J,"Russell, S; Kumar, A",,,,"Russell, Stephen; Kumar, Ashwin",,,Providing Care: Intrinsic Human-Machine Teams and Data,ENTROPY,,,,Article,,,,,,,,"Despite the many successes of artificial intelligence in healthcare applications where human-machine teaming is an intrinsic characteristic of the environment, there is little work that proposes methods for adapting quantitative health data-features with human expertise insights. A method for incorporating qualitative expert perspectives in machine learning training data is proposed. The method implements an entropy-based consensus construct that minimizes the challenges of qualitative-scale data such that they can be combined with quantitative measures in a critical clinical event (CCE) vector. Specifically, the CCE vector minimizes the effects where (a) the sample size is too small, (b) the data may not be normally distributed, or (c) The data are from Likert scales, which are ordinal, so parametric statistics cannot be used. The incorporation of human perspectives in machine learning training data provides encoding of human considerations in the subsequent machine learning model. This encoding provides a basis for increasing explainability, understandability, and ultimately trust in AI-based clinical decision support system (CDSS), thereby improving human-machine teaming concerns. A discussion of applying the CCE vector in a CDSS regime and implications for machine learning are also presented.","[Russell, Stephen; Kumar, Ashwin] Jackson Hlth Syst, Dept Res Opportun & Innovat Data Sci, Miami, FL 33136 USA",,"Russell, S (corresponding author), Jackson Hlth Syst, Dept Res Opportun & Innovat Data Sci, Miami, FL 33136 USA.",stephen.russell@jhsmiami.org,,,,,,,,0,0,,,,,,,,,,,OCT,2022,24,10,,,,,,,1369,10.3390/e24101369,http://dx.doi.org/10.3390/e24101369,,,,,,,,,,,,2025-05-29,WOS:000872757500001,View Full Record in Web of Science
J,"Li, DP; Liu, SM; Wang, BC; Yu, CY; Zheng, P; Li, WH",,,,"Li, Dongpeng; Liu, Shimin; Wang, Baicun; Yu, Chunyang; Zheng, Pai; Li, Weihua",,,Trustworthy AI for human-centric smart manufacturing: A survey,JOURNAL OF MANUFACTURING SYSTEMS,,,,Article,,,,,,,,"Human-centric smart manufacturing (HCSM) envisions a symbiotic relationship between humans and machines, leveraging human capability and Artificial Intelligence (AI)'s precision and computational power to achieve mutual enhancement. Trustworthy AI (TAI) is a promising enabler in this transition, ensuring that the integration of AI technologies within manufacturing scenarios is safe, transparent, and participatory. This paper systematically reviews TAI within the context of HCSM by adopting a progressive 3-layer framework. This framework aligns with the developmental stages of HCSM and includes basic safety (protection), advancing to explainability, accountability, and uncertainty awareness (perception), and culminating in continuous updating with human involvement (participation). The review explores the role of TAI across key stages of the product lifecycle, demonstrating how TAI can empower humans and highlighting current advancements while identifying ongoing challenges. The paper concludes by discussing future directions and offering insights for developing TAI-integrated HCSM.","[Li, Dongpeng; Liu, Shimin; Zheng, Pai] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hong Kong, Peoples R China; [Li, Dongpeng] South China Univ Technol, Shien Ming Wu Sch Intelligent Engn, Guangzhou 511441, Peoples R China; [Li, Dongpeng; Li, Weihua] Guangdong Artificial Intelligent & Digital Econ La, Pazhou Lab, Guangzhou 510335, Peoples R China; [Wang, Baicun] Zhejiang Univ, Sch Mech Engn, State Key Lab Fluid Power & Mechatron Syst, Hangzhou, Peoples R China; [Yu, Chunyang] China Acad Art, Design AI Lab, Hangzhou, Peoples R China; [Li, Weihua] South China Univ Technol, Sch Mech & Automot Engn, Guangzhou 510640, Peoples R China",,"Zheng, P (corresponding author), Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hong Kong, Peoples R China.",pai.zheng@polyu.edu.hk,,,,,,,,1,1,,,,,,,,,,,FEB,2025,78,,,,,,308,327,,10.1016/j.jmsy.2024.11.020,http://dx.doi.org/10.1016/j.jmsy.2024.11.020,,DEC 2024,,,,,,,,,,2025-05-29,WOS:001393255000001,View Full Record in Web of Science
J,"Marchi, F; Bellini, E; Iandelli, A; Sampieri, C; Peretti, G",,,,"Marchi, Filippo; Bellini, Elisa; Iandelli, Andrea; Sampieri, Claudio; Peretti, Giorgio",,,Exploring the landscape of AI-assisted decision-making in head and neck cancer treatment: a comparative analysis of NCCN guidelines and ChatGPT responses,EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY,,,,Article,,,,,,,,"PurposeRecent breakthroughs in natural language processing and machine learning, exemplified by ChatGPT, have spurred a paradigm shift in healthcare. Released by OpenAI in November 2022, ChatGPT rapidly gained global attention. Trained on massive text datasets, this large language model holds immense potential to revolutionize healthcare. However, existing literature often overlooks the need for rigorous validation and real-world applicability.MethodsThis head-to-head comparative study assesses ChatGPT's capabilities in providing therapeutic recommendations for head and neck cancers. Simulating every NCCN Guidelines scenarios. ChatGPT is queried on primary treatments, adjuvant treatment, and follow-up, with responses compared to the NCCN Guidelines. Performance metrics, including sensitivity, specificity, and F1 score, are employed for assessment.ResultsThe study includes 68 hypothetical cases and 204 clinical scenarios. ChatGPT exhibits promising capabilities in addressing NCCN-related queries, achieving high sensitivity and overall accuracy across primary treatment, adjuvant treatment, and follow-up. The study's metrics showcase robustness in providing relevant suggestions. However, a few inaccuracies are noted, especially in primary treatment scenarios.ConclusionOur study highlights the proficiency of ChatGPT in providing treatment suggestions. The model's alignment with the NCCN Guidelines sets the stage for a nuanced exploration of AI's evolving role in oncological decision support. However, challenges related to the interpretability of AI in clinical decision-making and the importance of clinicians understanding the underlying principles of AI models remain unexplored. As AI continues to advance, collaborative efforts between models and medical experts are deemed essential for unlocking new frontiers in personalized cancer care.","[Marchi, Filippo; Bellini, Elisa; Iandelli, Andrea; Peretti, Giorgio] IRCCS Osped Policlin San Martino, Unit Otorhinolaryngol Head & Neck Surg, Largo Rosanna Benzi 10, I-16132 Genoa, Italy; [Marchi, Filippo; Bellini, Elisa; Peretti, Giorgio] Univ Genoa, Dept Surg Sci & Integrated Diagnost DISC, I-16132 Genoa, Italy; [Sampieri, Claudio] Univ Genoa, Dept Expt Med DIMES, Genoa, Italy; [Sampieri, Claudio] Hosp Clin Univ, Dept Otolaryngol, Barcelona, Spain; [Sampieri, Claudio] Hosp Clin Barcelona, Funct Unit Head Neck Tumors, Barcelona, Spain",,"Bellini, E (corresponding author), IRCCS Osped Policlin San Martino, Unit Otorhinolaryngol Head & Neck Surg, Largo Rosanna Benzi 10, I-16132 Genoa, Italy.;Bellini, E (corresponding author), Univ Genoa, Dept Surg Sci & Integrated Diagnost DISC, I-16132 Genoa, Italy.",e.e.elisabellini@gmail.com,,,,,,,,16,16,,,,,,,,,,,APR,2024,281,4,,,,,2123,2136,,10.1007/s00405-024-08525-z,http://dx.doi.org/10.1007/s00405-024-08525-z,,FEB 2024,,,,,,,,,,2025-05-29,WOS:001172712200001,View Full Record in Web of Science
J,"Surendran, A; Daigavane, P; Shrivastav, S; Kamble, R; Sanchla, AD; Bharti, L; Shinde, M",,,,"Surendran, Aathira; Daigavane, Pallavi; Shrivastav, Sunita; Kamble, Ranjit; Sanchla, Abhishek D.; Bharti, Lovely; Shinde, Mrudula",,,The Future of Orthodontics: Deep Learning Technologies,CUREUS JOURNAL OF MEDICAL SCIENCE,,,,Review,,,,,,,,"Deep learning has emerged as a revolutionary technical advancement in modern orthodontics, offering novel methods for diagnosis, treatment planning, and outcome prediction. Over the past 25 years, the field of dentistry has widely adopted information technology (IT), resulting in several benefits, including decreased expenses, increased efficiency, decreased need for human expertise, and reduced errors. The transition from preset rules to learning from real -world examples, particularly machine learning (ML) and artificial intelligence (AI), has greatly benefited the organization, analysis, and storage of medical data. Deep learning, a type of AI, enables robots to mimic human neural networks, allowing them to learn and make decisions independently without the need for explicit programming. Its ability to automate cephalometric analysis and enhance diagnosis through 3D imaging has revolutionized orthodontic operations. Deep learning models have the potential to significantly improve treatment outcomes and reduce human errors by accurately identifying anatomical characteristics on radiographs, thereby expediting analytical processes. Additionally, the use of 3D imaging technologies such as cone -beam computed tomography (CBCT) can facilitate precise treatment planning, allowing for comprehensive examinations of craniofacial architecture, tooth movements, and airway dimensions. In today's era of personalized medicine, deep learning's ability to customize treatments for individual patients has propelled the field of orthodontics forward tremendously. However, it is essential to address issues related to data privacy, model interpretability, and ethical considerations before orthodontic practices can use deep learning in an ethical and responsible manner. Modern orthodontics is evolving, thanks to the ability of deep learning to deliver more accurate, effective, and personalized orthodontic treatments, improving patient care as technology develops.","[Surendran, Aathira; Daigavane, Pallavi; Shrivastav, Sunita; Kamble, Ranjit; Sanchla, Abhishek D.; Bharti, Lovely; Shinde, Mrudula] Sharad Pawar Dent Coll & Hosp, Dept Orthodont & Dentofacial Orthopaed, Wardha, India",,"Surendran, A (corresponding author), Sharad Pawar Dent Coll & Hosp, Dept Orthodont & Dentofacial Orthopaed, Wardha, India.",aathirasurendrank@gmail.com,,,,,,,,3,3,,,,,,,,,,,JUN 10,2024,16,6,,,,,,,e62045,10.7759/cureus.62045,http://dx.doi.org/10.7759/cureus.62045,,,,,,,,,,,,2025-05-29,WOS:001258884200028,View Full Record in Web of Science
J,"Cham, K; Shakiry, R; Yates, C",,,,"Cham, Karen; Shakiry, Raida; Yates, Carl",,,Dual Cognitive UXD and Explainable AI,JOURNAL OF USABILITY STUDIES,,,,Article,,,,,,,,"We are in an age where route to market for technological innovation is unimpeded by even the simplest of safety checks. Computer vision, for example, cannot differentiate the side of a lorry from an open patch of sky when driving an autonomous vehicle, whilst iris and facial recognition technologies are rolled out as infallible ID systems with huge error rates on black skin and eyes. Meanwhile, whistleblower testimony about how social media inadvertently engineers self-harm in young people and how there is more than a suggestion that our collective big data is being used in social engineering experiments at scale reinforces a growing vocal concern with ethics in professional UX circles. The chasm into which all of this simultaneously falls into and erupts from is human factors-that traditional add on to technology development that is firmly in the gap between analog and automation; between people and machine; between user and design, affordance, and agency. All of these issues are thus digital transformation issues. The steady migration of personal, social, and cultural values; policy; practice; law; and ideology into computer code with greater and lesser degrees of success. The goal of this essay is to share seminal research findings in eCommerce and games UX as a foundation for a dual cognitive or deep user experience design (Deep UXD) that integrates biometric insights. I suggest this can provide a fundamental basis from which to address persuasion, emotion, and trust (PET; Schaffer, 2009) in the development cycle of all human-computer interaction (HCI) applications. I conclude on the future field of application in terms of UX informed human-centered Al (HCAI) and human-in- the-loop (HITL) service design for Industry 4.0.","[Cham, Karen] Human Centred Futures, 71-75 Shelton St, London, England; [Shakiry, Raida] Experience Consultancy, London, England; [Yates, Carl] uMore, Miami, FL USA",,"Cham, K (corresponding author), Human Centred Futures, 71-75 Shelton St, London, England.",chiefdesinnscientist@humancentredfutures.com; raida@experience-consultancy.com; carl@umore.app,,,,,,,,2,2,,,,,,,,,,,NOV,2021,17,1,,,,,1,11,,,,,,,,,,,,,,,2025-05-29,WOS:000755073200001,View Full Record in Web of Science
J,"Lei, CY; Dang, K; Song, SF; Wang, ZL; Chew, SP; Bian, RT; Yang, XC; Guan, ZY; Lopes, CIMD; Wang, MH; Choy, RWC; Hu, XY; Lai, KKH; Chong, KKL; Pang, CP; Song, XF; Su, JL; Ding, XW; Zhou, HF",,,,"Lei, Chaoyu; Dang, Kang; Song, Sifan; Wang, Zilong; Chew, Sien Ping; Bian, Ruitong; Yang, Xichen; Guan, Zhouyu; Lopes, Claudia Isabel Marques de Abreu; Wang, Mini Hang; Choy, Richard Wai Chak; Hu, Xiaoyan; Lai, Kenneth Ka Hei; Chong, Kelvin Kam Lung; Pang, Chi Pui; Song, Xuefei; Su, Jionglong; Ding, Xiaowei; Zhou, Huifang",,,AI-assisted facial analysis in healthcare From disease detection to comprehensive management,PATTERNS,,,,Review,,,,,,,,"Medical conditions and systemic diseases often manifest as distinct facial characteristics, making identification of these unique features crucial for disease screening. However, detecting diseases using facial photography remains challenging because of the wide variability in human facial features and disease conditions. The integration of artificial intelligence (AI) into facial analysis represents a promising frontier offering a userfriendly, non-invasive, and cost-effective screening approach. This review explores the potential of AI-assisted facial analysis for identifying subtle facial phenotypes indicative of health disorders. First, we outline the technological framework essential for effective implementation in healthcare settings. Subsequently, we focus on the role of AI-assisted facial analysis in disease screening. We further expand our examination to include applications in health monitoring, support of treatment decision-making, and disease follow-up, thereby contributing to comprehensive disease management. Despite its promise, the adoption of this technology faces several challenges, including privacy concerns, model accuracy, issues with model interpretability, biases in AI algorithms, and adherence to regulatory standards. Addressing these challenges is crucial to ensure fair and ethical use. By overcoming these hurdles, AI-assisted facial analysis can empower healthcare providers, improve patient care outcomes, and enhance global health.","[Lei, Chaoyu; Dang, Kang; Song, Sifan; Wang, Zilong; Chew, Sien Ping; Bian, Ruitong; Yang, Xichen; Lai, Kenneth Ka Hei; Chong, Kelvin Kam Lung; Pang, Chi Pui; Song, Xuefei; Ding, Xiaowei; Zhou, Huifang] Shanghai Jiao Tong Univ, Sch Med, Shanghai Peoples Hosp 9, Dept Ophthalmol, Shanghai, Peoples R China; [Lei, Chaoyu; Chew, Sien Ping; Bian, Ruitong; Yang, Xichen; Chong, Kelvin Kam Lung; Song, Xuefei; Zhou, Huifang] Shanghai Key Lab Orbital Dis & Ocular Oncol, Shanghai, Peoples R China; [Lei, Chaoyu; Chew, Sien Ping; Bian, Ruitong; Yang, Xichen; Song, Xuefei; Ding, Xiaowei; Zhou, Huifang] Minist Educ, Ctr Basic Med Res & Innovat Visual Syst Dis, Shanghai, Peoples R China; [Lei, Chaoyu; Dang, Kang; Song, Sifan; Wang, Zilong; Su, Jionglong] Xian Jiaotong Liverpool Univ, XJTLU Entrepreneur Coll Taicang, Sch AI & Adv Comp, Suzhou, Peoples R China; [Dang, Kang; Song, Sifan] Voxelcloud Inc, Shanghai, Peoples R China; [Wang, Zilong] Microsoft Res Asia, Shanghai, Peoples R China; [Guan, Zhouyu] Shanghai Jiao Tong Univ, Sch Med, Shanghai, Peoples R China; [Lopes, Claudia Isabel Marques de Abreu; Pang, Chi Pui] United Nations Univ, Int Inst Global Hlth, Kuala Lumpur, Malaysia; [Wang, Mini Hang; Choy, Richard Wai Chak; Hu, Xiaoyan; Lai, Kenneth Ka Hei; Chong, Kelvin Kam Lung; Pang, Chi Pui] Chinese Univ Hong Kong, Fac Med, Dept Ophthalmol & Visual Sci, Hong Kong, Peoples R China; [Lai, Kenneth Ka Hei; Chong, Kelvin Kam Lung] Prince Wales Hosp, Dept Ophthalmol & Visual Sci, Hong Kong, Peoples R China; [Chong, Kelvin Kam Lung; Pang, Chi Pui] Hong Kong Eye Hosp, Hong Kong, Peoples R China; [Chong, Kelvin Kam Lung] Chinese Univ Hong Kong, Eye Ctr, Med Ctr, Hong Kong, Peoples R China; [Ding, Xiaowei] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai, Peoples R China",,"Song, XF; Ding, XW; Zhou, HF (corresponding author), Shanghai Jiao Tong Univ, Sch Med, Shanghai Peoples Hosp 9, Dept Ophthalmol, Shanghai, Peoples R China.;Song, XF; Zhou, HF (corresponding author), Shanghai Key Lab Orbital Dis & Ocular Oncol, Shanghai, Peoples R China.;Song, XF; Ding, XW; Zhou, HF (corresponding author), Minist Educ, Ctr Basic Med Res & Innovat Visual Syst Dis, Shanghai, Peoples R China.;Su, JL (corresponding author), Xian Jiaotong Liverpool Univ, XJTLU Entrepreneur Coll Taicang, Sch AI & Adv Comp, Suzhou, Peoples R China.;Ding, XW (corresponding author), Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai, Peoples R China.",songxuefei@shsmu.edu.cn; jionglong.su@xjtlu.edu.cn; dingxiaowei@sjtu.edu.cn; fangzzfang@sjtu.edu.cn,,,,,,,,1,1,,,,,,,,,,,FEB 14,2025,6,2,,,,,,,101175,10.1016/j.patter.2025.101175,http://dx.doi.org/10.1016/j.patter.2025.101175,,FEB 2025,,,,,,,,,,2025-05-29,WOS:001434206000001,View Full Record in Web of Science
J,"Zhang, Q; Xu, C; Li, J; Sun, YC; Bao, JS; Zhang, D",,,,"Zhang, Qi; Xu, Chao; Li, Jie; Sun, Yicheng; Bao, Jinsong; Zhang, Dan",,,LLM-TSFD: An industrial time series human-in-the-loop fault diagnosis method based on a large language model,EXPERT SYSTEMS WITH APPLICATIONS,,,,Article,,,,,,,,"Industrial time series data provides real-time information about the operational status of equipment and helps identify anomalies. Data-driven and knowledge-guided methods have become predominant in this field. However, these methods depend on industrial domain knowledge and high-quality industrial data which can lead to issues such as unclear diagnostic results and lengthy development cycles. This paper introduces a novel humanin-the-loop task-driven approach to reduce reliance on manually annotated data and improve the interpretability of diagnostic outcomes. This approach utilises a large language model for fault detection, fostering process autonomy and enhancing human-machine collaboration. Furthermore, this paper explores four key roles of the large language model: managing the data pipeline, correcting causality, controlling model management, and making decisions about diagnostic results. Additionally, it presents a prompt structure designed for fault diagnosis of time series data, enabling the large language model to realize task-driven. Finally, the paper validates the proposed framework through a case study in the context of steel metallurgy.","[Zhang, Qi; Xu, Chao; Li, Jie; Sun, Yicheng; Bao, Jinsong; Zhang, Dan] Donghua Univ, Coll Mech Engn, Shanghai 201602, Peoples R China; [Zhang, Dan] Hong Kong Polytech Univ, Dept Mech Engn, Hong Kong, Peoples R China",,"Bao, JS (corresponding author), Donghua Univ, Coll Mech Engn, Shanghai 201602, Peoples R China.",1229080@mail.dhu.edu.cn; 2222778@mail.dhu.edu.cn; jie.li@dhu.edu.cn; 1222014@mail.dhu.edu.cn; bao@dhu.edu.cn; dan.zhang@polyu.edu.hk,,,,,,,,2,2,,,,,,,,,,,MAR 10,2025,264,,,,,,,,125861,10.1016/j.eswa.2024.125861,http://dx.doi.org/10.1016/j.eswa.2024.125861,,NOV 2024,,,,,,,,,,2025-05-29,WOS:001372520200001,View Full Record in Web of Science
J,"Durlik, I; Miller, T; Kostecka, E; Kozlovska, P; Slaczka, W",,,,"Durlik, Irmina; Miller, Tymoteusz; Kostecka, Ewelina; Kozlovska, Polina; Slaczka, Wojciech",,,Enhancing Safety in Autonomous Maritime Transportation Systems with Real-Time AI Agents,APPLIED SCIENCES-BASEL,,,,Review,,,,,,,,"The maritime transportation sector is undergoing a profound shift with the emergence of autonomous vessels powered by real-time artificial intelligence (AI) agents. This article investigates the pivotal role of these agents in enhancing the safety, efficiency, and sustainability of autonomous maritime systems. Following a structured literature review, we examine the architecture of real-time AI agents, including sensor integration, communication systems, and computational infrastructure. We distinguish maritime AI agents from conventional systems by emphasizing their specialized functions, real-time processing demands, and resilience in dynamic environments. Key safety mechanisms-such as collision avoidance, anomaly detection, emergency coordination, and fail-safe operations-are analyzed to demonstrate how AI agents contribute to operational reliability. The study also explores regulatory compliance, focusing on emission control, real-time monitoring, and data governance. Implementation challenges, including limited onboard computational power, legal and ethical constraints, and interoperability issues, are addressed with practical solutions such as edge AI and modular architectures. Finally, the article outlines future research directions involving smart port integration, scalable AI models, and emerging technologies like federated and explainable AI. This work highlights the transformative potential of AI agents in advancing autonomous maritime transportation.","[Durlik, Irmina; Slaczka, Wojciech] Maritime Univ Szczecin, Fac Nav, Waly Chrobrego 1-2, PL-70500 Szczecin, Poland; [Miller, Tymoteusz] Univ Szczecin, Inst Marine & Environm Sci, Waska 13, PL-71415 Szczecin, Poland; [Miller, Tymoteusz] INTI Int Univ, Fac Data Sci & Informat Technol, Putra Nilai 71800, Negeri Sembilan, Malaysia; [Kostecka, Ewelina] Maritime Univ Szczecin, Fac Mechatron & Elect Engn, Waly Chrobrego 1-2, PL-70500 Szczecin, Poland; [Kozlovska, Polina] Univ Szczecin, Fac Econ Finance & Management, PL-71415 Szczecin, Poland",,"Miller, T (corresponding author), Univ Szczecin, Inst Marine & Environm Sci, Waska 13, PL-71415 Szczecin, Poland.;Miller, T (corresponding author), INTI Int Univ, Fac Data Sci & Informat Technol, Putra Nilai 71800, Negeri Sembilan, Malaysia.",i.durlik@pm.szczecin.pl; tymoteusz.miller@usz.edu.pl; e.kostecka@pm.szczecin.pl; 231805@stud.usz.edu.pl; w.slaczka@pm.szczecin.pl,,,,,,,,0,0,,,,,,,,,,,APR 30,2025,15,9,,,,,,,4986,10.3390/app15094986,http://dx.doi.org/10.3390/app15094986,,,,,,,,,,,,2025-05-29,WOS:001486045800001,View Full Record in Web of Science
J,"Alsamhi, SH; Kumar, S; Hawbani, A; Shvetsov, AV; Zhao, L; Guizani, M",,,,"Alsamhi, Saeed Hamood; Kumar, Santosh; Hawbani, Ammar; Shvetsov, Alexey V.; Zhao, Liang; Guizani, Mohsen",,,"Synergy of Human-Centered AI and Cyber-Physical-Social Systems for Enhanced Cognitive Situation Awareness: Applications, Challenges and Opportunities",COGNITIVE COMPUTATION,,,,Article,,,,,,,,"This paper explores the convergence of Human-Centered AI (HCAI) and Cyber-Physical Social Systems (CPSS) in pursuing advanced Cognitive Situation Awareness (CSA). Integrating HCAI principles within CPSS fosters systems prioritizing human needs, values, and experiences, improving perception, understanding, and responsiveness to complex environments. By incorporating transparency, interpretability, and usability into Artificial Intelligence (AI) systems, the human-centered approach enhances user interaction and cooperation with intelligent systems, leading to more adaptive and efficient CPSS. The study employs a comprehensive approach to explore the intersection of HCAI and CPSS. Moreover, the paper presents case studies to illustrate real-world applications of HCAI and CPSS, such as self-driving cars and smart homes, transportation, healthcare, energy management, social media, and emergency response systems. Nevertheless, technical complexities, privacy concerns, and regulatory considerations must be addressed. The paper demonstrates the practical implications of integrating HCAI into CPSS through case studies in various domains. Furthermore, It highlights the positive impact of CSA systems such as self-driving cars, showcasing improvements in transportation. This paper contributes to advancing CSA and designing intelligent systems, promoting human-machine collaboration and societal well-being. By examining the intersection of HCAI and CPSS, this study advances research in CSA and designing intelligent systems prioritizing human needs, values, and experiences.","[Alsamhi, Saeed Hamood] Ibb Univ, Fac Engn, Dept Elect Engn, Ibb, Yemen; [Kumar, Santosh] Int Inst Informat Technol Naya Raipur, Dept Comp Sci & Engn, Atal Nagar Nava Raipur, India; [Hawbani, Ammar; Zhao, Liang] Shenyang Aerosp Univ, Shenyang 110136, Peoples R China; [Shvetsov, Alexey V.] Moscow Polytech Univ, Dept Smart Technol, Moscow, Russia; [Shvetsov, Alexey V.] North Eastern Fed Univ, Dept Operat Rd Transport & Car Serv, Yakutsk 677000, Russia; [Guizani, Mohsen] Mohamed Bin Zayed Univ Artificial Intelligence MBZ, Machine Learning Dept, Abu Dhabi, U Arab Emirates",,"Alsamhi, SH (corresponding author), Ibb Univ, Fac Engn, Dept Elect Engn, Ibb, Yemen.",s.alsamhi.rs.ece@iitbhu.ac.in; santosh@iiitnr.edu.in; anmande@ustc.edu.cn; a.shvetsov@vvsu.ru; lzhao@sau.edu.cn; mguizani@ieee.org,,,,,,,,6,6,,,,,,,,,,,SEP,2024,16,5,,,,,2735,2755,,10.1007/s12559-024-10271-7,http://dx.doi.org/10.1007/s12559-024-10271-7,,APR 2024,,,,,,,,,,2025-05-29,WOS:001200367000001,View Full Record in Web of Science
J,"How, ML; Cheah, SM; Khor, AC; Chan, YJ",,,,"How, Meng-Leong; Cheah, Sin-Mei; Khor, Aik Cheow; Chan, Yong Jiet",,,Artificial Intelligence-Enhanced Predictive Insights for Advancing Financial Inclusion: A Human-Centric AI-Thinking Approach,BIG DATA AND COGNITIVE COMPUTING,,,,Article,,,,,,,,"According to the World Bank, a key factor to poverty reduction and improving prosperity is financial inclusion. Financial service providers (FSPs) offering financially-inclusive solutions need to understand how to approach the underserved successfully. The application of artificial intelligence (AI) on legacy data can help FSPs to anticipate how prospective customers may respond when they are approached. However, it remains challenging for FSPs who are not well-versed in computer programming to implement AI projects. This paper proffers a no-coding human-centric AI-based approach to simulate the possible dynamics between the financial profiles of prospective customers collected from 45,211 contact encounters and predict their intentions toward the financial products being offered. This approach contributes to the literature by illustrating how AI for social good can also be accessible for people who are not well-versed in computer science. A rudimentary AI-based predictive modeling approach that does not require programming skills will be illustrated in this paper. In these AI-generated multi-criteria optimizations, analysts in FSPs can simulate scenarios to better understand their prospective customers. In conjunction with the usage of AI, this paper also suggests how AI-Thinking could be utilized as a cognitive scaffold for educing (drawing out) actionable insights to advance financial inclusion.","[How, Meng-Leong] Nanyang Technol Univ, Natl Inst Educ, Singapore 639798, Singapore; [Cheah, Sin-Mei] Singapore Management Univ, Ctr Management Practice, Singapore 188065, Singapore; [Khor, Aik Cheow] Nanyang Technol Univ, Nanyang Business Sch, Singapore 639798, Singapore; [Chan, Yong Jiet] Monash Univ, Fac Educ, Clayton, Vic 3800, Australia",,"How, ML (corresponding author), Nanyang Technol Univ, Natl Inst Educ, Singapore 639798, Singapore.;Cheah, SM (corresponding author), Singapore Management Univ, Ctr Management Practice, Singapore 188065, Singapore.",mengleong.how@nie.edu.sg; smcheah@smu.edu.sg; ackhor.phd@gmail.com; yongjiet@yahoo.com,,,,,,,,18,19,,,,,,,,,,,JUN,2020,4,2,,,,,,,8,10.3390/bdcc4020008,http://dx.doi.org/10.3390/bdcc4020008,,,,,,,,,,,,2025-05-29,WOS:000697676000005,View Full Record in Web of Science
J,"Desot, T; Portet, F; Vacher, M",,,,"Desot, Thierry; Portet, Francois; Vacher, Michel",,,End-to-End Spoken Language Understanding: Performance analyses of a voice command task in a low resource setting,COMPUTER SPEECH AND LANGUAGE,,,,Article,,,,,,,,"Spoken Language Understanding (SLU) is a core task in most human-machine interaction systems . With the emergence of smart homes, smart phones and smart speakers, SLU has become a key technology for the industry. In a classical SLU approach, an Automatic Speech Recognition (ASR) module transcribes the speech signal into a textual representation from which a Natural Language Understanding (NLU) module extracts semantic information. Recently End-to-End SLU (E2E SLU) based on Deep Neural Networks has gained momentum since it benefits from the joint optimisation of the ASR and the NLU parts, hence limiting the cascade of error effect of the pipeline architecture. However, little is known about the actual linguistic properties used by E2E models to predict concepts and intents from speech input. In this paper, we present a study identifying the signal features and other linguistic properties used by an E2E model to perform the SLU task. The study is carried out in the application domain of a smart home that has to handle non-English (here French) voice commands. The results show that a good E2E SLU performance does not always require a perfect ASR capability. Furthermore, the results show the superior capabilities of the E2E model in handling background noise and syntactic variation compared to the pipeline model. Finally, a finer-grained analysis suggests that the E2E model uses the pitch information of the input signal to identify voice command concepts. The results and methodology outlined in this paper provide a springboard for further analyses of E2E models in speech processing.","[Desot, Thierry; Portet, Francois; Vacher, Michel] Univ Grenoble Alpes, Grenoble INP, CNRS, LIG, F-38000 Grenoble, France; [Desot, Thierry] Univ Ghent, Language & Translat Technol Team LT3, Groot Brittannielaan 45, B-9000 Ghent, Belgium",,"Portet, F (corresponding author), Batiment IMAG, Lab Informat Grenoble, 700 Ave Cent, F-38401 St Martin Dheres, France.",thierry.desot@ugent.be; francois.portet@imag.fr; michel.vacher@imag.fr,,,,,,,,8,8,,,,,,,,,,,SEP,2022,75,,,,,,,,101369,10.1016/j.csl.2022.101369,http://dx.doi.org/10.1016/j.csl.2022.101369,,MAR 2022,,,,,,,,,,2025-05-29,WOS:000821456000004,View Full Record in Web of Science
J,"Li, Q; Qin, LC; Xu, HF; Lin, QJ; Qin, ZY; Chu, FL",,,,"Li, Qi; Qin, Lichang; Xu, Haifeng; Lin, Qijian; Qin, Zhaoye; Chu, Fulei",,,Transparent information fusion network: An explainable network for multi-source bearing fault diagnosis via self-organized neural-symbolic nodes,ADVANCED ENGINEERING INFORMATICS,,,,Article,,,,,,,,"In recent years, the integration of Artificial Intelligence (AI) into Intelligent Fault Diagnosis (IFD) through multi-source signal fusion has advanced significantly. However, the inherent opacity of AI-driven IFD models often hampers explainability, a crucial factor for fostering deeper collaboration between humans and intelligent systems to enhance the safety and reliability of industrial assets. This study introduces a novel and explainable methodology termed the Transparent Information Fusion Network (TIFN). TIFN incorporates multiple self- organized Neural-Symbolic Nodes (NSNs) equipped with signal processing and statistical operators, as opposed to conventional black-box neural networks or manually crafted expert systems. NSNs are interconnected through learnable signal-wise gates to construct the Signal Operator Layer (SOL) and Feature Operator Layer (FOL). The entire network is trainable using gradient-based learning methods in a self-organized manner. This enables accurate representation of fault signals and establishes a fully comprehensible semantic framework with an explainable decision-making process. The transparency, generalization, and capability to learn from limited samples of TIFN are demonstrated through two case studies on rotating machinery equipped with different sensors. Case 1 fuses vibration and piezoelectric signals, while Case 2 integrates piezoelectric and triboelectric signals to achieve comprehensive information fusion at both signal and feature levels. By incorporating learnable NSNs, signal-wise gates, TIFN achieves superior diagnostic performance with fewer parameters compared to traditional expert-organized models. This research underscores the potential of TIFN as a fully explainable tool for industrial diagnostics with multi-source signals, paving the way for enhanced human-machine collaboration in Industry 5.0, with a focus on trustworthiness, transparency, and accountability.","[Li, Qi; Qin, Lichang; Lin, Qijian; Qin, Zhaoye; Chu, Fulei] Tsinghua Univ, Dept Mech Engn, Beijing 100084, Peoples R China; [Xu, Haifeng] Tongji Univ, Sch Aerosp Engn & Appl Mech, Shanghai 200092, Peoples R China",,"Qin, ZY (corresponding author), Tsinghua Univ, Dept Mech Engn, Beijing 100084, Peoples R China.",liq22@tsinghua.org.cn; qinzy@mail.tsinghua.edu.cn; xuhaifeng@tongji.edu.cn; linqj22@mails.tsinghua.edu.cn; qinzy@mail.tsinghua.edu.cn; chufl@mail.tsinghua.edu.cn,,,,,,,,0,0,,,,,,,,,,,MAY,2025,65,,A,,,,,,103156,10.1016/j.aei.2025.103156,http://dx.doi.org/10.1016/j.aei.2025.103156,,FEB 2025,,,,,,,,,,2025-05-29,WOS:001417300000001,View Full Record in Web of Science
J,"Chen, H; Yang, N; Song, XH; Lu, CH; Lu, ML; Chen, T; Deng, SL",,,,"Chen, Hao; Yang, Ni; Song, Xuanhua; Lu, Chunhua; Lu, Menglan; Chen, Tan; Deng, Shulin",,,A novel agricultural drought index based on multi-source remote sensing data and interpretable machine learning,AGRICULTURAL WATER MANAGEMENT,,,,Article,,,,,,,,"Drought is a frequent, destructive, and complex natural hazard, and seriously threatens eco-environment, socioeconomy, and the health of human. Previous studies suggested that integrated multi-source remote sensing drought indices have the potential to comprehensively monitor drought conditions, however most existing integrated drought indices still have several limitations. Here, we used solar-induced chlorophyll fluorescence, water balance, soil moisture, and land surface temperature to develop a new integrated remote sensing drought index, namely interpretable machine learning drought index (IMLDI), based on the Bayesian optimized treebased Light Gradient Boosting Machine and SHapley Additive exPlainations. The different land cover types were further considered, and the categories of drought severity were objectively determined by the iterative optimized method. The drought monitoring performance of IMLDI was validated in the eastern parts of China, and three integrated drought indies composited by PCA, multiple linear regression, and gradient boosting method were also included for comparison. The results show that IMLDI has a higher spatial and temporal consistency with standardized precipitation evapotranspiration index, can better reflect the real-world observed drought-affected cropland areas and gross primary production, and can also well describe the evolutions of 2009/2010 and 2019 drought events in the eastern parts of China, indicating higher drought monitoring performance of IMLDI. Besides, IMLDI-based agricultural drought risk analysis shows that the Huang-Hai Region and Yunnan, Guizhou, and Guangxi Provinces have a high risk to suffer from severe agricultural droughts. Overall, IMLDI has a great potential to use as a new integrated remote sensing drought index for agricultural drought monitoring.","[Chen, Hao; Song, Xuanhua; Lu, Chunhua; Lu, Menglan; Deng, Shulin] Nanning Normal Univ, Key Lab Environm Change & Resources Use Beibu Gulf, Minist Educ, Nanning 530001, Peoples R China; [Chen, Hao; Song, Xuanhua; Lu, Chunhua; Lu, Menglan; Deng, Shulin] Nanning Normal Univ, Sch Geog & Planning, Nanning 530001, Peoples R China; [Yang, Ni] China Univ Geosci, Sch Geog & Informat Engn, Wuhan 430074, Peoples R China; [Yang, Ni] Guangxi Univ Finance & Econ, Sch Management Sci & Engn, Nanning 530003, Peoples R China; [Chen, Tan] Chinese Acad Sci, Key Lab Watershed Geog Sci, Nanjing Inst Geog & Limnol, Nanjing 210008, Peoples R China",,"Deng, SL (corresponding author), Nanning Normal Univ, Key Lab Environm Change & Resources Use Beibu Gulf, Minist Educ, Nanning 530001, Peoples R China.",dengshulin@nnnu.edu.cn,,,,,,,,3,3,,,,,,,,,,,MAR 1,2025,308,,,,,,,,109303,10.1016/j.agwat.2025.109303,http://dx.doi.org/10.1016/j.agwat.2025.109303,,JAN 2025,,,,,,,,,,2025-05-29,WOS:001416214200001,View Full Record in Web of Science
J,"Fratangelo, R; Lolli, F; Scarpino, M; Grippo, A",,,,"Fratangelo, Roberto; Lolli, Francesco; Scarpino, Maenia; Grippo, Antonello",,,Point-of-Care Electroencephalography in Acute Neurological Care: A Narrative Review,NEUROLOGY INTERNATIONAL,,,,Review,,,,,,,,"Point-of-care electroencephalography (POC-EEG) systems are rapid-access, reduced-montage devices designed to address the limitations of conventional EEG (conv-EEG), enabling faster neurophysiological assessment in acute settings. This review evaluates their clinical impact, diagnostic performance, and feasibility in non-convulsive status epilepticus (NCSE), traumatic brain injury (TBI), stroke, and delirium. A comprehensive search of Medline, Scopus, and Embase identified 69 studies assessing 15 devices. In suspected NCSE, POC-EEG facilitates rapid seizure detection and prompt diagnosis, making it particularly effective in time-sensitive and resource-limited settings. Its after-hours availability and telemedicine integration ensure continuous coverage. AI-assisted tools enhance interpretability and accessibility, enabling use by non-experts. Despite variability in accuracy, it supports triaging, improving management, treatment decisions and outcomes while reducing hospital stays, transfers, and costs. In TBI, POC-EEG-derived quantitative EEG (qEEG) indices reliably detect structural lesions, support triage, and minimize unnecessary CT scans. They also help assess concussion severity and predict recovery. For strokes, POC-EEG aids triage by detecting large vessel occlusions (LVOs) with high feasibility in hospital and prehospital settings. In delirium, spectral analysis and AI-assisted models enhance diagnostic accuracy, broadening its clinical applications. Although POC-EEG is a promising screening tool, challenges remain in diagnostic variability, technical limitations, and AI optimization, requiring further research.","[Fratangelo, Roberto] Osped San Giuseppe, UOC Neurol, I-50053 Empoli, Italy; [Lolli, Francesco] Univ Florence, Dept Biomed Expt & Clin Sci Mario Serio, I-50134 Florence, Italy; [Scarpino, Maenia; Grippo, Antonello] Careggi Univ Hosp, Neurophysiol Unit, I-50134 Florence, Italy",,"Fratangelo, R (corresponding author), Osped San Giuseppe, UOC Neurol, I-50053 Empoli, Italy.",roberto.fratangelo@uslcentro.toscana.it; francesco.lolli@unifi.it; scarpinom@aou-careggi.toscana.it; antonello.grippo@unifi.it,,,,,,,,0,0,,,,,,,,,,,MAR 24,2025,17,4,,,,,,,48,10.3390/neurolint17040048,http://dx.doi.org/10.3390/neurolint17040048,,,,,,,,,,,,2025-05-29,WOS:001474505500001,View Full Record in Web of Science
J,"Li, JF; Jiang, XY; Liu, XY; Jia, FM; Dai, CY",,,,"Li, Jianfeng; Jiang, Xinyu; Liu, Xiangyu; Jia, Fumin; Dai, Chenyun",,,Optimizing the feature set and electrode configuration of high-density electromyogram via interpretable deep forest,BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,,,Article,,,,,,,,"Hand gesture recognition via high-density surface electromyogram (HDsEMG) has received increasing atten-tions in human-machine interactions. However, with an extremely large number of electrodes in the electrode arrays, the computational burden substantially increased in real world mobile computing applications. Additionally, with diverse features extracted from all electrodes, large information redundancy reduced the learning efficiency of machine learning models. Furthermore, most machine learning models were employed as black-box modules, increasing concerns on both ethics and the user trust on machine learning techniques, especially in human-centered applications. In this work, we applied deep forest in HDsEMG-based hand gesture recognition. Deep forest is a new deep learning architecture where information could be processed layer-by-layer via cascaded random forest modules. Built on highly interpretable decision trees, deep forest models retain the interpretability of decision trees. With the inherent interpretability of deep forest, the most important features and electrodes that deep forest focused on in the decision making process can also be used to optimize the feature set and electrode configuration. We also compared the model interpretation results with the anatomy structure of forearm muscles, providing relations between the interpretations of deep forest and the physiological basis of neuromuscular systems. HDsEMG (256 electrodes) from 20 subjects were used in our analyses. To simulate realistic application scenarios, all analyses and evaluations were performed in inter-subject validations. Results showed that with optimized feature set and electrode configuration, the number of features/electrodes was substantially reduced, with the overall classification accuracy improved. Data and codes are available online.","[Li, Jianfeng; Jiang, Xinyu; Dai, Chenyun] Fudan Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China; [Liu, Xiangyu] Univ Shanghai Sci & Technol, Coll Commun & Art Design, Shanghai, Peoples R China; [Jia, Fumin] Fudan Univ, Inst Sci & Technol Brain Inspired Intelligence, Shanghai, Peoples R China",,"Dai, CY (corresponding author), Fudan Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.;Jia, FM (corresponding author), Fudan Univ, Inst Sci & Technol Brain Inspired Intelligence, Shanghai, Peoples R China.",liuxiangyu@usst.edu.cn; jiangxy18@fudan.edu.cn; liuxiangyu@usst.edu.cn; jiangxy18@fudan.edu.cn; chenyundai@fudan.edu.cn,,,,,,,,7,7,,,,,,,,,,,JAN,2024,87,,B,,,,,,105445,10.1016/j.bspc.2023.105445,http://dx.doi.org/10.1016/j.bspc.2023.105445,,SEP 2023,,,,,,,,,,2025-05-29,WOS:001081302000001,View Full Record in Web of Science
J,"Chen, J; Xia, KJ; Zhang, ZH; Ding, Y; Wang, GH; Xu, XD",,,,"Chen, Jian; Xia, Kaijian; Zhang, Zihao; Ding, Yu; Wang, Ganhong; Xu, Xiaodan",,,Establishing an AI model and application for automated capsule endoscopy recognition based on convolutional neural networks (with video),BMC GASTROENTEROLOGY,,,,Article,,,,,,,,"BackgroundAlthough capsule endoscopy (CE) is a crucial tool for diagnosing small bowel diseases, the need to process a vast number of images imposes a significant workload on physicians, leading to a high risk of missed diagnoses. This study aims to develop an artificial intelligence (AI) model and application based on convolutional neural networks that can automatically recognize various lesions in small bowel capsule endoscopy.MethodsThree small bowel capsule endoscopy datasets were used for AI model training, validation, and testing, encompassing 12 categories of images. The model's performance was evaluated using metrics such as AUC, sensitivity, specificity, precision, accuracy, and F1 score to select the best model. A human-machine comparison experiment was conducted using the best model and endoscopists with varying levels of experience. Model interpretability was analyzed using Grad-CAM and SHAP techniques. Finally, a clinical application was developed based on the best model using PyQt5 technology.ResultsA total of 34,303 images were included in this study. The best model, MobileNetv3-large, achieved a weighted average sensitivity of 87.17%, specificity of 98.77%, and an AUC of 0.9897 across all categories. The application developed based on this model performed exceptionally well in comparison with endoscopists, achieving an accuracy of 87.17% and a processing speed of 75.04 frames per second, surpassing endoscopists of varying experience levels.ConclusionThe AI model and application developed based on convolutional neural networks can quickly and accurately identify 12 types of small bowel lesions. With its high sensitivity, this system can effectively assist physicians in interpreting small bowel capsule endoscopy images.Future studies will validate the AI system for video evaluations and real-world clinical integration.","[Chen, Jian; Ding, Yu; Xu, Xiaodan] Soochow Univ, Dept Gastroenterol, Changshu Hosp, Suzhou 215500, Peoples R China; [Xia, Kaijian] Soochow Univ, Ctr Intelligent Med Technol Res, Changshu Hosp, Suzhou 215500, Peoples R China; [Chen, Jian; Xia, Kaijian] Changshu Key Lab Med Artificial Intelligence & Big, Suzhou 215500, Peoples R China; [Zhang, Zihao] Shanghai Haoxiong Educ Technol Co Ltd, Shanghai 200434, Peoples R China; [Wang, Ganhong] Nanjing Univ Tradit Chinese Med, Changshu Hosp, Dept Orthopaed, Suzhou 215500, Peoples R China",,"Xu, XD (corresponding author), Soochow Univ, Dept Gastroenterol, Changshu Hosp, Suzhou 215500, Peoples R China.;Wang, GH (corresponding author), Nanjing Univ Tradit Chinese Med, Changshu Hosp, Dept Orthopaed, Suzhou 215500, Peoples R China.",651943259@qq.com; xxddocter@gmail.com,,,,,,,,1,1,,,,,,,,,,,NOV 6,2024,24,1,,,,,,,394,10.1186/s12876-024-03482-7,http://dx.doi.org/10.1186/s12876-024-03482-7,,,,,,,,,,,,2025-05-29,WOS:001350737100001,View Full Record in Web of Science
J,"Chen, HM; Dreizin, D; Gomez, C; Zapaishchykova, A; Unberath, M",,,,"Chen, Haomin; Dreizin, David; Gomez, Catalina; Zapaishchykova, Anna; Unberath, Mathias",,,Interpretable Severity Scoring of Pelvic Trauma Through Automated Fracture Detection and Bayesian Inference,IEEE TRANSACTIONS ON MEDICAL IMAGING,,,,Article,,,,,,,,"Pelvic ring disruptions result from blunt injury mechanisms and are potentially lethal mainly due to associated injuries and massive pelvic hemorrhage. The severity of pelvic fractures in trauma victims is frequently assessed by grading the fracture according to the Tile AO/OTA classification in whole-body Computed Tomography (CT) scans. Due to the high volume of whole-body CT scans generated in trauma centers, the overall information content of a single whole-body CT scan and low manual CT reading speed, an automatic approach to Tile classification would provide substantial value, e.g., to prioritize the reading sequence of the trauma radiologists or enable them to focus on other major injuries in multi-trauma patients. In such a high-stakes scenario, an automated method for Tile grading should ideally be transparent such that the symbolic information provided by the method follows the same logic a radiologist or orthopedic surgeon would use to determine the fracture grade. This paper introduces an automated yet interpretable pelvic trauma decision support system to assist radiologists in fracture detection and Tile grading. To achieve interpretability despite processing high-dimensional whole-body CT images, we design a neurosymbolic algorithm that operates similarly to human interpretation of CT scans. The algorithm first detects relevant pelvic fractures on CTs with high specificity using Faster-RCNN. To generate robust fracture detections and associated detection (un)certainties, we perform test-time augmentation of the CT scans to apply fracture detection several times in a self-ensembling approach. The fracture detections are interpreted using a structural causal model based on clinical best practices to infer an initial Tile grade. We apply a Bayesian causal model to recover likely co-occurring fractures that may have been rejected initially due to the highly specific operating point of the detector, resulting in an updated list of detected fractures and corresponding final Tile grade. Our method is transparent in that it provides fracture location and types, as well as information on important counterfactuals that would invalidate the system's recommendation. Our approach achieves an AUC of 0.89/0.74 for translational and rotational instability,which is comparable to radiologist performance. Despite being designed for human-machine teaming, our approach does not compromise on performance compared to previous black-box methods.","[Chen, Haomin; Gomez, Catalina; Zapaishchykova, Anna; Unberath, Mathias] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA; [Dreizin, David] Univ Maryland Baltimore, Dept Diagnost Radiol, Baltimore, MD 21201 USA; [Zapaishchykova, Anna] AIM Lab Harvard MGB, Boston, MA 02115 USA",,"Unberath, M (corresponding author), Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.",hchen135@jhu.edu; ddreizin@umm.edu; cgomezc1@jhu.edu; zapaishchykova@gmail.com; unberath@jhu.edu,,,,,,,,1,1,,,,,,,,,,,JAN,2025,44,1,,,,,130,141,,10.1109/TMI.2024.3428836,http://dx.doi.org/10.1109/TMI.2024.3428836,,,,,,,,,,,,2025-05-29,WOS:001389746700004,View Full Record in Web of Science
J,"Streitz, N; Charitos, D; Kaptein, M; Böhlen, M",,,,"Streitz, Norbert; Charitos, Dimitris; Kaptein, Maurits; Boehlen, Marc",,,Grand challenges for ambient intelligence and implications for design contexts and smart societies,JOURNAL OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS,,,,Article,,,,,,,,"This paper highlights selected grand challenges that concern especially the social and the design dimensions of research and development in Ambient Intelligence (AmI) and Smart Environments (SmE). Due to the increasing deployment and usage of 'smart' technologies determining a wide range of everyday life activities, there is an urgent need to reconsider their societal implications and how to address these implications with appropriate design methods. The paper presents four perspectives on the subject grounded in different approaches. First, introducing and reflecting on the implications of the 'smart-everything' paradigm, the resulting design trade-offs and their application to smart cities. Second, discussing the potential of non-verbal communication for informing the design of spatial interfaces for AmI design practices. Third, reflecting on the role of new data categories such as 'future data' and the role of uncertainty and their implications for the next generation of AmI environments. Finally, debating the merits and shortfalls of the world's largest professional engineering community effort to craft a global standards body on ethically aligned design for autonomous and intelligent systems. The paper benefits from taking different perspectives on common issues, provides commonalities and relationships between them and provides anchor points for important challenges in the field of ambient intelligence.","[Streitz, Norbert] Smart Future Initiat, Konrad Zuse Str 43, D-60438 Frankfurt Main, Germany; [Charitos, Dimitris] Natl & Kapodistrian Univ Athens, Sch Econ & Polit Sci, Dept Commun & Media Studies, Athens, Greece; [Kaptein, Maurits] Tilburg Univ, Stat & Res Methods, Tilburg, Netherlands; [Kaptein, Maurits] Jheronimus Acad Data Sci, Den Bosch, Netherlands; [Boehlen, Marc] Univ Buffalo, Dept Art, Computat Media, Buffalo, NY 14260 USA",,"Streitz, N (corresponding author), Smart Future Initiat, Konrad Zuse Str 43, D-60438 Frankfurt Main, Germany.",norbert.streitz@smart-future.net,,,,,,,,37,38,,,,,,,,,,,,2019,11,1,,,,,87,107,,10.3233/AIS-180507,http://dx.doi.org/10.3233/AIS-180507,,,,,,,,,,,,2025-05-29,WOS:000457824700006,View Full Record in Web of Science
J,"Krinkin, K; Shichkina, Y; Ignatyev, A",,,,"Krinkin, Kirill; Shichkina, Yulia; Ignatyev, Andrey",,,Co-evolutionary hybrid intelligence is a key concept for the world intellectualization,KYBERNETES,,,,Article,,,,,,,,"Purpose This study aims to show the inconsistency of the approach to the development of artificial intelligence as an independent tool (just one more tool that humans have developed); to describe the logic and concept of intelligence development regardless of its substrate: a human or a machine and to prove that the co-evolutionary hybridization of the machine and human intelligence will make it possible to reach a solution for the problems inaccessible to humanity so far (global climate monitoring and control, pandemics, etc.). Design/methodology/approach The global trend for artificial intelligence development (has been) was set during the Dartmouth seminar in 1956. The main goal was to define characteristics and research directions for artificial intelligence comparable to or even outperforming human intelligence. It should be able to acquire and create new knowledge in a highly uncertain dynamic environment (the real-world environment is an example) and apply that knowledge to solving practical problems. Nowadays artificial intelligence overperforms human abilities (playing games, speech recognition, search, art generation, extracting patterns from data etc.), but all these examples show that developers have come to a dead end. Narrow artificial intelligence has no connection to real human intelligence and even cannot be successfully used in many cases due to lack of transparency, explainability, computational ineffectiveness and many other limits. A strong artificial intelligence development model can be discussed unrelated to the substrate development of intelligence and its general properties that are inherent in this development. Only then it is to be clarified which part of cognitive functions can be transferred to an artificial medium. The process of development of intelligence (as mutual development (co-development) of human and artificial intelligence) should correspond to the property of increasing cognitive interoperability. The degree of cognitive interoperability is arranged in the same way as the method of measuring the strength of intelligence. It is stronger if knowledge can be transferred between different domains on a higher level of abstraction (Chollet, 2018). Findings The key factors behind the development of hybrid intelligence are interoperability - the ability to create a common ontology in the context of the problem being solved, plan and carry out joint activities; co-evolution - ensuring the growth of aggregate intellectual ability without the loss of subjectness by each of the substrates (human, machine). The rate of co-evolution depends on the rate of knowledge interchange and the manufacturability of this process. Research limitations/implications Resistance to the idea of developing co-evolutionary hybrid intelligence can be expected from agents and developers who have bet on and invested in data-driven artificial intelligence and machine learning. Practical implications Revision of the approach to intellectualization through the development of hybrid intelligence methods will help bridge the gap between the developers of specific solutions and those who apply them. Co-evolution of machine intelligence and human intelligence will ensure seamless integration of smart new solutions into the global division of labor and social institutions. Originality/value The novelty of the research is connected with a new look at the principles of the development of machine and human intelligence in the co-evolution style. Also new is the statement that the development of intelligence should take place within the framework of integration of the following four domains: global challenges and tasks, concepts (general hybrid intelligence), technologies and products (specific applications that satisfy the needs of the market).","[Krinkin, Kirill] St Petersburg Electrotech Univ LETI, Dept Software Engn & Comp Applicat, St Petersburg, Russia; [Shichkina, Yulia] St Petersburg Electrotech Univ LETI, Fac Comp Sci & Technol, St Petersburg, Russia; [Ignatyev, Andrey] MGIMO Univ, Ctr Global IT Cooperat, Moscow, Russia",,"Shichkina, Y (corresponding author), St Petersburg Electrotech Univ LETI, Fac Comp Sci & Technol, St Petersburg, Russia.",shichkina@etu.ai,,,,,,,,7,7,,,,,,,,,,,SEP 25,2023,52,9,,,,,2907,2923,,10.1108/K-03-2022-0472,http://dx.doi.org/10.1108/K-03-2022-0472,,OCT 2022,,,,,,,,,,2025-05-29,WOS:000866985600001,View Full Record in Web of Science
J,"Ball, B; Koliousis, A",,,,"Ball, Brian; Koliousis, Alexandros",,,Training philosopher engineers for better AI,AI & SOCIETY,,,,Article,,,,,,,,"There is a deluge of AI-assisted decision-making systems, where our data serve as proxy to our actions, suggested by AI. The closer we investigate our data (raw input, or their learned representations, or the suggested actions), we begin to discover bugs. Outside of their test, controlled environments, AI systems may encounter situations investigated primarily by those in other disciplines, but experts in those fields are typically excluded from the design process and are only invited to attest to the ethical features of the resulting system or to comment on demonstrations of intelligence and aspects of craftmanship after the fact. This communicative impasse must be overcome. Our idea is that philosophical and engineering considerations interact and can be fruitfully combined in the AI design process from the very beginning. We embody this idea in the role of a philosopher engineer. We discuss the role of philosopher engineers in the three main design stages of an AI system: deployment management (what is the system's intended use, in what environment?); objective setting (what should the system be trained to do, and how?); and training (what model should be used, and why?). We then exemplify the need for philosopher engineers with an illustrative example, investigating how the future decisions of an AI-based hiring system can be fairer than those contained in the biased input data on which it is trained; and we briefly sketch the kind of interdisciplinary education that we envision will help to bring about better AI.","[Ball, Brian; Koliousis, Alexandros] Northeastern Univ, New Coll Humanities, London, England",,"Ball, B (corresponding author), Northeastern Univ, New Coll Humanities, London, England.",brian.ball@nchlondon.ac.uk; alexandros.koliousis@nchlondon.ac.uk,,,,,,,,1,1,,,,,,,,,,,APR,2023,38,2,,,,,861,868,,10.1007/s00146-022-01535-7,http://dx.doi.org/10.1007/s00146-022-01535-7,,JUL 2022,,,,,,,,,,2025-05-29,WOS:000829288300002,View Full Record in Web of Science
J,"Cozzolino, C; Mao, S; Bassan, F; Bilato, L; Compagno, L; Salvò, V; Chiusaroli, L; Cocchio, S; Baldo, V",,,,"Cozzolino, Claudia; Mao, Sofia; Bassan, Francesco; Bilato, Laura; Compagno, Linda; Salvo, Veronica; Chiusaroli, Lorenzo; Cocchio, Silvia; Baldo, Vincenzo",,,Are AI-based surveillance systems for healthcare-associated infections ready for clinical practice? A systematic review and meta-analysis,ARTIFICIAL INTELLIGENCE IN MEDICINE,,,,Review,,,,,,,,"Healthcare-associated infections (HAIs) are a global public health concern, imposing significant clinical and financial burdens. Despite advancements, surveillance methods remain largely manual and resource-intensive, often leading to underreporting. In this context, automation, particularly through Artificial Intelligence (AI), shows promise in optimizing clinical workflows. However, adoption challenges persist. This study aims to evaluate the current performance and impact of AI in HAI surveillance, considering technical, clinical, and implementation aspects. We conducted a systematic review of Scopus and Embase databases following PRISMA guidelines. AI-based models' performances, accuracy, AUC, sensitivity, and specificity, were pooled using a random-effect model, stratifying by detected HAI type. Our study protocol was registered in PROSPERO (CRD42024524497). Of 2834 identified citations, 249 studies were reviewed. The performances of AI models were generally high but with significant heterogeneity between HAI types. Overall pooled sensitivity, specificity, AUC, and accuracy were respectively 0.835, 0.899, 0.864, and 0.880. About 35.7 % of studies compared AI system performance with alternative automated or standard-of-care surveillance methods, with most achieving better or comparable re-sults to clinical scores or manual surveillance. <7.6 % explicitly measured AI impact in terms of improved patient outcomes, workload reduction, and cost savings, with the majority finding benefits. Only 30 studies deployed the model in a user-friendly tool, and 9 tested it in real clinical practice. In this systematic review, AI shows promising performance in HAI surveillance, although its routine appli-cation in clinical practice remains uncommon. Despite over a decade, retrieved studies offer scant evidence on reducing burden, costs, and resource use. This prevents their potential superiority over traditional or simpler automated surveillance systems from being fully evaluated. Further research is necessary to assess impact, enhance interpretability, and ensure reproducibility.","[Cozzolino, Claudia; Mao, Sofia; Bassan, Francesco; Bilato, Laura; Compagno, Linda; Salvo, Veronica; Cocchio, Silvia; Baldo, Vincenzo] Univ Padua, Dept Cardiac Thorac Vasc Sci & Publ Hlth, I-35128 Padua, Italy; [Chiusaroli, Lorenzo] Univ Padua, Dept Womens & Childrens Hlth, Div Pediat Infect Dis, I-35128 Padua, Italy; [Cocchio, Silvia; Baldo, Vincenzo] Azienda Osped Univ Padova, Prevent Med & Risk Assessment Unit, I-35128 Padua, Italy",,"Cozzolino, C (corresponding author), Univ Padua, Dept Cardiac Thorac Vasc Sci & Publ Hlth, I-35128 Padua, Italy.",claudia.cozzolino@phd.unipd.it,,,,,,,,0,0,,,,,,,,,,,JUL,2025,165,,,,,,,,103137,10.1016/j.artmed.2025.103137,http://dx.doi.org/10.1016/j.artmed.2025.103137,,,,,,,,,,,,2025-05-29,WOS:001480874900001,View Full Record in Web of Science
J,"Sobhi, N; Sadeghi-Bazargani, Y; Mirzaei, M; Abdollahi, M; Jafarizadeh, A; Pedrammehr, S; Alizadehsani, R; Tan, RS; Islam, SMS; Acharya, UR",,,,"Sobhi, Navid; Sadeghi-Bazargani, Yasin; Mirzaei, Majid; Abdollahi, Mirsaeed; Jafarizadeh, Ali; Pedrammehr, Siamak; Alizadehsani, Roohallah; Tan, Ru-San; Islam, Sheikh Mohammed Shariful; Acharya, U. Rajendra",,,Artificial intelligence for early detection of diabetes mellitus complications via retinal imaging,JOURNAL OF DIABETES AND METABOLIC DISORDERS,,,,Review,,,,,,,,"BackgroundDiabetes mellitus (DM) increases the risk of vascular complications, and retinal vasculature imaging serves as a valuable indicator of both microvascular and macrovascular health. Moreover, artificial intelligence (AI)-enabled systems developed for high-throughput detection of diabetic retinopathy (DR) using digitized retinal images have become clinically adopted. This study reviews AI applications using retinal images for DM-related complications, highlighting advancements beyond DR screening, diagnosis, and prognosis, and addresses implementation challenges, such as ethics, data privacy, equitable access, and explainability.MethodsWe conducted a thorough literature search across several databases, including PubMed, Scopus, and Web of Science, focusing on studies involving diabetes, the retina, and artificial intelligence. We reviewed the original research based on their methodology, AI algorithms, data processing techniques, and validation procedures to ensure a detailed analysis of AI applications in diabetic retinal imaging.ResultsRetinal images can be used to diagnose DM complications including DR, neuropathy, nephropathy, and atherosclerotic cardiovascular disease, as well as to predict the risk of cardiovascular events. Beyond DR screening, AI integration also offers significant potential to address the challenges in the comprehensive care of patients with DM.ConclusionWith the ability to evaluate the patient's health status in relation to DM complications as well as risk prognostication of future cardiovascular complications, AI-assisted retinal image analysis has the potential to become a central tool for modern personalized medicine in patients with DM.","[Sobhi, Navid; Abdollahi, Mirsaeed; Jafarizadeh, Ali] Tabriz Univ Med Sci, Nikookari Eye Ctr, Tabriz, Iran; [Sadeghi-Bazargani, Yasin; Mirzaei, Majid] Tabriz Univ Med Sci, Student Res Comm, Tabriz, Iran; [Pedrammehr, Siamak; Alizadehsani, Roohallah] Deakin Univ, Inst Intelligent Syst Res & Innovat IISRI, 75 Pigdons Rd, Waurn Ponds, Vic 3216, Australia; [Pedrammehr, Siamak] Tabriz Islamic Art Univ, Fac Design, Tabriz, Iran; [Tan, Ru-San] Natl Heart Ctr Singapore, Singapore, Singapore; [Tan, Ru-San] Duke NUS Med Sch, Singapore, Singapore; [Islam, Sheikh Mohammed Shariful] Deakin Univ, Inst Phys Act & Nutr, Sch Exercise & Nutr Sci, Melbourne, Vic, Australia; [Islam, Sheikh Mohammed Shariful] George Inst Global Hlth, Cardiovasc Div, Newtown, Australia; [Islam, Sheikh Mohammed Shariful] Univ Sydney, Sydney Med Sch, Camperdown, Australia; [Acharya, U. Rajendra] Univ Southern Queensland, Sch Math Phys & Comp, Springfield, Qld 4300, Australia; [Acharya, U. Rajendra] Univ Southern Queensland, Ctr Hlth Res, Springfield, Australia",,"Jafarizadeh, A (corresponding author), Tabriz Univ Med Sci, Nikookari Eye Ctr, Tabriz, Iran.;Pedrammehr, S (corresponding author), Deakin Univ, Inst Intelligent Syst Res & Innovat IISRI, 75 Pigdons Rd, Waurn Ponds, Vic 3216, Australia.;Pedrammehr, S (corresponding author), Tabriz Islamic Art Univ, Fac Design, Tabriz, Iran.",Jafarizadeha@tbzmed.ac.ir; s.pedrammehr@deakin.edu.au,,,,,,,,0,0,,,,,,,,,,,APR 12,2025,24,1,,,,,,,104,10.1007/s40200-025-01596-7,http://dx.doi.org/10.1007/s40200-025-01596-7,,,,,,,,,,,,2025-05-29,WOS:001465335700001,View Full Record in Web of Science
J,"Gardezi, M; Joshi, B; Rizzo, DM; Ryan, M; Prutzer, E; Brugler, S; Dadkhah, A",,,,"Gardezi, Maaz; Joshi, Bhavna; Rizzo, Donna M.; Ryan, Mark; Prutzer, Edward; Brugler, Skye; Dadkhah, Ali",,,Artificial intelligence in farming: Challenges and opportunities for building trust,AGRONOMY JOURNAL,,,,Article,,,,,,,,"Artificial intelligence (AI) represents technologies with human-like cognitive abilities to learn, perform, and make decisions. AI in precision agriculture (PA) enables farmers and farm managers to deploy highly targeted and precise farming practices based on site-specific agroclimatic field measurements. The foundational and applied development of AI has matured considerably over the last 30 years. The time is now right to engage seriously with the ethics and responsible practice of AI for the well-being of farmers and farm managers. In this paper, we identify and discuss both challenges and opportunities for improving farmers' trust in those providing AI solutions for PA. We highlight that farmers' trust can be moderated by how the benefits and risks of AI are perceived, shared, and distributed. We propose four recommendations for improving farmers' trust. First, AI developers should improve model transparency and explainability. Second, clear responsibility and accountability should be assigned to AI decisions. Third, concerns about the fairness of AI need to be overcome to improve human-machine partnerships in agriculture. Finally, regulation and voluntary compliance of data ownership, privacy, and security are needed, if AI systems are to become accepted and used by farmers.","[Gardezi, Maaz; Joshi, Bhavna; Prutzer, Edward] Virginia Tech, Dept Sociol, Blacksburg, VA USA; [Rizzo, Donna M.; Dadkhah, Ali] Univ Vermont, Dept Civil & Environm Engn, Burlington, VT USA; [Ryan, Mark] Wageningen Univ & Res, Wageningen Econ Res, Wageningen, Netherlands; [Brugler, Skye] South Dakota State Univ, Dept Agron Hort & Plant Sci, Brookings, SD USA; [Gardezi, Maaz] Virginia Tech, Dept Sociol, 518 McBryde Hall,225 Stanger St, Blacksburg, VA 24061 USA",,"Gardezi, M (corresponding author), Virginia Tech, Dept Sociol, 518 McBryde Hall,225 Stanger St, Blacksburg, VA 24061 USA.",maaz@vt.edu,,,,,,,,20,20,,,,,,,,,,,MAY,2024,116,3,,,,,1217,1228,,10.1002/agj2.21353,http://dx.doi.org/10.1002/agj2.21353,,MAY 2023,,,,,,,,,,2025-05-29,WOS:000993351800001,View Full Record in Web of Science
J,"Feng, T; Noren, DP; Kulkarni, C; Mariani, S; Zhao, C; Ghosh, E; Swearingen, D; Frassica, J; McFarlane, D; Conroy, B",,,,"Feng, Ting; Noren, David P.; Kulkarni, Chaitanya; Mariani, Sara; Zhao, Claire; Ghosh, Erina; Swearingen, Dennis; Frassica, Joseph; McFarlane, Daniel; Conroy, Bryan",,,Machine learning-based clinical decision support for infection risk prediction,FRONTIERS IN MEDICINE,,,,Article,,,,,,,,"Background: Healthcare-associated infection (HAI) remains a significant risk for hospitalized patients and a challenging burden for the healthcare system. This study presents a clinical decision support tool that can be used in clinical workflows to proactively engage secondary assessments of pre-symptomatic and at-risk infection patients, thereby enabling earlier diagnosis and treatment.Methods: This study applies machine learning, specifically ensemble-based boosted decision trees, on large retrospective hospital datasets to develop an infection risk score that predicts infection before obvious symptoms present. We extracted a stratified machine learning dataset of 36,782 healthcare-associated infection patients. The model leveraged vital signs, laboratory measurements and demographics to predict HAI before clinical suspicion, defined as the order of a microbiology test or administration of antibiotics.Results: Our best performing infection risk model achieves a cross-validated AUC of 0.88 at 1 h before clinical suspicion and maintains an AUC >0.85 for 48 h before suspicion by aggregating information across demographics and a set of 163 vital signs and laboratory measurements. A second model trained on a reduced feature space comprising demographics and the 36 most frequently measured vital signs and laboratory measurements can still achieve an AUC of 0.86 at 1 h before clinical suspicion. These results compare favorably against using temperature alone and clinical rules such as the quick sequential organ failure assessment (qSOFA) score. Along with the performance results, we also provide an analysis of model interpretability via feature importance rankings.Conclusion: The predictive model aggregates information from multiple physiological parameters such as vital signs and laboratory measurements to provide a continuous risk score of infection that can be deployed in hospitals to provide advance warning of patient deterioration.","[Feng, Ting; Noren, David P.; Mariani, Sara; Zhao, Claire; Ghosh, Erina; McFarlane, Daniel; Conroy, Bryan] Philips Res North Amer, Cambridge, MA 02141 USA; [Kulkarni, Chaitanya] Philips Res Bangalore, Bengaluru, India; [Swearingen, Dennis] Banner Hlth, Dept Med Informat, Phoenix, AZ USA; [Swearingen, Dennis] Univ Arizona, Coll Med, Dept Biomed Informat, Phoenix, AZ USA; [Frassica, Joseph] MIT, Inst Med Engn & Sci, Cambridge, MA USA",,"Conroy, B (corresponding author), Philips Res North Amer, Cambridge, MA 02141 USA.",bryan.conroy@philips.com,,,,,,,,6,6,,,,,,,,,,,DEC 18,2023,10,,,,,,,,1213411,10.3389/fmed.2023.1213411,http://dx.doi.org/10.3389/fmed.2023.1213411,,,,,,,,,,,,2025-05-29,WOS:001134223700001,View Full Record in Web of Science
J,"Seidita, V; Sabella, AMP; Lanza, F; Chella, A",,,,"Seidita, Valeria; Sabella, Angelo Maria Pio; Lanza, Francesco; Chella, Antonio",,,"Agent talks about itself: an implementation using Jason, CArtAgO and Speech Acts",INTELLIGENZA ARTIFICIALE,,,,Article,,,,,,,,"Thinking to oneself is a prerogative of man when he needs to think about or repeat what he is doing or experiencing. It is a way of processing information and setting in motion a decision-making process. When this is done aloud, there is also a chance that someone else will understand the meaning or reasons for the action. Equipping an agent with the ability to reveal the reasons for its decisions is both a way to improve human interaction and a way to improve the triggering of a decision process. In this work, we propose to use the speech act to enable a coalition of agents to exhibit inner speech capabilities to explain their behavior, but also to guide and reinforce the creation of an inner model. The BDI agent paradigm, Jason, and CArtAgO are used to give agents the ability to act in a human-like manner. The BDI reasoning cycle has been extended to include inner speech. The proposed solution continues the research path that started with the definition of a cognitive model and architecture for human-robot teaming interaction and aims to integrate the believable interaction paradigm in it.","[Seidita, Valeria; Sabella, Angelo Maria Pio; Lanza, Francesco; Chella, Antonio] Univ Palermo, Dipartimento Ingn, Palermo, Italy",,"Seidita, V (corresponding author), Univ Palermo, Dipartimento Ingn, Palermo, Italy.",valeria.seidita@unipa.it,,,,,,,,1,1,,,,,,,,,,,,2023,17,1,,,SI,,7,18,,10.3233/IA-230005,http://dx.doi.org/10.3233/IA-230005,,,,,,,,,,,,2025-05-29,WOS:001005967600002,View Full Record in Web of Science
J,"Dai, CH; Zong, CF; Zhang, D; Li, G; Chuyo, K; Zheng, HY; Gao, F",,,,"Dai, Changhua; Zong, Changfu; Zhang, Dong; Li, Gang; Chuyo, Kaku; Zheng, Hongyu; Gao, Fei",,,Human-like lane-changing trajectory planning algorithm for human-machine conflict mitigation,JOURNAL OF INTELLIGENT AND CONNECTED VEHICLES,,,,Article,,,,,,,,"The purpose of this paper is to alleviate the potential safety problems associated with the human driver and the automatic system competing for the right of way due to different objectives by mitigating the human-machine conflict phenomenon in human-machine shared driving (HMSD) technology from the automation system. Firstly, a basic lane-changing trajectory algorithm based on the quintic polynomial in the Frenet coordinate system is developed. Then, in order to make the planned trajectory close to human behavior, naturalistic driving data is collected, based on which some lane-changing performance features are selected and analyzed. There are three aspects have been taken into consideration for the human-like lane-changing trajectory: vehicle dynamic stability performance, driving cost optimization, and collision avoidance. Finally, the HMSD experiments are conducted with the driving simulator to test the potential of the human-like lane-changing trajectory planning algorithm. The results demonstrate that the lane-changing trajectory planning algorithm with the highest degree of personalization is highly consistent with human driver behavior and consequently would potentially mitigate the human-machine conflict with the HMSD application. Furthermore, it could be further employed as an empirical trajectory prediction result. The algorithm employs the distribution state of the historical trajectory for human-like processing, simplifying the operational process and ensuring the credibility, integrity, and interpretability of the results. Moreover, in terms of optimization processing, the form of optimization search followed by collision avoidance detection is adopted to in principle reduce the calculation difficulty. Additionally, a new convex polygon collision detection method, namely the vertex embedding method, is proposed for collision avoidance detection.","[Dai, Changhua; Zong, Changfu; Zheng, Hongyu; Gao, Fei] Jilin Univ, State Key Lab Automot Simulat & Control, Changchun 130022, Peoples R China; [Zhang, Dong] Brunel Univ London, Dept Mech & Aerosp Engn, Uxbridge UB8 3PH, Middx, England; [Li, Gang] Liaoning Univ Technol, Coll Automobile & Traff Engn, Jinzhou 121000, Peoples R China; [Chuyo, Kaku] Jiangsu Chaoli Elect Co Ltd, Danyang 212300, Peoples R China",,"Zhang, D (corresponding author), Brunel Univ London, Dept Mech & Aerosp Engn, Uxbridge UB8 3PH, Middx, England.",dong.zhang@brunel.ac.uk,,,,,,,,10,11,,,,,,,,,,,MAR,2023,6,1,,,,,46,63,,10.26599/JICV.2023.9210004,http://dx.doi.org/10.26599/JICV.2023.9210004,,,,,,,,,,,,2025-05-29,WOS:001388193300004,View Full Record in Web of Science
J,"Perozzi, B; Akoglu, L",,,,"Perozzi, Bryan; Akoglu, Leman",,,Discovering Communities and Anomalies in Attributed Graphs: Interactive Visual Exploration and Summarization,ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA,,,,Article,,,,,,,,"Given a network with node attributes, how can we identify communities and spot anomalies? How can we characterize, describe, or summarize the network in a succinct way? Community extraction requires a measure of quality for connected subgraphs (e.g., social circles). Existing subgraph measures, however, either consider only the connectedness of nodes inside the community and ignore the cross-edges at the boundary (e.g., density) or only quantify the structure of the community and ignore the node attributes (e.g., conductance). In this work, we focus on node-attributed networks and introduce: (1) a new measure of subgraph quality for attributed communities called normality, (2) a community extraction algorithm that uses normality to extract communities and a few characterizing attributes per community, and (3) a summarization and interactive visualization approach for attributed graph exploration. More specifically, (1) we first introduce a new measure to quantify the normality of an attributed subgraph. Our normality measure carefully utilizes structure and attributes together to quantify both the internal consistency and external separability. We then formulate an objective function to automatically infer a few attributes (called the focus) and respective attribute weights, so as to maximize the normality score of a given subgraph. Most notably, unlike many other approaches, our measure allows for many cross-edges as long as they can be exonerated; i.e., either (i) are expected under a null graph model, and/or (ii) their boundary nodes do not exhibit the focus attributes. Next, (2) we propose AMEN (for Attributed Mining of Entity Networks), an algorithm that simultaneously discovers the communities and their respective focus in a given graph, with a goal to maximize the total normality. Communities for which a focus that yields high normality cannot be found are considered low quality or anomalous. Last, (3) we formulate a summarization task with a multi-criteria objective, which selects a subset of the communities that (i) cover the entire graph well, are (ii) high quality and (iii) diverse in their focus attributes. We further design an interactive visualization interface that presents the communities to a user in an interpretable, user-friendly fashion. The user can explore all the communities, analyze various algorithm-generated summaries, as well as devise their own summaries interactively to characterize the network in a succinct way. As the experiments on real-world attributed graphs show, our proposed approaches effectively find anomalous communities and outperform several existing measures and methods, such as conductance, density, OddBall, and SODA. We also conduct extensive user studies to measure the capability and efficiency that our approach provides to the users toward network summarization, exploration, and sensemaking.","[Perozzi, Bryan] SUNY Stony Brook, Google Res, Stony Brook, NY 11794 USA; [Akoglu, Leman] SUNY Stony Brook, Carnegie Mellon Univ, Stony Brook, NY USA",,"Perozzi, B (corresponding author), SUNY Stony Brook, Google Res, Stony Brook, NY 11794 USA.",bryan.perozzi@gmail.com; lakoglu@cs.cmu.edu,,,,,,,,26,30,,,,,,,,,,,MAR,2018,12,2,,,,,,,24,10.1145/3139241,http://dx.doi.org/10.1145/3139241,,,,,,,,,,,,2025-05-29,WOS:000435563100010,View Full Record in Web of Science
J,"Chen, JX; Shen, F; Chen, DZ; Flynn, PJ",,,,"Chen, Jianxu; Shen, Feng; Chen, Danny Ziyi; Flynn, Patrick J.",,,Iris Recognition Based on Human-Interpretable Features,IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY,,,,Article,,,,,,,,"The iris is a stable biometric trait that has been widely used for human recognition in various applications. However, deployment of iris recognition in forensic applications has not been reported. A primary reason is the lack of human-friendly techniques for iris comparison. To further promote the use of iris recognition in forensics, the similarity between irises should be made visualizable and interpretable. Recently, a human-in-the-loop iris recognition system was developed, based on detecting and matching iris crypts. Building on this framework, we propose a new approach for detecting and matching iris crypts automatically. Our detection method is able to capture iris crypts of various sizes. Our matching scheme is designed to handle potential topological changes in the detection of the same crypt in different images. Our approach outperforms the known visible-feature-based iris recognition method on three different data sets. In particular, our approach achieves over 22% higher rank one hit rate in identification, and over 51% lower equal error rate in verification. In addition, the benefit of our approach on multi-enrollment is experimentally demonstrated.","[Chen, Jianxu; Shen, Feng; Chen, Danny Ziyi; Flynn, Patrick J.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA",,"Chen, JX; Shen, F; Chen, DZ; Flynn, PJ (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.",jchen16@nd.edu; fshen1@nd.edu; dchen@nd.edu; flynn@nd.edu,,,,,,,,39,44,,,,,,,,,,,JUL,2016,11,7,,,,,1476,1485,,10.1109/TIFS.2016.2535901,http://dx.doi.org/10.1109/TIFS.2016.2535901,,,,,,,,,,,,2025-05-29,WOS:000374890000008,View Full Record in Web of Science
J,"Souza, F; Offermans, T; Barendse, R; Postma, G; Jansen, J",,,,"Souza, Francisco; Offermans, Tim; Barendse, Ruud; Postma, Geert; Jansen, Jeroen",,,Contextual Mixture of Experts: Integrating Knowledge into Predictive Modeling,IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,,,,Article,,,,,,,,"This article proposes a new data-driven model devised to integrate process knowledge into its structure to increase the human-machine synergy in the process industry. The proposed contextual mixture of experts (cMoE) explicitly uses process knowledge along the model learning stage to mold the historical data to represent operators' context related to the process through possibility distributions. This model was evaluated in two real case studies for quality prediction, including a sulfur recovery unit and a polymerization process. The cMoEs was employed to represent different contexts in both experiments. The results indicate that integrating process knowledge has increased the predictive performance while improving interpretability by providing insights into the variables affecting the process's different regimes.","[Souza, Francisco; Offermans, Tim; Postma, Geert; Jansen, Jeroen] Radboud Univ Nijmegen, Inst Mol & Mat, NL-6525 AJ Nijmegen, Netherlands; [Barendse, Ruud] Netherlands Org Appl Sci Res TNO, NL-2628 XE Delft, Netherlands",,"Souza, F (corresponding author), Radboud Univ Nijmegen, Inst Mol & Mat, NL-6525 AJ Nijmegen, Netherlands.",f.souza@science.ru.nl; t.offermans@science.ru.nl; ruud.barendse@dsm.com; g.j.postma@science.ru.nl; jj.jansen@science.ru.nl,,,,,,,,5,5,,,,,,,,,,,AUG,2023,19,8,,,,,9048,9059,,10.1109/TII.2022.3224973,http://dx.doi.org/10.1109/TII.2022.3224973,,,,,,,,,,,,2025-05-29,WOS:001030673600046,View Full Record in Web of Science
J,"Cantens, T",,,,"Cantens, Thomas",,,How will the state think with ChatGPT? The challenges of generative artificial intelligence for public administrations,AI & SOCIETY,,,,Article,,,,,,,,"This article explores the challenges surrounding generative artificial intelligence (GenAI) in public administrations and its impact on human-machine interactions within the public sector. First, it aims to deconstruct the reasons for distrust in GenAI in public administrations. The risks currently linked to GenAI in the public sector are often similar to those of conventional AI. However, while some risks remain pertinent, others are less so because GenAI has limited explainability, which, in return, limits its uses in public administrations. Confidentiality, marking of GenAI outputs and errors are specific matters for which responses should be technical as well as cultural, as they are pushing the boundaries of our instrumental conceptions of machines. Second, this article proposes some paradigm shifts in the perspective of using GenAI in public administrations due to the radical change caused by its language-based nature. GenAI represents a profound break from the numerical nature of AI systems implemented in public administrations to date. The transformative impact of GenAI on the intellectual production of the state raises fears of the replacement, or rather enslavement, of civil servants to machines. The article argues for the development of critical thinking as a specific skill for civil servants who have become highly specialized and will have to think with a machine that is eclectic by nature. It anticipates a transformation in the political nature of public administrations, which should lead to more considerations for the strategic stake related to training corpus and for our conceptualization of the neutrality of AI.","[Cantens, Thomas] Off Secretary Gen World Customs Org WCO, Res & Policy Unit, Brussels, Belgium; [Cantens, Thomas] Auvergne Univ, Ctr Etud & Rech Dev Int, Clermont Ferrand, France",,"Cantens, T (corresponding author), Off Secretary Gen World Customs Org WCO, Res & Policy Unit, Brussels, Belgium.;Cantens, T (corresponding author), Auvergne Univ, Ctr Etud & Rech Dev Int, Clermont Ferrand, France.",thomascantens@hotmail.com,,,,,,,,6,6,,,,,,,,,,,JAN,2025,40,1,,,,,133,144,,10.1007/s00146-023-01840-9,http://dx.doi.org/10.1007/s00146-023-01840-9,,JAN 2024,,,,,,,,,,2025-05-29,WOS:001144809200003,View Full Record in Web of Science
J,"Bennett, SJ; Catanzariti, B; Tollon, F",,,,"Bennett, S. J.; Catanzariti, Benedetta; Tollon, Fabio",,,Everybody knows what a pothole is: representations of work and intelligence in AI practice and governance,AI & SOCIETY,,,,Article; Early Access,,,,,,,,"In this paper, we empirically and conceptually examine how distributed human-machine networks of labour comprise a form of underlying intelligence within Artificial Intelligence (AI), considering the implications of this for Responsible Artificial Intelligence (R-AI) innovation. R-AI aims to guide AI research, development and deployment in line with certain normative principles, for example fairness, privacy, and explainability; notions implicitly shaped by comparisons of AI with individualised notions of human intelligence. However, as critical scholarship on AI demonstrates, this is a limited framing of the nature of intelligence, both of humans and AI. Furthermore, it dismisses the skills and labour central to developing AI systems, involving a distributed network of human-directed practices and reasoning. We argue that inequities in the agency and recognition of different types of practitioners across these networks of AI development have implications beyond RAI, with narrow framings concealing considerations which are important within broader discussions of AI intelligence. Drawing from interactive workshops conducted with AI practitioners, we explore practices of data acquisition, cleaning, and annotation, as the point where practitioners interface with domain experts and data annotators. Despite forming a crucial part of AI design and development, this type of data work is frequently framed as a tedious, unskilled, and low-value process. In exploring these practices, we examine the political role of the epistemic framings that underpin AI development and how these framings can shape understandings of distributed intelligence, labour practices, and annotators' agency within data structures. Finally, we reflect on the implications of our findings for developing more participatory and equitable approaches to machine learning applications in the service of R-AI.","[Bennett, S. J.] Univ Durham, Geog, Durham, England; [Catanzariti, Benedetta] Univ Edinburgh, Sci Technol & Innovat Studies, Edinburgh, Scotland; [Tollon, Fabio] Univ Edinburgh, Philosophy, Edinburgh, Scotland",,"Catanzariti, B (corresponding author), Univ Edinburgh, Sci Technol & Innovat Studies, Edinburgh, Scotland.",sj.bennett@durham.ac.uk; benedetta.catanzariti@ed.ac.uk; ftollon@ed.ac.uk,,,,,,,,1,1,,,,,,,,,,,2025 JAN 27,2025,,,,,,,,,,10.1007/s00146-024-02162-0,http://dx.doi.org/10.1007/s00146-024-02162-0,,JAN 2025,,,,,,,,,,2025-05-29,WOS:001408408700001,View Full Record in Web of Science
J,"Talaat, M; Si, XH; Xi, JX",,,,"Talaat, Mohamed; Si, Xiuhua; Xi, Jinxiang",,,Multi-Level Training and Testing of CNN Models in Diagnosing Multi-Center COVID-19 and Pneumonia X-ray Images,APPLIED SCIENCES-BASEL,,,,Article,,,,,,,,"Featured Application: Despite their reported high accuracy, a significant limitation of current AI-assisted COVID-19 diagnostic models is that they are often trained on datasets sourced from specific clinics or possessing a limited number of training images. This raises an important question: Will these models maintain high accuracy when deployed in other clinics where images might exhibit disparities? If accuracy does drop, to what extent can we expect this decline? Conversely, how much can accuracy be improved by augmenting the training dataset with new images? In this study, we evaluated the performances of four CNN models that were trained on incrementally augmented datasets and subsequently tested on images with decreasing similarities. Through multi-level testing, we assessed the models' capacities for verification, interpolation, and extrapolation in the context of diagnosing COVID-19 and pneumonia using multi-center X-ray images. Compared to conventional one-round training, multi-round training offers a more comprehensive insight into a model's learnability, robustness, and interpretability. This study aimed to address three questions in AI-assisted COVID-19 diagnostic systems: (1) How does a CNN model trained on one dataset perform on test datasets from disparate medical centers? (2) What accuracy gains can be achieved by enriching the training dataset with new images? (3) How can learned features elucidate classification results, and how do they vary among different models? To achieve these aims, four CNN models-AlexNet, ResNet-50, MobileNet, and VGG-19-were trained in five rounds by incrementally adding new images to a baseline training set comprising 11,538 chest X-ray images. In each round, the models were tested on four datasets with decreasing levels of image similarity. Notably, all models showed performance drops when tested on datasets containing outlier images or sourced from other clinics. In Round 1, 95.2 similar to 99.2% accuracy was achieved for the Level 1 testing dataset (i.e., from the same clinic but set apart for testing only), and 94.7 similar to 98.3% for Level 2 (i.e., from an external clinic but similar). However, model performance drastically decreased for Level 3 (i.e., outlier images with rotation or deformation), with the mean sensitivity plummeting from 99% to 36%. For the Level 4 testing dataset (i.e., from another clinic), accuracy decreased from 97% to 86%, and sensitivity from 99% to 67%. In Rounds 2 and 3, adding 25% and 50% of the outlier images to the training dataset improved the average Level-3 accuracy by 15% and 23% (i.e., from 56% to 71% to 83%). In Rounds 4 and 5, adding 25% and 50% of the external images increased the average Level-4 accuracy from 81% to 92% and 95%, respectively. Among the models, ResNet-50 demonstrated the most robust performance across the five-round training/testing phases, while VGG-19 persistently underperformed. Heatmaps and intermediate activation features showed visual correlations to COVID-19 and pneumonia X-ray manifestations but were insufficient to explicitly explain the classification. However, heatmaps and activation features at different rounds shed light on the progression of the models' learning behavior.","[Talaat, Mohamed; Xi, Jinxiang] Univ Massachusetts, Dept Biomed Engn, Lowell, MA 01854 USA; [Si, Xiuhua] Calif Baptist Univ, Dept Mech Engn, Riverside, CA 92504 USA",,"Xi, JX (corresponding author), Univ Massachusetts, Dept Biomed Engn, Lowell, MA 01854 USA.",mohamed_talaat@student.uml.edu; asi@calbaptist.edu; jinxiang_xi@uml.edu,,,,,,,,3,3,,,,,,,,,,,SEP,2023,13,18,,,,,,,10270,10.3390/app131810270,http://dx.doi.org/10.3390/app131810270,,,,,,,,,,,,2025-05-29,WOS:001073350100001,View Full Record in Web of Science
J,"Wehbe, RM; Katsaggleos, AK; Hammond, KJ; Hong, H; Ahmad, FS; Ouyang, D; Shah, SJ; Mccarthy, PM; Thomas, JD",,,,"Wehbe, Ramsey M.; Katsaggleos, Aggelos K.; Hammond, Kristian J.; Hong, Ha; Ahmad, Faraz S.; Ouyang, David; Shah, Sanjiv J.; Mccarthy, Patrick M.; Thomas, James D.",,,Deep Learning for Cardiovascular Imaging,JAMA CARDIOLOGY,,,,Review,,,,,,,,"Importance Artificial intelligence (AI), driven by advances in deep learning (DL), has the potential to reshape the field of cardiovascular imaging (CVI). While DL for CVI is still in its infancy, research is accelerating to aid in the acquisition, processing, and/or interpretation of CVI across various modalities, with several commercial products already in clinical use. It is imperative that cardiovascular imagers are familiar with DL systems, including a basic understanding of how they work, their relative strengths compared with other automated systems, and possible pitfalls in their implementation. The goal of this article is to review the methodology and application of DL to CVI in a simple, digestible fashion toward demystifying this emerging technology.Observations At its core, DL is simply the application of a series of tunable mathematical operations that translate input data into a desired output. Based on artificial neural networks that are inspired by the human nervous system, there are several types of DL architectures suited to different tasks; convolutional neural networks are particularly adept at extracting valuable information from CVI data. We survey some of the notable applications of DL to tasks across the spectrum of CVI modalities. We also discuss challenges in the development and implementation of DL systems, including avoiding overfitting, preventing systematic bias, improving explainability, and fostering a human-machine partnership. Finally, we conclude with a vision of the future of DL for CVI.Conclusions and Relevance Deep learning has the potential to meaningfully affect the field of CVI. Rather than a threat, DL could be seen as a partner to cardiovascular imagers in reducing technical burden and improving efficiency and quality of care. High-quality prospective evidence is still needed to demonstrate how the benefits of DL CVI systems may outweigh the risks.","[Wehbe, Ramsey M.] Med Univ South Carolina, Div Cardiol, 22 WestEdge St,Ste 200,Room WG213E, Charleston, SC 29403 USA; [Wehbe, Ramsey M.] Med Univ South Carolina, Biomed Informat Ctr, 22 WestEdge St,Ste 200,Room WG213E, Charleston, SC 29403 USA; [Wehbe, Ramsey M.] Med Univ South Carolina, Dept Med, Div Cardiol, Charleston, SC USA; [Wehbe, Ramsey M.] Med Univ South Carolina, Biomed Informat Ctr, Charleston, SC USA; [Wehbe, Ramsey M.; Ahmad, Faraz S.; Shah, Sanjiv J.; Thomas, James D.] Northwestern Univ, Feinberg Sch Med, Dept Med, Div Cardiol, Chicago, IL USA; [Katsaggleos, Aggelos K.] Northwestern Univ, Dept Comp & Elect Engn, Evanston, IL USA; [Hammond, Kristian J.] Northwestern Univ, Dept Comp Sci, Evanston, IL USA; [Hong, Ha] Medtronic, Minneapolis, MN USA; [Ahmad, Faraz S.] Northwestern Univ, Feinberg Sch Med, Inst Publ Hlth & Med, Ctr Hlth Informat Partnerships, Chicago, IL USA; [Ouyang, David] Cedars Sinai Med Ctr, Dept Med, Div Cardiol, Los Angeles, CA USA; [Mccarthy, Patrick M.] Northwestern Univ, Feinberg Sch Med, Dept Surg, Div Cardiac Surg, Chicago, IL USA; [Ahmad, Faraz S.; Shah, Sanjiv J.; Mccarthy, Patrick M.; Thomas, James D.] Northwestern Med Bluhm Cardiovasc Inst, Ctr Artificial Intelligence, Chicago, IL USA",,"Wehbe, RM (corresponding author), Med Univ South Carolina, Div Cardiol, 22 WestEdge St,Ste 200,Room WG213E, Charleston, SC 29403 USA.;Wehbe, RM (corresponding author), Med Univ South Carolina, Biomed Informat Ctr, 22 WestEdge St,Ste 200,Room WG213E, Charleston, SC 29403 USA.",wehbe@musc.edu,,,,,,,,20,20,,,,,,,,,,,NOV,2023,8,11,,,,,1089,1098,,10.1001/jamacardio.2023.3142,http://dx.doi.org/10.1001/jamacardio.2023.3142,,SEP 2023,,,,,,,,,,2025-05-29,WOS:001071407800002,View Full Record in Web of Science
J,"Liu, Q; Hagenmeyer, V; Keller, HB",,,,"Liu, Qi; Hagenmeyer, Veit; Keller, Hubert B.",,,A Review of Rule Learning-Based Intrusion Detection Systems and Their Prospects in Smart Grids,IEEE ACCESS,,,,Article,,,,,,,,"Intrusion detection systems (IDS) are commonly categorized into misuse based, anomaly based and specification based IDS. Both misuse based IDS and anomaly based IDS are extensively researched in academia and industry. However, as critical infrastructures including smart grids (SG) may often face sophisticated unknown attacks in the near future, misuse based attack detection techniques will mostly miss their targets. Despite the fact that anomaly based IDS can detect novel attacks, they are not often deployed in industry, mainly owing to high false positive rate and lack of interpretability of trained models. With misuse based IDS' inability to detect unknown attacks and requirement for frequently manually crafting and updating signatures and with anomaly based IDS' bad reputation for high false alarm rate, specification based IDS can be regarded as the most suitable detection engine for cyber-physical systems (CPS) including SG. We argue that specification based IDS especially using rule learning could prove to be the most promising IDS for SG. Intrusion detection rules are learned through rule learning techniques and periodically automatically updated to accommodate dynamic system behaviors in SG. Fortunately, rule learning based IDS can not only detect previously unknown attacks but also achieve higher interpretability, due to symbolic representation of learned rules. It can thus be considered more trustworthy from human perspective and further assist human in the loop security operation. The present work provides a systematic and deep analysis of rule learning techniques and their suitability for IDS in SG. Besides, it concludes the most important criteria for learning intrusion detection rules and assessing their quality. This work serves not only as a guide to a number of important rule learning techniques but also as the first survey on their applications in IDS, which indicates their potential opportunities in SG security.","[Liu, Qi; Hagenmeyer, Veit; Keller, Hubert B.] Karlsruhe Inst Technol, Inst Automat & Appl Informat, D-76344 Eggenstein Leopoldshafen, Germany",,"Liu, Q (corresponding author), Karlsruhe Inst Technol, Inst Automat & Appl Informat, D-76344 Eggenstein Leopoldshafen, Germany.",qi.liu@kit.edu,,,,,,,,36,37,,,,,,,,,,,,2021,9,,,,,,57542,57564,,10.1109/ACCESS.2021.3071263,http://dx.doi.org/10.1109/ACCESS.2021.3071263,,,,,,,,,,,,2025-05-29,WOS:000641939000001,View Full Record in Web of Science
J,"Banerjee, S; Ghasemzadeh, P; Hempel, M; Sharif, H",,,,"Banerjee, Subharthi; Ghasemzadeh, Pejman; Hempel, Michael; Sharif, Hamid",,,Topography Relaxation in Determining Unsafe State Intersections for Uncertain CPS,IEEE SENSORS LETTERS,,,,Article,,,,,,,,"Human-in-the-loop systems are systems that consider the presence of humans, human errors, and human interactions with a system. Accurate and validated sensing, coordinated control and decision over human errors and interactions, even at a scale and complexity, should be done reliably and seamlessly. In these systems, sensors, while being discretized and processed digitally, nevertheless represent physical properties. Therefore, modeling of these very large systems faces two key challenges: 1) While computing aspects can be represented using discrete-time events, physical parameters can only be monitored adequately using continuous-time models, and 2) with human factors involved, behavior modeling is intractable and highly inaccurate. Conventional and state-of-the-art systems always limit themselves in terms of the bounded measure calculated from the data available, without factoring in human rational information verification. In this article, uncertainty theory-based cyber-physical state-space approximation is proposed. These approximations are further morphed topographically based on Ricci flow and fuzzy qualifiers to match human verification of sensor data. The results show that sensor information can be formally approximated, verified, and identified by human belief degrees. To the best of our knowledge, this is the first implementation of Ricci flow in the domain of fuzzy cyber-physical systems, and it has the potential to improve overall reachable set interpretability with qualitative and quantitative interpretation.","[Banerjee, Subharthi; Ghasemzadeh, Pejman; Hempel, Michael; Sharif, Hamid] Univ Nebraska, Dept Elect & Comp Engn, Lincoln, NE 68106 USA",,"Banerjee, S (corresponding author), Univ Nebraska, Dept Elect & Comp Engn, Lincoln, NE 68106 USA.",sbanerjee15@huskers.unl.edu,,,,,,,,2,3,,,,,,,,,,,APR,2020,4,4,,,,,,,6000304,10.1109/LSENS.2020.2981936,http://dx.doi.org/10.1109/LSENS.2020.2981936,,,,,,,,,,,,2025-05-29,WOS:000723608800004,View Full Record in Web of Science
J,"Huang, X; Ju, SH",,,,"Huang, Xiang; Ju, Shenghong",,,Tutorial: AI-assisted exploration and active design of polymers with high intrinsic thermal conductivity,JOURNAL OF APPLIED PHYSICS,,,,Article,,,,,,,,"Designing polymers with high intrinsic thermal conductivity (TC) is critically important for the thermal management of organic electronics and photonics. However, this is a challenging task owing to the diversity of the chemical space and the barriers to advanced synthetic experiments/characterization techniques for polymers. In this Tutorial, the fundamentals and implementation of combining classical molecular dynamics simulation and machine learning (ML) for the development of polymers with high TC are comprehensively introduced. We begin by describing the core components of a universal ML framework, involving polymer data sets, property calculators, feature engineering, and informatics algorithms. Then, the process of constructing interpretable regression algorithms for TC prediction is introduced, aiming to extract the underlying relationships between microstructures and TCs for polymers. We also explore the design of sequence-ordered polymers with high TC using lightweight and mainstream active learning algorithms. Lastly, we conclude by addressing the current limitations and suggesting potential avenues for future research on this topic.","[Huang, Xiang; Ju, Shenghong] Shanghai Jiao Tong Univ, China UK Low Carbon Coll, Shanghai 201306, Peoples R China; [Ju, Shenghong] Shanghai Jiao Tong Univ, Mat Genome Initiat Ctr, Sch Mat Sci & Engn, Shanghai 201306, Peoples R China",,"Ju, SH (corresponding author), Shanghai Jiao Tong Univ, China UK Low Carbon Coll, Shanghai 201306, Peoples R China.;Ju, SH (corresponding author), Shanghai Jiao Tong Univ, Mat Genome Initiat Ctr, Sch Mat Sci & Engn, Shanghai 201306, Peoples R China.",shenghong.ju@sjtu.edu.cn,,,,,,,,3,3,,,,,,,,,,,MAY 7,2024,135,17,,,,,,,171101,10.1063/5.0201522,http://dx.doi.org/10.1063/5.0201522,,,,,,,,,,,,2025-05-29,WOS:001214480500002,View Full Record in Web of Science
J,"Kuddusi, Y; Dobbelaere, MR; Van Geem, KM; Zuettel, A",,,,"Kuddusi, Yasemen; Dobbelaere, Maarten R.; Van Geem, Kevin M.; Zuettel, Andreas",,,Accelerated design of nickel-cobalt based catalysts for CO2 hydrogenation with human-in-the-loop active machine learning,CATALYSIS SCIENCE & TECHNOLOGY,,,,Article,,,,,,,,"Thermo-catalytic conversion of CO2 into more valuable compounds, such as methane, is an attractive strategy for energy storage in chemical bonds and creating a carbon-based circular economy. However, designing heterogeneous catalysts remains a challenging, time- and resource-consuming task. Herein, we present an interpretable, human-in-the-loop active machine learning framework to efficiently plan catalytic experiments, execute them in an automated set-up, and estimate the effect of experimental variables on the catalytic activity. A dataset with 48 catalytic activity tests was compiled from a design space of Ni-Co/Al2O3 catalysts with over 50 million potential combinations in only eight iterations. This small dataset was found sufficient to predict CO2 conversion, methane selectivity, and methane space-time yield with remarkable accuracy (R-2 > 0.9) for untested catalysts and reaction conditions. New experiments and catalysts were selected with this methodology, leading to experimental conditions that improved the methane space-time yield by nearly 50% in comparison to the previously obtained maximum in the dataset. Interpretation of the model predictions unveiled the effect of each catalyst descriptor and reaction condition on the outcome. Particularly, the strong predicted inverse trend between the calcination temperature and the catalytic activity was validated experimentally, and characterization implied an underlying structure-performance relationship. Finally, it is demonstrated that the deployed active learning model is excellently suited to predict and fit kinetic trends with a minimal amount of data. This data-driven framework is a first step to faster, model-based, and interpretable design of catalysts and holds promise for broader applications across catalytic processes.","[Kuddusi, Yasemen; Zuettel, Andreas] Ecole Polytech Fed Lausanne EPFL Valais Wallis, Inst Chem Sci & Engn ISIC, Basic Sci Fac SB,Energypolis, Lab Mat Renewable Energy LMER, Rue Ind 17, CH-1951 Sion, Switzerland; [Kuddusi, Yasemen; Zuettel, Andreas] Empa Mat Sci & Technol, CH-8600 Dubendorf, Switzerland; [Dobbelaere, Maarten R.; Van Geem, Kevin M.] Univ Ghent, Dept Mat Text & Chem Engn, Lab Chem Technol, Technologiepk 125, B-9052 Ghent, Belgium",,"Kuddusi, Y (corresponding author), Ecole Polytech Fed Lausanne EPFL Valais Wallis, Inst Chem Sci & Engn ISIC, Basic Sci Fac SB,Energypolis, Lab Mat Renewable Energy LMER, Rue Ind 17, CH-1951 Sion, Switzerland.",yasemen.kuddusi@epfl.ch,,,,,,,,2,2,,,,,,,,,,,OCT 28,2024,14,21,,,,,6307,6320,,10.1039/d4cy00873a,http://dx.doi.org/10.1039/d4cy00873a,,SEP 2024,,,,,,,,,,2025-05-29,WOS:001310754000001,View Full Record in Web of Science
J,"Bianchi, F; Piroddi, L; Bemporad, A; Halasz, G; Villani, M; Piga, D",,,,"Bianchi, Federico; Piroddi, Luigi; Bemporad, Alberto; Halasz, Geza; Villani, Matteo; Piga, Dario",,,Active preference-based optimization for human-in-the-loop feature selection,EUROPEAN JOURNAL OF CONTROL,,,,Article,,,,,,,,"In various classification problems characterized by a large number of features, feature selection (FS) is essential to guarantee generalization capabilities. The FS problem is often ill-posed due to significant correlations among features, which may lead to several different feature subsets with comparable scores in terms of classification performance. However, not all these subsets are equivalent from a domain-oriented point of view due to known relationships among features and their different acquisition costs in production to deploy the trained classifier. In this paper, we consider the potential benefits of including the domain expert's preferences in the FS task, thus integrating both objective elements (e.g., classification accuracy) and subjective (often not quantifiable) considerations in the selection process. This goes in the direction of increasing the interpretability and the trustworthiness of the machine learning model, which is an often desired property in many application domains such as in medicine. The proposed method consists of an iterative procedure. At each iteration, the expert is asked to express a human preference on pairs of classifiers, each one trained from a different subset of features. The expressed preferences are used algorithmically to update a suitable surrogate function that mimics the latent subjective expert's objective function, and then to propose a new classifier for testing and comparison. The proposed method has been tested on academic and experimental FS problems, and notably, on a COVID'19 patients record. The preliminary experimental results are promising, in that a parsimonious and accurate solution is obtained after a relatively short number of iterations. (c) 2022 European Control Association. Published by Elsevier Ltd. All rights reserved.","[Bianchi, Federico; Piroddi, Luigi] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy; [Bemporad, Alberto] IMT Sch Adv Studies Lucca, I-55100 Lucca, Italy; [Halasz, Geza] Guglielmo da Saliceto Hosp, Cardiol Dept, I-29121 Piacenza, Italy; [Villani, Matteo] Guglielmo da Saliceto Hosp, Anesthesiol & ICU Dept, I-29121 Piacenza, Italy; [Piga, Dario] IDSIA Dalle Molle Inst Artificial Intelligence Re, USI, SUPSI, CH-6962 Lugano, Switzerland",,"Bianchi, F (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.",federico.bianchi@polimi.it; luigi.piroddi@polimi.it,,,,,,,,5,5,,,,,,,,,,,JUL,2022,66,,,,,,,,100647,10.1016/j.ejcon.2022.100647,http://dx.doi.org/10.1016/j.ejcon.2022.100647,,,,,,,,,,,,2025-05-29,WOS:000906551800003,View Full Record in Web of Science
J,"Wang, YB; Wang, HF; Peng, ZH",,,,"Wang, Yibin; Wang, Haifeng; Peng, Zhaohua",,,Rice diseases detection and classification using attention based neural network and bayesian optimization,EXPERT SYSTEMS WITH APPLICATIONS,,,,Article,,,,,,,,"In this research, an attention-based depthwise separable neural network with Bayesian optimization (ADSNNBO) is proposed to detect and classify rice disease from rice leaf images. Rice diseases frequently result in 20-40% corp production loss in yield and is highly related to the global economy. Rapid disease identification is critical to plan treatment promptly and reduce the corp losses. Rice disease diagnosis is still mainly performed manually. To achieve AI assisted rapid and accurate disease detection, we proposed the ADSNN-BO model based on MobileNet structure and augmented attention mechanism. Moreover, Bayesian optimization method is applied to tune hyper-parameters of the model. Cross-validated classification experiments are conducted based on a public rice disease dataset with four categories in total. The experimental results demonstrate that our mobile compatible ADSNN-BO model achieves a test accuracy of 94.65%, which outperforms all of the state-ofthe-art models tested. To check the interpretability of our proposed model, feature analysis including activation map and filters visualization approach are also conducted. Results show that our proposed attention-based mechanism can more effectively guide the ADSNN-BO model to learn informative features. The outcome of this research will promote the implementation of artificial intelligence for fast plant disease diagnosis and control in the agricultural field.","[Wang, Yibin; Wang, Haifeng] Mississippi State Univ, Dept Ind & Syst Engn, Mississippi State, MS 39762 USA; [Peng, Zhaohua] Mississippi State Univ, Dept Biochem Mol Biol Entomol & Plant Pathol, Mississippi State, MS 39762 USA",,"Wang, HF (corresponding author), Mississippi State Univ, Dept Ind & Syst Engn, Mississippi State, MS 39762 USA.",wang@ise.msstate.edu,,,,,,,,151,156,,,,,,,,,,,SEP 15,2021,178,,,,,,,,114770,10.1016/j.eswa.2021.114770,http://dx.doi.org/10.1016/j.eswa.2021.114770,,APR 2021,,,,,,,,,,2025-05-29,WOS:000696803100002,View Full Record in Web of Science
J,"Inbar, O; Inbar, O; Dlin, R; Casaburi, R",,,,"Inbar, Omri; Inbar, Or; Dlin, Ron; Casaburi, Richard",,,Transitioning from stress electrocardiogram to cardiopulmonary exercise testing: a paradigm shift toward comprehensive medical evaluation of exercise function,EUROPEAN JOURNAL OF APPLIED PHYSIOLOGY,,,,Review; Early Access,,,,,,,,"Cardiopulmonary exercise testing (CPET) has emerged as a powerful diagnostic tool, providing comprehensive physiological insights into the integrated function of cardiovascular, respiratory, and metabolic systems. Exploiting physiological interactions, CPET allows in-depth diagnostic insights. CPET performance entrains several complexities. Interpreting CPET data can be challenging, requiring significant physiological expertise. The advent of artificial intelligence (AI) has introduced a transformative approach to CPET interpretation, enhancing accuracy, efficiency, and clinical decision-making. This review article explores the current state of AI applications in CPET, highlighting AI's potential to replace the traditional stress electrocardiogram (ECG) test as the preferred diagnostic tool in preventive medicine and medical screening. The article discusses the underlying principles of AI, its integration into CPET interpretation, and the associated benefits, including improved diagnostic accuracy, reduced interobserver variability, and expedited decision-making. Additionally, it addresses the challenges and considerations surrounding the implementation of AI in CPET such as data quality, model interpretability, and ethical concerns. The review concludes by emphasizing the significant promise of AI-assisted CPET interpretation in revolutionizing preventive medicine and medical screening settings and enhancing patient care.","[Inbar, Omri] Tel Aviv Univ, Sackler Fac Med, Sch Publ Hlth, Clin & Exercise Physiol, Tel Aviv, Israel; [Inbar, Or] Medibyt LTD, Med Engn, Yakum, Israel; [Dlin, Ron] Links Med Clin, Exercise Med Hlth Audit, Edmonton, AB, Canada; [Casaburi, Richard] Harbor UCLA, Med Ctr, Lundquist Inst Biomed Innovat, Resp Res Ctr, Torrance, CA USA",,"Inbar, O (corresponding author), Tel Aviv Univ, Sackler Fac Med, Sch Publ Hlth, Clin & Exercise Physiol, Tel Aviv, Israel.",inbar@l-w.ac.il,,,,,,,,0,0,,,,,,,,,,,2025 MAR 21,2025,,,,,,,,,,10.1007/s00421-025-05740-2,http://dx.doi.org/10.1007/s00421-025-05740-2,,MAR 2025,,,,,,,,,,2025-05-29,WOS:001467609100001,View Full Record in Web of Science
J,"Walker, LE; Abuzour, AS; Bollegala, D; Clegg, A; Gabbay, M; Griffiths, A; Kullu, C; Leeming, G; Mair, FS; Maskell, S; Relton, S; Ruddle, RA; Shantsila, E; Sperrin, M; Van Staa, T; Woodall, A; Buchan, I",,,,"Walker, Lauren E.; Abuzour, Aseel S.; Bollegala, Danushka; Clegg, Andrew; Gabbay, Mark; Griffiths, Alan; Kullu, Cecil; Leeming, Gary; Mair, Frances S.; Maskell, Simon; Relton, Samuel; Ruddle, Roy A.; Shantsila, Eduard; Sperrin, Matthew; Van Staa, Tjeerd; Woodall, Alan; Buchan, Iain",,,The DynAIRx Project Protocol: Artificial Intelligence for dynamic prescribing optimisation and care integration in multimorbidity,JOURNAL OF MULTIMORBIDITY AND COMORBIDITY,,,,Article,,,,,,,,"BackgroundStructured Medication Reviews (SMRs) are intended to help deliver the NHS Long Term Plan for medicines optimisation in people living with multiple long-term conditions and polypharmacy. It is challenging to gather the information needed for these reviews due to poor integration of health records across providers and there is little guidance on how to identify those patients most urgently requiring review.ObjectiveTo extract information from scattered clinical records on how health and medications change over time, apply interpretable artificial intelligence (AI) approaches to predict risks of poor outcomes and overlay this information on care records to inform SMRs. We will pilot this approach in primary care prescribing audit and feedback systems, and co-design future medicines optimisation decision support systems.DesignDynAIRx will target potentially problematic polypharmacy in three key multimorbidity groups, namely, people with (a) mental and physical health problems, (b) four or more long-term conditions taking ten or more drugs and (c) older age and frailty. Structured clinical data will be drawn from integrated care records (general practice, hospital, and social care) covering an similar to 11m population supplemented with Natural Language Processing (NLP) of unstructured clinical text. AI systems will be trained to identify patterns of conditions, medications, tests, and clinical contacts preceding adverse events in order to identify individuals who might benefit most from an SMR.DiscussionBy implementing and evaluating an AI-augmented visualisation of care records in an existing prescribing audit and feedback system we will create a learning system for medicines optimisation, co-designed throughout with end-users and patients.","[Walker, Lauren E.] Univ Liverpool, Wolfson Ctr Personalized Med, Brownlow St, Liverpool L69 3BX, England; [Abuzour, Aseel S.; Clegg, Andrew] Univ Leeds, Bradford Teaching Hosp NHS Fdn Trust, Acad Unit Ageing & Stroke Res, Bradford, England; [Bollegala, Danushka] Univ Liverpool, Dept Comp Sci, Liverpool, England; [Gabbay, Mark; Shantsila, Eduard; Buchan, Iain] Univ Liverpool, Inst Populat Hlth, Liverpool, England; [Griffiths, Alan] Publ Advisor, Paris, France; [Kullu, Cecil] Mersey Care NHS Fdn Trust, Liverpool, England; [Leeming, Gary] Univ Liverpool, Civ Data Cooperat, Liverpool, England; [Mair, Frances S.] Univ Glasgow, Sch Hlth & Wellbeing, Gen Practice & Primary Care, Glasgow, Scotland; [Maskell, Simon] Univ Liverpool, Sch Elect Engn Elect & Comp Sci, Liverpool, England; [Relton, Samuel] Univ Leeds, Inst Hlth Sci, Leeds, England; [Ruddle, Roy A.] Univ Leeds, Sch Comp, Leeds, England; [Ruddle, Roy A.] Univ Leeds, Leeds Inst Data Analyt, Leeds, England; [Sperrin, Matthew; Van Staa, Tjeerd] Univ Manchester, Div Informat Imaging & Data Sci, Manchester, England; [Woodall, Alan] Powys Teaching Hlth Board, Directorate Mental Hlth & Learning Disabil, Bronllys, Wales",,"Walker, LE (corresponding author), Univ Liverpool, Wolfson Ctr Personalized Med, Brownlow St, Liverpool L69 3BX, England.",lauren.walker@liv.ac.uk,,,,,,,,5,5,,,,,,,,,,,DEC,2022,12,,,,,,,,2.63356E+16,10.1177/26335565221145493,http://dx.doi.org/10.1177/26335565221145493,,,,,,,,,,,,2025-05-29,WOS:001315298200001,View Full Record in Web of Science
J,"Huang, Z; Yang, E; Shen, J; Gratzinger, D; Eyerer, F; Liang, B; Nirschl, J; Bingham, D; Dussaq, AM; Kunder, C; Rojansky, R; Gilbert, A; Chang-Graham, AL; Howitt, BE; Liu, Y; Ryan, EE; Tenney, TB; Zhang, XM; Folkins, A; Fox, EJ; Montine, KS; Montine, TJ; Zou, JM",,,,"Huang, Zhi; Yang, Eric; Shen, Jeanne; Gratzinger, Dita; Eyerer, Frederick; Liang, Brooke; Nirschl, Jeffrey; Bingham, David; Dussaq, Alex M.; Kunder, Christian; Rojansky, Rebecca; Gilbert, Aubre; Chang-Graham, Alexandra L.; Howitt, Brooke E.; Liu, Ying; Ryan, Emily E.; Tenney, Troy B.; Zhang, Xiaoming; Folkins, Ann; Fox, Edward J.; Montine, Kathleen S.; Montine, Thomas J.; Zou, James",,,A pathologist-AI collaboration framework for enhancing diagnostic accuracies and efficiencies,NATURE BIOMEDICAL ENGINEERING,,,,Article,,,,,,,,"In pathology, the deployment of artificial intelligence (AI) in clinical settings is constrained by limitations in data collection and in model transparency and interpretability. Here we describe a digital pathology framework, nuclei.io, that incorporates active learning and human-in-the-loop real-time feedback for the rapid creation of diverse datasets and models. We validate the effectiveness of the framework via two crossover user studies that leveraged collaboration between the AI and the pathologist, including the identification of plasma cells in endometrial biopsies and the detection of colorectal cancer metastasis in lymph nodes. In both studies, nuclei.io yielded considerable diagnostic performance improvements. Collaboration between clinicians and AI will aid digital pathology by enhancing accuracies and efficiencies. A digital pathology-artificial intelligence framework that leverages active learning and clinician-in-the-loop real-time feedback improves performance in diagnostic tasks.","[Huang, Zhi; Yang, Eric; Shen, Jeanne; Gratzinger, Dita; Eyerer, Frederick; Liang, Brooke; Nirschl, Jeffrey; Bingham, David; Dussaq, Alex M.; Kunder, Christian; Rojansky, Rebecca; Gilbert, Aubre; Chang-Graham, Alexandra L.; Howitt, Brooke E.; Liu, Ying; Ryan, Emily E.; Tenney, Troy B.; Zhang, Xiaoming; Folkins, Ann; Fox, Edward J.; Montine, Kathleen S.; Montine, Thomas J.] Stanford Univ, Sch Med, Dept Pathol, Stanford, CA 94305 USA; [Huang, Zhi; Zou, James] Stanford Univ, Sch Med, Dept Biomed Data Sci, Stanford, CA 94305 USA",,"Montine, TJ (corresponding author), Stanford Univ, Sch Med, Dept Pathol, Stanford, CA 94305 USA.;Zou, JM (corresponding author), Stanford Univ, Sch Med, Dept Biomed Data Sci, Stanford, CA 94305 USA.",tmontine@stanford.edu; jamesz@stanford.edu,,,,,,,,8,9,,,,,,,,,,,APR,2025,9,4,,,,,,,,10.1038/s41551-024-01223-5,http://dx.doi.org/10.1038/s41551-024-01223-5,,JUN 2024,,,,,,,,,,2025-05-29,WOS:001250311800001,View Full Record in Web of Science
J,"Wang, YH; Hou, SH; Zhang, RQ; Tang, XQ",,,,"Wang, Yuheng; Hou, Senhao; Zhang, Rongqiao; Tang, Xiaoqiang",,,Interaction force measurement of parallel robots based on structure-integrated force sensors using interpretable linear neural networks,MECHATRONICS,,,,Article,,,,,,,,"The parallel robot in this research is mainly designed for the human-machine collaboration, which has two working modes: follow-up mode and pressing mode. In order to better realize these two functions, the measurement of the interaction force is mainly concerned. In the arrangement of the hardware, different from the sixdimensional force sensor method and current estimation method commonly used in industry, the structureintegrated force sensors (SIFS) measurement method is used. In the calculation method, a back propagation neural networks (BPNN) method is introduced to calculate the interaction force. Then, based on the prior knowledge of physics, a new interpretable linear neural networks (ILNN) method is proposed. The details of the ILNN algorithm and its differences from the classic neural network methods are given. Finally, the experimental results of the direct Newton-Euler method, the least square method, the BPNN method, and the ILNN method are compared. Experimental results show that the inference accuracy of the ILNN method is slightly better than the direct Newton-Euler method and the least square method, and its generalization ability is much better than the BPNN method. The use of the ILNN method based on the FIFS arrangement makes the measurement of the interaction force more accurate and reliable.","[Wang, Yuheng; Hou, Senhao; Zhang, Rongqiao; Tang, Xiaoqiang] Tsinghua Univ, Dept Mech Engn, State Key Lab Tribol, Beijing, Peoples R China; [Wang, Yuheng; Hou, Senhao; Zhang, Rongqiao; Tang, Xiaoqiang] Tsinghua Univ, Beijing Key Lab Precis Ultraprecis Mfg Equipment &, Beijing, Peoples R China",,"Hou, SH; Tang, XQ (corresponding author), Tsinghua Univ, Dept Mech Engn, State Key Lab Tribol, Beijing, Peoples R China.;Hou, SH; Tang, XQ (corresponding author), Tsinghua Univ, Beijing Key Lab Precis Ultraprecis Mfg Equipment &, Beijing, Peoples R China.",hou-sh16@mails.tsinghua.edu.cn; tang-xq@mail.tsinghua.edu.cn,,,,,,,,4,5,,,,,,,,,,,NOV,2022,87,,,,,,,,102895,10.1016/j.mechatronics.2022.102895,http://dx.doi.org/10.1016/j.mechatronics.2022.102895,,SEP 2022,,,,,,,,,,2025-05-29,WOS:000857344200003,View Full Record in Web of Science
J,"Salomao, LAT; Mahfouf, M; El-Samahy, E; Ting, CH",,,,"Salomao, Luis A. Torres; Mahfouf, Mahdi; El-Samahy, Emad; Ting, Ching-Hua",,,Psychophysiologically Based Real-Time Adaptive General Type 2 Fuzzy Modeling and Self-Organizing Control of Operator's Performance Undertaking a Cognitive Task,IEEE TRANSACTIONS ON FUZZY SYSTEMS,,,,Article,,,,,,,,"This paper presents a new modeling and control fuzzy-based framework validated with real-time experiments on human participants experiencing stress via mental arithmetic cognitive tasks identified through psychophysiological markers. The ultimate aim of the modeling/control framework is to prevent performance breakdown in human-computer interactive systems with a special focus on human performance. Two designed modeling/control experiments which consist of carrying-out arithmetic operations of varying difficulty levels were performed by ten participants (operators) in the study. With this new technique, modeling is achieved through a new adaptive, self-organizing, and interpretable modeling framework based on general Type-2 fuzzy sets. This framework is able to learn in real time through the implementation of a restructured performance learning algorithm that identifies important features in the data without the need for prior training. The information learnt by the model is later exploited via an energy model based controller that infers adequate control actions by changing the difficulty level of the arithmetic operations in the human-computer interaction system; these actions being based on the most current psychophysiological state of the subject under study. The real-time implementation of the proposed modeling and control configurations for the human-machine interaction under study shows superior performance as compared to other forms of modeling and control, with minimal intervention in terms of model retraining or parameter retuning to deal with uncertainties, disturbances, and inter/intrasubject parameter variability.","[Salomao, Luis A. Torres; Mahfouf, Mahdi] Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield S13 DJ, S Yorkshire, England; [El-Samahy, Emad] Mil Tech Coll, Biomed Engn Dept, Cairo 17654, Egypt; [Ting, Ching-Hua] Natl Chiayi Univ, Dept Mech & Energy Engn, Chiayi 60004, Taiwan",,"Salomao, LAT (corresponding author), Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield S13 DJ, S Yorkshire, England.",latsalomao@ieee.org; m.mahfouf@sheffield.ac.uk; e.elsamahy@gmail.com; cting@mail.ncyu.edu.tw,,,,,,,,9,10,,,,,,,,,,,FEB,2017,25,1,,,,,43,57,,10.1109/TFUZZ.2016.2598363,http://dx.doi.org/10.1109/TFUZZ.2016.2598363,,,,,,,,,,,,2025-05-29,WOS:000396393100005,View Full Record in Web of Science
J,"Sarailidis, G; Wagener, T; Pianosi, F",,,,"Sarailidis, Georgios; Wagener, Thorsten; Pianosi, Francesca",,,Integrating scientific knowledge into machine learning using interactive decision trees,COMPUTERS & GEOSCIENCES,,,,Article,,,,,,,,"Decision Trees (DT) describe a type of machine learning method that has been widely used in the geosciences to automatically extract patterns from complex and high dimensional data. However, like any data-based method, the application of DT is hindered by data limitations, such as significant biases, leading to potentially physically unrealistic results. We develop interactive DT (iDT) that put humans in the loop to integrate the power of experts' scientific knowledge with the power of the algorithms to automatically learn patterns from large datasets. We created an open-source Python toolbox that implements the iDT framework. Users can interactively create new composite variables, change the variable and threshold to split, prune and group variables based on their physical meaning. We demonstrate with three case studies how iDT overcomes problems with current DT thus achieving higher interpretability and robustness of the result.","[Sarailidis, Georgios; Pianosi, Francesca] Univ Bristol, Dept Civil Engn Water & Environm Engn, Bristol, England; [Wagener, Thorsten] Univ Potsdam, Inst Environm Sci & Geog, Potsdam, Germany",,"Sarailidis, G (corresponding author), Univ Bristol, Dept Civil Engn Water & Environm Engn, Bristol, England.",g.sarailidis@bristol.ac.uk,,,,,,,,23,24,,,,,,,,,,,JAN,2023,170,,,,,,,,105248,10.1016/j.cageo.2022.105248,http://dx.doi.org/10.1016/j.cageo.2022.105248,,OCT 2022,,,,,,,,,,2025-05-29,WOS:000877619700003,View Full Record in Web of Science
J,"Chen, J; Wang, GH; Zhou, JJ; Zhang, ZH; Ding, Y; Xia, KJ; Xu, XD",,,,"Chen, Jian; Wang, Ganhong; Zhou, Jingjie; Zhang, Zihao; Ding, Yu; Xia, Kaijian; Xu, Xiaodan",,,AI support for colonoscopy quality control using CNN and transformer architectures,BMC GASTROENTEROLOGY,,,,Article,,,,,,,,"BackgroundConstruct deep learning models for colonoscopy quality control using different architectures and explore their decision-making mechanisms.MethodsA total of 4,189 colonoscopy images were collected from two medical centers, covering different levels of bowel cleanliness, the presence of polyps, and the cecum. Using these data, eight pre-trained models based on CNN and Transformer architectures underwent transfer learning and fine-tuning. The models' performance was evaluated using metrics such as AUC, Precision, and F1 score. Perceptual hash functions were employed to detect image changes, enabling real-time monitoring of colonoscopy withdrawal speed. Model interpretability was analyzed using techniques such as Grad-CAM and SHAP. Finally, the best-performing model was converted to ONNX format and deployed on device terminals.ResultsThe EfficientNetB2 model outperformed other architectures on the validation set, achieving an accuracy of 0.992. It surpassed models based on other CNN and Transformer architectures. The model's precision, recall, and F1 score were 0.991, 0.989, and 0.990, respectively. On the test set, the EfficientNetB2 model achieved an average AUC of 0.996, with a precision of 0.948 and a recall of 0.952. Interpretability analysis showed the specific image regions the model used for decision-making. The model was converted to ONNX format and deployed on device terminals, achieving an average inference speed of over 60 frames per second.ConclusionsThe AI-assisted quality system, based on the EfficientNetB2 model, integrates four key quality control indicators for colonoscopy. This integration enables medical institutions to comprehensively manage and enhance these indicators using a single model, showcasing promising potential for clinical applications.","[Chen, Jian; Zhou, Jingjie; Ding, Yu; Xu, Xiaodan] Soochow Univ, Dept Gastroenterol, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China; [Wang, Ganhong] Changshu Traditional Chinese Med Hosp, Dept Gastroenterol, Suzhou 215500, Peoples R China; [Zhang, Zihao] Shanghai Haoxiong Educ Technol Co Ltd, Shanghai 200434, Peoples R China; [Xia, Kaijian] Soochow Univ, Dept Informat Engn, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China",,"Xu, XD (corresponding author), Soochow Univ, Dept Gastroenterol, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China.;Xia, KJ (corresponding author), Soochow Univ, Dept Informat Engn, Changshu Hosp Affiliated, Suzhou 215500, Peoples R China.",kjxia@suda.edu.cn; xxddocter@gmail.com,,,,,,,,2,2,,,,,,,,,,,AUG 9,2024,24,1,,,,,,,257,10.1186/s12876-024-03354-0,http://dx.doi.org/10.1186/s12876-024-03354-0,,,,,,,,,,,,2025-05-29,WOS:001288126700002,View Full Record in Web of Science
J,"Girardi, AM; Cardell, EA; Bird, SP",,,,"Girardi, Anna M.; Cardell, Elizabeth A.; Bird, Stephen P.",,,Artificial Intelligence in the Interpretation of Videofluoroscopic Swallow Studies: Implications and Advances for Speech-Language Pathologists,BIG DATA AND COGNITIVE COMPUTING,,,,Article,,,,,,,,"Radiological imaging is an essential component of a swallowing assessment. Artificial intelligence (AI), especially deep learning (DL) models, has enhanced the efficiency and efficacy through which imaging is interpreted, and subsequently, it has important implications for swallow diagnostics and intervention planning. However, the application of AI for the interpretation of videofluoroscopic swallow studies (VFSS) is still emerging. This review showcases the recent literature on the use of AI to interpret VFSS and highlights clinical implications for speech-language pathologists (SLPs). With a surge in AI research, there have been advances in dysphagia assessments. Several studies have demonstrated the successful implementation of DL algorithms to analyze VFSS. Notably, convolutional neural networks (CNNs), which involve training a multi-layered model to recognize specific image or video components, have been used to detect pertinent aspects of the swallowing process with high levels of precision. DL algorithms have the potential to streamline VFSS interpretation, improve efficiency and accuracy, and enable the precise interpretation of an instrumental dysphagia evaluation, which is especially advantageous when access to skilled clinicians is not ubiquitous. By enhancing the precision, speed, and depth of VFSS interpretation, SLPs can obtain a more comprehensive understanding of swallow physiology and deliver a targeted and timely intervention that is tailored towards the individual. This has practical applications for both clinical practice and dysphagia research. As this research area grows and AI technologies progress, the application of DL in the field of VFSS interpretation is clinically beneficial and has the potential to transform dysphagia assessment and management. With broader validation and inter-disciplinary collaborations, AI-augmented VFSS interpretation will likely transform swallow evaluations and ultimately improve outcomes for individuals with dysphagia. However, despite AI's potential to streamline imaging interpretation, practitioners still need to consider the challenges and limitations of AI implementation, including the need for large training datasets, interpretability and adaptability issues, and the potential for bias.","[Girardi, Anna M.; Cardell, Elizabeth A.; Bird, Stephen P.] Univ Southern Queensland, Sch Hlth & Med Sci, Ipswich, Qld 4305, Australia; [Girardi, Anna M.; Cardell, Elizabeth A.; Bird, Stephen P.] Univ Southern Queensland, Ctr Hlth Res, Toowoomba, Qld 4350, Australia; [Cardell, Elizabeth A.] Griffith Univ, Sch Med & Dent, Gold Coast, Qld 4222, Australia",,"Girardi, AM (corresponding author), Univ Southern Queensland, Sch Hlth & Med Sci, Ipswich, Qld 4305, Australia.;Girardi, AM (corresponding author), Univ Southern Queensland, Ctr Hlth Res, Toowoomba, Qld 4350, Australia.",anna.girardi@unisq.edu.au; elizabeth.cardell@unisq.edu.au; stephen.bird@unisq.edu.au,,,,,,,,4,4,,,,,,,,,,,DEC,2023,7,4,,,,,,,178,10.3390/bdcc7040178,http://dx.doi.org/10.3390/bdcc7040178,,,,,,,,,,,,2025-05-29,WOS:001136185700001,View Full Record in Web of Science
J,"Papalampidi, P; Keller, F; Lapata, M",,,,"Papalampidi, Pinelopi; Keller, Frank; Lapata, Mirella",,,Finding the Right Moment: Human-Assisted Trailer Creation via Task Composition,IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,,,,Article,,,,,,,,"Movie trailers perform multiple functions: they introduce viewers to the story, convey the mood and artistic style of the film, and encourage audiences to see the movie. These diverse functions make trailer creation a challenging endeavor. In this work, we focus on finding trailer moments in a movie, i.e., shots that could be potentially included in a trailer. We decompose this task into two subtasks: narrative structure identification and sentiment prediction. We model movies as graphs, where nodes are shots and edges denote semantic relations between them. We learn these relations using joint contrastive training which distills rich textual information (e.g., characters, actions, situations) from screenplays. An unsupervised algorithm then traverses the graph and selects trailer moments from the movie that human judges prefer to ones selected by competitive supervised approaches. A main advantage of our algorithm is that it uses interpretable criteria, which allows us to deploy it in an interactive tool for trailer creation with a human in the loop. Our tool allows users to select trailer shots in under 30 minutes that are superior to fully automatic methods and comparable to (exclusive) manual selection by experts.","[Papalampidi, Pinelopi; Keller, Frank; Lapata, Mirella] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Scotland",,"Papalampidi, P (corresponding author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Scotland.",nelipapalam@gmail.com; keller@inf.ed.ac.uk; mlap@inf.ed.ac.uk,,,,,,,,1,1,,,,,,,,,,,JAN,2024,46,1,,,,,292,304,,10.1109/TPAMI.2023.3323030,http://dx.doi.org/10.1109/TPAMI.2023.3323030,,,,,,,,,,,,2025-05-29,WOS:001123923900012,View Full Record in Web of Science
J,"Sun, DZ; Hu, YY; Li, YM; Yu, XB; Chen, X; Shen, P; Tang, XL; Wang, YH; Lai, CC; Kang, B; Bai, ZJ; Ni, ZX; Wang, NN; Wang, R; Guan, LA; Zhou, W; Gao, Y",,,,"Sun, Dezhi; Hu, Yangyi; Li, Yunming; Yu, Xianbiao; Chen, Xi; Shen, Pan; Tang, Xianglin; Wang, Yihao; Lai, Chengcai; Kang, Bo; Bai, Zhijie; Ni, Zhexin; Wang, Ningning; Wang, Rui; Guan, Lina; Zhou, Wei; Gao, Yue",,,Chamber Attention Network (CAN): Towards interpretable diagnosis of pulmonary artery hypertension using echocardiography,JOURNAL OF ADVANCED RESEARCH,,,,Article,,,,,,,,"Introduction:: : Accurate identification of pulmonary arterial hypertension (PAH) in primary care and rural areas can be a challenging task. However, recent advancements in computer vision offer the potential for automated systems to detect PAH from echocardiography . Objectives:: : Our aim was to develop a precise and efficient diagnostic model for PAH tailored to the unique requirements of intelligent diagnosis, especially in challenging locales like high-altitude regions. Methods:: : We proposed the Chamber Attention Network (CAN) for PAH identification from echocardiographic images, trained on a dataset comprising 13,912 individual subjects. A convolutional neural network (CNN) for view classification was used to select the clinically relevant apical four chamber (A4C) and parasternal long axis (PLAX) views for PAH diagnosis. To assess the importance of different heart chambers in PAH diagnosis, we developed a novel Chamber Attention Module. Results:: : The experimental results demonstrated that: 1) The substantial correspondence between our obtained chamber attention vector and clinical expertise suggested that our model was highly interpretable, potentially uncovering diagnostic insights overlooked by the clinical community. 2) The proposed CAN model exhibited superior image-level accuracy and faster convergence on the internal validation dataset compared to the other four models. Furthermore, our CAN model outperformed the others on the external test dataset, with image-level accuracies of 82.53% and 83.32% for A4C and PLAX, respectively. 3) Implementation of the voting strategy notably enhanced the positive predictive value (PPV) and negative predictive value (NPV) of individual-level classification results, enhancing the reliability of our classification outcomes. Conclusions:: : These findings indicate that CAN is a feasible technique for AI-assisted PAH diagnosis, providing new insights into cardiac structural changes observed in echocardiography. (c) 2024 The Authors. Published by Elsevier B.V. on behalf of Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","[Sun, Dezhi; Hu, Yangyi; Shen, Pan; Tang, Xianglin; Wang, Yihao; Lai, Chengcai; Bai, Zhijie; Ni, Zhexin; Wang, Ningning; Zhou, Wei; Gao, Yue] Beijing Inst Radiat Med, Dept Pharmaceut Sci, Beijing 100850, Peoples R China; [Li, Yunming] Gen Hosp Western Theater Command, Med Support Ctr, Dept Informat, Chengdu 610083, Sichuan, Peoples R China; [Yu, Xianbiao] Army 954 Hosp, Dept Ultrason Diag, Shannan 856000, Xizang, Peoples R China; [Chen, Xi] Army 954 Hosp, Dept Resp Med, Shannan 856000, Xizang, Peoples R China; [Kang, Bo] Army 954 Hosp, Dept Acad Affairs, Shannan 856000, Xizang, Peoples R China; [Wang, Rui; Guan, Lina] Gen Hosp Xinjiang Mil Reg Chinese Peoples Liberat, Urumqi 830000, Xinjiang, Peoples R China",,"Zhou, W; Gao, Y (corresponding author), Beijing Inst Radiat Med, Dept Pharmaceut Sci, Beijing 100850, Peoples R China.",zhouweisyl802@163.com; gaoyue@bmi.ac.cn,,,,,,,,1,1,,,,,,,,,,,SEP,2024,63,,,,,,103,115,,10.1016/j.jare.2023.10.013,http://dx.doi.org/10.1016/j.jare.2023.10.013,,AUG 2024,,,,,,,,,,2025-05-29,WOS:001297857000001,View Full Record in Web of Science
J,"Almotiri, J",,,,"Almotiri, Jasem",,,Dynamic Spatial Focus in Alzheimer's Disease Diagnosis via Multiple CNN Architectures and Dynamic GradNet,CMC-COMPUTERS MATERIALS & CONTINUA,,,,Article,,,,,,,,"The evolving field of Alzheimer's disease (AD) diagnosis has greatly benefited from deep learning models for analyzing brain magnetic resonance (MR) images. This study introduces Dynamic GradNet, a novel deep learning model designed to increase diagnostic accuracy and interpretability for multiclass AD classification. Initially, four state-of-the-art convolutional neural network (CNN) architectures, the self-regulated network (RegNet), residual network (ResNet), densely connected convolutional network (DenseNet), and efficient network (EfficientNet), were comprehensively compared via a unified preprocessing pipeline to ensure a fair evaluation. Among these models, EfficientNet consistently demonstrated superior performance in terms of accuracy, precision, recall, and F1 score. As a result, EfficientNet was selected as the foundation for implementing Dynamic GradNet. Dynamic GradNet incorporates gradient weighted class activation mapping (GradCAM) into the training process, facilitating dynamic adjustments that focus on critical brain regions associated with early dementia detection. These adjustments are particularly effective in identifying subtle changes associated with very mild dementia, enabling early diagnosis and intervention. The model was evaluated with the OASIS dataset, which contains greater than 80,000 brain MR images categorized into four distinct stages of AD progression. The proposed model outperformed the baseline architectures, achieving remarkable generalizability across all stages. This finding was especially evident in early-stage dementia detection, where Dynamic GradNet significantly reduced false positives and enhanced classification metrics. These findings highlight the potential of Dynamic GradNet as a robust and scalable approach for AD diagnosis, providing a promising alternative to traditional attention-based models. The model's ability to dynamically adjust spatial focus offers a powerful tool in artificial intelligence (AI) assisted precision medicine, particularly in the early detection of neurodegenerative diseases.","[Almotiri, Jasem] Taif Univ, Coll Comp & Informat Technol, Dept Comp Sci, Taif 21944, Saudi Arabia",,"Almotiri, J (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Comp Sci, Taif 21944, Saudi Arabia.",j.jasem@tu.edu.sa,,,,,,,,0,0,,,,,,,,,,,,2025,83,2,,,,,2109,2142,,10.32604/cmc.2025.06292,http://dx.doi.org/10.32604/cmc.2025.06292,,,,,,,,,,,,2025-05-29,WOS:001476607800001,View Full Record in Web of Science
J,"Ma, L; Chen, R; Ge, WG; Rogers, P; Lyn-Cook, B; Hong, HX; Tong, WD; Wu, NN; Zou, W",,,,"Ma, Li; Chen, Ru; Ge, Weigong; Rogers, Paul; Lyn-Cook, Beverly; Hong, Huixiao; Tong, Weida; Wu, Ningning; Zou, Wen",,,AI-powered topic modeling: comparing LDA and BERTopic in analyzing opioid-related cardiovascular risks in women,EXPERIMENTAL BIOLOGY AND MEDICINE,,,,Article,,,,,,,,"Topic modeling is a crucial technique in natural language processing (NLP), enabling the extraction of latent themes from large text corpora. Traditional topic modeling, such as Latent Dirichlet Allocation (LDA), faces limitations in capturing the semantic relationships in the text document although it has been widely applied in text mining. BERTopic, created in 2022, leveraged advances in deep learning and can capture the contextual relationships between words. In this work, we integrated Artificial Intelligence (AI) modules to LDA and BERTopic and provided a comprehensive comparison on the analysis of prescription opioid-related cardiovascular risks in women. Opioid use can increase the risk of cardiovascular problems in women such as arrhythmia, hypotension etc. 1,837 abstracts were retrieved and downloaded from PubMed as of April 2024 using three Medical Subject Headings (MeSH) words: opioid, cardiovascular, and women. Machine Learning of Language Toolkit (MALLET) was employed for the implementation of LDA. BioBERT was used for document embedding in BERTopic. Eighteen was selected as the optimal topic number for MALLET and 23 for BERTopic. ChatGPT-4-Turbo was integrated to interpret and compare the results. The short descriptions created by ChatGPT for each topic from LDA and BERTopic were highly correlated, and the performance accuracies of LDA and BERTopic were similar as determined by expert manual reviews of the abstracts grouped by their predominant topics. The results of the t-SNE (t-distributed Stochastic Neighbor Embedding) plots showed that the clusters created from BERTopic were more compact and well-separated, representing improved coherence and distinctiveness between the topics. Our findings indicated that AI algorithms could augment both traditional and contemporary topic modeling techniques. In addition, BERTopic has the connection port for ChatGPT-4-Turbo or other large language models in its algorithm for automatic interpretation, while with LDA interpretation must be manually, and needs special procedures for data pre-processing and stop words exclusion. Therefore, while LDA remains valuable for large-scale text analysis with resource constraints, AI-assisted BERTopic offers significant advantages in providing the enhanced interpretability and the improved semantic coherence for extracting valuable insights from textual data.","[Ma, Li; Ge, Weigong; Rogers, Paul; Hong, Huixiao; Tong, Weida; Zou, Wen] US FDA, Div Bioinformat & Biostat, Natl Ctr Toxicol Res, Jefferson, AR 72079 USA; [Ma, Li; Wu, Ningning] Univ Arkansas Little Rock, Dept Informat Sci, Little Rock, AR 72701 USA; [Chen, Ru] US FDA, Off New Drug, Ctr Drug Evaluat & Res, Silver Spring, MD USA; [Lyn-Cook, Beverly] US FDA, Div Biochem Toxicol, Natl Ctr Toxicol Res, Jefferson, AR USA",,"Zou, W (corresponding author), US FDA, Div Bioinformat & Biostat, Natl Ctr Toxicol Res, Jefferson, AR 72079 USA.;Wu, NN (corresponding author), Univ Arkansas Little Rock, Dept Informat Sci, Little Rock, AR 72701 USA.",nxwu@ualr.edu; wen.zou@fda.hhs.gov,,,,,,,,0,0,,,,,,,,,,,FEB 28,2025,250,,,,,,,,10389,10.3389/ebm.2025.10389,http://dx.doi.org/10.3389/ebm.2025.10389,,,,,,,,,,,,2025-05-29,WOS:001443729700001,View Full Record in Web of Science
J,"Yan, L; Liang, ZY; Zhang, H; Zhang, GS; Zheng, WW; Han, CG; Yu, DS; Zhang, HQ; Xie, XX; Liu, C; Zhang, WX; Zheng, H; Pei, J; Shen, DG; Qian, XJ",,,,"Yan, Lin; Liang, Zhiying; Zhang, Hao; Zhang, Gaosong; Zheng, Weiwei; Han, Chunguang; Yu, Dongsheng; Zhang, Hanqi; Xie, Xinxin; Liu, Chang; Zhang, Wenxin; Zheng, Hui; Pei, Jing; Shen, Dinggang; Qian, Xuejun",,,A domain knowledge-based interpretable deep learning system for improving clinical breast ultrasound diagnosis,COMMUNICATIONS MEDICINE,,,,Article,,,,,,,,"Background Though deep learning has consistently demonstrated advantages in the automatic interpretation of breast ultrasound images, its black-box nature hinders potential interactions with radiologists, posing obstacles for clinical deployment.Methods We proposed a domain knowledge-based interpretable deep learning system for improving breast cancer risk prediction via paired multimodal ultrasound images. The deep learning system was developed on 4320 multimodal breast ultrasound images of 1440 biopsy-confirmed lesions from 1348 prospectively enrolled patients across two hospitals between August 2019 and December 2022. The lesions were allocated to 70% training cohort, 10% validation cohort, and 20% test cohort based on case recruitment date.Results Here, we show that the interpretable deep learning system can predict breast cancer risk as accurately as experienced radiologists, with an area under the receiver operating characteristic curve of 0.902 (95% confidence interval = 0.882 - 0.921), sensitivity of 75.2%, and specificity of 91.8% on the test cohort. With the aid of the deep learning system, particularly its inherent explainable features, junior radiologists tend to achieve better clinical outcomes, while senior radiologists experience increased confidence levels. Multimodal ultrasound images augmented with domain knowledge-based reasoning cues enable an effective human-machine collaboration at a high level of prediction performance.Conclusions Such a clinically applicable deep learning system may be incorporated into future breast cancer screening and support assisted or second-read workflows. Breast cancer is one of the most common cancers, and finding it early can greatly improve patients' chances of survival and recovery. We create a tool based on artificial intelligence (AI)-whereby computer software learns to perform tasks that normally require human thinking-called MUP-Net. MUP-Net can analyze medical images to predict a patient's risk of having breast cancer. To make this AI tool usable in clinical practice, we enabled doctors to see the reasoning behind the AI's predictions by visualizing the key image features it analyzed. We showed that our AI tool not only makes doctors more confident in their diagnosis but also helps them make better decisions, especially for less experienced doctors. With further testing, our AI tool may help clinicians to diagnose breast cancer more accurately and quickly, potentially improving patient outcomes. Yan, Liang, Zhang et al. propose a domain knowledge-based interpretable deep learning system to improve breast cancer risk prediction from multimodal ultrasound images. Its inherent interpretability enables effective human-machine collaboration and thus may aid clinical decision-making.","[Yan, Lin] Xian Univ Finance & Econ, Sch Math, Xian, Peoples R China; [Liang, Zhiying; Yu, Dongsheng; Shen, Dinggang; Qian, Xuejun] ShanghaiTech Univ, Sch Biomed Engn, Shanghai, Peoples R China; [Zhang, Hao] Capital Med Univ, Beijing Friendship Hosp, Dept Neurosurg, Beijing, Peoples R China; [Zhang, Gaosong; Zhang, Hanqi; Zhang, Wenxin; Zheng, Hui] Anhui Med Univ, Affiliated Hosp 1, Dept Ultrasound, Hefei, Peoples R China; [Zheng, Weiwei] Xuancheng Peoples Hosp, Dept Ultrasound, Xuancheng, Peoples R China; [Han, Chunguang; Liu, Chang; Pei, Jing] Anhui Med Univ, Affiliated Hosp 1, Dept Gen Surg, Hefei, Peoples R China; [Xie, Xinxin] Peking Univ Third Hosp, Dept Ultrasound, Beijing, Peoples R China; [Liu, Chang; Pei, Jing] Anhui Med Univ, Affiliated Hosp 1, Dept Breast Surg, Hefei, Peoples R China; [Shen, Dinggang; Qian, Xuejun] ShanghaiTech Univ, State Key Lab Adv Med Mat & Devices, Shanghai, Peoples R China; [Shen, Dinggang; Qian, Xuejun] Shanghai United Imaging Intelligence Co Ltd, Shanghai, Peoples R China; [Shen, Dinggang] Shanghai Clin Res & Trial Ctr, Shanghai, Peoples R China",,"Shen, DG; Qian, XJ (corresponding author), ShanghaiTech Univ, Sch Biomed Engn, Shanghai, Peoples R China.;Pei, J (corresponding author), Anhui Med Univ, Affiliated Hosp 1, Dept Gen Surg, Hefei, Peoples R China.;Pei, J (corresponding author), Anhui Med Univ, Affiliated Hosp 1, Dept Breast Surg, Hefei, Peoples R China.;Shen, DG; Qian, XJ (corresponding author), ShanghaiTech Univ, State Key Lab Adv Med Mat & Devices, Shanghai, Peoples R China.;Shen, DG; Qian, XJ (corresponding author), Shanghai United Imaging Intelligence Co Ltd, Shanghai, Peoples R China.;Shen, DG (corresponding author), Shanghai Clin Res & Trial Ctr, Shanghai, Peoples R China.",peijing@ahmu.edu.cn; dgshen@shanghaitech.edu.cn; qianxj@shanghaitech.edu.cn,,,,,,,,5,5,,,,,,,,,,,MAY 17,2024,4,1,,,,,,,90,10.1038/s43856-024-00518-7,http://dx.doi.org/10.1038/s43856-024-00518-7,,,,,,,,,,,,2025-05-29,WOS:001227243200002,View Full Record in Web of Science
J,"Kalyta, O; Barmak, O; Radiuk, P; Krak, I",,,,"Kalyta, Oleg; Barmak, Olexander; Radiuk, Pavlo; Krak, Iurii",,,Facial Emotion Recognition for Photo and Video Surveillance Based on Machine Learning and Visual Analytics,APPLIED SCIENCES-BASEL,,,,Article,,,,,,,,"Featured Application Can be used in video surveillance systems for large groups of people.Abstract Modern video surveillance systems mainly rely on human operators to monitor and interpret the behavior of individuals in real time, which may lead to severe delays in responding to an emergency. Therefore, there is a need for continued research into the designing of interpretable and more transparent emotion recognition models that can effectively detect emotions in safety video surveillance systems. This study proposes a novel technique incorporating a straightforward model for detecting sudden changes in a person's emotional state using low-resolution photos and video frames from surveillance cameras. The proposed technique includes a method of the geometric interpretation of facial areas to extract features of facial expression, the method of hyperplane classification for identifying emotional states in the feature vector space, and the principles of visual analytics and human in the loop to obtain transparent and interpretable classifiers. The experimental testing using the developed software prototype validates the scientific claims of the proposed technique. Its implementation improves the reliability of abnormal behavior detection via facial expressions by 0.91-2.20%, depending on different emotions and environmental conditions. Moreover, it decreases the error probability in identifying sudden emotional shifts by 0.23-2.21% compared to existing counterparts. Future research will aim to improve the approach quantitatively and address the limitations discussed in this paper.","[Kalyta, Oleg; Barmak, Olexander; Radiuk, Pavlo] Khmelnytskyi Natl Univ, Dept Comp Sci, 11 Instytutska Str, UA-29016 Khmelnytskyi, Ukraine; [Krak, Iurii] Taras Shevchenko Natl Univ Kyiv, Dept Theoret Cybernet, 4d Akad Hlushkova Ave, UA-03680 Kiev, Ukraine; [Krak, Iurii] VM Glushkov Inst Cybernet, Lab Commun Informat Technol, 40 Akad Hlushkova Ave, UA-03187 Kiev, Ukraine",,"Radiuk, P (corresponding author), Khmelnytskyi Natl Univ, Dept Comp Sci, 11 Instytutska Str, UA-29016 Khmelnytskyi, Ukraine.",oleg.kalyta@gmail.com; alexander.barmak@gmail.com; radiukp@khmnu.edu.ua; yuri.krak@gmail.com,,,,,,,,7,8,,,,,,,,,,,SEP,2023,13,17,,,,,,,9890,10.3390/app13179890,http://dx.doi.org/10.3390/app13179890,,,,,,,,,,,,2025-05-29,WOS:001061021600001,View Full Record in Web of Science
J,"Zeng, ZN; Yin, BC; Wang, SP; Liu, JR; Yang, C; Yao, HS; Sun, XZ; Sun, MS; Xie, GT; Liu, ZY",,,,"Zeng, Zheni; Yin, Bangchen; Wang, Shipeng; Liu, Jiarui; Yang, Cheng; Yao, Haishen; Sun, Xingzhi; Sun, Maosong; Xie, Guotong; Liu, Zhiyuan",,,ChatMol: interactive molecular discovery with natural language,BIOINFORMATICS,,,,Article,,,,,,,,"Motivation Natural language is poised to become a key medium for human-machine interactions in the era of large language models. In the field of biochemistry, tasks such as property prediction and molecule mining are critically important yet technically challenging. Bridging molecular expressions in natural language and chemical language can significantly enhance the interpretability and ease of these tasks. Moreover, it can integrate chemical knowledge from various sources, leading to a deeper understanding of molecules.Results Recognizing these advantages, we introduce the concept of conversational molecular design, a novel task that utilizes natural language to describe and edit target molecules. To better accomplish this task, we develop ChatMol, a knowledgeable and versatile generative pretrained model. This model is enhanced by incorporating experimental property information, molecular spatial knowledge, and the associations between natural and chemical languages. Several typical solutions including large language models (e.g. ChatGPT) are evaluated, proving the challenge of conversational molecular design and the effectiveness of our knowledge enhancement approach. Case observations and analysis offer insights and directions for further exploration of natural-language interaction in molecular discovery.Availability and implementation Codes and data are provided in https://github.com/Ellenzzn/ChatMol/tree/main.","[Zeng, Zheni; Yin, Bangchen; Sun, Maosong; Liu, Zhiyuan] Tsinghua Univ, Dept Comp Sci & Technol, Shuangqing Rd, Beijing 100084, Peoples R China; [Wang, Shipeng; Liu, Jiarui; Yao, Haishen; Sun, Xingzhi; Xie, Guotong] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing, Peoples R China; [Yang, Cheng] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China",,"Liu, ZY (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Shuangqing Rd, Beijing 100084, Peoples R China.;Xie, GT (corresponding author), PingAn Int Financial Ctr, PingAn Technol, Xinyuan South Rd, Beijing 100027, Peoples R China.",xieguotong@pingan.com.cn; liuzy@mail.tsinghua.edu.cn,,,,,,,,1,1,,,,,,,,,,,SEP 14,2024,40,9,,,,,,,btae534,10.1093/bioinformatics/btae534,http://dx.doi.org/10.1093/bioinformatics/btae534,,,,,,,,,,,,2025-05-29,WOS:001312055100003,View Full Record in Web of Science
J,"Wahde, M; Virgolin, M",,,,"Wahde, Mattias; Virgolin, Marco",,,DAISY: An Implementation of Five Core Principles for Transparent and Accountable Conversational AI,INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION,,,,Article,,,,,,,,"We present a detailed implementation of five core principles for transparent and acccountable conversational AI, namely interpretability, inherent capability to explain, independent data, interactive learning, and inquisitiveness. This implementation is a dialogue manager called DAISY that serves as the core part of a conversational agent. We show how DAISY-based agents are trained with human-machine interaction, a process that also involves suggestions for generalization from the agent itself. Moreover, these agents are capable to provide a concise and clear explanation of the actions required to reach a conclusion. Deep neural networks (DNNs) are currently the de facto standard in conversational AI. We therefore formulate a comparison between DAISY-based agents and two methods that use DNNs, on two popular data sets involving multi-domain task-oriented dialogue. Specifically, we provide quantitative results related to entity retrieval and qualitative results in terms of the type of errors that may occur. The results show that DAISY-based agents achieve superior precision at the price of lower recall, an outcome that might be preferable in task-oriented settings. Ultimately, and especially in view of their high degree of interpretability, DAISY-based agents are a fundamentally different alternative to the currently popular DNN-based methods.","[Wahde, Mattias; Virgolin, Marco] Chalmers Univ Technol, Dept Mech & Maritime Sci, Gothenburg, Sweden; [Virgolin, Marco] Ctr Wiskunde & Informat, Life Sci & Hlth Grp, Amsterdam, Netherlands",,"Wahde, M (corresponding author), Chalmers Univ Technol, Dept Mech & Maritime Sci, Gothenburg, Sweden.",mattias.wande@chalmers.se,,,,,,,,7,7,,,,,,,,,,,MAY 28,2023,39,9,,,SI,,1856,1873,,10.1080/10447318.2022.2081762,http://dx.doi.org/10.1080/10447318.2022.2081762,,JUN 2022,,,,,,,,,,2025-05-29,WOS:000809514400001,View Full Record in Web of Science
J,"Hossain, SKM; Ema, SA; Sohn, H",,,,"Hossain, Sayed Kaes Maruf; Ema, Sajia Afrin; Sohn, Hansuk",,,Rule-Based Classification Based on Ant Colony Optimization: A Comprehensive Review,APPLIED COMPUTATIONAL INTELLIGENCE AND SOFT COMPUTING,,,,Review,,,,,,,,"The Ant Colony Optimization (ACO) algorithms have been well-studied by the Operations Research community for solving combinatorial optimization problems. A handful of researchers in the Data Science community have successfully implemented various ACO methodologies for rule-based classification. This family of ACO algorithms is referred to as AntMiner algorithms. Due to the flexibility of the framework, and the availability of alternative strategies at the modular level, a systematic review on the AntMiner algorithms can benefit the broader community of researchers and practitioners interested in highly interpretable classification techniques. In this paper, we provided a comprehensive review of each module of the AntMiner algorithms. Our motivation is to provide insight into the current practices and future research scope in the context of the rule-based classification. Our discussions address ACO methodologies, rule construction strategies, candidate selection metrics, rule quality evaluation functions, rule pruning strategies, methods to address continuous attributes, parameter selection, and experimental settings. This review also reports a summary of real-life implementations of the rule-based classifiers in diverse domains including medical, genetics, portfolio analysis, geographic information system (GIS), human-machine interaction (HMI), autonomous driving, ICT, quality, and reliability engineering. These implementations demonstrate the potential application domains that can be benefitted from the methodological contributions to the rule-based classification technique.","[Hossain, Sayed Kaes Maruf; Ema, Sajia Afrin; Sohn, Hansuk] New Mexico State Univ, Dept Ind Engn, Las Cruces, NM 88003 USA",,"Sohn, H (corresponding author), New Mexico State Univ, Dept Ind Engn, Las Cruces, NM 88003 USA.",shossain@nmsu.edu; emasajia@nmsu.edu; hsohn@nmsu.edu,,,,,,,,9,9,,,,,,,,,,,APR 8,2022,2022,,,,,,,,2232000,10.1155/2022/2232000,http://dx.doi.org/10.1155/2022/2232000,,,,,,,,,,,,2025-05-29,WOS:000789420500001,View Full Record in Web of Science
J,"Wang, H; Yu, SH; Chen, DK; Xiao, JH",,,,"Wang, Hui; Yu, Suihuai; Chen, Dengkai; Xiao, Jianghao",,,Mission-oriented situation awareness information requirements of submariners: A goal directed task analysis,OCEAN ENGINEERING,,,,Article,,,,,,,,"As the basis for ensuring correct situation awareness (SA), the identification of SA information requirements is crucial for the safe operation of complex human -machine systems. Many studies have emphasised the importance of identifying SA information requirements; however, they have not precisely defined the information items, especially in the field of manned submersibles. This study considers the sampling task of manned submersibles as a case study and presents a modified Goal -Directed Task Analysis (GDTA) that integrates the operational process by transforming the traditional goal -decision -information interview into a goal -decision -process interview. The transcript was graphically coded and analysed using task -network modelling techniques and complex network analysis. The information processing behaviour elements and logical relationships were obtained by exploring the tacit expert knowledge hidden in the process, thus distinguishing the operation -level information requirements with causal properties based on the identification of the perception -level information. The results assigned priority differences to perception -level information in terms of goal attainment and revealed the submariners' SA information requirements during the sampling task in an interpretable manner. This study extends the applicability of GDTA and can be used to provide theoretical foundation for the systematic and structured information presentation of SA -supporting information systems in complex cockpit environments.","[Wang, Hui; Yu, Suihuai; Chen, Dengkai; Xiao, Jianghao] Northwestern Polytech Univ, Key Lab Ind Design & Ergonom, Minist Ind & Informat Technol, Xian, Peoples R China",,"Wang, H (corresponding author), Northwestern Polytech Univ, Key Lab Ind Design & Ergonom, Minist Ind & Informat Technol, Xian, Peoples R China.",wanghui0617@mail.nwpu.edu.cn,,,,,,,,0,0,,,,,,,,,,,MAY 1,2024,299,,,,,,,,117200,10.1016/j.oceaneng.2024.117200,http://dx.doi.org/10.1016/j.oceaneng.2024.117200,,MAR 2024,,,,,,,,,,2025-05-29,WOS:001201792000001,View Full Record in Web of Science
J,"Abdelkader, SM; Kinga, S; Ebinyu, E; Amissah, J; Mugerwa, G; Taha, IBM; Mansour, DEA",,,,"Abdelkader, Sobhy M.; Kinga, Sammy; Ebinyu, Emmanuel; Amissah, Jeremiah; Mugerwa, Geofrey; Taha, Ibrahim B. M.; Mansour, Diaa-Eldin A.",,,Advancements in data-driven voltage control in active distribution networks: A Comprehensive review,RESULTS IN ENGINEERING,,,,Review,,,,,,,,"Distribution systems are integrating a growing number of distributed energy resources and converter-interfaced generators to form active distribution networks (ADNs). Numerous studies have been undertaken to mitigate various challenges in ADNs. However, voltage deviation and reactive power control still requires more attention from researchers and power system engineers. The Volt/VAr control (VVC) concept has been developed to improve the voltage quality, minimize active power losses, and maintain the voltage profile in ADNs. The deployed utility-owned legacy voltage control mechanisms such as on-load tap changers, capacitor banks, and automatic voltage regulators operate in discrete, slow timescales and unidirectionally, rendering them insufficient for optimal voltage regulation in ADNs. Owing to the increasing use of smart meters, smart inverters (SIs), smart sensors, data analytics tools, and improved communication networks, data has become an important resource. Data-driven control approaches, particularly reinforcement learning (RL)-based, have therefore gained more attention in recent years in effectively solving the VVC decision-making problem. This comprehensive review presents a detailed analysis of advanced approaches used to address the VVC problem. It includes a general overview of the problem formulation, control frameworks, and basic notations, as well as detailed comparisons of the existing and recently proposed methods. This study focuses on data-driven approaches, especially RL-based algorithms. Some of the open research challenges experienced in the application of these algorithms such as safety, data, scalability, communication problems, interpretability and cybersecurity threats are presented alongside the future research perspectives such as Internet of Things (IoT), Transfer Learning (TL), hybrid and human-in-the-loop AI approaches.","[Abdelkader, Sobhy M.; Kinga, Sammy; Ebinyu, Emmanuel; Amissah, Jeremiah; Mugerwa, Geofrey; Mansour, Diaa-Eldin A.] Egypt Japan Univ Sci & Technol E JUST, Dept Elect Power Engn, Alexandria 21934, Egypt; [Abdelkader, Sobhy M.] Mansoura Univ, Fac Engn, Dept Elect Engn, Mansoura 35516, Egypt; [Taha, Ibrahim B. M.] Taif Univ, Coll Engn, Dept Elect Engn, POB 11099, Taif 21944, Saudi Arabia; [Mansour, Diaa-Eldin A.] Tanta Univ, Fac Engn, Dept Elect Power & Machines Engn, Tanta 31511, Egypt",,"Mansour, DEA (corresponding author), Egypt Japan Univ Sci & Technol E JUST, Dept Elect Power Engn, Alexandria 21934, Egypt.",mansour@f-eng.tanta.edu.eg,,,,,,,,7,7,,,,,,,,,,,SEP,2024,23,,,,,,,,102741,10.1016/j.rineng.2024.102741,http://dx.doi.org/10.1016/j.rineng.2024.102741,,AUG 2024,,,,,,,,,,2025-05-29,WOS:001301086700001,View Full Record in Web of Science
J,"Pereira, P; Moniz, H; Carvalho, JP",,,,"Pereira, Patricia; Moniz, Helena; Carvalho, Joao Paulo",,,Deep emotion recognition in textual conversations: a survey,ARTIFICIAL INTELLIGENCE REVIEW,,,,Article,,,,,,,,"Emotion Recognition in Conversations (ERC) is a key step towards successful human-machine interaction. While the field has seen tremendous advancement in the last few years, new applications and implementation scenarios present novel challenges and opportunities. These range from leveraging the conversational context, speaker, and emotion dynamics modelling, to interpreting common sense expressions, informal language, and sarcasm, addressing challenges of real-time ERC, recognizing emotion causes, different taxonomies across datasets, multilingual ERC, and interpretability. This survey starts by introducing ERC, elaborating on the challenges and opportunities of this task. It proceeds with a description of the emotion taxonomies and a variety of ERC benchmark datasets employing such taxonomies. This is followed by descriptions comparing the most prominent works in ERC with explanations of the neural architectures employed. Then, it provides advisable ERC practices towards better frameworks, elaborating on methods to deal with subjectivity in annotations and modelling and methods to deal with the typically unbalanced ERC datasets. Finally, it presents systematic review tables comparing several works regarding the methods used and their performance. Benchmarking these works highlights resorting to pre-trained Transformer Language Models to extract utterance representations, using Gated and Graph Neural Networks to model the interactions between these utterances, and leveraging Generative Large Language Models to tackle ERC within a generative framework. This survey emphasizes the advantage of leveraging techniques to address unbalanced data, the exploration of mixed emotions, and the benefits of incorporating annotation subjectivity in the learning phase.","[Pereira, Patricia; Moniz, Helena; Carvalho, Joao Paulo] INESC ID, Lisbon, Portugal; [Pereira, Patricia; Carvalho, Joao Paulo] Univ Lisbon, Inst Super Tecn, Lisbon, Portugal; [Moniz, Helena] Univ Lisbon, Fac Letras, Lisbon, Portugal",,"Pereira, P (corresponding author), INESC ID, Lisbon, Portugal.;Pereira, P (corresponding author), Univ Lisbon, Inst Super Tecn, Lisbon, Portugal.",patriciaspereira@tecnico.ulisboa.pt; helena.moniz@inesc-id.pt; joao.carvalho@inesc-id.pt,,,,,,,,3,3,,,,,,,,,,,NOV 7,2024,58,1,,,,,,,10,10.1007/s10462-024-11010-y,http://dx.doi.org/10.1007/s10462-024-11010-y,,,,,,,,,,,,2025-05-29,WOS:001351608800004,View Full Record in Web of Science
J,"Runck, BC; Manson, S; Shook, E; Gini, M; Jordan, N",,,,"Runck, Bryan C.; Manson, Steven; Shook, Eric; Gini, Maria; Jordan, Nicholas",,,Using word embeddings to generate data-driven human agent decision-making from natural language,GEOINFORMATICA,,,,Article,,,,,,,,"Generating replicable and empirically valid models of human decision-making is crucial for the scientific accuracy and reproducibility of agent-based models. A two-fold challenge in developing models of decision-making is a lack of high resolution and high quality behavioral data and the need for more transparent means of translating these data into models. A common and largely successful approach to modeling is hand-crafting agent decision heuristics from qualitative field interviews. This empirically-based, qualitative approach successfully incorporates contextual decision making, heterogeneous preferences, and decision strategies. However, it is labor intensive and often leads to models that are hard to replicate, thereby limiting the scale and scope over which such methods can be usefully applied. A potential solution to these problems is provided by new approaches in natural language processing, which can use textual sources ranging from field interview transcripts to unstructured data from the web to capture and represent human cognition. Here we use word embeddings, a vector-based representation of language, to create agents that reason using similarity comparison. This approach proves to be effective at mirroring theoretical expectations for human decision biases across a range of natural language decision-making tasks. We provide a proof-of-concept agent-based model that illustrates how the agents we create can be readily deployed to study cultural diffusion. The agent-based model replicates previously found results with the added benefit of qualitative interpretability. The agent architecture we propose is able to mirror human likelihood assessments from natural language and offers a new way to model agent cognitive processes for a broad array of agent-based modeling use cases.","[Runck, Bryan C.; Manson, Steven; Shook, Eric] Univ Minnesota Twin Cities, Dept Geog Environm & Soc, 414 Social Sci Bldg,267 19th Ave S, Minneapolis, MN 55455 USA; [Gini, Maria] Dept Comp Sci & Engn, 4-192 Keller Hall,200 Union St SE, Minneapolis, MN 55455 USA; [Jordan, Nicholas] Dept Agron & Plant Genet, 411 Borlaug Hall,1991 Upper Buford Circle, St Paul, MN 55108 USA",,"Runck, BC (corresponding author), Univ Minnesota Twin Cities, Dept Geog Environm & Soc, 414 Social Sci Bldg,267 19th Ave S, Minneapolis, MN 55455 USA.",runck014@umn.edu,,,,,,,,9,11,,,,,,,,,,,APR,2019,23,2,,,SI,,221,242,,10.1007/s10707-019-00345-2,http://dx.doi.org/10.1007/s10707-019-00345-2,,,,,,,,,,,,2025-05-29,WOS:000468331900004,View Full Record in Web of Science
J,"Van Woensel, W; Tu, SW; Michalowski, W; Abidi, SSR; Abidi, S; Alonso, JR; Bottrighi, A; Carrier, M; Edry, R; Hochberg, I; Rao, MLK; Kingwell, S; Kogan, A; Marcos, M; Salvador, BM; Michalowski, M; Piovesan, L; Rian, D; Terenziani, P; Wilk, S; Peleg, M",,,,"Van Woensel, William; Tu, Samson W.; Michalowski, Wojtek; Abidi, Syed Sibte Raza; Abidi, Samina; Alonso, Jose-Ramon; Bottrighi, Alessio; Carrier, Marc; Edry, Ruth; Hochberg, Irit; Rao, Malvika; Kingwell, Stephen; Kogan, Alexandra; Marcos, Mar; Salvador, Begona Martnez; Michalowski, Martin; Piovesan, Luca; Rian, David; Terenziani, Paolo; Wilk, Szymon; Peleg, Mor",,,A community-of-practice-based evaluation methodology for knowledge intensive computational methods and its application to multimorbidity decision support,JOURNAL OF BIOMEDICAL INFORMATICS,,,,Article,,,,,,,,"Objective: The study has dual objectives. Our first objective (1) is to develop a community-of-practice-based evaluation methodology for knowledge-intensive computational methods. We target a whitebox analysis of the computational methods to gain insight on their functional features and inner workings. In more detail, we aim to answer evaluation questions on (i) support offered by computational methods for functional features within the application domain; and (ii) in-depth characterizations of the underlying computational processes, models, data and knowledge of the computational methods. Our second objective (2) involves applying the evaluation methodology to answer questions (i) and (ii) for knowledge-intensive clinical decision support (CDS) methods, which operationalize clinical knowledge as computer interpretable guidelines (CIG); we focus on multimorbidity CIG-based clinical decision support (MGCDS) methods that target multimorbidity treatment plans. Materials and methods: Our methodology directly involves the research community of practice in (a) identifying functional features within the application domain; (b) defining exemplar case studies covering these features; and (c) solving the case studies using their developed computational methods-research groups detail their solutions and functional feature support in solution reports. Next, the study authors (d) perform a qualitative analysis of the solution reports, identifying and characterizing common themes (or dimensions) among the computational methods. This methodology is well suited to perform whitebox analysis, as it directly involves the respective developers in studying inner workings and feature support of computational methods. Moreover, the established evaluation parameters (e.g., features, case studies, themes) constitute a re-usable benchmark framework, which can be used to evaluate new computational methods as they are developed. We applied our community-of-practice-based evaluation methodology on MGCDS methods. Results: Six research groups submitted comprehensive solution reports for the exemplar case studies. Solutions for two of these case studies were reported by all groups. We identified four evaluation dimensions: detection of adverse interactions, management strategy representation, implementation paradigms, and human-in-the-loop support. Based on our whitebox analysis, we present answers to the evaluation questions (i) and (ii) for MGCDS methods.Discussion: The proposed evaluation methodology includes features of illuminative and comparison-based approaches; focusing on understanding rather than judging/scoring or identifying gaps in current methods. It involves answering evaluation questions with direct involvement of the research community of practice, who participate in setting up evaluation parameters and solving exemplar case studies. Our methodology was successfully applied to evaluate six MGCDS knowledge-intensive computational methods. We established that, while the evaluated methods provide a multifaceted set of solutions with different benefits and drawbacks, no single MGCDS method currently provides a comprehensive solution for MGCDS.Conclusion: We posit that our evaluation methodology, applied here to gain new insights into MGCDS, can be used to assess other types of knowledge-intensive computational methods and answer other types of evaluation questions. Our case studies can be accessed at our GitHub repository (https://github.com/william-vw/MGCDS).","[Van Woensel, William; Michalowski, Wojtek; Rao, Malvika] Univ Ottawa, Telfer Sch Management, Ottawa, ON, Canada; [Tu, Samson W.] Stanford Univ, Ctr Biomed Informat Res, Stanford, CA 94305 USA; [Abidi, Syed Sibte Raza; Abidi, Samina] Dalhousie Univ, Fac Comp Sci, Halifax, NS, Canada; [Alonso, Jose-Ramon] Hosp Clin Barcelona, Barcelona, Spain; [Bottrighi, Alessio; Piovesan, Luca; Terenziani, Paolo] Univ Piemonte Orientale, DISIT, Alessandria, Italy; [Carrier, Marc; Kingwell, Stephen] Ottawa Hosp, Ottawa, ON, Canada; [Edry, Ruth; Hochberg, Irit] Technion Israel Inst Technol, Bruce Rappaport Fac Med, Hefa, Israel; [Edry, Ruth; Hochberg, Irit] Rambam Med Ctr, Hefa, Israel; [Kogan, Alexandra; Peleg, Mor] Univ Haifa, Dept Informat Syst, IL-3498838 Hefa, Israel; [Marcos, Mar; Salvador, Begona Martnez] Univ Jaume 1, Castellon de la Plana, Spain; [Michalowski, Martin] Univ Minnesota, Sch Nursing, Minneapolis, MN USA; [Rian, David] Univ Rovira i Virgili, Tarragona, Spain; [Rian, David] Inst Invest Sanitaria Pere Virgili, Tarragona, Spain; [Wilk, Szymon] Poznan Univ Tech, Inst Comp Sci, Poznan, Poland; [Van Woensel, William] 55 Laurier E DMS 6155, Ottawa, ON K1N 6N5, Canada",,"Van Woensel, W (corresponding author), 55 Laurier E DMS 6155, Ottawa, ON K1N 6N5, Canada.",wvanwoen@uottawa.ca,,,,,,,,7,7,,,,,,,,,,,JUN,2023,142,,,,,,,,104395,10.1016/j.jbi.2023.104395,http://dx.doi.org/10.1016/j.jbi.2023.104395,,MAY 2023,,,,,,,,,,2025-05-29,WOS:001013113200001,View Full Record in Web of Science
J,"Bryce, D; Goldman, RP; DeHaven, M; Beal, J; Bartley, B; Nguyen, TT; Walczak, N; Weston, M; Zheng, G; Nowak, J; Lee, P; Stubbs, J; Gaffney, N; Vaughn, MW; Myers, CJ; Moseley, RC; Haase, S; Deckard, A; Cummins, B; Leiby, N",,,,"Bryce, Daniel; Goldman, Robert P.; DeHaven, Matthew; Beal, Jacob; Bartley, Bryan; Nguyen, Tramy T.; Walczak, Nicholas; Weston, Mark; Zheng, George; Nowak, Josh; Lee, Peter; Stubbs, Joe; Gaffney, Niall; Vaughn, Matthew W.; Myers, Chris John; Moseley, Robert C.; Haase, Steven; Deckard, Anastasia; Cummins, Bree; Leiby, Nick",,,"Round Trip: An Automated Pipeline for Experimental Design, Execution, and Analysis",ACS SYNTHETIC BIOLOGY,,,,Article,,,,,,,,"Synthetic biology is a complex discipline that involves creating detailed, purpose-built designs from genetic parts. This process is often phrased as a Design-Build-Test-Learn loop, where iterative design improvements can be made, implemented, measured, and analyzed. Automation can potentially improve both the end-to-end duration of the process and the utility of data produced by the process. One of the most important considerations for the development of effective automation and quality data is a rigorous description of implicit knowledge encoded as a formal knowledge representation. The development of knowledge representation for the process poses a number of challenges, including developing effective human-machine interfaces, protecting against and repairing user error, providing flexibility for terminological mismatches, and supporting extensibility to new experimental types. We address these challenges with the DARPA SD2 Round Trip software architecture. The Round Trip is an open architecture that automates many of the key steps in the Test and Learn phases of a Design-Build-Test-Learn loop for highthroughput laboratory science. The primary contribution of the Round Trip is to assist with and otherwise automate metadata creation, curation, standardization, and linkage with experimental data. The Round Trip's focus on metadata supports fast, automated, and replicable analysis of experiments as well as experimental situational awareness and experimental interpretability. We highlight the major software components and data representations that enable the Round Trip to speed up the design and analysis of experiments by 2 orders of magnitude over prior ad hoc methods. These contributions support a number of experimental protocols and experimental types, demonstrating the Round Trip's breadth and extensibility. We describe both an illustrative use case using the Round Trip for an on-the-loop experimental campaign and overall contributions to reducing experimental analysis time and increasing data product volume in the SD2 program.","[Bryce, Daniel; Goldman, Robert P.; DeHaven, Matthew] SIFT LLC, Minneapolis, MN 55401 USA; [Beal, Jacob; Bartley, Bryan; Nguyen, Tramy T.; Walczak, Nicholas] Raytheon BBN Technol, Cambridge, MA 02138 USA; [Weston, Mark; Zheng, George] Netrias Inc, Annapolis, MD 21409 USA; [Nowak, Josh] Strateos Inc, Menlo Pk, CA 94025 USA; [Lee, Peter] Ginkgo Bioworks Inc, Boston, MA 02210 USA; [Stubbs, Joe; Gaffney, Niall; Vaughn, Matthew W.] Texas Adv Comp Ctr, Austin, TX 78758 USA; [Myers, Chris John] Colorado Univ, Boulder, CO 80203 USA; [Moseley, Robert C.; Haase, Steven] Duke Univ, Durham, NC 27708 USA; [Deckard, Anastasia] Geometr Data Analyt Inc, Durham, NC 27701 USA; [Cummins, Bree] Montana State Univ, Bozeman, MT 59717 USA; [Leiby, Nick] Two Six Technol Inc, Arlington, VA 22203 USA",,"Bryce, D (corresponding author), SIFT LLC, Minneapolis, MN 55401 USA.",dbryce@sift.net,,,,,,,,5,5,,,,,,,,,,,FEB 18,2022,11,2,,,,,608,622,,10.1021/acssynbio.1c00305,http://dx.doi.org/10.1021/acssynbio.1c00305,,,,,,,,,,,,2025-05-29,WOS:000758255800011,View Full Record in Web of Science