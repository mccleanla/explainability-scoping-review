draws from  research question, eligibility criteria, and  the terminology used in the seed papers. [[_Bibliography before scoping review|_Bibliography before scoping review]]

| search terms                                                                                                                                                                                                                                                                                                                                                                                                   | why                                                                                                                                                                                                                                                              |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| "explainable AI" OR "explainable agent" OR "explainability" OR "explainable artificial intelligence" OR "explanation interface" OR "explanation need" OR "explanation mechanism" OR "explanation requirement" OR "operational explanation" OR "AI explanation" OR "human-centred XAI" OR HCXAI OR "AI transparency" OR "transparency in AI" OR "algorithmic transparency" OR "system transparency" OR "legib*" | to focus the search on human-centred explanation.  Synonym choice to expand range of results                                                                                                                                                                     |
| "real world" OR "real-world" OR "stakeholders" OR "industry" OR "in-the-wild" OR deploy* OR "field study" OR "control room" OR operational* OR integrat* or "work system" OR "socio-technical" OR "sociotechnical" OR "time-sensitive" OR "time pressure" OR "safety-critical" OR "safety critical" OR "high stakes" OR "high-stakes"                                                                          | first filter focuses on reducing scope to real-world studies that are in high-stakes or time pressured situations. Across domains" means we should be cautious about overly specific domain terms unless used as examples or to broaden, not restrict too early. |
| "human-AI" OR "human-XAI" OR "HAI" OR "hybrid intelligence" OR "human-machine" OR supervisor* OR "human-autonomy" OR "human-agent" OR "AI-assisted" OR "human-in-the-loop" OR "algorithmic decision*" OR "AI-augmented"                                                                                                                                                                                        | second filter ensures there is human-ai interaction discussed, to ensure the purpose of in-situ explanation within an operational context is the focus                                                                                                           |
| NOT ("technique" OR "post-hoc")                                                                                                                                                                                                                                                                                                                                                                                | to avoid technical papers focused on post-hoc explainabiltiy techniques                                                                                                                                                                                          |


**Pillar 1: The "Explanation" concept*

Drawn from Miller (2019), Ehsan et al. (2022, 2024), Vered et al. (2023), and Liao et al. (2021, 2024):
- "explainable AI", "explainable agent" and "interpretable AI" are standard.  "explanation interface*" and "AI explanation*" reflect focus on the interactional layer (Venditti et al. 2025, Liao 2024). 
	- To capture "-ity" I have used wildcards and dropped the "AI". I have widened explanation synonyms, however noise may be a problem:
		- pilot searches suggest this still focuses on the AI aspects without too much noise.
		- **return to fuller set of terms, or only search in abstract.**
		- **or use a NEAR search, if available.**
- "AI transparency" captures regulatory and socio-technical framings. "algorithmic transparency" and "system transparency" connects to broader governance literature.  I have retained "AI" for this example with a synonym

**Pillar 2: operational/contextual deployment (environment/purpose)

Bach et al. (2023), Payrovnaziri et al. (2020), Sujan et al. (2022):
- "real-world", "industry" and "operational" highlight in-situ deployment and use.
- "Safety-critical", "High stakes", "fast-paced decision making", 


**Pillar 3: human-centred / interaction framing (the where/who)

Core to Ehsan et al. (2023), Liao & Wortman Vaughan (2024), Dhanorkar et al. (2021), Hoffman et al. (2023):
- "human-centered" and "socio-technical" capture the framing of explanation as embedded in context.  I want to capture literature that frames AI systems as embedded in systems of human practice, organisation, and context.
- "human-ai" variants captured (eg teaming, collaboration, interaction etc) by going shorter
- "mental models", "situational awareness", "cognitive load" and "actionability" tie into ergonomics (Sujan et al. 2022).
  





